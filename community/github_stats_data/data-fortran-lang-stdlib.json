{
    "name": "fortran-lang/stdlib",
    "issues": [
        {
            "number": 239,
            "user": "wclodius2",
            "date": "2020-09-30 02:05:04+00:00",
            "title": "Bitsets3",
            "text": "Branch to implement bitset data types. Committed the following new source files:\nsrc/stdlib_bitsets.f90\nsrc/stdlib_bitset_64.f90\nsrc/stdlib_bitset_large.f90\nAdded the following new test files:\nsrc/tests/bitsets/CMakeLists.txt\nsrc/tests/bitsets/Makefile.manual\nsrc/tests/bitsets/test_stdlib_bitset_64.f90\nsrc/tests/bitsets/test_stdlib_bitset_large.f90\nAdded the following new documentation file:\ndoc/specs/stdlib_bitssets.md\nModified the following compilation files:\nsrc/CMakeLists.txt\nsrc/Makefile.manual\nsrc/tests/CMakeLists.txt\nsrc/tests/Makefile.manual",
            "comments": []
        },
        {
            "number": 238,
            "user": "jvdp1",
            "date": "2020-09-29 18:22:19+00:00",
            "title": "Explicit conversion",
            "text": "Addition of some explicit conversions as discussed in the thread starting with this comment.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-09-29 19:13:11+00:00",
                    "text": "Thank you for both approvals. I will merge it."
                }
            ]
        },
        {
            "number": 237,
            "user": "wclodius2",
            "date": "2020-09-29 00:36:29+00:00",
            "title": "PR run failed: Build and Deploy Documents",
            "text": "This morning I submitted a PR that failed, because I failed to properly update a CMakeLists.txt file and because my main testing processor, gfortran 10.2 on MacOS, was too forgiving in accepting F2018 semantics, and in initializing uninitialized attributes to zero. After testing with ifort 18.03 I was able to fix the obvious problems with my code, but then I got an email message with the header\n[fortran-lang/stdlib] PR run failed: Build and Deploy Documents - Bitsets (3f6f77b)\nand the body\nRun failed for bitsets (3f6f77b)\nRepository: fortran-lang/stdlib\nWorkflow: Build and Deploy Documents\nDuration: 7.0 seconds\nFinished: 2020-09-28 21:42:02 UTC\nView results\nJobs:\nBuild-API-Docs failed (1 annotation)\n\u2014\nYou are receiving this because this workflow ran on your branch.\nManage your GitHub Actions notifications here.\nWhen I view results I get the link\nhttps://github.com/fortran-lang/stdlib/actions/runs/277439934\nWhich tells me that the error occurred during the Build-API-Docs and it is an internal error. I suspect that it is either a problem with my markdown document, doc/specs/stdlib_bitsets.md, or with FORD attempting to process src/stdlib_bitsets.f90, src/stdlib_bitset_64.f90,or src/stdlib_bitset_large.f90. In either case I don't know how to fix the problem.  Any suggestions? Is it possible to kill a PR, and if so how?",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-09-29 16:42:44+00:00",
                    "text": "You can close any PR by simply clicking on the \"Close\" button. You can reopen a new PR with a new branch, or even the same branch."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-29 18:49:30+00:00",
                    "text": "As mentioned in this comment, I copied your branch in my repo, and all actions passed.\nIMO, the best thing to do is to close #236 and open a new and clean PR, as explained in this comment"
                }
            ]
        },
        {
            "number": 236,
            "user": "wclodius2",
            "date": "2020-09-28 14:09:15+00:00",
            "title": "Bitsets",
            "text": "This branch is intended to provide implementations of bitsets. It defines a parent abstract type bitset_type, and two descendants: bitset_64 for bitsets up to 64 bits in size; and bitset_large, for larger bitsets. The main code is implemented in the module file src/stdlib_bitsets.f90 and its submodule files src/stdlib_bitset_64.f90 and src/stdlib_bitset_large.f90. There are also the test codes src/tests/bistsets/test_stdlib_bitset_64.f90 and src/tests/bistsets/test_stdlib_bitset_large.f90 and a markdown document doc/specs/stdlib_bitsets.md. Various other CMakeLists.txt and Makefile.manual files have been modified so that the code should be compilable with cmake ./ or make -f Makefile.manual.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-09-29 18:44:15+00:00",
                    "text": "@wclodius2\nSince the PR on the logger is merged, could you re-open a new PR without all the commits related to the logger? This would help the review.\nA solution to do that is to:\n\nCreate a new branch from your master (e.g., wclodius2:bitsets2)\nSync this new branch with fortran-lang/stdlib master\nMerge your current branch wclodius:bitsets with the new branch wclodius:bitsets2\nClose the PR related to bitsets and open a new PR from bitsets2. Only the commits from this commit should then appear in the PR.\n\nEDIT: I copied your branch in my repo, and all actions passed!"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-29 21:31:58+00:00",
                    "text": "@jvdp1 How do I sync a branch with the master? I am not seeing any obvious way to do this on https://github.com/wclodius2/stdlib/tree/bitsets2/src."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-09-29 21:38:16+00:00",
                    "text": "In your case I would recommend the following:\ngit checkout master\ngit pull upstream master # or whatever name you've given the remote for the fortran-lang repo\ngit checkout bitsets2\ngit merge master\n\nThis makes sure you're master branch is up to date with the fortran-lang master branch, and then does a merge commit, bringing any recent changes into your branch. Let me know if you need any additional details."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-30 02:19:32+00:00",
                    "text": "I have created a PR for a branch called bitsets3. The PR had one one that failed on ubuntu, out of six attempts, three on ubuntu and three on macOS.."
                }
            ]
        },
        {
            "number": 235,
            "user": "arjenmarkus",
            "date": "2020-09-24 19:27:25+00:00",
            "title": "Update ascii - second round: clean up the code and implement robust versions of to_lower and to_upper",
            "text": "The comments to the previous pull request are now all solved:\n\n\nExtra parentheses have been removed (for readability those around the logical disjunctions and conjunctions have been kept)\n\n\nSome clean-up of the comments (more explicitly stating the ranges)\n\n\nThe functions to_lower and to_upper have been made robust (perhaps slower than before, but the performance is certainly not bad)\n\n\nSuggestion for further improvement: allow to_lower and to_upper to convert strings of arbitrary length - this seems to me to be the most common usage.",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2020-09-25 20:02:08+00:00",
                    "text": "Suggestion for further improvement: allow to_lower and to_upper to convert strings of arbitrary length - this seems to me to be the most common usage.\n\nThis has been requested as part of the strings module. I have wondered already if it would be easier to just have a single function with the interface:\npure function upper(str) result(ustr)\ncharacter(len=*), intent(in) :: str\ncharacter(len=len(str)) :: ustr\nend function\nand get rid of the single character case conversions entirely. As you say, the most common usage will be arbitrary length strings, so I am not sure if we need a specialization for single letters. The arbitrary length version can be used on single characters too (hopefully the compilers are capable enough to remove the loop for characters with len=1).\nThe reason I included the case conversions in the first plase was just to cover the same functionality as the <ctype.h> header file from C."
                }
            ]
        },
        {
            "number": 234,
            "user": "Jim-215-Fisher",
            "date": "2020-09-21 16:17:19+00:00",
            "title": "Proposal for statistical distributions",
            "text": "Besides common descriptive statistics, we need standard modules for various continuous statistical distribution (e.g.,  gamma distribution) and discrete distribution (e.g., bernoulli distribution). These statistical distributions will be very useful to various computer simulation techniques.\nEven though these functions are available in Scipy package for python, I think it is worthwhile to have in stdlib with pure Fortran. There are plenty of source codes on the net, we just need to convert them.",
            "comments": [
                {
                    "user": "epagone",
                    "date": "2020-09-21 18:02:22+00:00",
                    "text": "Prior art.\n\nGSL has a comprehensive section of random number distributions that should be available in Fortran though the fgsl module. This should be stable and well maintained.\nRichard Chandler and Paul Northrop from UCL have developed a nice library in ancient FORTRAN77. Latest update has been in 2003. License is very \"liberal\" (they only ask to be cited) but the interface is not simple. Documentation is minimal but seems sufficient. No examples or tutorials are provided.\nA library for normal distributions only, one more generic with a large number of distributions and another one focussed on cumulative density function are provided on Jacob Burkardt site. This is Fortran 90 compliant code. The license is GNU LGPL and documentation is adequate with examples.\nThis post in a blog is the translation in Modern Fortran of a public domain, simple, Julia library about different distributions. It's simple but documentation is almost non-existent.\nThe site of Jean-Pierre Moreau has a number of files available (apparently in a somewhat modern Fortran). However, some files appear to be taken from the book \"Numerical Recipes\" (which has a peculiar license) and it is not clear if the distributions are included."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-21 19:26:46+00:00",
                    "text": "I agree with @Jim-215-Fisher 's comment. Thank you for the suggestion.\nTo add to the prior art mentioned by @epagone:\n\nRANLIB: Fortran90 (license: LGPL) (and its F77 version). I believe this library is also used in Octave."
                },
                {
                    "user": "Jim-215-Fisher",
                    "date": "2020-09-21 23:00:44+00:00",
                    "text": "Should stdlib be based on GSL through fgsl?"
                },
                {
                    "user": "certik",
                    "date": "2020-09-22 02:17:21+00:00",
                    "text": "@Jim-215-Fisher Unfortunately GSL is GPL licensed, which prohibits its inclusion into stdlib which is MIT licensed."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-09-22 10:59:10+00:00",
                    "text": "Don't forget the Software from Alan J. Miller: https://wp.csiro.au/alanmiller/random.html\n(a mirror exists at https://jblevins.org/mirror/amiller/)"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-22 11:03:43+00:00",
                    "text": "i agree with that: it is an extensive collection provided by a well-known\nprofessional in the field. It may require some reorganisation, as it is not\norganised in modules and the like, but it is certainly worth our while.\n\nOp di 22 sep. 2020 om 12:59 schreef Ivan <notifications@github.com>:\n\u2026\n Don't forget the Software from Alan J. Miller:\n https://wp.csiro.au/alanmiller/random.html\n (a mirror exists at https://jblevins.org/mirror/amiller/)\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#234 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YRZSJTTC675SELMLNWLSHB7Q3ANCNFSM4RUXIQFQ>\n ."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-22 11:06:45+00:00",
                    "text": "i agree with that: it is an extensive collection provided by a well-known professional in the field. It may require some reorganisation, as it is not organised in modules and the like, but it is certainly worth our while. Op di 22 sep. 2020 om 12:59 schreef Ivan notifications@github.com:\n\u2026\nDon't forget the Software from Alan J. Miller: https://wp.csiro.au/alanmiller/random.html (a mirror exists at https://jblevins.org/mirror/amiller/) \u2014 You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub <#234 (comment)>, or unsubscribe https://github.com/notifications/unsubscribe-auth/AAN6YRZSJTTC675SELMLNWLSHB7Q3ANCNFSM4RUXIQFQ .\n\nIndeed, I agree. However, it is unclear to me what the license is for these files."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-22 11:12:19+00:00",
                    "text": "It says that the code written by Alan Miller is in the public domain, I\nwill ask Jason what this means exactly.\n\nOp di 22 sep. 2020 om 13:07 schreef Jeremie Vandenplas <\nnotifications@github.com>:\n\u2026\n i agree with that: it is an extensive collection provided by a well-known\n professional in the field. It may require some reorganisation, as it is not\n organised in modules and the like, but it is certainly worth our while. Op\n di 22 sep. 2020 om 12:59 schreef Ivan ***@***.***:\n \u2026 <#m_-2168024105408715737_>\n Don't forget the Software from Alan J. Miller:\n https://wp.csiro.au/alanmiller/random.html (a mirror exists at\n https://jblevins.org/mirror/amiller/) \u2014 You are receiving this because\n you are subscribed to this thread. Reply to this email directly, view it on\n GitHub <#234 (comment)\n <#234 (comment)>>,\n or unsubscribe\n https://github.com/notifications/unsubscribe-auth/AAN6YRZSJTTC675SELMLNWLSHB7Q3ANCNFSM4RUXIQFQ\n .\n\n Indeed, I agree. However, it is unclear to me what the license is for\n these files.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#234 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR2XPP2KHV2B46IZE3LSHCANJANCNFSM4RUXIQFQ>\n ."
                },
                {
                    "user": "Jim-215-Fisher",
                    "date": "2020-09-22 17:41:35+00:00",
                    "text": "If it is public domain, then there is no copyrights."
                },
                {
                    "user": "Jim-215-Fisher",
                    "date": "2020-09-22 22:56:38+00:00",
                    "text": "In terms of license, as long as there are mathematic formulae, I think license issue should not be a concern.\nBased on comments so far, it looks like majority agreed to have statistical distributions in stdlib. So the next question is what kind of API should be. We can either define a data type for each distribution and various type-bound procedures, or define various procedures for each type of distribution directly in the stdlib module. For example, normal distribution one could have:\nmodule stdlib\ntype :: norm_dist_t\nreal :: x\nreal :: loc\nreal :: scale\ncontains\ngeneric :: pdf => norm_dist_pdf\ngeneric :: cdf => norm_dist_cdf\n.\n.\n.\nend type norm_dist_t\ncontains\n{procedure definition}\n.\n.\n.\nend module stdlib\nor directly in stdlib module:\nmodule stdlib\nfunction norm_dist_pdf(x, loc, scale)\nend function norm_dist_pdf\n.\n.\n.\nend module stdlib\nThe first one is object oriented, data and procedure are encapsulated. The second one is more traditional like intrinsic function call familiar to users. Which one is better?"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-23 08:57:46+00:00",
                    "text": "In these matters it is not likely that there is a \"best\" solution. It is a\nmatter of taste, I would say. But I am leaning towards a procedural style\nin this. Typical use of this functionality:\n\n   - I have a time series and I want to see if it can be fitted to a normal\n   or log-normal distribution. In that case, I would pass the time series to\n   some function that uses a relevant statistical test (say Lillifors) to\n   determine whether the fit is good enough. Rather than setting up an object\n   that takes the confidence level and perhaps a few other data, why not use a\n   simple function?\n   - I have determined the mean and standard deviation of my data set and\n   new data come in. Do they follow the same distribution? Again a function\n   seems more appropriate.\n\nI do see the attractiveness of an object-oriented interface, especially if\nyou want to examine several different data sets against the same\ndistribution, but it feels indirect in many cases. So I would prefer a\nfunctional/procedural interface, at least for the moment. An OO interface\ncan be added later.\n\nOp wo 23 sep. 2020 om 00:56 schreef Jing <notifications@github.com>:\n\u2026\n In terms of license, as long as there are mathematic formulae, I think\n license issue should not be a concern.\n\n Based on comments so far, it looks like majority agreed to have\n statistical distributions in stdlib. So the next question is what kind of\n API should be. We can either define a data type for each distribution and\n various type-bound procedures, or define various procedures for each type\n of distribution directly in the stdlib module. For example, normal\n distribution one could have:\n\n module stdlib\n type :: norm_dist_t\n real :: x\n real :: loc\n real :: scale\n\n contains\n generic :: pdf => norm_dist_pdf\n generic :: cdf => norm_dist_cdf\n .\n .\n .\n end type norm_dist_t\n\n contains\n {procedure definition}\n .\n .\n .\n end module stdlib\n\n or directly in stdlib module:\n\n module stdlib\n function norm_dist_pdf(x, loc, scale)\n end function norm_dist_pdf\n .\n .\n .\n end module stdlib\n\n The first one is object oriented, data and procedure are encapsulated. The\n second one is more traditional like intrinsic function call familiar to\n users. Which one is better?\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#234 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR74DUUVPIAE2UBA4WDSHETTHANCNFSM4RUXIQFQ>\n ."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-23 18:56:06+00:00",
                    "text": "My preference is a procedural style.\nThis choice \"procedural\" vs \"OOP\" style has been already discussed in previous issues (I can't find them back), and, if I remember wel, procedural style should be prefered over OOP. Of course similar functionality in a OOP style could be always proposed on top of the procedural ones."
                },
                {
                    "user": "Jim-215-Fisher",
                    "date": "2020-09-23 22:23:01+00:00",
                    "text": "Yeh, I have checked the style guide and can't find any recommendation. Anyway, procedure style is the Fortran way. I will go ahead to implement a small module."
                },
                {
                    "user": "certik",
                    "date": "2020-09-23 23:12:40+00:00",
                    "text": "@Jim-215-Fisher we should put it into the style guide, great idea. Here are some links where it was discussed in the past:\n\n#220 (comment)\n#14 (comment)\n#229 (comment)\n#135 (comment)"
                },
                {
                    "user": "Jim-215-Fisher",
                    "date": "2020-09-24 01:19:35+00:00",
                    "text": "@certik  Thanks for the links. BTW, is there a table/list/link showing status of each stdlib module/proposal?"
                },
                {
                    "user": "certik",
                    "date": "2020-09-24 03:42:31+00:00",
                    "text": "The latest status is in the open issue and PR for a given proposal. We don't have a nice table summarizing it.\n\u2026\nOn Wed, Sep 23, 2020, at 7:19 PM, Jing wrote:\n\n\n @certik <https://github.com/certik> Thanks for the links. BTW, is there\n a table/list/link showing status of each stdlib module/proposal?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#234 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWGOUJQG5L5OALIM5ITSHKNDHANCNFSM4RUXIQFQ>."
                },
                {
                    "user": "jrblevin",
                    "date": "2020-09-25 14:08:45+00:00",
                    "text": "It says that the code written by Alan Miller is in the public domain, I will ask Jason what this means exactly.\n\nArjen, thanks for writing to ask about the licensing. When I took over hosting Alan Miller's files no license was stated. So I asked him about that and he told me he intended his code to be public domain. So, his work can be incorporated into libraries, such as this one, with other licenses."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-25 14:17:23+00:00",
                    "text": "Hi Jason,\n\ngreat, this work deserves widespread use. And having it available via the\nFortran Wiki and hopefully at some point via the standard library (or\nsomething similar) will make it much easier.\n\nOp vr 25 sep. 2020 om 16:09 schreef Jason Blevins <notifications@github.com\n\u2026\n:\n It says that the code written by Alan Miller is in the public domain, I\n will ask Jason what this means exactly.\n\n Arjen, thanks for writing to ask about the licensing. When I took over\n hosting Alan Miller's files no license was stated. So I asked him about\n that and he told me he intended his code to be public domain. So, his work\n can be incorporated into libraries, such as this one, with other licenses.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#234 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR5H3ALI5OV5IHOSLOLSHSP73ANCNFSM4RUXIQFQ>\n ."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-25 16:42:47+00:00",
                    "text": "Thank oyu @jrblevin and @arjenmarkus for these explanations. These codes would be a good start for this proposal IMO."
                },
                {
                    "user": "Jim-215-Fisher",
                    "date": "2020-09-27 00:22:09+00:00",
                    "text": "In terms of Alan Miller's code, should we use his code/module directly, or reorganize it according to current style?"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-27 10:43:38+00:00",
                    "text": "I would say we need to reorganize it - make sure things are consistent\nwithin the standard library. That will help people to understand how to use\nit and to avoid certain types of mistakes.\n\nOp zo 27 sep. 2020 om 02:22 schreef Jing <notifications@github.com>:\n\u2026\n In terms of Alan Miller's code, should we use his code/module directly, or\n reorganize it according to current style?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#234 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR3AE3OZ7AA3OV5VG3LSH2ATZANCNFSM4RUXIQFQ>\n ."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-28 06:40:58+00:00",
                    "text": "I agree with @arjenmarkus . We will need to re-organize the code (and probably re-write some parts) to be consistent with stdlib style guide. It is anyway a great start.\nIt seems that the people involved in this thread would agree to use Alan Miller 's code as a starting point, and that a procedural approach should be used (in agreement with several other discussions).\nIf I may propose, @Jim-215-Fisher would you be interested to start a proposal for API?"
                },
                {
                    "user": "Jim-215-Fisher",
                    "date": "2020-09-28 13:04:29+00:00",
                    "text": "Yes, I am working on it, hopefully send PR soon."
                }
            ]
        },
        {
            "number": 233,
            "user": "arjenmarkus",
            "date": "2020-09-16 15:48:13+00:00",
            "title": "Update ascii",
            "text": "The changes I made allow the code to work properly on a system that uses a different encoding than ASCII, for isntance systems that use EBCDIC.\nNote: the conversion to lower case and upper case should be regarded with care! I am uncertain that they would work as intended.",
            "comments": [
                {
                    "user": "14NGiestas",
                    "date": "2020-09-16 16:13:06+00:00",
                    "text": "The to_lower and to_upper functions assumes that the input char. is in ASCII. The EBCDIC support is trickier, since it's not compatible with ASCII table conversions.\nEDIT: I just realized... the whole module is called stdlib_ascii it would be weird to assume or support other tables\nEDIT2: It seems in the current code, both functions will work with EBCDIC chars reference here"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-17 06:15:52+00:00",
                    "text": "I can think of a number of solutions:\n\n   - The lazy one: forget that there are other encodings than ASCII because\n   they are too rare to be of practical interest\n   - Look up the character in an alphabet string (k = index( 'ABCDE..', c);\n   to_lower = lowercase(k:k)).\n   - Use a look-up table, constructed at run time (the first invocation)\n   - Use a static look-up table, constructed at build time\n\nI started this, of course, because I think that the library should be as\ngeneral as practically possible, therefore that we should care about\nnon-ASCII encodings - to avoid puzzling or even nasty surprises. Which, in\nmy opinion, rules out possibility 1 ;).\nPossibility 2 is the easiest to implement, but might be \"slow\" due to the\nsearching in a string.\nPossibility 3 requires care with multithreaded environments, as the\ninitialisation works with static data.\nPossibility 4 requires support from the build environment - I imagine a\nsmall, separate, Fortran program that writes the ables in an include file.\nCMake is perfectly capable of arranging that sort of thing.\n\nRegards,\n\nArjen\n\nOp wo 16 sep. 2020 om 18:13 schreef Ian Giestas Pauli <\nnotifications@github.com>:\n\u2026\n The to_lower and to_upper functions assumes that the input char. is in\n ASCII. The EBCDIC <https://en.wikipedia.org/wiki/EBCDIC> conversion is\n trickier and not compatible with ASCII table\n <https://en.wikipedia.org/wiki/EBCDIC#Compatibility_with_ASCII>.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#233 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR7F5RUTWL6YUEWCU4DSGDP2FANCNFSM4RPBDAVA>\n ."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-09-17 10:43:07+00:00",
                    "text": "Thank you @arjenmarkus for fixing this.\nI was aware of these issues since posting about the character validation functions at the Fortran Discourse (see https://fortran-lang.discourse.group/t/character-validation-functions/131) but hadn't taken the time to fix them. In fact at some point I would like to see all of these routines replaced by static lookup tables (https://github.com/ivan-pi/fortran-ascii/blob/master/fortran_ascii_bit.f90), as this solution appears to be the most performant one.\nFor the functions to_upper and to_lower, I've seen a dozen of different possibilities on comp.lang.fortran. The solution I used here was adapted from @certik's library: https://github.com/certik/fortran-utils/blob/master/src/utils.f90#L18\nAre you worried about non-ascii characters or other encodings?\n+1 to merge"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-18 06:36:07+00:00",
                    "text": "Personally, I do not like to add extra parentheses around such expressions,\nI just left them when I found them. While I think it is a matter of style,\nI would indeed opt for removing the superfluous ones, unless they increase\nreadability, such as when you have .and. and .or. combined.\n\nI am all for explicit comments like the proposed one to explain the use of\n~.\n\nI will make these changes.\n\nOp vr 18 sep. 2020 om 01:50 schreef Ian Giestas Pauli <\nnotifications@github.com>:\n\u2026\n ***@***.***NGiestas* commented on this pull request.\n ------------------------------\n\n In src/stdlib_ascii.f90\n <#233 (comment)>:\n\n >      end function\n\n\n\n      !> Checks whether `c` is a lowercase ASCII letter (a .. z).\n\n      pure logical function is_lower(c)\n\n          character(len=1), intent(in) :: c !! The character to test.\n\n -        is_lower = (c >= 'a') .and. (c <= 'z')\n\n +        integer :: ic\n\n +        ic = iachar(c)\n\n +        is_lower = (ic >= iachar('a')) .and. (ic <= iachar('z'))\n\n\n Is this parenthesis really needed here?\n \u2b07\ufe0f Suggested change\n\n -        is_lower = (ic >= iachar('a')) .and. (ic <= iachar('z'))\n\n +        is_lower = ic >= iachar('a') .and. ic <= iachar('z')\n\n\n ------------------------------\n\n In src/stdlib_ascii.f90\n <#233 (comment)>:\n\n > @@ -145,13 +145,15 @@ pure logical function is_printable(c)\n\n          character(len=1), intent(in) :: c !! The character to test.\n\n          integer :: ic\n\n          ic = iachar(c)                    ! '~'\n\n\n z'7E' = '~'\n I suggest either adding some spaces so the character is aligned again\n (or removing it and adding a explicit comment in a new line showing how we\n are checking it)\n \u2b07\ufe0f Suggested change\n\n -        ic = iachar(c)                    ! '~'\n\n +        ic = iachar(c)\n\n +        !The character is printable if it's between ' ' and '~' in the ASCII table\n\n\n What do you think?\n ------------------------------\n\n In src/stdlib_ascii.f90\n <#233 (comment)>:\n\n >      end function\n\n\n\n      !> Checks whether `c` is a lowercase ASCII letter (a .. z).\n\n      pure logical function is_lower(c)\n\n          character(len=1), intent(in) :: c !! The character to test.\n\n -        is_lower = (c >= 'a') .and. (c <= 'z')\n\n +        integer :: ic\n\n +        ic = iachar(c)\n\n +        is_lower = (ic >= iachar('a')) .and. (ic <= iachar('z'))\n\n\n I noticed the entire code has those extra parenthesis except the change\n above so... I think we should either remove all of them or add some extra\n parenthesis in the function is_printable above so it matches the style of\n the other ones.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#233 (review)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR2H274ZGQKU3MU4KMTSGKOFPANCNFSM4RPBDAVA>\n ."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-18 07:57:58+00:00",
                    "text": "Well, I was curious about the performance, so I wrote a small program to\ntest it. I had to use a size of 100 million characters to see any\nsignificant CPU time and both implementations give roughly the same CPU\ntime - order 0.06 seconds. The differences - if different values are\nreported - are not consistent: either of the implementations may appear as\nfastest. Of course, performance tests are very difficult to get right, but\nI do think this indicates that performance is not an issue.\n\nSo, a simple robust and general implementation should be enough, certainly\nfor a first version.\n\nOp do 17 sep. 2020 om 12:43 schreef Ivan <notifications@github.com>:\n Thank you @arjenmarkus <https://github.com/arjenmarkus> for fixing this.\n\n I was aware of these issues since posting about the character validation\n functions at the Fortran Discourse (see\n https://fortran-lang.discourse.group/t/character-validation-functions/131)\n but hadn't taken the time to fix them. In fact at some point I would like\n to see all of these routines replaced by static lookup tables (\n https://github.com/ivan-pi/fortran-ascii/blob/master/fortran_ascii_bit.f90),\n as this solution appears to be the most performant one.\n\n For the functions to_upper and to_lower, I've seen a dozen of different\n possibilities on comp.lang.fortran. The solution I used here was adapted\n from @certik <https://github.com/certik>'s library:\n https://github.com/certik/fortran-utils/blob/master/src/utils.f90#L18\n Are you worried about non-ascii characters or other encodings?\n\n +1 to merge\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#233 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR4PHMKOZ3AMDZAVQ6LSGHR4VANCNFSM4RPBDAVA>\n .\n\n! test_lower.f90 --\n!     Test the performance of two implementations of to_lower.\n!\nmodule ascii\n    implicit none\n\ncontains\n    !> Checks whether `c` is an uppercase ASCII letter (A .. Z).\n    pure logical function is_upper(c)\n        character(len=1), intent(in) :: c !! The character to test.\n        integer :: ic\n        ic = iachar(c)\n        is_upper = (ic >= iachar('A')) .and. (ic <= iachar('Z'))\n    end function\n    pure function to_lower(c) result(t)\n        character(len=1), intent(in) :: c !! A character.\n        character(len=1)             :: t\n        integer :: diff\n        diff = iachar('A')-iachar('a')\n        t = c\n        ! if uppercase, make lowercase\n        if (is_upper(t)) t = achar(iachar(t) - diff)\n    end function\n    pure function to_lower_2(c) result(t)\n        character(len=1), intent(in) :: c !! A character.\n        character(len=1)             :: t\n        character(len=26), parameter :: lower_case = 'abcdefghijklmnopqrstuvwxyz'\n        character(len=26), parameter :: upper_case = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n        integer :: k\n\n        k = index( upper_case, c )\n\n        if ( k > 0 ) then\n            t = lower_case(k:k)\n        else\n            t = c\n        endif\n    end function\nend module ascii\n\nprogram test_lower\n    use ascii\n\n    implicit none\n\n    real                                  :: r\n    character(len=1), dimension(10000000) :: c, t    ! Store the results, to avoid false results from aggressive optimisation\n    integer                               :: ic, i\n    real                                  :: t1, t2, t_method1, t_method2\n\n\n    do i = 1,size(c)\n        call random_number( r )\n        ic    = int( 256 * r )\n        c(i)  = achar(ic)\n    enddo\n\n    !\n    ! Method 1\n    !\n    call cpu_time( t1 )\n\n    do i = 1,size(c)\n        t(i) = to_lower(c(i))\n    enddo\n\n    call cpu_time( t2 )\n\n    t_method1 = t2 - t1\n\n    !\n    ! Method 2\n    !\n    call cpu_time( t1 )\n\n    do i = 1,size(c)\n        t(i) = to_lower(c(i))\n    enddo\n\n    call cpu_time( t2 )\n\n    t_method2 = t2 - t1\n\n    !\n    ! Print the results\n    !\n    write(*,*) 'Method 1 (shift):   ', t_method1\n    write(*,*) 'Method 2 (look-up): ', t_method2\n\n    do i = 1,100\n        write(*,*) c(i), t(i)\n    enddo\nend program test_lower"
                },
                {
                    "user": "LKedward",
                    "date": "2020-09-18 08:35:45+00:00",
                    "text": "Hi @arjenmarkus, I noticed in the benchmark code you posted that you appear to be testing the same implementation twice as opposed to two different implementations - is this a typo? On my machine I see the lookup implementation as being almost two orders of magnitude slower than the shift implementation.\nAs an aside, the lookup approach can be implemented much more efficiently by using the character code directly as an index into a static table instead of using index. EDIT: Apologies, I see you've already considered this.\nI am aware performance is not the primary concern for this PR or the stdlib reference implementation but I thought I would point it out."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-09-18 08:57:54+00:00",
                    "text": "So, a simple robust and general implementation should be enough, certainly for a first version.\n\nI agree."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-18 11:02:02+00:00",
                    "text": "Hi Laurence,\n\nO dear, that is a stupid mistake. No wonder things looked so much the same!\nYes, after correcting the program I get a clear difference:\n\n0.05 seconds for the \"shift\" implementation and 0.2 for the \"look-up\" one.\nThis is roughly the same with Intel Fortran and gfortran (on Windows and\nCygwin).\n\nOptimisation with -O2 does not give substantial changes to the second one,\nbut I need to do something with the result array, as otherwise both loops\ngive zero CPU time with gfortran.\n\nStill, 0.2 seconds for 100 million characters is not that bad :).\n\nOp vr 18 sep. 2020 om 10:36 schreef Laurence Kedward <\nnotifications@github.com>:\n\u2026\n Hi @arjenmarkus <https://github.com/arjenmarkus>, I noticed in the\n benchmark code you posted that you appear to be testing the same\n implementation twice as opposed to two different implementations - is this\n a typo? On my machine I see the lookup implementation as being almost two\n orders of magnitude slower than the shift implementation.\n As an aside, the lookup approach can be implemented much more efficiently\n by using the character code directly as an index into a static table\n instead of using index.\n\n I am aware performance is not the primary concern for this PR or the\n stdlib reference implementation but I thought I would point it out.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#233 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR5BFMU2VV73XAFLICLSGMLXHANCNFSM4RPBDAVA>\n ."
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-18 15:59:21+00:00",
                    "text": "It makes sense since in the lookup method in the worst case scenario (letter 'z') has to check 26 chars, on the other side the iachar method is constant for all cases. This explains the difference in the execution time."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-24 19:03:13+00:00",
                    "text": "Closing this after committing the suggestions. I will make a few more edits (especially remove the extra parentheses to make the code a bit more consistent) and I will also implement the to_lower and to_upper functions differently."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-24 19:11:01+00:00",
                    "text": "@arjenmarkus Did you mean to merge it? You only closed the PR without merging it."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-24 19:28:49+00:00",
                    "text": "Hi @milan Curcic <caomaco@gmail.com>, yes, good heavens, again the wrong\naction. How do I properly merge it?\n\nOp do 24 sep. 2020 om 21:11 schreef Milan Curcic <notifications@github.com>:\n\u2026\n @arjenmarkus <https://github.com/arjenmarkus> Did you mean to merge it?\n You only closed the PR without merging it.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#233 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR5H2CE3FXNZTGMFQALSHOKVJANCNFSM4RPBDAVA>\n ."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-24 19:31:57+00:00",
                    "text": "Hm, I see a failure from CI, but I do not see what went wrong - the code I\ncommitted works fine on my machine. Or at least I am convinced it does. How\ncan I see the reason?\n\nOp do 24 sep. 2020 om 21:28 schreef Arjen Markus <arjen.markus895@gmail.com\n\u2026\n:\n Hi @milan Curcic ***@***.***>, yes, good heavens, again the wrong\n action. How do I properly merge it?\n\n Op do 24 sep. 2020 om 21:11 schreef Milan Curcic ***@***.***\n >:\n\n> @arjenmarkus <https://github.com/arjenmarkus> Did you mean to merge it?\n> You only closed the PR without merging it.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <#233 (comment)>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAN6YR5H2CE3FXNZTGMFQALSHOKVJANCNFSM4RPBDAVA>\n> .\n>"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-24 19:38:01+00:00",
                    "text": "Hm, I see a failure from CI, but I do not see what went wrong - the code I committed works fine on my machine. Or at least I am convinced it does. How can I see the reason? Op do 24 sep. 2020 om 21:28 schreef Arjen Markus\n\nYou can go in Actions to find the details. Here is the link"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-24 19:42:03+00:00",
                    "text": "Right, the failure is on MacOS: Error:\n/Users/runner/work/stdlib/stdlib/build is not a directory\n\nThis happens for all three versions (7,8 and 9). Any suggestions as to how\nto solve this?\n\n\nOp do 24 sep. 2020 om 21:38 schreef Jeremie Vandenplas <\nnotifications@github.com>:\n\u2026\n Hm, I see a failure from CI, but I do not see what went wrong - the code I\n committed works fine on my machine. Or at least I am convinced it does. How\n can I see the reason? Op do 24 sep. 2020 om 21:28 schreef Arjen Markus <\n ***@***.***\n \u2026 <#m_6303207014123977784_>\n : Hi @milan <https://github.com/milan> Curcic *@*.*>, yes, good heavens,\n again the wrong action. How do I properly merge it? Op do 24 sep. 2020 om\n 21:11 schreef Milan Curcic @.* >: > @arjenmarkus\n <https://github.com/arjenmarkus> https://github.com/arjenmarkus Did you\n mean to merge it? > You only closed the PR without merging it. > > \u2014 > You\n are receiving this because you were mentioned. > Reply to this email\n directly, view it on GitHub > <#233 (comment)\n <#233 (comment)>>,\n > or unsubscribe >\n https://github.com/notifications/unsubscribe-auth/AAN6YR5H2CE3FXNZTGMFQALSHOKVJANCNFSM4RPBDAVA\n > . >\n\n You can go in Actions to find the details. Here is the link\n <https://github.com/fortran-lang/stdlib/runs/1162227548>\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#233 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR7FCXMFG673DMDPVSTSHON2PANCNFSM4RPBDAVA>\n ."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-24 19:48:31+00:00",
                    "text": "A problem already appeared earlier:\n\ngit -c http.extraheader=\"AUTHORIZATION: basic ***\" fetch --tags --prune\n--progress --no-recurse-submodules origin\n+refs/heads/*:refs/remotes/origin/*\n+refs/pull/233/merge:refs/remotes/pull/233/merge\n28\n<https://github.com/fortran-lang/stdlib/runs/1162227548?check_suite_focus=true#step:2:28>Error:\nfatal: couldn't find remote ref refs/pull/233/merge\n29\n<https://github.com/fortran-lang/stdlib/runs/1162227548?check_suite_focus=true#step:2:29>Warning:\nGit fetch failed with exit code 128, back off 6.955 seconds before retry.\n30\n<https://github.com/fortran-lang/stdlib/runs/1162227548?check_suite_focus=true#step:2:30>git\n-c http.extraheader=\"AUTHORIZATION: basic ***\" fetch --tags --prune\n--progress --no-recurse-submodules origin\n+refs/heads/*:refs/remotes/origin/*\n+refs/pull/233/merge:refs/remotes/pull/233/merge\n31\n<https://github.com/fortran-lang/stdlib/runs/1162227548?check_suite_focus=true#step:2:31>Error:\nfatal: couldn't find remote ref refs/pull/233/merge\n32\n<https://github.com/fortran-lang/stdlib/runs/1162227548?check_suite_focus=true#step:2:32>Warning:\nGit fetch failed with exit code 128, back off 4.998 seconds before retry.\n\n\nNo idea what it could be.\n\n\n\nLe jeu. 24 sept. 2020 \u00e0 21:42, Arjen Markus <notifications@github.com> a\n\u00e9crit :\n\u2026\n Right, the failure is on MacOS: Error:\n /Users/runner/work/stdlib/stdlib/build is not a directory\n\n This happens for all three versions (7,8 and 9). Any suggestions as to how\n to solve this?\n\n\n Op do 24 sep. 2020 om 21:38 schreef Jeremie Vandenplas <\n ***@***.***>:\n\n > Hm, I see a failure from CI, but I do not see what went wrong - the code\n I\n > committed works fine on my machine. Or at least I am convinced it does.\n How\n > can I see the reason? Op do 24 sep. 2020 om 21:28 schreef Arjen Markus <\n > ***@***.***\n > \u2026 <#m_6303207014123977784_>\n > : Hi @milan <https://github.com/milan> Curcic *@*.*>, yes, good heavens,\n > again the wrong action. How do I properly merge it? Op do 24 sep. 2020 om\n > 21:11 schreef Milan Curcic @.* >: > @arjenmarkus\n > <https://github.com/arjenmarkus> https://github.com/arjenmarkus Did you\n > mean to merge it? > You only closed the PR without merging it. > > \u2014 >\n You\n > are receiving this because you were mentioned. > Reply to this email\n > directly, view it on GitHub > <#233 (comment)\n > <#233 (comment)\n >>,\n > > or unsubscribe >\n >\n https://github.com/notifications/unsubscribe-auth/AAN6YR5H2CE3FXNZTGMFQALSHOKVJANCNFSM4RPBDAVA\n > > . >\n >\n > You can go in Actions to find the details. Here is the link\n > <https://github.com/fortran-lang/stdlib/runs/1162227548>\n >\n > \u2014\n > You are receiving this because you were mentioned.\n > Reply to this email directly, view it on GitHub\n > <#233 (comment)\n >,\n > or unsubscribe\n > <\n https://github.com/notifications/unsubscribe-auth/AAN6YR7FCXMFG673DMDPVSTSHON2PANCNFSM4RPBDAVA\n >\n > .\n >\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#233 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD5RO7HMPAMARM3XG2RS4RTSHOOJVANCNFSM4RPBDAVA>\n ."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-24 19:53:10+00:00",
                    "text": "Okay, thanks anyway. At the moment there is not much we can do about it\nthen.\n\nOp do 24 sep. 2020 om 21:48 schreef Jeremie Vandenplas <\nnotifications@github.com>:\n\u2026\n A problem already appeared earlier:\n\n git -c http.extraheader=\"AUTHORIZATION: basic ***\" fetch --tags --prune\n --progress --no-recurse-submodules origin\n +refs/heads/*:refs/remotes/origin/*\n +refs/pull/233/merge:refs/remotes/pull/233/merge\n 28\n <\n https://github.com/fortran-lang/stdlib/runs/1162227548?check_suite_focus=true#step:2:28\n >Error:\n fatal: couldn't find remote ref refs/pull/233/merge\n 29\n <\n https://github.com/fortran-lang/stdlib/runs/1162227548?check_suite_focus=true#step:2:29\n >Warning:\n Git fetch failed with exit code 128, back off 6.955 seconds before retry.\n 30\n <\n https://github.com/fortran-lang/stdlib/runs/1162227548?check_suite_focus=true#step:2:30\n >git\n -c http.extraheader=\"AUTHORIZATION: basic ***\" fetch --tags --prune\n --progress --no-recurse-submodules origin\n +refs/heads/*:refs/remotes/origin/*\n +refs/pull/233/merge:refs/remotes/pull/233/merge\n 31\n <\n https://github.com/fortran-lang/stdlib/runs/1162227548?check_suite_focus=true#step:2:31\n >Error:\n fatal: couldn't find remote ref refs/pull/233/merge\n 32\n <\n https://github.com/fortran-lang/stdlib/runs/1162227548?check_suite_focus=true#step:2:32\n >Warning:\n Git fetch failed with exit code 128, back off 4.998 seconds before retry.\n\n\n No idea what it could be.\n\n\n\n Le jeu. 24 sept. 2020 \u00e0 21:42, Arjen Markus ***@***.***> a\n \u00e9crit :\n\n > Right, the failure is on MacOS: Error:\n > /Users/runner/work/stdlib/stdlib/build is not a directory\n >\n > This happens for all three versions (7,8 and 9). Any suggestions as to\n how\n > to solve this?\n >\n >\n > Op do 24 sep. 2020 om 21:38 schreef Jeremie Vandenplas <\n > ***@***.***>:\n >\n > > Hm, I see a failure from CI, but I do not see what went wrong - the\n code\n > I\n > > committed works fine on my machine. Or at least I am convinced it does.\n > How\n > > can I see the reason? Op do 24 sep. 2020 om 21:28 schreef Arjen Markus\n <\n > > ***@***.***\n > > \u2026 <#m_6303207014123977784_>\n > > : Hi @milan <https://github.com/milan> Curcic *@*.*>, yes, good\n heavens,\n > > again the wrong action. How do I properly merge it? Op do 24 sep. 2020\n om\n > > 21:11 schreef Milan Curcic @.* >: > @arjenmarkus\n > > <https://github.com/arjenmarkus> https://github.com/arjenmarkus Did\n you\n > > mean to merge it? > You only closed the PR without merging it. > > \u2014 >\n > You\n > > are receiving this because you were mentioned. > Reply to this email\n > > directly, view it on GitHub > <#233 (comment)\n > > <\n #233 (comment)\n > >>,\n > > > or unsubscribe >\n > >\n >\n https://github.com/notifications/unsubscribe-auth/AAN6YR5H2CE3FXNZTGMFQALSHOKVJANCNFSM4RPBDAVA\n > > > . >\n > >\n > > You can go in Actions to find the details. Here is the link\n > > <https://github.com/fortran-lang/stdlib/runs/1162227548>\n > >\n > > \u2014\n > > You are receiving this because you were mentioned.\n > > Reply to this email directly, view it on GitHub\n > > <\n #233 (comment)\n > >,\n > > or unsubscribe\n > > <\n >\n https://github.com/notifications/unsubscribe-auth/AAN6YR7FCXMFG673DMDPVSTSHON2PANCNFSM4RPBDAVA\n > >\n > > .\n > >\n >\n > \u2014\n > You are receiving this because you commented.\n > Reply to this email directly, view it on GitHub\n > <#233 (comment)\n >,\n > or unsubscribe\n > <\n https://github.com/notifications/unsubscribe-auth/AD5RO7HMPAMARM3XG2RS4RTSHOOJVANCNFSM4RPBDAVA\n >\n > .\n >\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#233 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR57Q7NXNJSYDNVTNGDSHOPB7ANCNFSM4RPBDAVA>\n ."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-24 19:58:33+00:00",
                    "text": "Well, I see that you opened a new PR #235 from the same branch update_ascii, and that the CI for this PR #235 is fine. So, I would say that the problem is solved by himself (at least temporarily) ;)\nFurthermore this PR cannot be reopened because #235 exists."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-24 20:02:22+00:00",
                    "text": "Well, I am learning the rules of Github the hard way, I guess. Hopefully I\nwill turn out to be a quick learner.\n\nSo: once you have made a pull request for a particular branch, you have to\ncreate a new branch to continue work. Seems reasonably simple.\n\nOp do 24 sep. 2020 om 21:58 schreef Jeremie Vandenplas <\nnotifications@github.com>:\n\u2026\n Well, I see that you opened a new PR #235\n <#235> from the same branch\n update_ascii, and that the CI for this PR #235\n <#235> is fine. So, I would\n say that the problem is solved by himself (at least temporarily) ;)\n Furthermore this PR cannot be reopened because #235\n <#235> exists.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#233 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YRZLEGQVRNGYBMDUR2TSHOQHRANCNFSM4RPBDAVA>\n ."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-24 20:12:54+00:00",
                    "text": "So: once you have made a pull request for a particular branch, you have to create a new branch to continue work. Seems reasonably simple.\n\nI am not sure what you mean and what were your intentions. However, for me, #235 seems to be #233 with some additional commits that were pushed to update_ascii after opening #233.\nIf #233 was not closed (before pushing the additonal commits to update_ascii), these additional commits would have appear in #233. And #235 would have not been needed (since #233 would include the additional commits)."
                }
            ]
        },
        {
            "number": 232,
            "user": "arjenmarkus",
            "date": "2020-09-14 11:51:53+00:00",
            "title": "Wrt stdlib_ascii.f90: use iachar/achar consistently",
            "text": "While having a quick look at the documentation, I stumbled upon the implementation of the ASCII functions. For instance:\n    pure logical function is_alpha(c) character(len=1), intent(in) :: c !! The character to test. is_alpha = (c >= 'A' .and. c <= 'Z') .or. (c >= 'a' .and. c <= 'z') end function\nThe implementation assumes that the character that is passed is in ASCII encoding. While ubiquitous nowadays, it is certainly not the only possible encoding. For stdlib we should be as general as possible, Here is a possible alternative for the is_alpha() function:\npure logical function is_alpha(cin)\n    character(len=1), intent(in) :: cin !! The character to test.\n    integer :: c\n    c = iachar(cin)\n    is_alpha = (c >= iachar('A') .and. c <= iachar('Z')) .or. (c >= iachar('a') .and. c <= iachar('z'))\nend function",
            "comments": [
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-14 11:55:39+00:00",
                    "text": "Perhaps it is over cautious, but it cannot hurt to consider this."
                },
                {
                    "user": "certik",
                    "date": "2020-09-14 14:06:45+00:00",
                    "text": "Can you send this as a Pull Request (PR)? I think this change is fine."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-15 06:06:49+00:00",
                    "text": "It is not quite complete yet . Will check the rest later.\n\nOp ma 14 sep. 2020 16:07 schreef Ond\u0159ej \u010cert\u00edk <notifications@github.com>:\n\u2026\n Can you send this as a Pull Request (PR)? I think this change is fine.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#232 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR2NO6AXASUXBXKEVODSFYPQLANCNFSM4RLQC7FQ>\n ."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-16 14:56:29+00:00",
                    "text": "Oh dear, I inadvertently pushed it to the central repository instead of\ncreating a pull request. Please have a look at my changes - if not\nappropriate, I will revert this.\n\nOp di 15 sep. 2020 om 08:06 schreef Arjen Markus <arjen.markus895@gmail.com\n\u2026\n:\n It is not quite complete yet . Will check the rest later.\n\n Op ma 14 sep. 2020 16:07 schreef Ond\u0159ej \u010cert\u00edk ***@***.***>:\n\n> Can you send this as a Pull Request (PR)? I think this change is fine.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <#232 (comment)>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAN6YR2NO6AXASUXBXKEVODSFYPQLANCNFSM4RLQC7FQ>\n> .\n>"
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-16 15:26:03+00:00",
                    "text": "I think you should revert the commit so we can fully review the changes, if I'm not mistaken, there is already a missing line in your changes."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-16 15:29:11+00:00",
                    "text": "Okay, will do so.\n\nOp wo 16 sep. 2020 17:26 schreef Ian Giestas Pauli <notifications@github.com\n\u2026\n:\n I think you should revert the commit so we can fully review the changes,\n if I'm not mistaken, there is already a missing line in your changes.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#232 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR6VUF2ASUV3RASPHW3SGDKJ3ANCNFSM4RLQC7FQ>\n ."
                }
            ]
        },
        {
            "number": 231,
            "user": "Jim-215-Fisher",
            "date": "2020-09-10 17:18:23+00:00",
            "title": "Proposal for arbitrary precision data type and arbitrary precision Lapack/Blas",
            "text": "Like to see an arbitrary precision data type in stdlib. Other languages like python, c++, java and Julia have already implemented. As a programming language for scientific calculation, Fortran should have the arbitrary precision data type implemented as well.\nGNU has a GMP multiple precision library for c++. To the Fortran side, there are David Bailey's MPfun2015 package (https://www.davidhbailey.com/dhbsoftware/)  and David Smith's FM package (https://dmsmith.lmu.build/).\nFor arbitrary precision Lapack/Blas, there is mpack(http://mplapack.sourceforge.net/).",
            "comments": [
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-14 09:27:19+00:00",
                    "text": "I like the idea - while I do not usually need multiple precision in my\ndaily work or my hobbies, having such a feature readily available is\ncertainly welcome. Something that might also be useful: arbitrary precision\ninteger data.\n\nHave you checked the status and the licence of the various libraries?\n\nRegards,\n\nArjen\n\nOp do 10 sep. 2020 om 19:18 schreef Jing <notifications@github.com>:\n\u2026\n Like to see an arbitrary precision data type in stdlib. Other languages\n like python, c++, java and Julia have already implemented. As a programming\n language for scientific calculation, Fortran should have the arbitrary\n precision data type implemented as well.\n\n GNU has a GMP multiple precision library for c++. To the Fortran side,\n there are David Bailey's MPfun2015 package (\n https://www.davidhbailey.com/dhbsoftware/) and David Smith's FM package (\n https://dmsmith.lmu.build/).\n\n For arbitrary precision Lapack/Blas, there is mpack(\n http://mplapack.sourceforge.net/).\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#231>, or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR3P3GD2R4P5RE5KRO3SFEC7BANCNFSM4RFPDUUA>\n ."
                },
                {
                    "user": "Jim-215-Fisher",
                    "date": "2020-09-20 15:56:06+00:00",
                    "text": "For mpack, it is 2-caluse BSD style license. It has not been updated since 2012.\nFor MPfun2015 package, it has LIMITED BSD LICENSE, i do know what that means.\nFor FM package, it is free."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-22 06:59:55+00:00",
                    "text": "Thanks for looking into this. I cannot find any information about a limited\nBSD license, but there is a Github mirror by @jacobwilliams for this\npackage. Maybe Jacob can explain this? In any case, there are no obvious\nrestrictions based on the license text I found there to the use of theat\npackage in the Fortran stdlib.\n\nOp zo 20 sep. 2020 om 17:56 schreef Jing <notifications@github.com>:\n\u2026\n For mpack, it is 2-caluse BSD style license. It has not been updated since\n 2012.\n For MPfun2015 package, it has LIMITED BSD LICENSE, i do know what that\n means.\n For FM package, it is free.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#231 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR5SXBO2M7L3B2RHF43SGYQ2FANCNFSM4RFPDUUA>\n ."
                }
            ]
        },
        {
            "number": 230,
            "user": "MuellerSeb",
            "date": "2020-09-08 15:25:55+00:00",
            "title": "Argument parser for executables",
            "text": "Could this be a place to provide an argument parser in fortran?\nHere are two implementations:\n\nhttps://github.com/haniibrahim/f90getopt\nhttps://github.com/cngilbreth/optionsf90",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-09-08 15:38:57+00:00",
                    "text": "Yes, I think argument parsing is in scope. See also:\n\nhttps://github.com/szaghi/FLAP\nhttps://github.com/urbanjost/M_CLI2\n@everythingfunctional is working on one, I can't find the link now"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-09-08 20:02:46+00:00",
                    "text": "I've found the link for the one from @everythingfunctional:\n\ncmdff\n\nThere has also been a discussion of available modules for option parsing in fortran-lang/fpm#135. Three more libraries I mentioned in that thread are:\n\ncommand_args from @arjenmarkus\nFTN_Getopt by Reinhold Bader\nlibSUFR by @MarcvdSluys\n\nI also believe that many of the libraries in the list of popular Fortran projects have their own argument parsers.\nGiven this much prior art, I think it is a good idea to draw up some kind of comparison table and identify what are the most commonly required features, and what kind of different programming approaches are used in practice."
                },
                {
                    "user": "certik",
                    "date": "2020-09-08 20:06:50+00:00",
                    "text": "I think we all agree that stdlib should have command line parsing.\nOne way to get there is to first implement it as a separate library as an fpm package, and get projects use it, and then eventually include into stdlib as we get more real life usage, to ensure the API works."
                },
                {
                    "user": "MuellerSeb",
                    "date": "2020-09-13 11:01:13+00:00",
                    "text": "AFAICT, https://github.com/urbanjost/M_CLI2 already provides a fpm package."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-09-13 18:21:33+00:00",
                    "text": "I did not quite get hooked into the process so I do not think that will be pulled in, but yes .. I made a branch that implemented all the command line parsing in the current FPM and all the functionality except the pull/curl request, and tdetermining the compilation order was primitive but I made that private so I could continue experimenting while the more critical TOML interface and gitlib/libcurl/system interfaces seemed to be racing along, and others seemed to be working on the CLI interface.  Apparently I did not remove everything I thought I did. So the fpm CLI interface is gone from the M_CLI2 site but if anyone wants me to integrate that into a more recent fpm package let me know."
                }
            ]
        },
        {
            "number": 229,
            "user": "14NGiestas",
            "date": "2020-09-08 12:12:12+00:00",
            "title": "ANSI Colors support",
            "text": "Colors Module\nIn order to support colors and styling (bold, underline and etc) I propose a small utility to handle colored output, namely stdlib_colors. The use cases can vary, but the main application would be the richer logger and errors which helps a lot to visually identify what kind of message is right away.\n\nFigure 1 - coloredlogs python library showing a use case\nFew remarks from the community in #193\n\n@mobius-eng commented on 20 May\n(...)\nJulia (and Python and R) are meant to be used interactively. Thus, colors play an important role with the output to the terminal. By contrast, Fortran programs are meant to be run in the \"batch mode\" with log going to the file.\n\n\n@aradi commented on 24 May\nAs for colors: I am fine, as long as they are optional. I think most people typically run Fortran programs in batch systems with redirected output. Seeing a lot of color control sequences when opening the output files is rather disturbing...\n\n\n@jvdp1 commented on 23 May\n(...)\nColors are not needed for me.\n\n\n@wclodius2\nA problem with using colors is that output_unit can be directed to a file where the \"color codes\u201d will be distracting.\n\nProof of Concept and fixing the issue with redirection\n\nWell, gnu utils have support to colored output for eons and when it gets redirected it handles correctly, how is that possible? So I did some research in order to figure out how they are made and found this.\nSo basically we test if there is a teletypewriter device (A interactive terminal) connected with the isatty function (from <unistd.h>), if isatty returns true then we write the ANSI colors, otherwise no colors in the output.\nA lot of compiler vendors support this function as a extension, however is not a standard so we can't rely on it. That being said I think it should be included in the stdlib_system module as a new function binding the C one (and alternatives to other platforms).\nIn order to show that it works I made a small change in a program to output colors from the fortran-wiki and its here\n\nSome other related projects that could inspire the API\n\nFACE by @szaghi\nFoul, as pointed by @arjenmarkus]",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-09-10 23:00:30+00:00",
                    "text": "I think something along the FACE and Foul libraries would be good for stdlib. I like using colors a lot in a terminal, it helps.\nThe ANSI escape sequences for colors work out of the box on Linux / macOS, but must be turned on to work on Windows.\nSo one needs some basic terminal support. I created this library in C++ to do colors on all platforms as well as keyboard input:\nhttps://github.com/certik/terminal\nThis allows to create things like interactive prompts, get arrows working for cursor movements, and to draw anywhere on the screen. Similar to the ncurses Linux library, but multi-platform and only using the ANSI sequences that are now supported on all platforms (including Windows), which simplifies things."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-09-11 13:16:33+00:00",
                    "text": "I like the FACE interface. I have a similar library but it is not as completely or nicely developed. For something fancier than colors I generally use ncurses from Fortran http://www.urbanjost.altervista.org/LIBRARY/libscreen/ncurses/pdsrc/ncurses_from_Fortran.html but I think that is a bit beyond the stdlib but would be appropriate for fpm if it supported C wrappers as well as Fortran. Specifically for xterm(1) I have a library that lets you set fonts, window size and position, window title, etc. The esc(1) program in the GPF collection actually combines the two\n\nwhen called without CLI options.  So I use escape sequences quite extensively in one form or another but find using ncurses preferable for something past basic text formatting; so I personally support adding some basic ANSI color interface but think that getting a mostly-Fortran fpm(1) package manager up and getting the authors of packages like those mentioned to add their libraries to the registry more appropriate myself. There are ISO_C_BINDING interfaces for terminfo/termlib out there too which give you extensive terminal escape sequence support as well; although the ability to support different terminals is not nearly as important now that almost everyone uses a terminal emulator instead of a terminal, and those tend to emulate the ANSI terminals like VT102 or do not support escape sequences at all."
                },
                {
                    "user": "certik",
                    "date": "2020-09-11 14:44:15+00:00",
                    "text": "@urbanjost yes, I agree that going beyond colors should go into a separate fpm package.\nI would recommend in general to not depend on platform specific libraries, such as ncurses (which doesn't work on Windows in the native cmd.exe terminal), and rather always implement things in a platform independent (multiplatform) way. I have done that in C++ in the terminal library, and the same thing can be done in pure Fortran as an fpm package also.\nI agree that the reason that can be done is that nowadays everybody supports some subset of the ANSI escape sequences, and so one can just use those."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-09-13 02:15:15+00:00",
                    "text": "I put  M_escape\n onto github as it uses a different API model than the others referenced so far, although the parsing method used is just a prototype it is functional for basic string coloring.\nI found it interesting to see what language have color built-in and how many have a standard module or library for it in Rosetta Code."
                },
                {
                    "user": "certik",
                    "date": "2020-09-13 13:51:25+00:00",
                    "text": "That seems similar to the approach here:\n\nhttps://python-prompt-toolkit.readthedocs.io/en/master/pages/printing_text.html#html\n\nIt works. But it's slower, because you have to parse the string. So it depends on the application.\n\u2026\nOn Sat, Sep 12, 2020, at 8:15 PM, urbanjost wrote:\n\n\n I put M_escape <https://github.com/urbanjost/M_escape>\n image\n <https://user-images.githubusercontent.com/29845229/93008620-c2065e80-f544-11ea-84d1-0fbba159c769.png> onto github as it uses a different API model than the others referenced so far, although the parsing method used is just a prototype it is functional for basic string coloring.\n\n I found it interesting to see what language have color built-in and how\n many have a standard module or library for it in Rosetta Code.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#229 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWBXFUPNUIPL4BX5VCLSFQTMBANCNFSM4Q74M77Q>."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-09-13 14:29:15+00:00",
                    "text": "Speed is not always an issue in that you can process fixed strings once, as in\nerror=esc(\"ERROR\")\nand then just use the error variable; but usually adding color for human consumption at a terminal so I would not imagine using this with large amounts of data; but I agree."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-09-14 13:59:09+00:00",
                    "text": "The advantage of the approach of replacing in-band escape sequences\nwith formatting directives contained on each line is that it is easy\nto turn off when running batch, but more importantly your program can\nbe run in \"raw\" mode and write a file with the directives in it that\ncan then be read back in by a simple filter program that strips it\nback to plain text or displays it to a screen in color or converts it\nto HTML or Adobe PDF. By making each line self-contained by default\nthis can still be done with any selected group of lines from the file.\nI need to add some example filters  (a loop that reads the \"raw\" files and displays them as plain text or as color on screen would liternally be a read/write loop that calls the esc(3f) routine, but an HTML and PDF example ala like the M_ncurses does for ncurses dumps (to HTML) or the asa2pdf(1) program does for \"ASA carriage control\" might make a stronger case); but have not seen a lot of interest in this so far(?) so it is on the \"one of these days\" lists for now. People can write HTML pretty easily from Fortran, after all. This actually has some advantages because it is simple and assumes fix spaced output  and keeps each line independent by default. So that is how I justify the parsing overhead. It compliments traditional batch use but still lets you throw a little sparkle in your output."
                },
                {
                    "user": "certik",
                    "date": "2020-09-14 20:51:58+00:00",
                    "text": "It's a question what to use for markup to show colors. HTML is certainly one way to do that, used in python-prompt-toolkit. It's a clean way to do that.\nTo be honest though, I still kind of like the simplicity of just outputting ANSI sequences, as you don't have to worry about any kind of HTML, you just output the sequences directly, here is an example from C++:\n        std::string text = \"Some text with \"\n            + color(fg::red) + color(bg::green) + \"red on green\"\n            + color(bg::reset) + color(fg::reset) + \" and some \"\n            + color(style::bold) + \"bold text\" + color(style::reset) + \".\";\n        std::cout << text << std::endl;\nYou can use less -r to see files with ANSI escape sequences. It works great. One can then convert it to HTML, I've used the ansi2html filter in Jinja in the past when converting a terminal output to html:\n\nhttps://nbconvert.readthedocs.io/en/4.2.0/architecture.html#templates-and-filters\n\nOne way to design color output is to first provide the color function together with the predefined fg, bg and style enumerations (somehow in Fortran) and then build the HTML layer on top. People who prefer HTML can use it, people who prefer a more direct style can use the color function directly."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-09-15 04:02:49+00:00",
                    "text": "I use the ansi2html(1) bash shell as well. I changed   M_escape to have not only the pseudo-XML mode, but a function-based and direct ANSI escape sequence mode and added an fpm(1) config for it and simple filters called plain(1) and light(1) to read the pseudo-XML files and print the output to stdout with and without color as examples for discussion. I was going to do an OOP interface too, but I think the other resources listed here cover that. Comments welcome. I put a list of resources that compliments those mentioned here as well. If anyone tries it I would be interested in a vote as to which interface people prefer. The README files shows an example of each of the three modes."
                },
                {
                    "user": "certik",
                    "date": "2020-09-15 06:14:30+00:00",
                    "text": "@urbanjost thanks! I like your example as the lowest level API:\n   program direct\n      use M_escape, only : &\n     ! FOREGROUND COLORS\n        & fg_red, fg_cyan, fg_magenta, fg_blue, fg_green, fg_yellow, fg_white, fg_ebony, fg_default, &\n     ! BACKGROUND COLORS\n        & bg_red, bg_cyan, bg_magenta, bg_blue, bg_green, bg_yellow, bg_white, bg_ebony, bg_default, &\n     ! ATTRIBUTES\n        & bold, italic, inverse, underline,  unbold, unitalic, uninverse, ununderline,  reset, &\n     ! DISPLAY\n        & clear\n      implicit none\n\twrite(*,'(*(g0))')fg_red,bg_green,bold,'Hello!',reset\n   end program direct\nI think that works great. With this, and your html API, I think that covers most use cases."
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-16 14:17:08+00:00",
                    "text": "I think that works great. With this, and your html API, I think that covers most use cases.\n\nI think this kind of low level API is great, but we should keep in mind the complaint about the redirection issue too. So i think it should have a higher level API with a function that handles all the functionality:\nprogram\n    use stdlib_colors only: color & ! other suggestions: colorize, stylize...\n                            fg_blue, sgr_bold\n    implicit none\n    write(*,*) color('Hello... ',      fg='red',  bg='yellow'), &\n               color(\"it's me you're \",fg='blue', bg='yellow'), &\n               color('LOOKING FOR?',   fg='red',  bg='yellow', style='bold')\n    write(*,*) color('I can see it in your <b>eyes</b>') \n    write(*,*) color('I can see it in your <y>smile</y>') \n    write(*,*) 'Tell me how to win your ', color('<3', 'red')\nend program\nThis would apply the escapes and the reset and handle the file redirection thing.\nUsing only the XML tags and the low level API would leave behind some kind of procedural colorization use case: imagine parsing a json and colorize it in some way, i think would be easier to just read the color name and style and pass to a function rather than build a XML string to escape or use a select case to apply the right low level escape."
                },
                {
                    "user": "certik",
                    "date": "2020-09-16 14:25:03+00:00",
                    "text": "complaint about the redirection\n\nCan you explain what you mean by this? Is it to change the output from ANSI sequences to HTML using the same code?\nThe API you proposed is very good also, and it can be built on top of the low level API we discussed above."
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-16 14:28:05+00:00",
                    "text": "I mean the redirection of such outputs to a file, since they would write the ansi escapes sequences too, polluting it (see \"Few remarks from the community\" section of this issue).\nEDIT: And yes I think the higher API should be built upon the low level one."
                },
                {
                    "user": "certik",
                    "date": "2020-09-16 14:35:16+00:00",
                    "text": "I see. I feel this must go into the API that is above the low level API.\nI see his architecture all over many of the other issues in stdlib. In this case, the API layers as I can see them could be (from lowest to highest):\n\n\nlowest level: the goal is to output the correct ANSI string without having to deal with ansi sequences directly, but there should be no over head and it should be as simple as possible. The two proposed solutions would both work:\n\nprint *, fg_red, bg_green, bold, 'Hello!', reset\nprint *, color('Hello!', fg=fg_red, bg=bg_green, style=style_bold) (notice the fg_red is not a string \"red\" to avoid string parsing / comparison, and just efficiently output the ANSI sequence)\n\n\n\nhigher level: a function color that can work in many ways, output both ANSI or HTML output and allows to turn off colors\n\n\nhigh level: some intermediate representation (XML) that can be parsed into, and then manipulated to any output (HTML, ANSI, latex, ...)"
                }
            ]
        },
        {
            "number": 228,
            "user": "wclodius2",
            "date": "2020-09-02 00:48:26+00:00",
            "title": "Logger",
            "text": "The main files to focus on are src/stdlib_logger.f90, src/tests/logger/test_stdlib_logger.f90, and doc/specs/stdlib_logger.md. I have also updated the CMakeLists.txt, and Makefile.manual so they should compile with this branch, but my original testing was with a download of  the current main branch and not this older one. Note I had some problems with the other source code when compiled with a couple years old version of ifort, but no problems with gfortran.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-09-02 14:58:31+00:00",
                    "text": "Great, thanks William, I will review it."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-03 19:04:40+00:00",
                    "text": "Thank you @wclodius2 for this PR. I will review it this weekend"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-05 22:55:27+00:00",
                    "text": "Two reviewers will be great.\n\u2026\n On Sep 3, 2020, at 1:04 PM, Jeremie Vandenplas ***@***.***> wrote:\n\n\n Thank you @wclodius2 <https://github.com/wclodius2> for this PR. I will review it this weekend\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#228 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOTEVLEKXSRSLZKKIELSD7SFRANCNFSM4QSNH5WA>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-06 20:46:53+00:00",
                    "text": "It was indeed to be more explicit, but also to follow the same logic as for\nthe declaration of variables inside the derived type (private default), and\nof the module (private default too).\n\nLe dim. 6 sept. 2020 \u00e0 22:39, Milan Curcic <notifications@github.com> a\n\u00e9crit :\n\u2026\n ***@***.**** commented on this pull request.\n ------------------------------\n\n In src/stdlib_logger.f90\n <#228 (comment)>:\n\n > +!        procedure, pass(self) :: assert\n +        procedure, pass(self) :: add_log_file\n +        procedure, pass(self) :: add_log_unit\n +        procedure, pass(self) :: configuration\n +        procedure, pass(self) :: configure\n +        procedure, pass(self) :: log_error\n +        procedure, pass(self) :: log_information\n +        procedure, pass(self) :: log_io_error\n +        procedure, pass(self) :: log_message\n +        procedure, pass(self) :: log_text_error\n +        procedure, pass(self) :: log_units_assigned\n +        procedure, pass(self) :: log_warning\n +        procedure, pass(self) :: remove_log_unit\n\n I don't think this change is needed. Type-bound methods are public by\n default unless explicitly set to private, right? Unless that with this\n change you aim to be more explicit.\n\n \u2014\n You are receiving this because your review was requested.\n Reply to this email directly, view it on GitHub\n <#228 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD5RO7H2Y4U25BP64TBWS3LSEPXQDANCNFSM4QSNH5WA>\n ."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-06 20:52:28+00:00",
                    "text": "It was indeed to be more explicit, but also to follow the same logic as for the declaration of variables inside the derived type (private default), and of the module (private default too).\n\nYou're right, we should be consistent. Your suggested change is fine with me."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-07 00:58:41+00:00",
                    "text": "I went ahead and committed some straightforward fixes by @jvdp1. Others may need some discussion."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-11 00:21:33+00:00",
                    "text": "Now that @milancurcic and @jvdp1 are taking a breather it is time for me to see what more I can do for this code. @jvdp1 suggested that the type logger_t might benefit from having a final routine and I am inclined to agree with him. Should I write a finalizer that flushes all units upon the expiration of a logger_t variable? Is there anything else I should do for the code?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-11 00:31:20+00:00",
                    "text": "I agree about the finalizer. The only thing more I want to do before approving is to play with it--write a few toy programs that use the logger, so I can get the feel for it. I'll do it this coming weekend."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-11 18:08:44+00:00",
                    "text": "I was consistent in using lower case for source code, and upper case for variables in comments. I hope to go through the code and convert the upper case in comments to lower case, but if others want to do that they are more than welcome.\n\u2026\n On Sep 11, 2020, at 12:01 PM, Jeremie Vandenplas ***@***.***> wrote:\n\n\n @jvdp1 commented on this pull request.\n\n In src/stdlib_logger.f90 <#228 (comment)>:\n\n > @@ -569,7 +569,9 @@ end subroutine configure\n\n\n      subroutine final_logger( self )\n -!! finalizes the logger_t entity by flushing the units\n +!! version: experimental\n +\n +!! finalizes the logger_t entity sekf by flushing the units\n Thank you @14NGiestas <https://github.com/14NGiestas> for your review. Following the Style guide of stdlib <https://github.com/fortran-lang/stdlib/blob/master/STYLE_GUIDE.md#variable-and-procedure-naming>, variables should be lowercase. Would it be possible to modify your suggestion following this rule, please?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#228 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOSJ25QZ3DJRP2CTFCLSFJQXNANCNFSM4QSNH5WA>."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-12 02:01:22+00:00",
                    "text": "It seems relevant to resurrect #225 here. We didn't get a consensus there.\nWe're currently naming the type logger_t here. This was also @wclodius2's preference in his last comment in #225.\nBased on that thread, @jvdp1 and I prefer logger_type for consistency with several intrinsic derived types like team_type, event_type, lock_type, and others.\nShould we consider naming the logger type logger_type? The upside is that it's explicit and consistent with Fortran. The downside is that it's 3 characters longer than logger_t."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-12 02:14:49+00:00",
                    "text": "My guess is that the usage of the type will be very localized in the source code. Most people will use just the global_logger and not use the type at all. Others will use it for one or two module \"variables\". With that low a usage, name length is a minor concern. So why not logger_type?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-12 15:57:55+00:00",
                    "text": "I'm playing with a minimal program that outputs an info, warning, and error message. Here's the output:\n$ ./test \n\n2020-09-12 11:37:01.410\nINFORMATION: This is an info message.\n\n2020-09-12 11:37:01.410\nWARNING: This is a warning.\n\n2020-09-12 11:37:01.410\nERROR: This is an error.\n\nI personally prefer more compact output,  so the blank lines irked me a bit. I see that I can call `logger % configure(add_line=.false.). Now I get:\n$ ./test \n2020-09-12 11:41:17.830\nINFORMATION: This is an info message.\n2020-09-12 11:41:17.830\nWARNING: This is a warning.\n2020-09-12 11:41:17.830\nERROR: This is an error.\n\nI have a few questions and suggestions:\n\n\nShould we consider not outputting a blank line by default, that is, setting add_line = .false. in the derived type definition? Then if a blank line is desired, the user can call logger % configure(add_line=.true.) to enable the blank line output. So, which one is the preferred default? Mine is to not include it.\n\n\nI suggest we rename logger_t % add_line component and argument to logger_t % configure to add_blank_line, for clarity.\n\n\nI suggest that by default we output everything on a single line, for example:\n\n\n$ ./test \nINFORMATION 2020-09-12 11:41:17.830: This is an info message.\nWARNING 2020-09-12 11:41:17.830: This is a warning.\nERROR 2020-09-12 11:41:17.830: This is an error.\n\nRationale: If you have multiple loggers writing in parallel to stdout and/or stderr, then their outputs could get enmeshed and corrupt the log. For example, you could get:\n$ ./test \n2020-09-12 11:41:17.830\n2020-09-12 11:41:17.830\n2020-09-12 11:41:17.830\nWARNING: This is a warning.\nERROR: This is an error.\nINFORMATION: This is an info message\n\nwhich is not a big deal in this trivial example, but it gets worse for larger programs and multiple loggers.\nPersonal style preference: I don't have a rational explanation for this, but it feels the cleanest to me if one procedure call outputs one and only one line."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-12 16:01:10+00:00",
                    "text": "Another suggestion that is mostly aesthetic and personal preference: Default to INFO and WARN instead of INFORMATION and WARNING. I think both INFO and WARN are unambiguous and clear about what they mean, and they would reduce the amount of overflow of some long logs to the second line.\nINFO 2020-09-12 11:41:17.830: This is an info message.\nWARN 2020-09-12 11:41:17.830: This is a warning.\nERROR 2020-09-12 11:41:17.830: This is an error."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-12 17:28:04+00:00",
                    "text": "1 and 2 seem good to me and are easy to do. 3 I have to think about. It requires a complete rewrite of some of the code. Certainly the whole idea of formatting to fit into a maximum column width becomes problematic. Note for example that the add_log_file doesn\u2019t currently allow adding the asynchronous specifier to the open statement. How does your opinion change if the user also outputs the module and procedure names?\n\u2026\n On Sep 12, 2020, at 9:58 AM, Milan Curcic ***@***.***> wrote:\n\n\n I'm playing with a minimal program that outputs an info, warning, and error message. Here's the output:\n\n $ ./test\n\n 2020-09-12 11:37:01.410\n INFORMATION: This is an info message.\n\n 2020-09-12 11:37:01.410\n WARNING: This is a warning.\n\n 2020-09-12 11:37:01.410\n ERROR: This is an error.\n I personally prefer more compact output, so the blank lines irked me a bit. I see that I can call `logger % configure(add_line=.false.). Now I get:\n\n $ ./test\n 2020-09-12 11:41:17.830\n INFORMATION: This is an info message.\n 2020-09-12 11:41:17.830\n WARNING: This is a warning.\n 2020-09-12 11:41:17.830\n ERROR: This is an error.\n I have a few questions and suggestions:\n\n Should we consider not outputting a blank line by default, that is, setting add_line = .false. in the derived type definition? Then if a blank line is desired, the user can call logger % configure(add_line=.true.) to enable the blank line output. So, which one is the preferred default? Mine is to not include it.\n\n I suggest we rename logger_t % add_line component and argument to logger_t % configure to add_blank_line, for clarity.\n\n I suggest that by default we output everything on a single line, for example:\n\n $ ./test\n INFORMATION 2020-09-12 11:41:17.830: This is an info message.\n WARNING 2020-09-12 11:41:17.830: This is a warning.\n ERROR 2020-09-12 11:41:17.830: This is an error.\n Rationale: If you have multiple loggers writing in parallel to stdout and/or stderr, then their outputs could get enmeshed and corrupt the log. For example, you could get:\n\n $ ./test\n 2020-09-12 11:41:17.830\n 2020-09-12 11:41:17.830\n 2020-09-12 11:41:17.830\n WARNING: This is a warning.\n ERROR: This is an error.\n INFORMATION: This is an info message\n\n which is not a big deal in this trivial example, but it gets worse for larger programs and multiple loggers.\n\n Personal style preference: I don't have a rational explanation for this, but it feels the cleanest to me if one procedure call outputs one and only one line.\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#228 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOSFYMHC3LNG2AXSRKDSFOLBBANCNFSM4QSNH5WA>."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-12 17:29:46+00:00",
                    "text": "Seems reasonable to me.\n\u2026\n On Sep 12, 2020, at 10:01 AM, Milan Curcic ***@***.***> wrote:\n\n\n Another suggestion that is mostly aesthetic and personal preference: Default to INFO and WARN instead of INFORMATION and WARNING. I think both INFO and WARN are unambiguous and clear about what they mean, and they would reduce the amount of overflow of some long logs to the second line.\n\n INFO 2020-09-12 11:41:17.830: This is an info message.\n WARN 2020-09-12 11:41:17.830: This is a warning.\n ERROR 2020-09-12 11:41:17.830: This is an error.\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#228 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOWGXB275YT26OEXCF3SFOLNHANCNFSM4QSNH5WA>."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-12 17:51:07+00:00",
                    "text": "It requires a complete rewrite of some of the code.\n\nI thought so. We don't need to worry about it for now. If this shows to be highly requested by the users, we can revisit it.\n\nCertainly the whole idea of formatting to fit into a maximum column width becomes problematic.\n\nYes, max. column width is relevant if the user explicitly wants multi-line logs.\n\nNote for example that the add_log_file doesn\u2019t currently allow adding the asynchronous specifier to the open statement.\n\nYes, but this issue comes up in any parallel program (MPI or coarrays) that would log to standard I/O streams. Perhaps for now we can simply recommend that for logging parallel applications, users should log from each process to a dedicated file. This is also a common approach in large applications and frameworks I work with (WRF, ESMF).\n\nHow does your opinion change if the user also outputs the module and procedure names?\n\nIt does not. If a user (like me) insists on single-line logs, they are okay with lines getting very long. I don't feel gung ho about it though. We can move forward and revisit if people ask for it."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-13 00:54:29+00:00",
                    "text": "Based on this recent exchange I am going to do the following:\n\nChange logger_t to logger_type\nChange add_line to add_blank_line\nChange the initial value of add_blank_line to be .false.\nChange the initial value of max_columns to be 0 so by default no formatting is done.\nChange the labeling to \"WARN\" and \"INFO\"\n\nThings to think about doing:\n\nAdd asynchronous argument to add_log_file\nAdd prefix or label argument to log_message so changes in formatting can be localized tp log_message"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-13 14:01:10+00:00",
                    "text": "Before I change the labeling to WARN and INFO should I also change log_warning and log_information to log_warn and log_info?"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-13 16:29:18+00:00",
                    "text": "Some of my recent changes have initially failed verification, apparently because I didn't update the testing as the same time as I changed the main source code. Is there a way to update them simultaneously?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-16 12:50:31+00:00",
                    "text": "I played a bit with this PR. In general I am pleased with this PR. When the name of a procedure is provided, here is the output:\nN/A % TEST_STDLIB_LOGGER\nWARNING: Test warning\n\nFor similar reasons as @milancurcic, I would prefer both on one line, e.g.,\nN/A % TEST_STDLIB_LOGGER: WARNING: Test warning\n\nLooking to the code, I think it could be easily implemented (in opposition to date and time). However, if I am the only one with this remark, it can stay like that."
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-16 13:19:54+00:00",
                    "text": "Looking to the code, I think it could be easily implemented (in opposition to date and time). However, if I am the only one with this remark, it can stay like that.\n\nI agree, the one-liner output should be the default, multi-line logs exists (example here) however they aren't so common IMHO."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-16 13:50:37+00:00",
                    "text": "So the consensus seems to be to strive for one line. I think also putting date and time on the one line is straightforward. This prompts the following questions:\n\nWhat should be first in the line: date and time or module and procedure?\nShould WARNING and INFORMATION be shortened to WARN and INFO as requested by Milan to shorten the line?\nIf the above is done should log_warning and log_information be shortened to log_warn and log_info?\nShould I continue to output stat, errmsg, iostat, and iomsg as separate lines? If not how should I format them?"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-16 13:59:51+00:00",
                    "text": "In my opinion a single line is much clearer - it is much easier to select\nthe messages that are relevant then. As for your questions:\nad 1.\nMy preference would be date+time and then module/procedure. At least that\nis the sort of logging I see most of the time\nad 2.\nYes, shorten it. It also has the advantage that both keywords have the\nlength (with a fixed-width font), so that things are automatically aligned\nvertically\nad 3.\nI lean to the full name here :).\nad 4.\nI will leave that to others - but one line has my preference.\n\n\nOp wo 16 sep. 2020 om 15:50 schreef William B. Clodius <\nnotifications@github.com>:\n\u2026\n So the consensus seems to be to strive for one line. I think also putting\n date and time on the one line is straightforward. This prompts the\n following questions:\n\n    1. What should be first in the line: date and time or module and\n    procedure?\n    2. Should WARNING and INFORMATION be shortened to WARN and INFO as\n    requested by Milan to shorten the line?\n    3. If the above is done should log_warning and log_information be\n    shortened to log_warn and log_info?\n    4. Should I continue to output stat, errmsg, iostat, and iomsg as\n    separate lines? If not how should I format them?\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#228 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR4RYNTKD64DJYFQMBLSGC7EBANCNFSM4QSNH5WA>\n ."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-16 14:22:26+00:00",
                    "text": "What should be first in the line: date and time or module and procedure?\n\n\nI would prefer first \"date-time\" followed by \"module/procedures\" names.\n\n\nShould WARNING and INFORMATION be shortened to WARN and INFO as requested by Milan to shorten the line?\n\n\nYes, I prefer WARN and info.\n\n\nIf the above is done should log_warning and log_information be shortened to log_warn and log_info?\n\n\nlog_warn sounds strange to me. Therefore, I am in favor of log_warning and log_information.\n\n\nShould I continue to output stat, errmsg, iostat, and iomsg as separate lines? If not how should I format them?\n\n\nI would prefer on one line. But if a link can be drawn between the main line and these separate lines, I think it would be fine for me."
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-16 15:53:29+00:00",
                    "text": "What should be first in the line: date and time or module and procedure?\n\n\nIt seems we have a consensus about the date-time being in front by default. A further enhancement could be let the user include a custom format string (this is kinda related with #19 ).\n\n\nShould WARNING and INFORMATION be shortened to WARN and INFO as requested by Milan to shorten the line?\n\n\nI like the shorter versions too, WARN and INFO.\n\n\nIf the above is done should log_warning and log_information be shortened to log_warn and log_info?\n\n\nI think log_warning it's better than log_warn but did the community considered/discussed about calling it global_logger % warn (global_logger % <verb>) instead of global_logger % log_warning? The logger-log thing sounds weird.\n\n\nShould I continue to output stat, errmsg, iostat, and iomsg as separate lines? If not how should I format them?\n\n\nSince they are exceptional cases (and could lead to a lengthy string) adding it with a new_line would be better IMO."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-16 19:04:07+00:00",
                    "text": "What should be first in the line: date and time or module and procedure?\nShould WARNING and INFORMATION be shortened to WARN and INFO as requested by Milan to shorten the line?\nIf the above is done should log_warning and log_information be shortened to log_warn and log_info?\nShould I continue to output stat, errmsg, iostat, and iomsg as separate lines? If not how should I format them?\n\n\nI agree with @arjenmarkus on all 4 points."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-16 19:05:02+00:00",
                    "text": "Since there seems to be a consensus I am in the process of changing the code and documentation as follows:\n\nChanging 'INFORMATION: ' and 'WARNING: ' to 'INFO: ' and 'WARN: '\nAdd a prefix argument to log_message so the prefixes 'ERROR', 'INFO', 'I/O ERROR', and 'WARN' can add color formatting later if desired\nChange log_message so all the information (outside of stat, errmsg, iostate, and iomsg) is output as one line.\nPolish up the comments in the source code so they are simpler and describe the new structure\nUpdate the documentation in stdlib_logger.md so they reflect the changes.\nUpdate test_stdlib_logger.f90 so its running description of the outputs is accurate.\n\nI am thinking of adding a suffix argument to log_message fo deal with stat, errmsg, iostate, and iomsg"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-16 20:29:07+00:00",
                    "text": "I have implemented the planned changes 1-6. Let me know what you think of the new format, and feel free to update the code, comments, and documentation."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-18 06:18:18+00:00",
                    "text": "I have implemented the planned changes 1-6. Let me know what you think of the new format, and feel free to update the code, comments, and documentation.\n\nThank you for these changes. I will test this new version during the next days."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-18 16:25:17+00:00",
                    "text": "@wclodius2 thanks a lot for the great work, I will play with it this weekend and report back. I think we're approaching home stretch."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-19 15:52:46+00:00",
                    "text": "@wclodius2 Minor style nit-pick: Would you object to slightly different use of blank lines in if-blocks and do-loops. For example, instead of this:\n        if ( present(prefix) ) then\n            pref = prefix // ': '\n\n        else\n            pref = ''\n\n        end if\n\n        if ( self % time_stamp ) then\n            d_and_t = time_stamp() // ': '\n\n        else\n            d_and_t = ''\n\n        end if\nwould you object if we did this?\n        if ( present(prefix) ) then\n            pref = prefix // ': '\n        else\n            pref = ''\n        end if\n\n        if ( self % time_stamp ) then\n            d_and_t = time_stamp() // ': '\n        else\n            d_and_t = ''\n        end if\nThis way, the blank line can be used to more easily distinguish between 2 if-blocks. If you agree, I can tackle this."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-19 16:39:18+00:00",
                    "text": "Its a lot of code to change, but if you think it is useful go ahead.\n\u2026\n On Sep 19, 2020, at 9:52 AM, Milan Curcic ***@***.***> wrote:\n\n\n @wclodius2 <https://github.com/wclodius2> Minor style nit-pick: Would you object to slightly different use of blank lines in if-blocks and do-loops. For example, instead of this:\n\n         if ( present(prefix) ) then\n             pref = prefix // ': '\n\n         else\n             pref = ''\n\n         end if\n\n         if ( self % time_stamp ) then\n             d_and_t = time_stamp() // ': '\n\n         else\n             d_and_t = ''\n\n         end if\n would you object if we did this?\n\n         if ( present(prefix) ) then\n             pref = prefix // ': '\n         else\n             pref = ''\n         end if\n\n         if ( self % time_stamp ) then\n             d_and_t = time_stamp() // ': '\n         else\n             d_and_t = ''\n         end if\n This way, the blank line can be used to more easily distinguish between 2 if-blocks. If you agree, I can tackle this.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#228 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOSIIRAT4YOELYMF66DSGTHVXANCNFSM4QSNH5WA>."
                },
                {
                    "user": "certik",
                    "date": "2020-09-19 16:41:43+00:00",
                    "text": "I also prefer Milan's formatting.\n\u2026\nOn Sat, Sep 19, 2020, at 11:39 AM, William B. Clodius wrote:\n\n\n Its a lot of code to change, but if you think it is useful go ahead.\n\n > On Sep 19, 2020, at 9:52 AM, Milan Curcic ***@***.***> wrote:\n >\n >\n > @wclodius2 <https://github.com/wclodius2> Minor style nit-pick: Would you object to slightly different use of blank lines in if-blocks and do-loops. For example, instead of this:\n >\n > if ( present(prefix) ) then\n > pref = prefix // ': '\n >\n > else\n > pref = ''\n >\n > end if\n >\n > if ( self % time_stamp ) then\n > d_and_t = time_stamp() // ': '\n >\n > else\n > d_and_t = ''\n >\n > end if\n > would you object if we did this?\n >\n > if ( present(prefix) ) then\n > pref = prefix // ': '\n > else\n > pref = ''\n > end if\n >\n > if ( self % time_stamp ) then\n > d_and_t = time_stamp() // ': '\n > else\n > d_and_t = ''\n > end if\n > This way, the blank line can be used to more easily distinguish between 2 if-blocks. If you agree, I can tackle this.\n >\n > \u2014\n > You are receiving this because you were mentioned.\n > Reply to this email directly, view it on GitHub <#228 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOSIIRAT4YOELYMF66DSGTHVXANCNFSM4QSNH5WA>.\n >\n\n \u2014\n You are receiving this because your review was requested.\n Reply to this email directly, view it on GitHub\n <#228 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWHKBOGSIVN6DHRLJJLSGTNEHANCNFSM4QSNH5WA>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-19 21:47:19+00:00",
                    "text": "I commited several changes such that FORD generates links from the specs to the code (and vice versa).\nThere are still a few changes (editing/formating of the examples) that need to be discussed and commited.\nOtherwise, for me, it is almost good to be merged. Thanks @wclodius2 for this work and PR."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-20 16:49:02+00:00",
                    "text": "I think I have committed all outstanding suggestions by @jvdp1 (Thank you!).\nConsidering the size of this PR and small number of reviewers, let's leave it open for another week or so before merging."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-20 17:15:17+00:00",
                    "text": "Considering the size of this PR and small number of reviewers, let's leave it open for another week or so before merging.\n\nI agree. I think it would be good to discuss it during the next monthly call."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-22 17:22:43+00:00",
                    "text": "I have needed a breather, and you two have also put in a lot of useful work. One additional change I have thought of  doing is to  add an optional suffix argument so that stat, instate, errmsg, and iomsg can be output as part  of one single write statement. However while they would be part of one write statement they would be output as separate lines using the new_line function. But I can put that off if you want. FWIW I intend to attend the monthly call this Friday."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-23 19:01:27+00:00",
                    "text": "I have needed a breather, and you two have also put in a lot of useful work. One additional change I have thought of doing is to add an optional suffix argument so that stat, instate, errmsg, and iomsg can be output as part of one single write statement. However while they would be part of one write statement they would be output as separate lines using the new_line function.\n\nThis could solve indeed some potential issues with parallel programming. This proposition would be more robust IMO.\nAnyway, I am happy with the actual code, and this option could be added in a next PR."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-28 15:53:46+00:00",
                    "text": "If there are no objections, I'll merge this tomorrow into master.\nIf anybody would like more time to review, just write here."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-28 21:36:24+00:00",
                    "text": "Answering each of the points;\n\n* Good\n\n* I have trouble seeing the usefulness of a low level API, for a logger. FWIW the loggers in FLIBS, Futility, SLATEC, and Python are all higher level than what you describe.\n\n* I have trouble interpreting \u201cwrite all logs into a string\u201d. What functionality do you see over redirecting standard output?\n  - Do you mean all logs into a single string? With Fortran\u2019s concatenation semantics that can be O(N**2), though with growable strings doubling when necessary, I guess that could be O(N ln N).\n  - Do you mean each log command into its own string? Easily do able, but I don\u2019t see the use.\n  - Do you mean each log to a list of strings, to be concatenated on demand?\n\n* FWIW Python,,does have a logger, https://docs.python.org/3/library/logging.html <https://docs.python.org/3/library/logging.html>. It is impractical to do its \u201cchild\u201d hierarchy in Fortran. we could add the option of turning off output depending on the error level: error > warning > info.\n\u2026\n On Sep 28, 2020, at 10:04 AM, Ond\u0159ej \u010cert\u00edk ***@***.***> wrote:\n\n\n @certik approved this pull request.\n\n Here is my review:\n\n Overall I am fine with merging as is.\n\n This is what I would consider a high level API. If there is demand, we can provide a low level API that does not use a derived type, thus passing all configuration as arguments. In this case such low level API might not be as useful.\n\n Does this design allow to extend it in the future to write all logs into a string? That would be helpful for things like interactive usage in a Jupyter notebook, to send all logs over it it from the kernel.\n\n I don't have an opinion on the more general issue of: unlike some of the other functionality in stdlib, such as statistics, linear algebra, special functions etc. where there is a lot of prior art (in scipy, matlab, etc.) regarding their API, this logger API is in some sense designed in this PR. As such, it is not clear this is the best design, and it doesn't have usage yet. Down the road, for such new APIs, it might make sense to implement them as fpm packages first. And only later \"standardize\" in stdlib. However, at the same time, this logger API is experimental. So I think there is no harm including it also, with the understanding that the API might change in the future as we gain experience using it.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#228 (review)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOVABFA7ICC5ZRO7NU3SICX2NANCNFSM4QSNH5WA>."
                },
                {
                    "user": "certik",
                    "date": "2020-09-28 22:53:53+00:00",
                    "text": "I agree a lower level API might not be useful.\nRegarding saving to a string, Python has a concept of Handlers: https://docs.python.org/3/howto/logging.html#useful-handlers, which allow to specify where the log messages are being written. You might decide to send them over a network, or do something else with them, and use standard output separately. So you cannot just redirect a standard output. The best interface would be to provide a user call back every time a message is written. That way users can overwrite this and do whatever they want."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-28 23:33:11+00:00",
                    "text": "What could be done for \"handlers\" is define for the logger_type an internal array of procedure pointers with an interface say\ninterface\n    subroutine logger_handle( string )\n        character(*), intent(in) :: string\n    end subroutine logger_handler\nend interface\n\nor define an array of class handler with a method\ninterface\n    subroutine logger_handle( handle, string )\n        class(handler), intent(in) :: handle\n        character(*), intent(in) :: string\n    end subroutine logger_handler\nend interface"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-29 14:40:13+00:00",
                    "text": "Merging, thank you all and especially @wclodius2!"
                }
            ]
        },
        {
            "number": 227,
            "user": "wclodius2",
            "date": "2020-08-07 22:56:33+00:00",
            "title": "Develop an API for a STDLIB logging system",
            "text": "It is common for a library of code to have the equivalent of one or more error logging modules. SLATEC has its XERROR codes, Futility has its ExceptionHandler.f90 and FileTypeLog.f90, and FLIBS has its reporting, m_logger, m_multilog, and m_exception modules. I propose that STDLIB have its own logger module that I propose naming STDLIB_LOGGER. I propose that the logger have options to:\n\nbe able to send the same text to multiple logical units;\nbe able to configure which units receive the text;\nby default have one of those units be one of OUTPUT_UNIT or ERROR_UNIT;\nprecede messages by a blank line;\nprecede messages by a time stamp of the form yyyy-mm-dd hh:mm:ss.sss;\nprecede a message with module and procedure names;\nfollow a message with the STAT and ERRMSG of the statement that prompted the log message;\nfollow a message with the IOSTAT and IOMSG of the I/O statement that prompted the log message;\nlabel a message with one of 'INFORMATION: ', 'WARNING: ', or 'ERROR: ';\nindent subsequent lines of the messages; and\nformat the text to fit within a maximum column width.\n\nThe maximum number of logical units to be supported at one time is a minimum of two: one of either OUTPUT_UNIT or ERROR_UNIT and an additional formatted file, but by using an array of logical units it should be possible to support more, such as the five supported by SLATEC's XERROR. While the initial implementation will use Fortran's standard file interface through logical units, I hope to hide enough of the details that wrappers to the logical units can be deployed if desired. The above proposal prompts the following questions:\n\nIs the general outline of the proposal a good one?\nIs STDLIB ready for such a proposal at this time?\nWhich should be the default logical unit for the logger: OUTPUT_UNIT or ERROR_UNIT?\nShould you be able to output to both OUTPUT_UNIT and ERROR_UNIT at the same time?\nHow many output units should be supported at one time?\nShould output of the labels be determined by the name of the procedure, e.g., LOG_ERROR, LOG_WARNING, and LOG_INFO, or by a flag?\nAre there any other questions I am missing?",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-08-10 22:31:39+00:00",
                    "text": "Thank you @wclodius2. Note #193.\n\nIs the general outline of the proposal a good one?\n\nI think so.\n\nIs STDLIB ready for such a proposal at this time?\n\nYes. There may not be as much excitement or intense discussion on the topic as you'd like, but we should still go forward with it and iterate as issues come up.\n\nWhich should be the default logical unit for the logger: OUTPUT_UNIT or ERROR_UNIT?\n\nI think stdout should be default.\n\nShould you be able to output to both OUTPUT_UNIT and ERROR_UNIT at the same time?\n\nYes.\n\nHow many output units should be supported at one time?\n\nAs I understand it, it seems to me the choice is between 1 and as many as you want, depending on the implementation. Multiple loggers in the same application seems like it'd be useful for multi-component programs.\n\nShould output of the labels be determined by the name of the procedure, e.g., LOG_ERROR, LOG_WARNING, and LOG_INFO, or by a flag?\n\nThis seems like a matter of style. Personally I think having separate procedures log_error(), log_warning(), and log_info() makes for a nicer and easier to learn API. They can be just thin wrappers around a generic log() to avoid duplication of code.\nLet's discuss it on our call next week: https://fortran-lang.discourse.group/t/fortran-monthly-call-august-2020"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-20 04:54:36+00:00",
                    "text": "The tentative API I have developed is described below.\nThe module STDLIB_LOGGER\nIntroduction\nThis module defines procedures to be used for reporting by the Fortran\nStandard Library of errors and other information. The reportsnormally\ngo to formatted files represented by the array of logical unit,\nLOG_UNITS. An arbitrary number of log units can be open at a\ntime. LOG_UNITS may be associated with files dedicated to\nSTDLIB_LOGGER or may be associated with previously opened files. If\nLOG_UNITS is empty then the output goes to OUTPUT_UNIT of\nISO_FORTRAN_ENV.\nThe logger has the options to:\n\nchange which units receive the log messages;\nreport which units recieve the log messages;\nprecede messages by a blank line;\nprecede messages by a time stamp of the form\nyyyy-mm-dd hh:mm:ss.sss;\nprecede messages with the names of a module and procedure;\nfollow a message with the STAT and ERRMSG of the error report\nthat prompted the log message;\nfollow a message with the IOSTAT and IOMSG of the I/O error\nreport that prompted the log message;\nlabel a message with one of 'INFORMATION: ', 'WARNING: ', or\n'ERROR: ';\nindent subsequent lines of the messages; and\nformat the text to fit within a maximum column width.\n\nThe STDLIB_LOGGER constants\nThe module defines seven distinct named integer constants for\nreporting errors in STAT arguments. SUCCESS,\nINVALID_INDEX_ERROR, OPEN_FAILURE, READ_ONLY_ERROR,\nSEQUENTIAL_ACCESS_ERROR, UNFORMATTED_IN_ERROR, and\nUNOPENED_IN_ERROR. SUCCESS indicates that no\nerror has occurred. INVALID_INDEX_ERROR indicates that\nSTART_INDEX was invalid for the given LINE. OPEN_FAILURE\nindicates that an OPEN statement failed. READ_ONLY_ERROR indicates\nthat an output unit did not have a WRITE or READWRITE\naction. SEQUENTIAL_ACCESS_ERROR indicates that the unit did not have\nSEQUENTIAL access. UNFORMATTED_IN_ERROR indicates that the unit\ndid not have a FORM of FORMATTED. Finally, UNOPENED_IN_ERROR\nindicates that the unit was not opened.\nThe STDLIB_LOGGER module procedures\nOverview of the procedures\nThe module defines thirteen public procedures: one function and twelve\nsubroutines. The one function is an inquiry function:\nLOG_UNITS_ASSIGNED\n: verifies whether LOG_UNITS has been assigned one or more logical\nunits.\nThere are three subroutines for manipulating LOG_UNITS:\nADD_LOG_FILE\n: opens a file using NEWUNIT, and adds the resulting logical unit\nnumber to the LOG_UNITS list.\nADD_LOG_UNIT\n: adds an existing logical unit number to the LOG_UNITS list.\nREMOVE_LOG_UNIT\n: remove the UNIT from th LOG_UNITS array and optionally closes\nit.\nThere are seven subroutines for sending messages to the LOG_UNITS:\nASSERT\n: tests a logical condition and if .FALSE. sends a log\nmessage and stops processing.\nLOG_ERROR\n: sends a message prepended by 'ERROR: ' optionally followed by a\nSTAT or ERRMSG or both.\nLOG_INFORMATION\n: sends a message prepended by 'INFORMATION: '\nLOG_IO_ERROR\n: sends a message prepended by 'I/O ERROR: 'optionally followed by\nan IOSTAT or IOMSG or both.\nLOG_MESSAGE\n: sends a message.\nLOG_TEXT_ERROR\n: sends a message describing an error found in a line of text.\nLOG_WARNING\n: sends a message prepended by 'WARNING: '.\nThere is one subroutine for configuring the logger:\nCONFIGURE_LOGGING\n: configures the details of the logging process.\nThere is one subroutine for reporting the details of the logging\nconfiguration.\nLOGGING_CONFIGURATION\n: reports the details of the logging configuration."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-08-20 14:34:18+00:00",
                    "text": "Thank you, @wclodius2. Can you make it to the call today? https://fortran-lang.discourse.group/t/fortran-monthly-call-august-2020/260/2\nIt'd be good to discuss it live and get a temperature on what people think about it."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-20 16:54:12+00:00",
                    "text": "I will try to make it, but it will be my first zoom.\n\u2026\n On Aug 20, 2020, at 8:34 AM, Milan Curcic ***@***.***> wrote:\n\n\n Thank you, @wclodius2 <https://github.com/wclodius2>. Can you make it to the call today? https://fortran-lang.discourse.group/t/fortran-monthly-call-august-2020/260/2 <https://fortran-lang.discourse.group/t/fortran-monthly-call-august-2020/260/2>\n It'd be good to discuss it live and get a temperature on what people think about it.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#227 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOUK2QYUIXG2IYODA5TSBUX7TANCNFSM4PYCWD2Q>."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-20 21:04:34+00:00",
                    "text": "Given that the response seemed positive at the call I will now proceed. Next should be a detailed outline of the proposed API, followed by an implementation of any changes in the API, then testing, then a checkout of the STDLIB source, and then a PR for the implementation and tests. What follows is a detailed summary of the procedures in a form that parallels the format used in the standard. Possible sources of controversy are:\n\nthe lack of STAT arguments for most of the LOG_* subroutines,\nthe use of the language keywords, MODULE and PROCEDURE, as arguments to the LOG_* and ASSERT subroutines,\nthe presence of the ASSERT subroutine,\nthe number of LOG_* subroutines,\nthe use of MESSAGE as an argument rather than the shorter MSG,\nthe presence of the LOG_TEXT_ERROR subroutine, and\nthat the INDENT argument of the configuration routines is a logical argument and not a numeric one\n\nMy response to the above are\n\nThe only obvious source of problems with the LOG_* routines is a failure with the WRITE statements. I don't know of a good way of handling such an error in the error reporting routines.\nThey seemed the most obvious names for their intended semantics. MODULE_NAME, and PROCEDURE_NAME seemed too wordy, MOD had a similar conflict with the Standard's intrinsic function.\nIt seemed useful and appropriate\nAll of them seemed useful\nI have no strong feelings on this\nIt seemed useful to me\nI have no strong feelings on this.\n\nSpecification of the Procedures\nADD_LOG_FILE( FILENAME, UNIT [, ACTION, POSITION, STATUS, STAT ] )\nDescription. Sets FILENAME to be a file in LOG_UNITS and\nreturns the associated I/O unit number, UNIT. The file will be a\nformatted sequential access file. STAT, if present, has the value\nSUCCESS if FILENAME could be opened, and OPEN_FAILURE\notherwise. If STAT is absent and FILENAME could not be opened then\nprocessing will stop with a write to LOG_UNITS.\nClass. Subroutine\nArguments.\nFILENAME shall be a scalar default CHARACTER expression. It is\nan INTENT(IN) argument. It shall be the name of the file to be\nopened,\nUNIT shall be a scalar default INTEGER variable. It is an\nINTENT(OUT) argument. It will be the unit number returned by the\nNEWUNIT specifier of the OPEN statement for FILENAME.\nACTION (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It shall be the ACTION\nspecifier of the OPEN statement and must have one of the values\n'WRITE' or 'READWRITE'. It has the default value of 'WRITE'.\nPOSITION (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It shall be the\nPOSITION specifier of the OPEN statement and must have one of\nthe values 'ASIS', 'REWIND', or 'APPEND'. It has the default\nvalue of 'REWIND'.\nSTATUS (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It shall be the\nSTATUS specifier of the OPEN statement and must have one of\nthe values 'OLD', 'NEW', 'REPLACE', or 'UNKNOWN'. It has the\ndefault value of 'REPLACE'.\nSTAT (optional) shall be a scalar default INTEGER variable. It\nis an INTENT(OUT) argument. If present, on return it will have the\nvalue SUCCESS if FILENAME could be opened, or the value\nOPEN_FAILURE if it could not be opened. If absent and FILENAME\ncould not be opened then processing will stop with amessage to\nLOG_UNITS.\nADD_LOG_UNIT( UNIT [, STAT ] )\nDescription Adds UNIT to the array of LOG_UNITS. UNIT shall\nbe the UNIT number for an opened, sequential, formatted file with an\naction specifier of WRITE or READWRITE. Failure of UNIT to meet\nthose requirements will result cause STAT, if present, to not be\nSUCCESS and UNIT not to be added to LOG_UNITS, or, if STAT is\nnot present, cause processing to stop with an informative string as\nthe stop code.\nClass. Subroutine.\nArguments.\nUNIT shall be a scalar default INTEGER expression. It is an\nINTENT(IN) argument. It shall be the UNIT number for an opened,\nsequential, formatted file with an action specifier of WRITE or\nREADWRITE.\nSTAT (optional) shaa be a scalar default INTEGER variable. It is\nan INTENT(OUT) argument. If present it will have the value of one\nof the module's integer constants indicating any errors found with\nUNIT. The constants are\n\nSUCCESS - no problems found\nREAD_ONLY_ERROR - UNIT had an ACTION specifier of 'READ'\nwhen it needs a specifier of 'WRITE' or 'READWRITE'\nSEQUENTIAL_ACCESS_ERROR - UNIT did not have an ACCESS of\nSEQUENTIAL\nUNFORMATTED_IN_ERROR - UNIT did not have a FORM of\nFORMATTED\nUNOPENED_IN_ERROR - UNIT was not opened\n\nASSERT( TEST, MESSAGE [, MODULE, PROCEDURE ] )\nDescription. Checks the value of TEST and if TEST is\n.FALSE. writes output to the LOG_UNITS and stops processing,\notherwise it returns with no effect.\nBehavior. If TEST is .FALSE. ASSERT will write to\nLOG_UNITS, otherwise nothing is written. If time stamps are active\nthen the time stamp will be written first. Then if MODULE and\nPROCEDURE are present then they will be written. Finally MESSAGE,\nwill be written prepended by the string 'ASSERTION FAILURE: '.\nClass. Subroutine.\nArguments.\nTEST shall be a scalar default LOGICAL expression. It is an\nINTENT(IN) argument.\nMESSAGE shall be a scalar default CHARACTER expression. It is an\nINTENT(IN) argument. Normally it is a representation of TEST.\nMODULE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe module containing the ASSERT call.\nPROCEDURE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe procedure containing the ASSERT call.\nCONFIGURE_LOGGING( [ ADD_LINE, INDENT, MAX_WIDTH, TIME_STAMP ] )\nDescription. Configures the logging process.\nClass. Subroutine.\nArguments.\nADD_LINE (optional) shall be a scalar default LOGICAL\nexpression. It is an INTENT(IN) argument. Set to .TRUE. to start\noutput with a blank line, and to .FALSE. otherwise. ADD_LINE has\na default value of .TRUE..\nINDENT (optional) shall be a scalar default LOGICAL\nexpression. It is an INTENT(IN) argument. Set to .TRUE. to\nindent subsequent lines by four spaces, and to .FALSE.\notherwise. INDENT has a default value of .TRUE..\nMAX_WIDTH (optional) shall be a scalar default INTEGER\nexpression. It is an INTENT(IN) argument. Set to a positive value\nbigger than four to define the maximum width of the output,\notherwise there is no maximum width. MAX_WIDTH has a default value\nof 80.\nTIME_STAMP (optional) shall be a scalar default LOGICAL\nexpression. It is an INTENT(IN) argument. Set to .TRUE. to\nprecede output with a time stamp of the form 'yyyy-mm-dd\nhh:mm:ss.sss', and to .FALSE. otherwise.  TIME_STAMP has a\ndefault value of .TRUE..\nLOG_ERROR( MESSAGE [, MODULE, PROCEDURE, STAT, ERRMSG ] )\nDescription. Writes the string MESSAGE to LOG_UNITS with\noptional additional text.\nBehavior. If time stamps are active, a time stamp is written\nfirst. Then if MODULE or PROCEDURE are present, they are\nwritten. Then MESSAGE is written with the prefix 'ERROR: '. Then\nif STAT or ERRMSG are present they are written.\nClass. Subroutine.\nMESSAGE shall be a scalar default CHARACTER expression. It is an\nINTENT(IN) argument.\nMODULE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe module containing the LOG_ERROR call.\nPROCEDURE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe procedure containing the LOG_ERROR call.\nSTAT (optional) shall be a scalar default INTEGER expression. It\nis an INTENT(IN) argument. It should be the STAT specifier of\nthe subroutine call or intrinsic statement that prompted the\nLOG_ERROR call.\nERRMSG (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the\nERRMSG specifier of the subroutine call or intrinsic statement\nthat prompted the LOG_ERROR call.\nLOG_INFORMATION( MESSAGE [, MODULE, PROCEDURE ] )\nDescription. Writes the string MESSAGE to LOG_UNITS with\noptional additional text.\nBehavior. If time stamps are active, a time stamp is written\nfirst. Then if MODULE or PROCEDURE are present, they are\nwritten. Then MESSAGE is written with the prefix\nINFORMATION: '.\nClass. Subroutine.\nMESSAGE shall be a scalar default CHARACTER expression. It is an\nINTENT(IN) argument.\nMODULE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe module containing the LOG_INFORMATION call.\nPROCEDURE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe procedure containing the LOG_INFORMATION call.\nLOG_IO_ERROR( MESSAGE [, MODULE, PROCEDURE, IOSTAT, IOMSG ] )\nDescription. Writes the string MESSAGE to LOG_UNITS with\noptional additional text.\nBehavior. If time stamps are active, a time stamp is written\nfirst. Then if MODULE or PROCEDURE are present, they are\nwritten. Then MESSAGE is written with the prefix\n'I/O ERROR: '. Then if IOSTAT or IOMSG are present they are\nwritten.\nClass. Subroutine.\nMESSAGE shall be a scalar default CHARACTER expression. It is an\nINTENT(IN) argument.\nMODULE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe module containing the LOG_IO_ERROR call.\nPROCEDURE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe procedure containing the LOG_IO_ERROR call.\nIOSTAT (optional) shall be a scalar default INTEGER\nexpression. It is an INTENT(IN) argument. It should be the\nIOSTAT specifier of the subroutine call or intrinsic statement\nthat prompted the LOG_IO_ERROR call.\nIOMSG (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the\nIOMSG specifier of the subroutine call or intrinsic statement\nthat prompted the LOG_IO_ERROR call.\nLOG_MESSAGE( MESSAGE [, MODULE, PROCEDURE ] )\nDescription. Writes the string MESSAGE to LOG_UNITS with\noptional additional text.\nBehavior. If time stamps are active, a time stamp is written\nfirst. Then if MODULE or PROCEDURE are present, they are\nwritten. Then MESSAGE is written with no prefix.\nClass. Subroutine.\nMESSAGE shall be a scalar default CHARACTER expression. It is an\nINTENT(IN) argument.\nMODULE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe module containing the LOG_MESSAGE call.\nPROCEDURE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe procedure containing the LOG_MESSAGE call.\nLOG_TEXT_ERROR( LINE, COLUMN, DESCRIP [, FILENAME, LINE_NUMBER, STAT ] )\nDescription. LOG_TEXT_ERROR sends a message to LOG_UNITS\ndescribing an error found in a line of text.\nBehavior. If time stamps are active first a time stamp is\nwritten. Then if FILENAME or LINE_NUMBER are present they are\nwritten. Then if LEVEL is present a string is written indicating the\nlevel of the error. Then LINE is written. Then a caret, '^', is\nwritten below LINE at the column indicated by COLUMN. Then\nDESCRIP is written below the caret.\nClass. Subroutine.\nArguments.\nLINE shall be a scalar default CHARACTER expression. It is an\nINTENT(IN) argument. It should be the line of text in which the\nerror was found.\nCOLUMN shall be a scalar default INTEGER expression. It is an\nINTENT(IN) argument. It should be the one's based column at which\nthe error location begins.\nDESCRIP shall be a scalar default CHARACTER expression. It is an\nINTENT(IN) argument. It should be the description of the error in\nLINE.\nFILENAME (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe file, if any, in which LINE was found.\nLINE_NUMBER (optional) shall be a scalar default INTEGER\nexpression. It is an INTENT(IN) argument. It should be the line\nnumber in FILENAME associated with LINE.\nSTAT (optional) shall be a scalar default CHARACTER variable. It\nis an INTENT(OUT) argument. If present will have the value of\nSUCCESS if no errors were encountered, the value\nINDEX_INVALID_ERROR if COLUMN is less than one or greater than\nLEN(LINE)+1, or the value WRITE_FAULT if the writes to any of\nLOG)UNITS failed. If STAT is absent and would not have the value\nSUCCESS then processing will stop with an informative message.\nLOG_UNITS_ASIGNED()\nDescription. Returns .TRUE. if LOG_UNITS has at least one\nlogical unit assigned and .FALSE. otherwise.\nClass. Function.\nResult Character. The result is a scalar default LOGICAL.\nResult Value. The result is .TRUE. if LOG_UNITS has at least\none logical unit assigned and .FALSE. otherwise.\nLOG_WARNING( MESSAGE [, MODULE, PROCEDURE ] )\nDescription. Writes the string MESSAGE to LOG_UNITS with\noptional additional text.\nBehavior. If time stamps are active, a time stamp is written\nfirst. Then if MODULE or PROCEDURE are present, they are\nwritten. Then MESSAGE is written with the prefix\nWARNING: '.\nClass. Subroutine.\nMESSAGE shall be a scalar default CHARACTER expression. It is an\nINTENT(IN) argument.\nMODULE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe module containing the LOG_WARNING call.\nPROCEDURE (optional) shall be a scalar default CHARACTER\nexpression. It is an INTENT(IN) argument. It should be the name of\nthe procedure containing the LOG_WARNING call.\nLOGGING_CONFIGURATION( [ ADD_LINE, INDENT, MAX_WIDTH, TIME_STAMP, LOG_UNITS ] )\nDescription. Reports the logging configuration.\nClass. Subroutine.\nArguments.\nADD_LINE (optional) shall be a scalar default LOGICAL\nvariable. It is an INTENT(OUT) argument. A value of .TRUE.\nstarts output with a blank line, and .FALSE. otherwise.\nINDENT (optional) shall be a scalar default LOGICAL variable. It\nis an INTENT(OUT) argument. A value of .TRUE. indents subsequent\nlines by four spaces, and .FALSE. otherwise.\nMAX_WIDTH (optional) shall be a scalar default INTEGER\nvariable. It is an INTENT(OUT) argument. A positive value bigger\nthan four defines the maximum width of the output, otherwise there\nis no maximum width.\nTIME_STAMP (optional) shall be a scalar default LOGICAL\nvariable. It is an INTENT(OUT) argument. A value of .TRUE.\nprecedes output with a time stamp of the form 'yyyy-mm-dd\nhh:mm:ss.sss', and .FALSE. otherwise.\nLOG_UNITS (optional) shall be a rank one allocatable array\nvariable of type default INTEGER. It is an INTENT(OUT)\nargument. On return it shall be the elements of the LOG_UNITS\narray.\nREMOVE_LOG_UNIT( UNIT [, CLOSE_UNIT ] )\nDescription. Remove UNIT from the LOG_UNITS list. If\nCLOSE_UNIT is present and .TRUE. then the corresponding file is\nclosed. If UNIT is not in LOG_UNITS then nothing is done.\nClass. Subroutine.\nArguments\nUNIT shall be a scalar default INTEGER expression. It is an\nINTENT(IN) argument. It should be one of the I/O UNIT numbers\nin LOG_UNITS. If it is not, then nothing is done.\nCLOSE_UNIT (optional) shall be a scalar default LOGICAL\nexpression. It is an INTENT(IN) argument. If .TRUE and UNIT is\nin LOG_UNITS then UNIT will be closed, otherwise the I/O UNIT\nwill be unaffected."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-08-26 17:37:38+00:00",
                    "text": "Hi @wclodius2, thank you for the detailed spec. At this time I'll only comment on the proposal of assert. Stdlib already has a subroutine check in the stdlib_error module (see docs) that has a broader but overlapping scope as your assert. So I suggest that we omit it from the logging module.\nI think you can go ahead with the PR and I will assist you with the edits and testing. The PR should also include the spec following an existing format (see examples here). It looks like you already have all the information that goes into the spec, it just needs to be re-formatted. Also, please follow the Style guide."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-29 19:22:56+00:00",
                    "text": "@milancurcic sorry for the delay. I had ben working on the BITSETS code, and wanted it to successfully compile before I put put it aside.\nI have decided to convert the logger into a derived type, logger_t, so it can be used both as a global and a local logger. It will take about a day to do the conversion. Then it will take about another day to convert and extend my testing. I will also comment out the ASSERT code.\nThe existing specs only cover procedures, and I will have to cover more than that so there will be new ground: the derived type, module defined constants, and a module variable, global_logger. My existing procedure summaries are similar in structure to the existing specs so that part should go quickly. My personal style is compatible with the Style guide, with the occasional exception of a larger use of abbreviations. However, for the logger I have only been using abbreviations which the standard uses: STAT, IOSTAT, ERRMSG, and IOMSG."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-01 00:57:29+00:00",
                    "text": "@milancurcic I have the stdlib_logger module and the test_stdlib_logger test code successfully compiling and running. The test code output is a bit messy, but so is the API it is testing so I don't see how to make it much cleaner. I think I am testing everything except the failures that result in an error stop. If testing of those is desired I will probably need a separate test code for each error stop.\nI also have a markdown document documenting the  API.\nBefore I check in the code and document I want to test it out using Cmake. I am having problems integrating Cmake and fypp. CMake out of the box cannot find fypp on my Mac. It is obvious that Cmake uses find_program to locate fypp. I find CMake documentation idiomatic, and I don't use it often enough to internalize the idioms, so I am having problems with the find_program documentation. It has too many options with too many qualifiers. Do you use a Unix environment (Linux, Mac, or BSD) and, if you do use it, how do you specify the path to fypp so that CMake can find it?"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-01 03:07:53+00:00",
                    "text": "Never mind the integrating of fypp and CMake.  Adding the appropriate directory to the PATH worked fine."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-01 19:34:16+00:00",
                    "text": "I have finished testing the code with cmake. Now how do I submit a PR for stdlib? I have tried to push the revised code but I get the error message\ngit push\nUsername for 'https://github.com': wclodius2\nPassword for 'https://wclodius2@github.com':\nremote: Permission to fortran-lang/stdlib.git denied to wclodius2.\nfatal: unable to access 'https://github.com/fortran-lang/stdlib/': The requested URL returned error: 403\nThe internet suggests that the most common cause of the 403 error is a bad password, but changing the password to something known to be bad now gives a different message :\ngit push\nUsername for 'https://github.com': wclodius2\nPassword for 'https://wclodius2@github.com':\nremote: Invalid username or password.\nfatal: Authentication failed for 'https://github.com/fortran-lang/stdlib/'\nDo you know how to fix the 403 error? FWIW I have an older fork of stdlib here, but I can't seem to merge recent changes in the source directories.  Should I upload the revised files there anyway and do a PR from there?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-01 19:40:35+00:00",
                    "text": "Hi William, yes, you need to create a new branch on your fork (wclodius2/stdlib), then open a new Pull Request from the fortran-lang/stdlib page (there will be a yellow prompt near the top).\nAs an aside, 403 means Forbidden, which indicates correct password but lack of permission to write to fortran-lang/stdlib. In your second case, the error is 401 Unauthorized. That's why you get a different answer in those two attempts."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-02 03:02:57+00:00",
                    "text": "Hi Milan. I have done a PR from my fork. The main files to concentrate on are the doc/specs/stdlib_logger.md, src/stdlib_logger.f90, and src/tests/logger/test_stdlib_logger.f90. I have also provided mods of the pertinent CMakeLists.txt and Makefile.manual files to be compatible with my fork, but I didn't know if you wanted those to be compatible with my fork,  or with the current main branch, or with whatever branch you work with. Fortunately, they are easy to modify to be compatible with what you want. I am fairly happy with the stdlib_logger.md and stdlib_logger.f90 files. I am less happy with the test_stdlib_logger.f90 file, but it does what needs to be done."
                }
            ]
        },
        {
            "number": 226,
            "user": "jvdp1",
            "date": "2020-07-28 17:50:55+00:00",
            "title": "Small fix to a md file",
            "text": "",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-07-28 18:11:56+00:00",
                    "text": "I'll merge! Really a small fix in the specs."
                }
            ]
        },
        {
            "number": 225,
            "user": "aradi",
            "date": "2020-07-26 20:34:58+00:00",
            "title": "Derived type naming convention",
            "text": "Several PRs (#201, #221, #224) wishes to introduce derived types into stdlib. We need a name convention for them. The conventions I have met in Fortran code so far, are the following ones:\n\n\nSingular noun, such as type(os_error), type(bitfield). Pro: compatible with Fortrans naming convention (e.g. type(c_ptr)). Con: You reserve a name, which would be also very natural for an instance variable, e.g. type(bitfield) :: bitfield does not work.\n\n\nPlural noun, such as type(os_errors) and type(bitfields) as suggested for example in #221.  Pro: You can give the corresponding singular name to the instance variable: type(bitfields) :: bitfield. Con: All languages I know use singular for type/class names, so it may feel strange an unnatural for stdlib-newcomers.\n\n\nSingular noun with a _t suffix, such as: type(os_error_t), type(bitfield_t). Pro: You can use the noun without the suffix as instance variable, e.g. type(bitfield_t) :: bitfield. Con: The extra _t is redundant.\n\n\nI am tending towards option 1. with the additional restriction, that derived type should always contain at least two nouns (connected by underscores). Then, the corresponding variable instance name could be still exactly the same, but without the connecting underscore, e.g. type(bit_field) :: bitfield or type(os_error) :: oserror.\nAny opinions on this?",
            "comments": [
                {
                    "user": "everythingfunctional",
                    "date": "2020-07-26 20:47:57+00:00",
                    "text": "I lean towards option 3. It may be redundant, but it helps not clutter up the namespace. It would also be consistent with what I would think would be a decent convention for using the _m suffix for modules and the _i suffix for abstract interfaces. I think there will be too many instances where coming up with a second word for the type would be very awkward/unnatural."
                },
                {
                    "user": "certik",
                    "date": "2020-07-26 21:18:54+00:00",
                    "text": "I would lean towards _t for derived types, but I don't like _m for modules.\n\u2026\nOn Sun, Jul 26, 2020, at 2:48 PM, Brad Richardson wrote:\n\n\n I lean towards option 3. It may be redundant, but it helps not clutter\n up the namespace. It would also be consistent with what I would think\n would be a decent convention for using the `_m` suffix for modules and\n the `_i` suffix for abstract interfaces. I think there will be too many\n instances where coming up with a second word for the type would be very\n awkward/unnatural.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#225 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWFEBAKDEJOQYTHSODLR5SJATANCNFSM4PIEYLMA>."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-07-26 21:41:35+00:00",
                    "text": "This is a big pet peeve of mine.  Mangling type and module names with something like _t and _m is just so dumb to me.  The only place you encounter a type name is in a type statement (or select type) where it's abundantly clear that the name is a type. Similarly, module names are only encountered in a use statement. They are pointless appendages.  True that a variable name must differ from a type name, but mindlessly mangling one so that you have great freedom in the other isn't necessary. One can be more creative about variable naming.  If you have a module that defines a bitfield type, then an actually useful name for the module is bitfield_type as it tells you what the module provides.\nPS: So I'm definitely in the option 1 camp."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-26 21:52:13+00:00",
                    "text": "I prefer 1 for the same reason as Neil."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-26 22:59:23+00:00",
                    "text": "I'm now at a keyboard so I'll elaborate more why 1.\nFirst, I do appreciate not wanting to clutter the namespace and I've had the same dilemma. However, in what scenarios would you want to name the type instance the same as the type itself? The only ones that come to mind are toy examples in tutorials or types intended to be used as singletons.\nHowever, in real-world code this is not common. Why call a string instance string, a datetime instance datetime, or a bit field instance bitfield? Types and their instances (variables) don't live in the same semantic space. Types are more abstract, their instances more concrete. If you have to argue one way or the other, you'd want the names to reflect the different semantic meaning of types and instances.\nSecond, does the value of giving the user more freedom in naming variables outweigh the cost of the ugliness of _t throughout the code? The more a type needs to be referred to by name the worse it gets. Consider an extreme example of type(string_t), which I assume would be used a lot in client code. The pro is that the user has the freedom to have a variable called string. The con is that a significant fraction of future Fortran library ecosystem will be pepper-sprayed with the ugly type(string_t). If stdlib is to be successful, and I think all of us here are doubling down on, then how we name derived types in stdlib has a huge impact on the aesthetics of future Fortan libraries and applications.\nI assumed that type(string_t) is uglier than type(string), and that wanting to name your instance the same as your type is an edge case rather than common use. If these assumptions are true, then we should prioritize giving nice names to our types over giving marginally more flexibility to client code. If the user insists to name their variable string, then they can do:\nuse stdlib_string, only: string_t => string\ntype(string_t) :: string\nI think it's okay to make an exception to the rule when justified. If an appendage to the type name is necessary, then I think _type is less ugly and more clear than _t."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-07-26 23:12:59+00:00",
                    "text": "I'm not opposed to 1, and you're right that it is noise. I just think it does at least occasionally lead to name clashes due to the design of the language.\nFor example, in a library for dealing with the composition of matter, I invariably have a type element. I'd like to define that type, and related operations, type bound procedures, etc. in a module element, and in another module dealing with chemicals, I'm likely to have variables that would be most appropriately named element in the procedures. In this instance, element_type would not be an appropriate name for the module, as it provides more than just the type. And trying to come up with a different name for the variables just to avoid the name clash with the type leads to more noise than the suffix (i.e. the_element).\nHowever, I will grant that this is not likely to be the majority case, and probably not likely to be a frequent occurrence in stdlib. Also, for the very generic use case of stdlib types, I agree with @milancurcic point about variable names with the same name as the type being unlikely. So, in that case I would be fine with option 1, and not bother worrying about the two word requirement for types.\nI will note however, that for @milancurcic example, had it not been for the stdlib namespace, he would have demonstrated exactly my point about the module name."
                },
                {
                    "user": "septcolor",
                    "date": "2020-07-27 03:05:16+00:00",
                    "text": "FWIW, I use Option 3 above in all my codes, partly by following the convention used in C++, e.g.\nhttps://docs.microsoft.com/en-us/cpp/cpp/char-wchar-t-char16-t-char32-t?view=vs-2019\nso personally it does not appear very awkward to use _t as derived type names.\n(I noticed some people prefer xxx_type or xxxType. This could be an alternative,\nbut in my case, I use xxx_type as a variable name... (because _t is already \"reserved\"\nfor type names and there is no worry for name collision.) But I think xxx_type is another\npopular convention for type names (like xxx_mod  below), so again they appear also OK to me.\nAs for modules, I had used _mod initially, but more recently tend to use _m for brevity\n(and following the above _t pattern). But I agree that this convention is not so \"popular\"\nin other languages and also find some people do not like it very much.\nAs for interfaces, I am still wondering what is a nice suffix... I tried _if or _intf etc, but\nnot very nice. I have never used _i up to now, but if used consistently, it may be useful\nfor brevity (if one gets used to it).\nI noticed plural forms are sometimes used as some library names (e.g., XyzLists), but\nI usually avoid it for type names because I use plural names to distinguish scalars and\narrays (e.g., word and words(:)).\nAnyway, in a line similar to @everythingfunctional (in the first post), I think it is useful\nand practically convenient if the naming convention eliminates name collision (with user\nvariables) as automatically as possible, so reducing the need to care about such collisions.\n(Personally, I think that it is a (historical) design flaw in Fortran to be not able to\ndistinguish upper and lowercase names in symbols... (maybe due to old punched cards?),\nand so I need to use some systematic workaround throughout my codes."
                },
                {
                    "user": "certik",
                    "date": "2020-07-27 04:06:02+00:00",
                    "text": "Most C++ codes seem to follow the Python convention of using CamelCase for class names, and lower_case for variable names:\n\nhttps://google.github.io/styleguide/cppguide.html#General_Naming_Rules\n\nI like that convention also, it's just that it only works for Fortran if you have at least two words.\n\nDo people prefer to use all lowercase for derived type, or CamelCase?\n\u2026\nOn Sun, Jul 26, 2020, at 9:05 PM, septcolor wrote:\n\n\n FWIW, I use Option 3 above in all my codes, partly by following the\n convention used in C++, e.g.\n https://docs.microsoft.com/en-us/cpp/cpp/char-wchar-t-char16-t-char32-t?view=vs-2019\n so personally it does not appear very awkward to use `_t` as derived\n type names.\n (I noticed some people prefer `xxx_type` or `xxxType`. This could be an\n alternative,\n but in my case, I use `xxx_type` as a variable name... (because `_t` is\n already \"reserved\"\n for type names and there is no worry for name collision.)\n\n As for modules, I had used `_mod` initially, but more recently tend to\n use `_m` for brevity\n (and following the above `_t` pattern). But I agree that this\n convention is not so \"popular\"\n in other languages and also find some people do not like it very much.\n\n As for interfaces, I am still wondering what is a nice suffix... I\n tried `_if` or `_intf` etc, but\n not very nice. I have never used `_i` up to now, but if used\n consistently, it may be useful\n for brevity (if one gets used to it).\n\n I noticed plural forms are sometimes used as some library names (e.g.,\n `XyzLists`), but\n I usually avoid it for type names because I use plural names to\n distinguish scalars and\n arrays (e.g., `word` and `words(:)`).\n\n Anyway, in a line similar to @everythingfunctional\n <https://github.com/everythingfunctional> (in the first post), I think\n it is useful\n and practically convenient if the naming convention eliminates name\n collision (with user\n variables) as automatically as possible, so reducing the need to care\n about such collisions.\n\n (Personally, I think that it is a (historical) design flaw in Fortran\n to be not able to\n distinguish upper and lowercase names in symbols... (maybe due to old\n punched cards?),\n and so I need to use some systematic workaround throughout my codes.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#225 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWDNTRXYPFXYGCEAVJ3R5TVHVANCNFSM4PIEYLMA>."
                },
                {
                    "user": "Romendakil",
                    "date": "2020-07-27 06:31:47+00:00",
                    "text": "Definitely not CamelCase! We want Fortran style, not C++ or Python. In our code we are using option 3, so this looks very familiar to me. But I think it is just a matter of taste."
                },
                {
                    "user": "aradi",
                    "date": "2020-07-27 08:09:46+00:00",
                    "text": "Although we are using camel-case in some of our projects, I won't recommend it for stdlib for several reasons:\n\n\nThe one derived type already in the language type(c_ptr) uses the lower-case + underscore convention. (Are there any other derived types inthe standard?)\n\n\nSince we have a case-insensitive language, people will start to use the type names differently without being notified by the compiler e.g. type(OSError), type(OsError), type(OSerror). I think, the safest convention to ensure consistent usage for a case-insensitive language is to consistently write everything lower cased. (The temptation to use type(OS_error) instead of type(os_error) is hopefully smaller.)"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-27 08:54:22+00:00",
                    "text": "I agree: if someone wants to use CamelCase or judicially located upper case\ncharacters, then let them, but we should not make that a convention. It may\nforce us to be slightly more inventive wrt names, but that is a minor\ndrawback. Using underscores to separate parts of a name happens in a lot of\nplaces - think of ISO_FORTRAN_ENV for instance and the kinds and other\nentities it defines.\n\nOp ma 27 jul. 2020 om 10:10 schreef B\u00e1lint Aradi <notifications@github.com>:\n\u2026\n Although we are using camel-case in some of our projects, I won't\n recommend it for stdlib for several reasons:\n\n    -\n\n    The one derived type already in the language type(c_ptr) uses the\n    lower-case + underscore convention. (Are there any other derived types\n    inthe standard?)\n    -\n\n    Since we have a case-insensitive language, people will start to use\n    the type names differently without being notified by the compiler e.g.\n    type(OSError), type(OsError), type(OSerror). I think, the safest\n    convention to ensure consistent usage for a case-insensitive language is to\n    consistently write everything lower cased. (The temptation to use\n    type(OS_error) instead of type(os_error) is hopefully smaller.)\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#225 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR3JLH6SGUFW4TTBC2LR5UY5VANCNFSM4PIEYLMA>\n ."
                },
                {
                    "user": "septcolor",
                    "date": "2020-07-27 15:58:39+00:00",
                    "text": "I think it is interesting that CamelCase is not very much preferred (according to the above posts), although I use it for type names (e.g., FooBaa_t). Though I'm not proposing CamelCase at all (I use snake + lower cases for variable names), it might be useful to create a thread on Discourse and ask people about: \"What type/variable name style(s) do you use in your coding? Is there specific reasons why you chose or settled down to that style? etc. Then I think the reader might also find some new insights from other people's posts."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-30 04:06:34+00:00",
                    "text": "Even though I agree with @milancurcic that naming variables after their type is bad style ( type(string) :: string is a good strategy to confuse maintainers) , I would also opt for a _t or _type suffix or prefix. Since Fortran is case insensitive  (CamelCase is not an option) and does not support multiple namespaces, the namespace is already quite small and we need to avoid conflicts.\nSomehow related to the question of naming conventions for variables is the naming convention for modules. For class-like types, it could be meaningful to have a module that contains one type only (see e.g. https://github.com/MarDiehl/quaternions). Would the module name in that case be the name of the type/class with some variation?\nExamples\nuse stdlib_list\n\ntype(t_list) :: names\n\nAlternatively (multiple types/classes in one module):\nuse stdlib_types\n\ntype(t_list) :: names\ntype(t_dict) :: children\n\nThere is also the point that a type can be something like a C struct (just a collection of variables) or a python Class (object oriented approach with type-bound procedures). I don't think it makes sense to differentiate them (e.g. string_c because it has type bound procedures and is considered to be a class)"
                },
                {
                    "user": "shahmoradi",
                    "date": "2020-08-02 17:55:16+00:00",
                    "text": "I agree with @MarDiehl. Just sharing my experience and my trial and errors on this topic: This is the design that I settled with, in my personal projects after several years of try and improve:\nmodule string_mod\n    type :: string_type\n    end type\nend module string_mod\nprogram main\nuse string_mod, only: string_type\ntype(string_type) :: string\nend\nIn practice, I have found that I use the variable string far more frequently than the suffixed type and module names (string_type, string_mod). So it has made sense for me to suffix the type and module names and have freedom in choosing variable names, instead of inventing and living with awkward variable names. Other languages that do not use these suffixes (like Python or MATLAB) are case-sensitive, so they can define something like the following,\nfrom string import String\nstring = String()\nBut this is (, perhaps, fortunately)  impossible in Fortran. An alternative that comes to my mind for Fortran is,\nmodule string_mod\n    type :: string\n    end type\nend module string_mod\nprogram main\nuse string_mod, only: string_type => string\ntype(string_type) :: string\nend\nBut this would be highly inferior to the former method of suffixing types with _type. It takes more time and energy to achieve the same goal.\nIn my opinion, there is nothing wrong with being expressive and clear in naming conventions, for example in choosing string_type vs. string_t or vs. string as the type name.\nRegarding the CamelCase, it has been my own strong preference everywhere, even in Python. But in the special case of Fortran stdlib, I think it would make more sense to follow the naming convention of the standard Fortran, which is the snake_case.\nIf you are interested to see how this naming convention looks and feels in practice, take a look at this example module here: https://github.com/cdslaborg/paramonte/blob/master/src/ParaMonte/String_mod.f90\ncheers"
                },
                {
                    "user": "FortranFan",
                    "date": "2020-08-03 17:17:23+00:00",
                    "text": "For whatever it's worth, I too prefer \"_t\" suffix for derived types in Fortran; \"_m\" for modules; and \"_sm\" for submodules.\nI disagree with @milancurcic 's comment earlier, \"in real-world code this is not common. Why call a string instance string, a datetime instance datetime, or a bitfield instance bitfield\"\n\nTest-driven development (TDD) and prototype implementation and all modes of testing starting from unit tests are of utmost importance to \"real-world code\", so much of illustration and the accompanying communication, collaboration, and brainstorming, also the application enhancement which follows, and the advancement of associated technology takes place using the small programs associated with these critical needs.\n\nThe teams I work with and I have found it to be tremendously helpful and productive to name an instance of a 'foo' type as foo itself which is accomplished by the simple type(foo_t) :: foo in such small programs.\nSo much so that some teams have carried that forward (or one can say brought back since _t had started to appear in C-based languages during the 1980s i.e., before Fortran 90 and flexible naming was introduced in Fortran) to other languages such as C# that are case-sensitive where the usual practice, as mentioned upthread, was to use some case convention (e.g., camelCase) but which was found to be a struggle for some developers with special visual needs."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-08-03 18:11:20+00:00",
                    "text": "For whatever it's worth, I too prefer \"_t\" suffix for derived types in Fortran; \"_m\" for modules; and \"_sm\" for submodules.\n\nI think this is worth the most--this thread asks what each of us prefers.\nYes, TDD leads to some real-world code, and type(foo_t) :: foo has as much to do with TDD as type(foo) :: a. Different teams have different habits and styles.\nConsidering a stronger preference so far for a suffix to type names, does anybody object to the suffix being _type over _t? I'm worried that the latter may be quite opaque to newcomers to the language."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-08-03 18:24:08+00:00",
                    "text": "I would opt for the option 3 (i.e., '_t' or '_type' as suffix). I would even prefer them as prefix, as typing e.g., t_ or type_ in the editor would result in proposing all the types already used in the file.\nI am quite opposed against plural nouns. There are probably some cases where using a plural noun would make no sense, and these situations could lead confusions.\n\nConsidering a stronger preference so far for a suffix to type names, does anybody object to the suffix being _type over _t? I'm worried that the latter may be quite opaque to newcomers to the language.\n\n@milancurcic Would you still be worried if this convention is mentioned clearly in the docs?"
                },
                {
                    "user": "shahmoradi",
                    "date": "2020-08-03 18:29:43+00:00",
                    "text": "@milancurcic I agree with you that _t is somewhat opaque to beginners compared with _type. and for that reason, I personally prefer the latter. I think being expressive and clear is more important than being concise. But as you said, these issues are mostly personal preferences.\ncheers"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-08-03 18:41:47+00:00",
                    "text": "@milancurcic Would you still be worried if this convention is mentioned clearly in the docs?\n\nYes, we'd document any convention in the docs and style guide and this helps for sure. I'm concerned more about what happens in the first 0.5 s or so when your eyes read string_t--there's an extra brain cycle to map \"t\" -> \"type\". Of course, if you've been used to it, it's no issue. It trips me up every time, but as I read the code for a while I get used to it. I don't see this paradigm outside of Fortran, thus the newcomers concern."
                },
                {
                    "user": "aradi",
                    "date": "2020-08-03 19:19:46+00:00",
                    "text": "As for me, I am in favor of _t over _type if we go for the suffixed version. Fortran is usually very (way too) verbose and typing intensive, but at least in the naming of type(c_ptr) (the  only intrinsic derived type in the language I am aware of) it happened to be compact. As majority here seems to support a naming convention which is more verbose than the intrinsic one (option 3 instead of option 1), let's try to keep it at least as compact as possible.\nFortunately, for modules we do not need any suffixes, as the namespace-prefix makes it highly unlikely that module names do not collide with type names or variable names. So, I think, if at all, we should suffix type names only."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-08-03 19:41:44+00:00",
                    "text": "I like _type and _module much better than _t and _mod."
                },
                {
                    "user": "Romendakil",
                    "date": "2020-08-03 19:46:05+00:00",
                    "text": "We always use _t in our code, this seems much more natural to me."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-08-03 19:48:49+00:00",
                    "text": "Regarding _mod/_module/_m: Is this convention used 'in the wild'? Neither the intrinsic modules (ISO_C_Binding, IEEE_arithmetic, iso_fortran_env) nor the libraries that I use (hdf5, petsc, MPI) have such a suffix."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-08-03 19:54:42+00:00",
                    "text": "Regarding _mod/_module/_m: Is this convention used 'in the wild'?\n\nI used _mod in the past to allow naming a type with the name of the module base name.\nModule suffixes don't pertain to stdlib because we prefix modules with stdlib_."
                },
                {
                    "user": "shahmoradi",
                    "date": "2020-08-03 19:58:17+00:00",
                    "text": "@milancurcic since the community's opinion on the matter of naming convention appears to be fragmented, do you think a poll could resolve this issue of naming? perhaps a poll with an extra question on the years of experience of the participant with Fortran, so that the answers could be weighted based on experience."
                },
                {
                    "user": "septcolor",
                    "date": "2020-08-03 20:41:56+00:00",
                    "text": "Is it really necessary to enforce a unique naming convention throughout the library? Doesn't several \"recommendations\" work such that some freedom is left to contributors to choose his/her style (for making a new experimental module) ? My concern is that (1) enforcing a unique style might discourage potential contributors to join if they dislike the given style, and (2) there are indeed multiple popular styles in the wild, and fixing the style does not reflect such situations. I guess a rather mild \"recommendation\" of styles may work, for example:\nPrimary recommendation:   (e.g. _t)\nSecondary recommendation:  (e.g. _type)\nTertiary recommendation:  (e.g. CamelStyle)\nGeneral note: If you do not have strong preference, please follow\nthe order of recommended styles as much as possible (<-- a weak recommendation).\nAnother reason is that, I feel that very basic types like string and error handling\ncould be without _t or _type, because one needs to type it so many times (pun intended :-)\nAlso, \"string\" (or \"String\") is the de fact standard name for such string type (except for Python...), while variable names may be str etc. A long typename like \"SymmetricMatrix\" also seems to not need additional _t (considering little chance of name collision).\nBut possible \"cons\" of such approach are that: (1) if different styles appear in different modules,\nthe difference may need to be absorbed (?) via USE, ONLY etc (not very sure); and (2) one needs to determine which style to use when writing a module and so needs additional energy; (3) it may take more time to determine which is primary, secondary, etc (but the results of a poll might be useful). Making a rule like \"please use one consistent style at least in a given module\" might also be useful.\nI think a poll would also be nice, but I am afraid weighting the results with the years of experience might have unexpected effects (e.g., people using Fortran from 1960' might have rather special (??) preference.)"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-04 03:05:39+00:00",
                    "text": "@septcolor the language was case insensitive because early computers used only six bits to represent characters . With only 64 character codes, 10 code points for digits, about 10 code points for special characters, and a few code points for control codes there weren't enough code points available for both upper and lower case.\n@aradi in addition to C_PTR the standard also identifies C_FUNPTR, in ISO_C_BINDING, LOCK_TYPE and TEAM_TYPE in ISO_FORTRAN_ENV, IEEE_FLAG_TYPE, IEEE_MODES_TYPE, and IEEE_STATUS_TYPE of IEEE_EXCEPTIONS, IEEE_CLASS_TYPE, and IEEE_ROUND_TYPE of IEEE_ARITHMETIC, and IEEE_FEATURES_TYPE, of IEEE_FEATURES as derived types. Eleven derived types in all if I have not missed any."
                },
                {
                    "user": "zerothi",
                    "date": "2020-08-04 12:58:17+00:00",
                    "text": "To repeat already opinions:\n\nI prefer _t it allows me to re-use the same variable as the type. In very many cases I only need a single object and I wan't clarity in code. type(name_t) :: name makes it clear what name is. In our code bases this is coming across quite frequently.\nI prefer the file name implementation.f90, in it, module implementation_m for module. This allows me to have a subroutine subroutine implementation. This is quite frequent for small self-contained modules that only expose one method. The file name clarifies intent, and so does the module name. I.e. _m suffix.\nI agree with @aradi that stdlib should refrain from using camelcase. Whether it be all upper or all lower case with _ separators is not really important to me. It seems to me that users of stdlib may use the names as they like so it fits their coding conventions. E.g. code bases which relies on all upper case may still use stdlib as such."
                },
                {
                    "user": "zerothi",
                    "date": "2020-08-04 13:00:40+00:00",
                    "text": "@milancurcic since the community's opinion on the matter of naming convention appears to be fragmented, do you think a poll could resolve this issue of naming? perhaps a poll with an extra question on the years of experience of the participant with Fortran, so that the answers could be weighted based on experience.\n\nI don't think experience years should count. We want to advocate new comers to the language on an equal footing (they are the inheriting use base!). :)\nHowever, total fortran newbies should be recommended not to vote ;)"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-04 14:09:31+00:00",
                    "text": "FWIW I agree with @certik that with the STDLIB prefix there is no need for a _m or _mod suffix to modules."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-08-04 14:31:48+00:00",
                    "text": "in addition to C_PTR the standard also identifies C_FUNPTR, in ISO_C_BINDING, LOCK_TYPE and TEAM_TYPE in ISO_FORTRAN_ENV, IEEE_FLAG_TYPE, IEEE_MODES_TYPE, and IEEE_STATUS_TYPE of IEEE_EXCEPTIONS, IEEE_CLASS_TYPE, and IEEE_ROUND_TYPE of IEEE_ARITHMETIC, and IEEE_FEATURES_TYPE, of IEEE_FEATURES as derived types. Eleven derived types in all if I have not missed any.\n\nThank you @wclodius2 for this information.\nBased on this, I am in favor of using _type over _t as suffix, because it is already used in the Fortran standard."
                },
                {
                    "user": "certik",
                    "date": "2020-08-04 15:16:53+00:00",
                    "text": "Just like with the indentation convention, let's simply document the most viable approaches here, so that people can choose from it. Let's not enforce any particular approach right now, as it is too early for multiple reasons: our community is very young, and we are still in early stages of developing fpm, which will have a convention for naming modules.\nLet's start with modules: the convention for fpm packages (programs or libraries) is that each module is prefixed with the path where it sits on the filesystem, starting with the name of the package. So a module in src/something/bitfield.f90 will have a name stdlib_something_bitfield.f90. If you just have src/bitfield.f90, then it will have a name stdlib_bitfield.f90. The same if you have a program / application, it will be prefixed by the name of your application. This naming convention will be enforced by default by fpm. We can discuss this further, but this is the best so far that we were able to come up that allows combining different packages, and have effective \"namespaces\", and you just put your files into any directory structure you want and fpm will help with naming your modules correctly (e.g., it could rename your modules on a request). Assuming we will continue with this approach, then we don't need to append any _m or _mod or _module to modules.\nRegarding derived types, the options are to append nothing, _t and _type. It looks like people agree to just use lowercase. So let's document these as the 3 options and move on. Later we can revisit as more fpm enabled Fortran libraries will be available and we gain more experience combining and depending on lots of dependencies."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-08-04 15:21:06+00:00",
                    "text": "@milancurcic since the community's opinion on the matter of naming convention appears to be fragmented, do you think a poll could resolve this issue of naming? perhaps a poll with an extra question on the years of experience of the participant with Fortran, so that the answers could be weighted based on experience.\n\nYes, and I think we already have a decent poll in this thread--a separate poll could break the flow we have here. I don't agree with weighing votes by experience. I think everybody's input should count equally, newcomers and old-timers alike."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-04 15:47:02+00:00",
                    "text": "FWIW in regards to type naming, I am now of the opinion that is the type name is long or otherwise inconvenient to be used as a variable name it should not have a suffix, but if likely to be used as a variable name it should have the _t suffix."
                }
            ]
        },
        {
            "number": 224,
            "user": "aradi",
            "date": "2020-07-23 08:14:59+00:00",
            "title": "Handling and propagating errors in stdlib",
            "text": "Before the file system layer (see #201, #220) in stdlib can be implemented, it would be important to reach some agreement on how to signalize errors within stdlib. I am not talking about logging, as this is an add on we can discuss later. I want to concentrate here on how errors can be passed between routines in stdlib.\nFortran's current approach to report status in I/O commands is to have some optional integer argument, returning the status of the operation. If the argument has not been specified, the code stops in case of errors. I'd propose to generalize this principle, but using derived types to achieve higher robustness and flexibility:\n\nThe status should become a derived type (type(status)), which methods allowing to set and query it.\nThe status-type has a finalizer. If it goes out of scope with an unhandled error in it (without having been handled by the caller), it calls error stop.\nThe derived has a special field which contains a class(error) item. It can carry arbitrary types derived from a base class, so that arbitrary complex error information can be passed around. This way, the error signaling mechanism is extensible, we could even think to add an error-hierarchy as we have in Python.\n\nI have made a toy project to demonstrate the principle.  Please, have a look at it and let me know what you think.\nA few more notes:\n\nThis error passing should be applied to cases, where error reporting via special values in not feasible (e.g. change_dir()).\nWe could of course implement in the error-class to information about how it was propagate (backtrace).\n\nThis issue is related to several other error discussons, e.g. #219 , #193, #95. My suggestion is, again, to first reach agreement on the low-level of the error reporting, and we can add extended functionality, such as logging, on top later.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-07-23 15:40:51+00:00",
                    "text": "Would the idea still be that if the status argument is not provided, that it will error out right away? I think this is the key principle.\nI think your approach can work.\nThe only possible downside that I can see is that you can notice that built-in Fortran functions never return a derived type, but only simple arguments such as integers or arrays. The reason for that is that it does not impose any particular derived type on the user. In here, we would be imposing the type type(status). So that's the main downside compared to returning just an integer.\nRegarding speed, the derived type can possibly be a bit slower than an integer. So maybe not a good idea for small functions in hot loops. But for IO functions, the possible overhead is probably small.\nJust like integer, type(status) is thread safe, does not have any global state.\nAnd the Pros are: extensible, can convey more rich error information such as a string.\nAnd it is still relatively simple.\n\nIf we chose to go with returning just an integer, then we can document the various different errors as different integers, and then provide a function that prints a nice error message based on the integer number.\nSo I think the key difference to an integer is that type(status) allows to convey information that is not just the error type, but something that changes all the time --- for example which directory failed, or what error some low level command (shell) returned. As is obvious from fpm, we need to have some functionality for running commands, and if they fail, the stderr output can be put into type(status) and propagated to the user. That would be hard to do with just integers.\nSo it seems to me if just a simple error with no extra information is needed, the integer might be better. But if more information must be attached to the error that is only known at runtime, then I think your type(status) is the way to go."
                },
                {
                    "user": "aradi",
                    "date": "2020-07-23 16:24:55+00:00",
                    "text": "Would the idea still be that if the status argument is not provided, that it will error out right away? I think this is the key principle.\n\nActually, originally I wanted to propose to make them mandatory. But to be in accordance with Fortrans usual way of doing things, we could make it optional, and hope, that people would always pass (and handle it) in order to obtain a robust program.\nI agree, that Fortran ususally operates with scalar types and arrays of them preventing to impose derived types on the programmer.  But in my opinion, this is exaclty what makes many things quite painful, needing a lot of extra-coding for basic stuff.\nAs for type(status), the extensibility would be very important:\n\nWe could attach any kind of error information to ease the understanding what happened (similar to Pythons exception)\nWe could extend type(status) with traceback capabilities, so that it can collect the call stack while being propagated upwards."
                },
                {
                    "user": "certik",
                    "date": "2020-07-23 16:37:41+00:00",
                    "text": "we could make it optional, and hope, that people would always pass (and handle it) in order to obtain a robust program.\n\nWhy would you consider a program not robust if it does not handle the error? If the status is not provided, then the function stops the program with a useful error message. I consider this very robust and the desired behavior. If I don't want to handle the error, I want to get a nice error message and a stacktrace. If the user wants to handle the error, then the status is provided. So it seems it is robust either way.\nRegarding the stacktrace --- I think it's the compiler's job to create a nice stacktrace when the error occurs. GFortran does it, although I would like it to be formatted better.\nWhat we can do is to try using type(status) in the IO routines and see how it goes."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-23 16:40:11+00:00",
                    "text": "I overall like it, although I don't think it's feasible to use for everything. For procedures that return a single result we use functions, and if we use an intent(out) argument in functions we can't make them pure. If we trust the long-term vision of Fortran being parallel and running on emerging architectures, then writing pure functions is what we should aim for.\nSo, without being convinced otherwise, my suggestion would be to limit such status/error propagation to subroutines that modify variables in-place. I/O and file system stuff is I think the perfect candidate for such things, stats functions not so much."
                },
                {
                    "user": "certik",
                    "date": "2020-07-23 16:45:11+00:00",
                    "text": "@milancurcic I agree. The stat functions will be used in hot loops, so we do not want to have the overhead of more general error handling there. The IO functions will have the overhead of the IO, so we can afford more general error handling there."
                },
                {
                    "user": "aradi",
                    "date": "2020-07-23 18:55:36+00:00",
                    "text": "Of course, this error handling mechanism is not meant for functions at all. Especially numerical functions have better ways of signalizing errors by returning a specific value (e.g. nan).\nI'd propose to use this error-handling mechanism in those cases, where otherwise an error stop would have been called. IMO, a library, which calls an error stop in a deeply nested internal routine instead of propagating the error back to the consumer is a true nightmare and can not really be considered being robust."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-07-23 19:33:38+00:00",
                    "text": "There are 2 schools of thought I think on having an error stop in a library procedure. On the one hand, the error is unlikely to be helpful to a user of the program, as they're unlikely to be able to deduce why their input caused an error in that procedure without the rest of the context, which isn't available to that procedure to print out.\nHowever, if such an error occurs, it is more likely a bug in the program, the procedure was called with invalid inputs, and that's on the caller. You need to fix your program.\nSo you could take the stance that, here's the requirements of calling this procedure, if you violate them that's on you, or, you can strive for \"total functions\", that can gracefully handle all possible inputs, but force the caller to deal with potential errors.\nI generally like using libraries that strive towards the latter, as it makes explicit in the interface that things might go wrong, but there are of course performance penalties, and there's nothing wrong with a procedure taking the stance of \"if you call me with bad inputs, I crash\"."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-24 04:00:20+00:00",
                    "text": "I consider a procedure that only calls ERROR STOP when it encounters a problem to be a nightmare, but I also consider one that passes a status flag up to a calling procedure, that represents a problem a calling procedure can't be expected to handle, to also be a nightmare. Instead, a procedure, if it encounters a problem it thinks is unhandleable, should print a detailed error message describing the type of problem, and the location where it was found, and then call ERROR STOP. On rare occasions when the errors are genuinely handleable (e.g. a fast but non-robust method, that discovers it is having problems may pass a flag indicating that a more robust method is needed), it should pass an optional STATUS flag, that, if not present, stops the application with the detailed error message. FWIW I also consider most user errors to be unhadleable. See Herb Sutter\u2019s paper for SC22/WG21, \"Zero-overhead deterministic exceptions: Throwing values\u201d, for a discussion of the problems with trying to handle user or allocation errors."
                },
                {
                    "user": "certik",
                    "date": "2020-07-24 04:26:37+00:00",
                    "text": "Yes, I think we all agree to print detailed error information before calling error stop.\n\u2026\nOn Thu, Jul 23, 2020, at 10:00 PM, William B. Clodius wrote:\n\n\n I consider a procedure that only calls ERROR STOP when it encounters a\n problem to be a nightmare, but I also consider one that passes a status\n flag up to a calling procedure, that represents a problem a calling\n procedure can't be expected to handle, to also be a nightmare. Instead,\n a procedure, if it encounters a problem it thinks is unhandleable,\n should print a detailed error message describing the type of problem,\n and the location where it was found, and then call ERROR STOP. On rare\n occasions when the errors are genuinely handleable (e.g. a fast but\n non-robust method, that discovers it is having problems may pass a flag\n indicating that a more robust method is needed), it should pass an\n optional STATUS flag, that, if not present, stops the application with\n the detailed error message. FWIW I also consider most user errors to be\n unhadleable. See Herb Sutter\u2019s paper for SC22/WG21, \"Zero-overhead\n deterministic exceptions: Throwing values\u201d,\n <http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r0.pdf>\n for a discussion of the problems with trying to handle user or\n allocation errors.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#224 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWHYE3IFPQESMTZGE33R5EBOBANCNFSM4PFPIXJQ>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-24 06:47:07+00:00",
                    "text": "Yes, I think we all agree to print detailed error information before calling error stop.\n\nIndeed, I think we agree all on that. However, this means that functions are not allowed to be pure, as currently in stdlib_experimental_stats (see example here.\nAny ideas how to resolve that for functions, since this proposition doesn't seem to cover functions?"
                },
                {
                    "user": "aradi",
                    "date": "2020-07-24 07:48:51+00:00",
                    "text": "Of course, error stop with message is better. But often, the error is not caused by a bug, but by wrong user input (e.g. paths, some numerical values). And I find it much nicer, if the simulation package writes out a qualified error message  (Error while trying to read the specified parameterization file (input.txt:23)) instead of (Could not read 'something.dat. Or The mixer scheme failed, try to use a different mixer settings versus Unable to solve linearly dependent system of equations.\nAs for functions: I think, we should only allow for functions which either never fail or can report their failure via a special value of their return type (e.g. NaN)."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-24 08:30:12+00:00",
                    "text": "As for functions: I think, we should only allow for functions which either never fail or can report their failure via a special value of their return type (e.g. NaN).\n\nI am not sure I fully agree with that. For example, for the function mean, the dimension dim can be provided (with 0 < dim < maximum_rank_array). Currently if the user provides a wrong dim, a message is printed and error stop is called.\nThis is similar to what happen with the intrinsic sum (with gfortran):\nFortran runtime error: Dim argument incorrect in SUM intrinsic: is 3, should be between 1 and 2\n\nI don't think that returning NaN in this case would be correct, but this strategy would allow pure functions."
                },
                {
                    "user": "certik",
                    "date": "2020-07-24 15:38:41+00:00",
                    "text": "However, this means that functions are not allowed to be pure\n\nIt seems error stop can be in pure functions, at least with GFortran. We should check the Fortran Standard on this one.\nThis function indeed does not compile:\npure integer function f(x)\ninteger, intent(in) :: x\nf = x+1\nstop \"ok\"\nend function\nwith:\na.f90:4:9:\n\n stop \"ok\"\n         1\nError: STOP statement not allowed in PURE procedure at (1)\n\nBut this one compiles:\npure integer function f(x)\ninteger, intent(in) :: x\nf = x+1\nerror stop \"ok\"\nend function"
                },
                {
                    "user": "aradi",
                    "date": "2020-07-24 15:42:08+00:00",
                    "text": "According to MRC: \"Execution of an error stop statement causes execution to cease as soon as possible on all images, so there is no need to disallow it in a pure procedure. It is now allowed ...\" (It is apparently a Fortran 2018 thing)."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-24 15:43:17+00:00",
                    "text": "It seems error stop can be in pure functions, at least with GFortran. We should check the Fortran Standard on this one.\n\nSince Fortran 2018, indeed."
                },
                {
                    "user": "certik",
                    "date": "2020-07-24 15:45:37+00:00",
                    "text": "There you go. So this is an option. One still cannot have any print statements in pure functions, but we can communicate the message via error stop, as in this function:\npure integer function f(x)\ninteger, intent(in) :: x\ncharacter(len=100) :: msg\nmsg = \"some text\"\nf = x+1\nerror stop msg\nend function"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-24 15:57:03+00:00",
                    "text": "There you go. So this is an option. One still cannot have any print statements in pure functions, but we can communicate the message via error stop, as in this function:\n\nThis is indeed an option. However it might limit the number of compilers that support pure procedures with F18 error stop. But for the long term, it is indeed a solution."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-25 01:27:11+00:00",
                    "text": "@aradi the main performance impact I see in your proposal is that I believe the finalizer will be called every time a procedure is called with a STAT argument with INTENT(OUT) whether or not the STAT argument is present. If not present it obviously will be called when the procedure ends. If present I believe it will be called on entry since the corresponding variable will cease to exist. The call of the finalizer will have the cost of the creation of the call stack, the jump to the procedure, the if branch in the procedure, and unwinding the call stack.\nIf the class(error) can be used to pass arbitrary information the structure of a STAT object can be arbitrarily complex which can make constructing the stack and accessing the object from the stack more costly. I don't know what effect that will have on the finalizer. There is a cost for an arbitrary class hierarchy.\nFWIW I have minor objections to the name STATUS for the type, as that is the natural name for the STAT variable, and users will try out that name forgetting that types and variables belong to the same namespace. FWIW I use a type ERRORS for my enumerations of error conditions for that reason."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-07-26 18:58:02+00:00",
                    "text": "Don't forget about those of us developing GUI applications. For us, an error_stop is never acceptable, and printing a message to the console is useless since the user may not even see that. All errors have to be handled.\nI like the type(status) extensible type. But of course, what we really need is proper exception handling in the language. Anything else is just a stop gap solution. (like the current integer and string error messages of some of the intrinsic routines). It's just not enough in 2020."
                },
                {
                    "user": "aradi",
                    "date": "2020-07-26 20:15:12+00:00",
                    "text": "I agree, the finalization may give an extra overhead, especially due to the intent(out) arguments.  Thanks @wclodius2 to point it out! So, I have an alternative suggestion, which should decrease the overhead significantly and is almost as convenient and flexible as the previous suggestion:\n\nError reporting capability for a subroutine is provided by an allocatable, intent(out) dummy argument of a given derived type.\nAt call, the actual argument is unallocated. (Therefore, no finalization is necessary.)\nIf the subroutine finishes without error, it leaves the dummy argument unallocated. If the subroutine finishes with error, it allocates the dummy argument and puts the necessary information into it.\nThe caller can check the success of the subroutine by checking the allocation-status of the actual argument after the call.\nThe derived types for various errors are derived from a base-error type. This base class ensures, that if the error goes out of scope before having been \"deactivated\", the program is stopped. The error can be deactivated by calling its %deactivate() method.\nIf a subroutine only emits one kind of error, it accepts a given error-type as argument\nsubroutine emits_os_error_only(error, ...)\n  type(os_error), allocatable, intent(out) :: error\n\nConsequently the calling routine can directly access the publicly available components of the error type:\ntype(os_error), allocatable :: error\ncall emits_os_es_error_only(error, ...)\nif (allocated(error)) then\n  ! Do something with the info found in an os_error type\n  ...\nend if\n\n\nIf a routine can emmit multiple type of errors, it accepts a given error-class as argument\nsubroutine emits_multiple_error_types(error, ...)\n  class(critical_error), allocatable, intent(out) :: error\n\nIn this case, the caller uses select type if it wants to differentiate between the different error types:\nclass(critical_error), allocatable :: error\ncall emits_multiple_error_types(error, ...)\nif (allocated(error)) then\n  select type (error)\n  type is (os_error)\n    ! handle os-error\n   ...\n  end select\nend if\n\n\n\nI have rewritten FX-Error to demonstrate this way of error handling, so have a look at the relevant source files there for further details."
                },
                {
                    "user": "aradi",
                    "date": "2020-07-26 20:35:59+00:00",
                    "text": "@wclodius2 As for the naming convention, I've opened issue #225 on derived type naming conventions."
                },
                {
                    "user": "aradi",
                    "date": "2020-07-26 21:01:24+00:00",
                    "text": "I am not sure I fully agree with that. For example, for the function mean, the dimension dim can be provided (with 0 < dim < maximum_rank_array). Currently if the user provides a wrong dim, a message is printed and error stop is called.\nThis is similar to what happen with the intrinsic sum (with gfortran):\n[...]\nI don't think that returning NaN in this case would be correct, but this strategy would allow pure functions.\n\n@jvdp1 Yes, returning NaN here were not correct, for sure. However, in my opinion, this case is a clear programming error, as the caller is responsible to set a dimension which is compatible with the data it passes to the function (the same way as the programmer is responsible not to address elements beyond the array sizes). In those cases I'd find stop error with a proper error message acceptable and probably the best/only option we have at the moment, especially if the function is supposed to be pure.\nThe error-reporting mechanism here is more for cases, where the error is expected by design as the success of the call can not be warranted by the programmer/caller, like\n\nTrying to open a directory/file for reading:  The directory/file may not exist, or it exists but may not be readable due to missing permissions, etc.\nTrying to solve a linear system of equations: The caller has probably no knowledge about the linear dependence of the input data. Finding out about linear dependency in advance  would take as much time as solving the equations, so it would be highly inefficient. So, we need some way of reporting back the failure, which can be handled by the caller."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-29 03:01:36+00:00",
                    "text": "@aradi your test program, test_fxerror, doesn't appear to have an example of a call of a procedure with an optional STAT argument. When I try to imagine how the code would be set up for an optional argument I don't see how having the finalizer simplifies things. If it is used for the optional STAT argument, it will have to be guarded by IF blocks in such a way that if it exists it never goes out of scope, while if it is used for local variables it will always go out of scope."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-29 23:15:29+00:00",
                    "text": "As near as I can tell the most user friendly way to propagate errors\nin Fortran is through an optional argument, typically called STAT or\nSTATUS. The programmer ensures that if STAT is present the\nresulting argument has information about the nature of any error\nencountered in executing the subprogram, and if STAT is absent the\nprogram stops if an error is found and reports details about the\nnature of the error to either ERROR_UNIT or an appropriate log\nfile. The main questions to be answered are:\n\nWhat information should STAT convey;\nWhat type should STAT have; and\nWhat form should the error reporting take?\n\nI will put off discussing the form of error reporting and focus on\nthe information STAT could convey, and options for the type of\nSTAT.\nThere are two categories of information that a STAT argument might\nconvey: the severity of the error, and the cause of the error.\nFLIBS and\nFutility\nseem to focus on the severity of the error providing values\nrepresenting:\n\nInformation - provides information to the user without stopping;\nWarning - provides a warning to the user without stopping;\nError - that will stop processing only if stop on error is set;\nFatal Error - that will always stop processing; and\nFailure - not well defined\n\nThe severity flags seem to be more useful for logging routines\nand not for use as a STAT argument. My cursory review indicates that\nthe FLIBS and Futility library codes focus on error reporting and not\non error handling. As to the cause of the error, in many cases a\nlibrary code is well focussed and can have only one cause of\nerrors. For such codes a simple success/failure flag is sufficient to\nidentify the cause. But for some codes there can be multiple causes of\nfailure, e.g., a code that reads a value out of a file may fail\nbecause the file does not exist, the file exists, but does not have\nread privileges, an end of file was found before the desired value,\nthe value did not have the desired form, or the value was outside its\nexpected range. Each cause has a different possible fix, and each\ncause should be distinguished by the STAT argument value. They can\nbe distinguished by either an ad hoc module specific set of error\ncodes, or by a library defined set of error codes.\nThe most obvious type for STAT is a default INTEGER. This is what\nthe Fortran standard has historically used, and, as a result, what\nevery Fortran programmer is familiar with. The use of an integer has a\nbad rap as the standard did nothing for decades about standardizing\nthe values, so that all a user could rely on was that a non-zero value\nindicated that an error had occurred. Even when it standardized the\nmeaning of some values in ISO_FORTRAN_ENV it limited the number of\ndefined values to a handful. However integers could be used for\neither an application specific enumeration of error codes, or for a\nlibrary wide enumeration of error code values. This allows it to\npotentially convey a significant amount of information about the\nnature of an error. It has the advantage that no wrapper procedures\nare needed for comparisons or setting values, so it can be very\nefficient. A problem with an application specific enumeration is that\ndifferent applications may use the same numeric value for different\nerrors, or different numeric values for essentially the same error. A\nproblem with a library wide enumeration is that it will initially be\nincomplete, requiring updates. Another problem is that it will be\nlarge, I suspect with more than a hundred values, so finding the\nappropriate code will require a detailed search. FWIW I have created\nmy own enumeration of error codes. It numbers over 90 entries, though\nsome are, I believe, relatively useless so trimming might lower the\nnumber of codes to about 80.\nThe other option is a derived type. Such a derived type can\ndistinguish between different errors in several ways:\n\n\nBy a component that is an integer that takes on different values\nfor different categories of errors; or\n\n\nBy a component that is another intrinsic type that takes on\ndifferent values for different errors; or\n\n\nBy having the derived type be a class and using inheritance to\ncreate different classes that represent different errors.\n\n\nAn integer component has many of the advantages and disadvantages of\nusing an integer directly. Unless a library wide enumeration of values\nis provided, different applications may use the same value to\nrepresent different sources of errors or different values to\nrepresent the same error. If the component is not made private, then\ncomparisons and setting values can be very efficient, at the syntactic\ncost of consistently referring to the component. If the component is\nmade private then comparisons and setting values will require the\n(implicit) use of simple procedures, that will require inter-module\noptimization to reduce the cost.\nUsing other intrinsic types as component to distinguish different\nerrors is problematic. I cannot see enumerating errors using a REAL\nor COMPLEX, though it can be done. A LOGICAL value can be used to\nnote whether an error is active, but not to meaningfully distinguish\nerrors. A CHARACTER string can be used to distinguish errors, but\nthe comparisons would have a significant performance cost. Still a\nCHARACTER string component can be used to supplement an INTEGER\ncomponent, by providing an error specific message. The usefulness\nof this message depends on whether information about the error should\nbe specific to where it is first detected, or to where it is\nreported. In the first case the string is useful, in the second case\nit is much less useful.\nUsing the class hierarchy to distinguish different errors has one\nmajor advantage: the processor will ensure that different names of\nerrors will correspond to different values. However the same name can\nbe used by different applications, and if defined in different modules\nthe same name can correspond to different values. This problem again\nmight be addressed by a library wide enumeration of error\ncodes. However from @aradi's code it seems that ALLOCATE needs to be\nused to activate an error and MOVE_ALLOC needs to be used to\nassociate that specific error with the nominal STAT argument, though\nmaybe `ALLOCATE( TYPE(error-type-name):: STAT ) might work instead. In\nany case the syntax would be unintuitive to a novice.\nThe above analysis prompts the following questions:\nShould the library support STAT arguments? (yes/no)\nIf it supports STAT arguments should they represent severity or\ncause?\nIf it supports STAT arguments should they be:\nA. Integers?\nB. A derived type wrapper around integers with the component public?\nC. A derived type wrapper around integers with the component private?\nD. A derived type that uses the class hierarchy to distinguish errors?\nIf the library uses a derived type to support STAT arguments, should\nit have a CHARACTER string component, e.g., MSG?\nIf the library uses a derived type to support STAT arguments, should\nit follow the integer path of using a special value to indicate that\nno error was found or should there be an internal logical(?) flag to\nindicate whether an error occurred?\nIf the library supports STAT arguments, should it provide a\npredefined enumeration of error codes, or should it leave it up to the\nmodule's programmer to come up with an ad hoc enumeration of module\nspecific codes?\nFWIW my answers to the above questions are that the library should\nsupport STAT arguments, that they should represent the cause of the\nerror, that they should be either integers or a derived type wrapper\naround integers with the component public, with a mild preference for\nsimple integers, that the derived type, if it is used, should have a\nstring component, that it should use a special value to indicate that\nno error occurred, and that it should provide a pre-defined\nenumeration of error codes."
                },
                {
                    "user": "certik",
                    "date": "2020-07-29 23:44:26+00:00",
                    "text": "I pretty much agree with everything that William wrote and have the same preferences (slight preference for an integer, but not opposed to a derived type).\n\u2026\nOn Wed, Jul 29, 2020, at 5:15 PM, William B. Clodius wrote:\n\n\n As near as I can tell the most user friendly way to propagate errors\n in Fortran is through an optional argument, typically called `STAT` or\n `STATUS`. The programmer ensures that if `STAT` is present the\n resulting argument has information about the nature of any error\n encountered in executing the subprogram, and if `STAT` is absent the\n program stops if an error is found and reports details about the\n nature of the error to either `ERROR_UNIT` or an appropriate log\n file. The main questions to be answered are:\n\n  * What information should `STAT` convey;\n  * What type should `STAT` have; and\n  * What form should the error reporting take?\n I will put off discussing the form of error reporting and focus on\n the information `STAT` could convey, and options for the type of\n `STAT`.\n\n There are two categories of information that a `STAT` argument might\n convey: the severity of the error, and the cause of the error.\n FLIBS <http://flibs.sourceforge.net/m_exception.html> and\n Futility <https://github.com/CASL/Futility/blob/master/src/ExceptionHandler.f90>\n seem to focus on the severity of the error providing values\n representing:\n\n  * Information - provides information to the user without stopping;\n  * Warning - provides a warning to the user without stopping;\n  * Error - that will stop processing only if stop on error is set;\n  * Fatal Error - that will always stop processing; and\n  * Failure - not well defined\n The severity flags seem to be more useful for logging routines\n and not for use as a `STAT` argument. My cursory review indicates that\n the FLIBS and Futility library codes focus on error reporting and not\n on error handling. As to the cause of the error, in many cases a\n library code is well focussed and can have only one cause of\n errors. For such codes a simple success/failure flag is sufficient to\n identify the cause. But for some codes there can be multiple causes of\n failure, e.g., a code that reads a value out of a file may fail\n because the file does not exist, the file exists, but does not have\n read privileges, an end of file was found before the desired value,\n the value did not have the desired form, or the value was outside its\n expected range. Each cause has a different possible fix, and each\n cause should be distinguished by the `STAT` argument value. They can\n be distinguished by either an ad hoc module specific set of error\n codes, or by a library defined set of error codes.\n\n The most obvious type for `STAT` is a default `INTEGER`. This is what\n the Fortran standard has historically used, and, as a result, what\n every Fortran programmer is familiar with. The use of an integer has a\n bad rap as the standard did nothing for decades about standardizing\n the values, so that all a user could rely on was that a non-zero value\n indicated that an error had occurred. Even when it standardized the\n meaning of some values in `ISO_FORTRAN_ENV` it limited the number of\n defined values to a handful. However integers could be used for\n either an application specific enumeration of error codes, or for a\n library wide enumeration of error code values. This allows it to\n potentially convey a significant amount of information about the\n nature of an error. It has the advantage that no wrapper procedures\n are needed for comparisons or setting values, so it can be very\n efficient. A problem with an application specific enumeration is that\n different applications may use the same numeric value for different\n errors, or different numeric values for essentially the same error. A\n problem with a library wide enumeration is that it will initially be\n incomplete, requiring updates. Another problem is that it will be\n large, I suspect with more than a hundred values, so finding the\n appropriate code will require a detailed search. FWIW I have created\n my own enumeration of error codes. It numbers over 90 entries, though\n some are, I believe, relatively useless so trimming might lower the\n number of codes to about 80.\n\n The other option is a derived type. Such a derived type can\n distinguish between different errors in several ways:\n\n  1. By a component that is an integer that takes on different values\n for different categories of errors; or\n\n  2. By a component that is another intrinsic type that takes on\n different values for different errors; or\n\n  3. By having the derived type be a class and using inheritance to\n create different classes that represent different errors.\n\n An integer component has many of the advantages and disadvantages of\n using an integer directly. Unless a library wide enumeration of values\n is provided, different applications may use the same value to\n represent different sources of errors or different values to\n represent the same error. If the component is not made private, then\n comparisons and setting values can be very efficient, at the syntactic\n cost of consistently referring to the component. If the component is\n made private then comparisons and setting values will require the\n (implicit) use of simple procedures, that will require inter-module\n optimization to reduce the cost.\n\n Using other intrinsic types as component to distinguish different\n errors is problematic. I cannot see enumerating errors using a `REAL`\n or `COMPLEX`, though it can be done. A `LOGICAL` value can be used to\n note whether an error is active, but not to meaningfully distinguish\n errors. A `CHARACTER` string can be used to distinguish errors, but\n the comparisons would have a significant performance cost. Still a\n `CHARACTER` string component can be used to supplement an `INTEGER`\n component, by providing an error specific message. The usefulness\n of this message depends on whether information about the error should\n be specific to where it is first detected, or to where it is\n reported. In the first case the string is useful, in the second case\n it is much less useful.\n\n Using the class hierarchy to distinguish different errors has one\n major advantage: the processor will ensure that different names of\n errors will correspond to different values. However the same name can\n be used by different applications, and if defined in different modules\n the same name can correspond to different values. This problem again\n might be addressed by a library wide enumeration of error\n codes. However from @aradi <https://github.com/aradi>'s code it seems\n that `ALLOCATE` needs to be\n used to activate an error and `MOVE_ALLOC` needs to be used to\n associate that specific error with the nominal `STAT` argument, though\n maybe `ALLOCATE( TYPE(error-type-name):: STAT ) might work instead. In\n any case the syntax would be unintuitive to a novice.\n\n The above analysis prompts the following questions:\n\n Should the library support `STAT` arguments? (yes/no)\n\n If it supports `STAT` arguments should they represent severity or\n cause?\n\n If it supports `STAT` arguments should they be:\n\n A. Integers?\n\n B. A derived type wrapper around integers with the component public?\n\n C. A derived type wrapper around integers with the component private?\n\n D. A derived type that uses the class hierarchy to distinguish errors?\n\n If the library uses a derived type to support `STAT` arguments, should\n it have a `CHARACTER` string component, e.g., `MSG`?\n\n If the library uses a derived type to support `STAT` arguments, should\n it follow the integer path of using a special value to indicate that\n no error was found or should there be an internal logical(?) flag to\n indicate whether an error occurred?\n\n If the library supports `STAT` arguments, should it provide a\n predefined enumeration of error codes, or should it leave it up to the\n module's programmer to come up with an ad hoc enumeration of module\n specific codes?\n\n FWIW my answers to the above questions are that the library should\n support `STAT` arguments, that they should represent the cause of the\n error, that they should be either integers or a derived type wrapper\n around integers with the component public, with a mild preference for\n simple integers, that the derived type, if it is used, should have a\n string component, that it should use a special value to indicate that\n no error occurred, and that it should provide a pre-defined\n enumeration of error codes.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#224 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWHYBAVPYKCH4OJNH23R6CUR7ANCNFSM4PFPIXJQ>."
                },
                {
                    "user": "aradi",
                    "date": "2020-07-30 14:28:33+00:00",
                    "text": "@wclodius2 The finalizer in my approach made sure, that one can not let the error being unhandled: If the subroutine returns an error, it must be handled (and explicitely deactivated) before it goes out of scope. Especially, anti-patterns like\n! We pass the optional error argument, but do not hande it afterwards before passing it to the next routine.\ncall some_routine(error=error, ...)\ncall other_routine(error=error,...)\n...\n\nwould give then a run-time error. If that is too much of constraints, we could leave away the finalizer. Then, we were basically back to my original proposal using a derived type as status container. No allocation, no move_alloc necessary then.\nI would still argue for using derived types / classes for error classification, as this is the only way can stay flexible with the payload of the error. Some (maybe most) errors only return a simple error message, but sometimes also additiional data could be useful to understand the details of the error (numerical value of the determinant of the matrix, which could not be inverted...). We can make the error msg + integer combination the default case, but it should be possible to go beyond that, if needed.\nThe following minimal working example demonstrates what I vaguealy have in mind:\nmodule error_handling\n  implicit none\n  private\n\n  public :: general_error, status, raise_error\n\n\n  type :: general_error\n    character(:), allocatable :: msg\n    integer :: error_code\n  contains\n    procedure :: as_char => general_error_as_char\n  end type general_error\n\n\n  type :: status\n    class(general_error), allocatable :: error\n  contains\n    procedure :: is_ok => status_is_ok\n    procedure :: has_failed => status_has_failed\n  end type status\n\n\n  interface general_error\n    module procedure construct_general_error\n  end interface general_error\n\n\ncontains\n\n  pure function status_is_ok(this) result(isok)\n    class(status), intent(in) :: this\n    logical :: isok\n\n    isok = .not. allocated(this%error)\n\n  end function status_is_ok\n\n\n  pure function status_has_failed(this) result(hasfailed)\n    class(status), intent(in) :: this\n    logical :: hasfailed\n\n    hasfailed = allocated(this%error)\n\n  end function status_has_failed\n\n\n  function construct_general_error(msg, errorcode) result(this)\n    character(:), allocatable :: msg\n    integer, intent(in) :: errorcode\n    type(general_error) :: this\n\n    this%msg = msg\n    this%error_code = errorcode\n\n  end function construct_general_error\n\n\n  function general_error_as_char(this) result(errorchar)\n    class(general_error), intent(in) :: this\n    character(:), allocatable :: errorchar\n\n    character(100) :: buffer\n\n    write(buffer, \"(' (Error code: ',I0,')')\") this%error_code\n    errorchar = this%msg // trim(buffer)\n\n  end function general_error_as_char\n\n\n  subroutine raise_error(stat, error)\n    type(status), optional, intent(out) :: stat\n    class(general_error), intent(in) :: error\n\n    character(:), allocatable :: errormsg\n\n    if (present(stat)) then\n      stat%error = error\n    else\n      errormsg = error%as_char()\n      error stop errormsg\n    end if\n\n  end subroutine raise_error\n\nend module error_handling\n\n\nprogram test_error_handling\n  use error_handling\n\n  type(status) :: stat\n  call error_raiser(stat, .true.)\n  if (stat%has_failed()) then\n    print *, \"Error occured: \", stat%error%as_char()\n  end if\n\ncontains\n\n  subroutine error_raiser(stat, raise)\n    type(status), optional, intent(out) :: stat\n    logical, intent(in) :: raise\n\n    if (raise) then\n      ! It either sets an error in stat, or stops if stat was not present\n      call raise_error(stat, general_error(\"Some error occured\", -1))\n      return\n    end if\n\n  end subroutine error_raiser\n\nend program test_error_handling\n\nErrors with more complicated payload could be derived from type(general_error). If the handler wished to access the additional details, it would have to use select type to access the content of the derived error type."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-31 03:30:13+00:00",
                    "text": "@aradi it is not clear to me that being flexible with the payload of an error is that useful. If you need detailed context for handling the error then you are better off handling it where it is first detected and you have all the context available. What errors do you see needing large payloads?\n\nFWIW passing unbounded objects on the stack is one of Herb Sutters' complaints about the C++ exception handling system: \"Zero-overhead deterministic exceptions: Throwing values\u201d, http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r0.pdf <http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r0.pdf> . According to his claims it has a significant run-time cost, and little benefit.\n\u2026\n On Jul 30, 2020, at 8:28 AM, B\u00e1lint Aradi ***@***.***> wrote:\n\n\n @wclodius2 <https://github.com/wclodius2> The finalizer in my approach made sure, that one can not let the error being unhandled: If the subroutine returns an error, it must be handled (and explicitely deactivated) before it goes out of scope. Especially, anti-patterns like\n\n ! We pass the optional error argument, but do not hande it afterwards before passing it to the next routine.\n call some_routine(error=error, ...)\n call other_routine(error=error,...)\n ...\n would give then a run-time error. If that is too much of constraints, we could leave away the finalizer. Then, we were basically back to my original proposal using a derived type as status container. No allocation, no move_alloc necessary then.\n\n I would still argue for using derived types / classes for error classification, as this is the only way can stay flexible with the payload of the error. Some (maybe most) errors only return a simple error message, but sometimes also additiional data could be useful to understand the details of the error (numerical value of the determinant of the matrix, which could not be inverted...). We can make the error msg + integer combination the default case, but it should be possible to go beyond that, if needed.\n The following minimal working example demonstrates what I vaguealy have in mind:\n\n module error_handling\n   implicit none\n   private\n\n   public :: general_error, status, raise_error\n\n\n   type :: general_error\n     character(:), allocatable :: msg\n     integer :: error_code\n   contains\n     procedure :: as_char => general_error_as_char\n   end type general_error\n\n\n   type :: status\n     class(general_error), allocatable :: error\n   contains\n     procedure :: is_ok => status_is_ok\n     procedure :: has_failed => status_has_failed\n   end type status\n\n\n   interface general_error\n     module procedure construct_general_error\n   end interface general_error\n\n\n contains\n\n   pure function status_is_ok(this) result(isok)\n     class(status), intent(in) :: this\n     logical :: isok\n\n     isok = .not. allocated(this%error)\n\n   end function status_is_ok\n\n\n   pure function status_has_failed(this) result(hasfailed)\n     class(status), intent(in) :: this\n     logical :: hasfailed\n\n     hasfailed = allocated(this%error)\n\n   end function status_has_failed\n\n\n   function construct_general_error(msg, errorcode) result(this)\n     character(:), allocatable :: msg\n     integer, intent(in) :: errorcode\n     type(general_error) :: this\n\n     this%msg = msg\n     this%error_code = errorcode\n\n   end function construct_general_error\n\n\n   function general_error_as_char(this) result(errorchar)\n     class(general_error), intent(in) :: this\n     character(:), allocatable :: errorchar\n\n     character(100) :: buffer\n\n     write(buffer, \"(' (Error code: ',I0,')')\") this%error_code\n     errorchar = this%msg // trim(buffer)\n\n   end function general_error_as_char\n\n\n   subroutine raise_error(stat, error)\n     type(status), optional, intent(out) :: stat\n     class(general_error), intent(in) :: error\n\n     character(:), allocatable :: errormsg\n\n     if (present(stat)) then\n       stat%error = error\n     else\n       errormsg = error%as_char()\n       error stop errormsg\n     end if\n\n   end subroutine raise_error\n\n end module error_handling\n\n\n program test_error_handling\n   use error_handling\n\n   type(status) :: stat\n   call error_raiser(stat, .true.)\n   if (stat%has_failed()) then\n     print *, \"Error occured: \", stat%error%as_char()\n   end if\n\n contains\n\n   subroutine error_raiser(stat, raise)\n     type(status), optional, intent(out) :: stat\n     logical, intent(in) :: raise\n\n     if (raise) then\n       ! It either sets an error in stat, or stops if stat was not present\n       call raise_error(stat, general_error(\"Some error occured\", -1))\n       return\n     end if\n\n   end subroutine error_raiser\n\n end program test_error_handling\n Errors with more complicated payload could be derived from type(general_error). If the handler wished to access the additional details, it would have to use select type to access the content of the derived error type.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#224 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOTNCURVZUJFVSOTMD3R6F7SJANCNFSM4PFPIXJQ>."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-31 17:08:30+00:00",
                    "text": "I like the type(status) extensible type. But of course, what we really need is proper exception handling in the language. Anything else is just a stop gap solution. (like the current integer and string error messages of some of the intrinsic routines). It's just not enough in 2020.\n\nI agree that the error handling of Fortran is quite cumbersome. error stop with a fixed error message (i.e no runtime information can be communicated to the user) seems to be the best that the language offers. I have used error stop  in the os and os_path implementations and figured out that it gives at least a reasonable stack trace.\nFor subroutines, the error handling by means of return values is quite reasonable, but for functions with one return value it becomes annoying. If I remember correctly, intent(out) is not even allowed in pure functions.\nI would prefer if basic building blocks of the stdlib would use error stop without more elaborated error handling. In addition, stdlib should provide reasonable error handling/logging utilities that allow the user to deal with unexpected situations. Consider the following case:\ncall chdir('this_dir_does_not_exist') ! will terminate with error stop\n\nif(.not. isdir('this_dir_does_not_exist')) then\n  call stdlib_error_handler('this_dir_does_not_exist'// 'does not exist')\nelse\n call chdir('this_dir_does_not_exist') \nendif\n\nThis means extra work for the user, but all intrinsic statements (i.e. open) work like that.\nIf we would enforce error propagation by means of an error type, we would essentially forbid the use of pure functions!"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-31 18:15:12+00:00",
                    "text": "Fortran 2018 increased the functionality of ERROR STOP by:\n\n1. Allowing it in pure procedures\n\n2. Allowing it to have runtime stop codes.\n\nHowever the num her of processors \"in the wild\u201d that don\u2019t implement this part of F18 is still very large, and it is probably best that the standard library limit itself to F08 functionality. In F08 runtime stop codes can sometimes be kluged, by using SELECT CASE to choose at runtime among a fixed set of static stop codes.\n\nConstraint C1583 in my copy of the draft of the standard for PURE functions requires that all non-pointer arguments of the function have the INTENT(IN) or VALUE attribute.\n\nEven without the constraint Fortran imposes only a partial order of evaluation for many expression, so functions with side effects, such as INTENT(INOUT) or INTENT(OUT) are generally a bad idea unless you can guarantee they will only be used with great discipline.\n\nPure functions can indicate a problem was found either by returning a special value, e.g. NaN for REAL function results, or -1  for some INTEGER function results, or by invoking ERROR STOP in F18.\n\nFWIW I have taken to using the idiom for error handling roughly equivalent to\n\n    if (.not. isdir(the_dir) ) then\n        if ( present(stat) ) then\n            stat = missing_dir_failure\n            return\n        else\n            call error_handler( the_dir // \u2018 is missing\u2019, &\n\t        module = this_module, &\n                procedure = this_procedure, &\n                stat = missing_dir_failure ) ! invoking error stop\n        end if\n    else\n        opent(newlun=lun, file=the_dir // filename, \u2026 )\n    end if\n\nNote that following FLIBS and FUTIL I am considering adding a `LEVEL` keyword to `ERROR_HANDLER` which can take as arguments predefined values: `INFORMATION`, `WARNING`, `ERROR`, or `FATAL_ERROR`."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-08-01 10:27:48+00:00",
                    "text": "If the conditions that lead to an error stop are \"identifiable\" from the\noutside, like the above example, then we can always allow for a wrapper\nthat checks the error conditions first. Such a wrapper can then be used to\npass on the information that something went wrong and allow for error\nrecovery. Whether a programmer wants to use the underlying routine or the\nwrapper is then up to them.\n\nThis would be more difficult, if you have, say, a matrix solver, that\nhalfway through, concludes that the matrix is near-singular and then stops.\nThis would not be something easily checked in advance.\n\nRegards,\n\nArjen\n\nOp vr 31 jul. 2020 om 19:08 schreef Martin Diehl <notifications@github.com>:\n\u2026\n I like the type(status) extensible type. But of course, what we really\n need is proper exception handling in the language. Anything else is just a\n stop gap solution. (like the current integer and string error messages of\n some of the intrinsic routines). It's just not enough in 2020.\n\n I agree that the error handling of Fortran is quite cumbersome. error stop\n with a fixed error message (i.e no runtime information can be communicated\n to the user) seems to be the best that the language offers. I have used error\n stop in the os and os_path implementations and figured out that it gives\n at least a reasonable stack trace.\n For subroutines, the error handling by means of return values is quite\n reasonable, but for functions with one return value it becomes annoying. If\n I remember correctly, intent(out) is not even allowed in pure functions.\n\n I would prefer if basic building blocks of the stdlib would use error stop\n without more elaborated error handling. In addition, stdlib should provide\n reasonable error handling/logging utilities that allow the user to deal\n with unexpected situations. Consider the following case:\n\n call chdir('this_dir_does_not_exist') ! will terminate with error stop\n\n if(.not. isdir('this_dir_does_not_exist')) then\n   call stdlib_error_handler('this_dir_does_not_exist'// 'does not exist')\n else\n  call chdir('this_dir_does_not_exist')\n endif\n\n This means extra work for the user, but all intrinsic statements (i.e.\n open) work like that.\n\n *If we would enforce error propagation by means of an error type, we would\n essentially forbid the use of pure functions!*\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#224 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR342UMCE64AYSM3ROTR6L3B7ANCNFSM4PFPIXJQ>\n ."
                },
                {
                    "user": "aradi",
                    "date": "2020-08-01 10:27:56+00:00",
                    "text": "@MarDiehl I'd personally would have very-very strong objections against letting low level I/O-routines die on error with error stop without the possibility of preventing it via error reporting / handling. Think about a Fortran library linked to a big graphical UI. It is a no-go, if an entire UI just crashes / stops without saving user data, just because a badly written Fortran routine at the very depth is not able to handle / propagate errors.\nIn my opinion, there must be always an alternative to error stop whenever\n\nthe programmer has not full control over the environment and can therefore not ensure proper action in advance or\nwhenever ensuring the right conditions would be way too elaborate (e.g. finding out whether a system of equation is linearly dependent before passing it to the solver routine).\n\nHow, the error is indicated/propagated/handled is of course a matter of taste (and topic of this issue \ud83d\ude09 ) and can even differ in each case,  but error stop without an alternative can not be a serious choice for a standard library IMO. We can offer the error stop solution if the caller wants it (e.g. by making the error/status argument optional and stopping on error if not present.) But we also provide an alternative way, so that one can write robust components of big packages in Fortran.\nYour proposed error handling for change_directory is not robust IMO. It would be quite elaborate to find out in advance whether you can change into a directory as you would also have to check for the proper access rights for example (which is usually not covered by is_dir()). And even then, it may happen, that a concurrent process deletes the directory between  is_dir() and chdir. The simplest and most robust way to know, whether you can change into it is to try it (make the appropriate libc-call), report the error on failure  and let the caller decide."
                },
                {
                    "user": "aradi",
                    "date": "2020-08-01 10:33:52+00:00",
                    "text": "As for pure functions: I think, we only should allow pure functions, where:\n\nThe function can not fail or\nthe function can report failure with special return values (e.g. -1 or NaN).\n\nNote that I am not referring here to programming errors as mentioned by @jvdp1 . If you pass the wrong dimension to a routine, it is OK if it calls stop error as this a clear programming error."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-08-01 12:06:42+00:00",
                    "text": "You have convinced me that error stop is a bad idea and will change os and os_pathaccordingly.\nMy suggestion would be to follow the Fortran way and use integer return values and/or return special values. This is for example also done in the open statement. The user can then handle errors from stdlib and the core language in a similar way.\nIn also think that it makes sense to offer a stdlib solution for error handling (a special type/printing messages etc). However, I would like to avoid a strong coupling of individual parts from stdlib. Therefore, I'm opposing to use this error handling routine in basic routines like os and os_path. That would force the user to also use the error handling routine (which is not part of the language, but 'just' a part of the standard library). If it turns out that there is a commonly used pattern of combining file system routines and error handling, this could become a second level module (similar to os.path and Pathlib in python: A more direct, low level library and a more advanced, OO-based approach)."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-01 13:51:22+00:00",
                    "text": "In the codes I am attempting to write, I find error handling to be a pervasive problem and think that strong coupling to library defined error handling to be unavoidable. I do not want each module to provide its own logging system. I therefore want the library to provide strong quality error handling routines. For other applications strong coupling to the file handling and os services may be unavoidable."
                },
                {
                    "user": "certik",
                    "date": "2020-08-01 15:57:47+00:00",
                    "text": "Take our linalg as an example.\n\nThe very low level API is Lapack itself, which does not use derived types (thus there could be 15 arguments, but everything is essentially pure, no side effects) nor error stop, errors are propagated up, the user has to check them and handle them. This design ensures maximum reusability, it truly works for everybody.\n\nThe rest of the work is providing optional layers on top to simplify the API for some users, but some other users will always use Lapack directly.\n\nThe mid level API that I am hoping will go to stdlib is to provide simple Matlab/Python like functions such as y=solve(A, x). This has the following features: still no derived types, but it will fail with error stop is the matrix is singular, to ensure users code will never continue with bogus answers. We can optionally add a status variable, which if provided will propagate the error up. This API is for a subset of users who want to quickly prototype their code and just solve a matrix, not having to lose time figuring out the 15 arguments for lapack, and they want it to fail with error stop.\n\nThen there can be an OO style API, like solver = Factorize(A); y=solver.solve(x).\n\nThere can be various ways to do error handling, different for each API. But it all starts having the procedural low level API that can be used as a building blocks for everything else.\n\u2026\nOn Sat, Aug 1, 2020, at 7:51 AM, William B. Clodius wrote:\n\n\n In the codes I am attempting to write, I find error handling to be a\n pervasive problem and think that strong coupling to library defined\n error handling to be unavoidable. I do not want each module to provide\n its own logging system. I therefore want the library to provide strong\n quality error handling routines. For other applications strong coupling\n to the file handling and os services may be unavoidable.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#224 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWCTYID2FTFMCZ3TXCLR6QMWNANCNFSM4PFPIXJQ>."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-01 19:32:00+00:00",
                    "text": "Do we want users to have the option of sending the error messages, if the optional STAT is not present, to their log files as well as the ERROR_UNIT of ERROR STOP? If we do then we want the library to consistently use our logging routines for error reporting."
                },
                {
                    "user": "certik",
                    "date": "2020-08-01 20:50:12+00:00",
                    "text": "What I had in mind for the y=solve(A,x) kind of middle level API is that it would just call error stop with some nice explanation, and that's it. If users want something more sophisticated, then they have to provide the optional stat argument, or use the lower level or more OO oriented API. That way functions like solve can stay pure."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-08-02 19:28:05+00:00",
                    "text": "Do we want users to have the option of sending the error messages, if the optional STAT is not present, to their log files as well as the ERROR_UNIT of ERROR STOP? If we do then we want the library to consistently use our logging routines for error reporting.\n\nI would suggest to make it consistent with the language features: exit with error stop if stat is not present and an error occurs, otherwise do not exit and inform via stat. This is at least the case for read and open"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-08-02 19:30:50+00:00",
                    "text": "What I had in mind for the y=solve(A,x) kind of middle level API is that it would just call error stop with some nice explanation, and that's it. If users want something more sophisticated, then they have to provide the optional stat argument, or use the lower level or more OO oriented API. That way functions like solve can stay pure.\n\ny=solve(A,x)  with optional stat argument cannot be pure, it would need to be call solve(A,x,y) or call solve(A,x,y,err). Pure functions can have only intent(in) arguments, unless for pointers. Could make sense to define the a pointer solution for the error handling routines.\nBut apart of this, I like the approach to have a error handling type for more involved/abstract functions and use plain integer for simple functions."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-08 23:09:54+00:00",
                    "text": "I would suggest to make it consistent with the language features: exit with error stop if stat is not present and an error occurs, otherwise do not exit and inform via stat. This is at least the case for read and open\n\nand write, inquire, close, rewind, backspace, allocate, deallocate, the \"atomic\" subroutines, and basically anything else that can go wrong that the processor can detect. There are two limitations with error stop by itself for this application: first, in Fortran 08 it cannot accept variable strings as arguments; and, second, it is awkward by itself to send detailed messages. Both of these issues could be dealt with by having a logging system in the standard library."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-08 23:19:10+00:00",
                    "text": "But apart of this, I like the approach to have a error handling type for more involved/abstract functions and use plain integer for simple functions.\n\nThere is no simple dividing line between involved/abstract functions and simple functions. I like using the same approach for all procedures."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-11 17:53:32+00:00",
                    "text": "To facilitate discussion of this issue I thought it would be useful to\ncode up examples for different approaches to error handling where\nadditional information might be useful. As my example I chose an\nan I/O failure on an OPEN statement, where the standard provides\naddional data in the form of an IOSTAT and IOMSG. In practice, I\nthought an I/O failure would be more amenable to handling, than an\nallocation or co-array related failure, where the standard provides\nadditional information in the form of a STAT (or STATUS) and\nERRMSG.  For my examples I choose a simple flattend derived type,\nscalar integer codes, and a variant of @aradi's derived type that has a\nderived type as an attribute. In all examples I assume the existence\nof a module ERROR_CODES with predefined values for the most obvious\nerror codes. FWIW I have such a module with about 100 error codes\ndefined.\nFor my first example of a handling method I chose a flattened derived\ntype, ERROR_T, with the attributes, CODE, MSG, STAT, and\nERRMSG as one that could handle both IOSTAT with IOMSG and\nSTAT with ERRMSG. As testing for the value of the CODE value is\nboth a cheap and relatively intuitive means of determining whether an\nerror has occured I don't define IS_OK or HAS_FAILED\nfunctions. Additional attributes MODULE and PROCEDURE to indicate\nthe source of the error, might also be usefully added to ERROR_T.\nmodule error_handling\n\n    use error_codes, only : success\n    implicit none\n    private\n\n    public :: error_t, error\n\n    type :: error_t\n        integer :: code = success\n        character(:), allocatable :: msg\n        integer :: stat = 0\n        character(:), allocatable :: errmsg\n    contains\n        procedure :: as_char => error_as_char\n    end type error_t\n\n    interface error\n        module procedure construct_error\n    end interface error\n\ncontains\n\n    function construct_error(msg, code, errmsg, stat) &\n        result(this)\n        character(:), intent(in) :: msg\n        integer, intent(in) :: code\n        character(:), intent(in), optional :: errmsg\n        integer, intent(in), optional :: stat\n        type(error_t) :: this\n\n        this % msg = msg\n        this % code = code\n        if ( present(errmsg) ) then\n            this % errmsg = errmsg\n        end if\n        if ( present(stat) ) then\n            this % stat = stat\n        end if\n\n    end function construct_error\n\n\n    function error_as_char(this) result(errorchar)\n        type(error_t), intent(in) :: this\n        character(:), allocatable :: errorchar\n\n        character(100) :: buffer\n\n        write(buffer, \"(' (Error code: ',I0,')')\") this % code\n        errorchar = trim(this % msg) // trim(buffer)\n\n    end function error_as_char\n\nend module error_handling\n\n\nprogram test_error_t_handling\n    use error_handling\n    use error_codes, only: success, missing_file_failure, &\n        open_failure\n\n    type(error_t) :: stat\n\n    call error_raiser(stat)\n    if (stat % code /= success) then\n        print *, \"Error occured: \", stat % as_char()\n        write(output_unit, '(\"IOMSG =\", a)' ) stat % errmsg\n        write(output_unit, '(\"IOSTAT = \", i0)' ) stat % stat\n    end if\n\ncontains\n\n    subroutine error_raiser(stat)\n        type(error_t), optional, intent(out) :: stat\n        logical :: exist\n        integer :: iostat, lun\n        character(256) :: iomsg\n\n        open( newunit=lun, file='dummy.txt', status='old', &\n              form='formatted', action='read', err=999,    &\n              iostat=iostat, iomsg=iomsg )\n        return\n\n999     inquire( file='dummy.txt' exist=exist )\n        if ( exist ) then\n! May never happen\n            if ( present(stat) ) then\n                stat = error( msg='Unable to open existing' // &\n                    ' \"OLD\" file \"dummy.txt\".', &\n                    code = open_failure, errmsg=trim(iomsg), &\n                    stat=iostat )\n                return\n            else\n                write(output_unit, '(\"Procedure: ERROR_RAISER\")' )\n                write(output_unit, '(\"IOMSG =\", a)' ) iomsg\n                write(output_unit, '(\"IOSTAT = \", i0)' ) iostat\n                error stop 'Unable to open existing \"OLD\" file ' // &\n                    '\"dummy.txt\".'\n            end if\n        else\n! May be due to a lack of READ priviledges for the file\n            if ( present(stat) ) then\n                stat = error( msg='Missing \"OLD\" file \"dummy.txt\".', &\n                    code = missing_file_failure, errmsg=trim(iomsg), &\n                    stat=iostat )\n                return\n            else\n                write(output_unit, '(\"Procedure: ERROR_RAISER\")' )\n                write(output_unit, '(\"IOMSG =\", a)' ) iomsg\n                write(output_unit, '(\"IOSTAT = \", i0)' ) iostat\n                error stop 'Missing \"OLD\" file \"dummy.txt\".'\n            end if\n        end if\n\n    end subroutine error_raiser\n\nend program test_error_t_handling\n\nAs an alternative, I show the handling with a simple integer error\ncode. This, of course, lacks the derived type's MSG, STAT, and\nERRMSG attributes. FWIW for the I/O errors I suspect the fixes would\ninvolve either moving a file or changing its priviledges, and for\nthose actions I suspect the error code is sufficient and the other\nattributes are unnecessary.\nprogram test_integer_handling\n    use error_codes, only: success, missing_file_failure, &\n        open_failure\n\n    integer :: stat\n    call error_raiser(stat)\n    if (stat /= success) then\n        select case ( stat )\n        case( open_failure )\n            print *, \"A failure occurred on an OPEN statement.\"\n        case( missing_file_failure )\n            print *, \"A missing file failure occured.\"\n        end select\n\n    end if\n\ncontains\n\n    subroutine error_raiser(stat)\n        integer, optional, intent(out) :: stat\n        logical :: exist\n        integer :: iostat, lun\n        character(256) :: iomsg\n\n        open( newunit=lun, file='dummy.txt', status='old', &\n              form='formatted', action='read', err=999,    &\n              iostat=iostat, iomsg=iomsg )\n        return\n\n999     inquire( file='dummy.txt' exist=exist )\n        if ( exist ) then\n! May never happen\n            if ( present(stat) ) then\n                stat =  open_failure\n                return\n            else\n                write(output_unit, '(\"Procedure: ERROR_RAISER\")' )\n                write(output_unit, '(\"IOMSG =\", a)' ) iomsg\n                write(output_unit, '(\"IOSTAT = \", i0)' ) iostat\n                error stop 'Unable to open existing \"OLD\"' // &\n                    ' file \"dummy.txt\".'\n            end if\n        else\n! May be due to a lack of READ priviledges for the file\n            if ( present(stat) ) then\n                stat = missing_file_failure\n                return\n            else\n                write(output_unit, '(\"Procedure: ERROR_RAISER\")' )\n                write(output_unit, '(\"IOMSG =\", a)' ) iomsg\n                write(output_unit, '(\"IOSTAT = \", i0)' ) iostat\n                error stop 'Missing \"OLD\" file \"dummy.txt\".'\n            end if\n        end if\n\n    end subroutine error_raiser\n\nend program test_integer_handling\n\nFinally I show a modified version of @aradi's code in which I extend\nhis GENERAL_ERROR with IO_ERROR with the additional attributes\nIOSTAT and IOMSG. This also requires defining an additonal\nconstructor for IO_ERROR. Because defining a new type and associated\nconstructor for each type of error strikes me as awkward and a pain, I\nassume that ERRORCODE is used to distinguish different sub-types of\nI/O errors.\nmodule error_handling\n    implicit none\n    private\n\n    public :: general_error, io_error, status, raise_error\n\n    type :: general_error\n        character(:), allocatable :: msg\n        integer :: error_code\n    contains\n        procedure :: as_char => general_error_as_char\n    end type general_error\n\n    type, extends(general_error) :: io_error\n        character(:), allocatable :: iomsg\n        integer :: iostat\n    end type io_error\n\n    type :: status\n        class(general_error), allocatable :: error\n    contains\n        procedure :: is_ok => status_is_ok\n        procedure :: has_failed => status_has_failed\n    end type status\n\n    interface general_error\n        module procedure construct_general_error\n    end interface general_error\n\n    interface io_error\n        module procedure construct_io_error\n    end interface io_error\n\ncontains\n\n    pure function status_is_ok(this) result(isok)\n        class(status), intent(in) :: this\n        logical :: isok\n\n        isok = .not. allocated(this%error)\n\n    end function status_is_ok\n\n    pure function status_has_failed(this) result(hasfailed)\n        class(status), intent(in) :: this\n        logical :: hasfailed\n\n        hasfailed = allocated(this%error)\n\n    end function status_has_failed\n\n    function construct_general_error(msg, errorcode) &\n        result(this)\n        character(*), intent(in) :: msg\n        integer, intent(in) :: errorcode\n        class(general_error) :: this\n\n        this%msg = msg\n        this%error_code = errorcode\n\n    end function construct_general_error\n\n    function construct_io_error(msg, errorcode, iomsg, iostat) &\n        result(this)\n        character(*), intent(in) :: msg\n        integer, intent(in) :: errorcode\n        character(*), intent(in) :: iomsg\n        integer, intent(in) :: iostat\n        class(io_error) :: this\n\n        this % msg = msg\n        this % error_code = errorcode\n        this % iomsg = iomsg\n        this % iostat = iostat\n\n    end function construct_io_error\n\n    function general_error_as_char(this) result(errorchar)\n        class(general_error), intent(in) :: this\n        character(:), allocatable :: errorchar\n\n        character(100) :: buffer\n\n        write(buffer, \"(' (Error code: ',I0,')')\") this%error_code\n        errorchar = this%msg // trim(buffer)\n\n    end function general_error_as_char\n\n    subroutine raise_error(stat, error)\n        type(status), optional, intent(out) :: stat\n        class(general_error), intent(in) :: error\n\n        character(:), allocatable :: errormsg\n\n        if (present(stat)) then\n            stat%error = error\n            return\n        else\n            errormsg = error%as_char()\n            error stop errormsg ! Legal in F18 but not in F08\n        end if\n\n    end subroutine raise_error\n\nend module error_handling\n\n\nprogram test_error_handling\n    use error_handling\n    use error_codes, only: success, missing_file_failure, &\n        open_failure\n\n    type(status) :: stat\n    call error_raiser(stat)\n    if (stat%has_failed()) then\n        print *, \"Error occured: \", stat%error%as_char()\n    end if\n\ncontains\n\n    subroutine error_raiser(stat)\n        type(status), optional, intent(out) :: stat\n        logical :: exist\n        integer :: iostat, lun\n        character(256) :: iomsg\n\n        open( newunit=lun, file='dummy.txt', status='old', &\n              form='formatted', action='read', err=999,    &\n              iostat=iostat, iomsg=iomsg )\n        return\n\n999     inquire( file='dummy.txt' exist=exist )\n        if ( exist ) then\n! May never happen\n            if ( present(stat) ) then\n                call raise_error( stat, io_error( msg='Unable' // &\n                    ' to open existing \"OLD\" file \"dummy.txt\".', &\n                    errorcode = open_failure, errmsg=trim(iomsg), &\n                    stat=iostat ) )\n                return\n            else\n                write(output_unit, '(\"Procedure: ERROR_RAISER\")' )\n                write(output_unit, '(\"IOMSG =\", a)' ) iomsg\n                write(output_unit, '(\"IOSTAT = \", i0)' ) iostat\n                error stop 'Unable to open existing \"OLD\" file ' // &\n                    '\"dummy.txt\".'\n            end if\n        else\n! May be due to a lack of READ priviledges for the file\n            if ( present(stat) ) then\n                call raise_error( stat, io_error( msg='Missing' // & \n                    ' \"OLD\" file \"dummy.txt\".', &\n                    errorcode = missing_file_failure, &\n                    errmsg=trim(iomsg), &\n                    stat=iostat )\n                return\n            else\n                write(output_unit, '(\"Procedure: ERROR_RAISER\")' )\n                write(output_unit, '(\"IOMSG =\", a)' ) iomsg\n                write(output_unit, '(\"IOSTAT = \", i0)' ) iostat\n                error stop 'Missing \"OLD\" file \"dummy.txt\".'\n            end if\n        end if\n\n    end subroutine error_raiser\n\nend program test_error_handling"
                },
                {
                    "user": "aradi",
                    "date": "2020-08-25 14:24:21+00:00",
                    "text": "As for the third version, considering our earlier discussions, I'd suggest to use the error type directly, and its allocation status as status flag (not allocated: OK, allocated: error occured). This is more direct and probably also somewhat more efficient. So, it would be something like:\nmodule error_handling\n  implicit none\n  private\n\n  public :: general_error, io_error\n\n  type :: general_error\n    character(:), allocatable :: msg\n    integer :: error_code\n  contains\n    procedure :: as_char => general_error_as_char\n  end type general_error\n\n  type, extends(general_error) :: io_error\n    character(:), allocatable :: iomsg\n    integer :: iostat\n  end type io_error\n\n  interface general_error\n    module procedure construct_general_error\n  end interface general_error\n\n  interface io_error\n    module procedure construct_io_error\n  end interface io_error\n\ncontains\n\n  function construct_general_error(msg, errorcode) result(this)\n    character(*), intent(in) :: msg\n    integer, intent(in) :: errorcode\n    type(general_error) :: this\n\n    this%msg = msg\n    this%error_code = errorcode\n\n  end function construct_general_error\n\n\n  function construct_io_error(msg, errorcode, iomsg, iostat) result(this)\n    character(*), intent(in) :: msg\n    integer, intent(in) :: errorcode\n    character(*), intent(in) :: iomsg\n    integer, intent(in) :: iostat\n    type(io_error) :: this\n\n    this%msg = msg\n    this%error_code = errorcode\n    this%iomsg = iomsg\n    this%iostat = iostat\n\n  end function construct_io_error\n\n\n  function general_error_as_char(this) result(errorchar)\n    class(general_error), intent(in) :: this\n    character(:), allocatable :: errorchar\n\n    character(100) :: buffer\n\n    write(buffer, \"(' (Error code: ',I0,')')\") this%error_code\n    errorchar = this%msg // trim(buffer)\n\n  end function general_error_as_char\n\n\nend module error_handling\n\n\nprogram test_error_handling\n  use error_handling\n  use error_codes, only: success, missing_file_failure, open_failure\n\n  type(io_error), allocatable :: error\n\n  call ioerror_raiser(error)\n  if (allocated(error)) then\n    print *, \"Error occured: \", error%as_char()\n  end if\n\ncontains\n\n  subroutine ioerror_raiser(error)\n    type(io_error), allocatable, intent(out), optional :: error\n\n    logical :: exist\n    integer :: iostat, lun\n    character(256) :: iomsg\n\n    open(newunit=lun, file='dummy.txt', status='old', form='formatted',&\n        & action='read', err=999, iostat=iostat, iomsg=iomsg)\n    return\n\n999 inquire(file='dummy.txt', exist=exist)\n    if (exist) then\n      ! May never happen\n      if (present(error)) then\n        error = io_error(msg='Unable to open existing \"OLD\" file \"dummy.txt\"',&\n            & errorcode=open_failure, iomsg=trim(iomsg), iostat=iostat)\n        return\n      else\n        write(output_unit, '(\"Procedure: ERROR_RAISER\")' )\n        write(output_unit, '(\"IOMSG =\", a)' ) iomsg\n        write(output_unit, '(\"IOSTAT = \", i0)' ) iostat\n        error stop 'Unable to open existing \"OLD\" file ' // &\n            '\"dummy.txt\".'\n      end if\n    else\n      ! May be due to a lack of READ priviledges for the file\n      if (present(error)) then\n        error = io_error(msg='Missing \"OLD\" file \"dummy.txt\".', &\n            & errorcode = missing_file_failure, iomsg=trim(iomsg),&\n            & iostat=iostat)\n        return\n      else\n        write(output_unit, '(\"Procedure: ERROR_RAISER\")' )\n        write(output_unit, '(\"IOMSG =\", a)' ) iomsg\n        write(output_unit, '(\"IOSTAT = \", i0)' ) iostat\n        error stop 'Missing \"OLD\" file \"dummy.txt\".'\n      end if\n    end if\n\n  end subroutine ioerror_raiser\n\nend program test_error_handling"
                }
            ]
        },
        {
            "number": 223,
            "user": "jvdp1",
            "date": "2020-07-22 16:54:27+00:00",
            "title": "Changes directory structure of stdlib as discussed in #216",
            "text": "This PR changes the directory structure of stdlib as discussed in #216 opened by @wclodius2\nIn short:\n\nall \"experimental\" terms have been removed from the names of the modules\na version (\"experimental\") tag has been added to all procedures and also in the specs. FORD uses the version tag as meta-data.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-07-22 17:05:11+00:00",
                    "text": "The FORD documentation can be dowloaded here."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-22 17:07:49+00:00",
                    "text": "This is a major change in terms of structure for stdlib.\nIs everybody ok with that? It should be easier for the users to use stdlib now. However, is it still clear enough that the procedures are experimentatl?"
                },
                {
                    "user": "certik",
                    "date": "2020-07-22 17:14:36+00:00",
                    "text": "I think we are ok with the general idea to do it like this.\nI think the only thing to figure out is how exactly to document that all those routines are experimental. Should we also add a comment next to each subroutine in the source file? I think I would prefer that --- we want to convey as clearly as possible that the subroutine is experimental."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-07-22 17:22:35+00:00",
                    "text": "@certik I believe having the version: experimental as @jvdp1 has done should suffice.  Having the experimental tag in the Ford  doc comments covers all bases.  Is there anywhere else that would more clearly indicate the experimental nature of a function?\nCould we have a script that simply parses out \"version: experimental\" and lists them in the docs?  Maybe this is something we could add to FORD?"
                },
                {
                    "user": "certik",
                    "date": "2020-07-22 17:27:53+00:00",
                    "text": "Given how important the change is, I am CCing others who committed the most code so far: @zbeekman, @nshaffer, @scivision, @fiolj, @MarDiehl, @aradi, @ivan-pi, to make sure everybody is on board."
                },
                {
                    "user": "fiolj",
                    "date": "2020-07-22 17:52:52+00:00",
                    "text": "I've been away for a while. I am ok with the change in structure."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-22 17:59:07+00:00",
                    "text": "Could we have a script that simply parses out \"version: experimental\" and lists them in the docs? Maybe this is something we could add to FORD?\n\nThe version of each procedure is mentioned in FORD website when you open the page of a procedure.\nI think it would be also nice if the version would be added in the table that lists all the procedures."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-07-22 21:23:39+00:00",
                    "text": "So in the generated docs, experimental interfaces get a subsection like\nVersion\nExperimental\nWhat would this say for stable interfaces, \"stable\"? Seems strange to me. Might just be the word \"version\". If we are only classifying interfaces as \"experimental\" or \"stable\", I think maybe calling this section \"status\" makes more sense? If I'm a user and I see \"Version: stable\", I wonder \"OK, so is there and unstable version as well?\" (a la how some Linux distributions classify packages as stable/unstable/testing).\nOther than that detail, I support this change."
                },
                {
                    "user": "certik",
                    "date": "2020-07-22 21:37:07+00:00",
                    "text": "I agree, using Status instead of Version is better I think."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-24 07:59:44+00:00",
                    "text": "I agree with the comments on status vs version. I changed the title Version in the specs to Status in this commit.\nIMO The Status keyword has also the advantage that when a procedure will be moved to the stable version, it could  be mentioned something like (if we go in this direction of course):\n\nStatus\nStable, since x.x.x"
                },
                {
                    "user": "scivision",
                    "date": "2020-07-24 09:11:58+00:00",
                    "text": "Yes this is a good and necessary change"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-28 17:34:03+00:00",
                    "text": "It seems there is an agreement on the proposed change of the structure of stdlib.\nThank you all for your feedback. I'll merge."
                }
            ]
        },
        {
            "number": 222,
            "user": "jvdp1",
            "date": "2020-07-22 07:09:58+00:00",
            "title": "Install GFortran macOS in doc-deployment CI",
            "text": "Issue: gfortran was not found for the doc-deployment script.\nInstalling it solved the problem.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-07-22 16:42:54+00:00",
                    "text": "Yes. The actuall problem is that only gfortran-9 is installed, but not gfortran. For fpm I fixed this in here this way:\nfortran-lang/fpm#132\nFor stdlib, if this PR works (it seems it does), then +1."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-22 16:47:40+00:00",
                    "text": "Good. I will merge it."
                }
            ]
        },
        {
            "number": 221,
            "user": "wclodius2",
            "date": "2020-07-18 02:36:09+00:00",
            "title": "API for a bitset data type ",
            "text": "Both C++ and Java define a bitset type, so I propose that the standard\nlibrary also have a module implementing a bitset type. My first draft\nfor a public API for that module is as follows.\nThe module name is STDLIB_BITSETS.\nThe module exports one constant, BITS_KIND, to be used as a KIND\nvalue in addressing bits in the bitset. This will initially be\nINT32.\nThe module exports one derived type, BITSETS, with a plural name so\nthat users can name their scalar realizations as BITSET. The type\nwill contain two private components: BITS a scalar integer of kind\nBITS_KIND giving the number of bits in a bitset entity, and a rank\none allocatable integer array BLOCK of private kind BLOCK_KIND,\nthat will be INT32, to be used in holding the bit values. The type\nhas an ASSIGNMENT(=) operation defined.\nBITSETS will have the following procedures: ALL, AND, AND_NOT,\nANY_BIT, BIT_COUNT, BITS, CLEAR, EOR, EQUIV, EXTRACT,\nFLIP, INIT, INPUT, MAX_SET_BIT, NONE, OR, OUTPUT,\nPRINT_BITSET, READ_BITSET, SET, TEST, and VALUE. Some of\nthese procedures will be overloaded:\ninterface clear\n    module procedure clear_bit, clear_range\nend interface clear\n\ninterface flip\n    module procedure flip_bit, flip_range\nend interface flip\n\ninterface init\n    module procedure init_copy, init_zero\nend interface init\n\ninterface set\n    module procedure set_bit, set_range\nend interface set\n\ninterface print_bitset\n    module procedure print_bitset_string, print_bitset_unit\nend interface print_bitset\n\ninterface read_bitset\n    module procedure read_bitset_string, read_bitset_unit\nend interface read_bitset\n\nThe API for the individual procedures is listed below. The following\naspects of the API may be controversial:\n\n\nHow the range is defined for CLEAR_RANGE, FLIP_RANGE, and\nSET_RANGE. I have roughly followed Java's bitset here.\n\n\nThat the first argument is modified in AND, AND_NOT, EOR, and\nOR. That is how it is done in the Java bitset, but I can see\nhaving a function that returns the result rather than a subroutine\nthat modifies the first argument.\n\n\nThat the I/O procedures INPUT, OUTPUT, PRINT_BITSET, and\nREAD_BITSET have STATUS flags.\n\n\nThat the procedures often ignore user specification of positions\noutside the range 0 to BITS-1. An alternative is to make the\nprocedures impure and invoking ERROR STOP. Another option is to\nadd a STATUS argument, but I am reluctant to do that for a simple\nuser error.\n\n\nThe names of some of the procedures could be more similar to the\nnames of Fortran's bit intrinsics.\n\n\nsubroutine init_copy(set, aset, bits)\n: Creates the bitset SET, of size BITS if present, otherwise of the\nsize of ASET. All bits in the range of ASET are copied from ASET. If\nBITS is present and larger than the size of ASET then all additional\nbits are zero.\nsubroutine init_zero(set, bits)\n: Creates the bitset, SET, of size BITS, with all bits initialized to\nzero. BITS must be non-negative.\nelemental function all_bits( set )\n: Returns .TRUE. if all bits in SET are 1, .FALSE. otherwise.\nelemental subroutine and(set1, set2)\n: Sets the bits in SET1 to the bitwise AND of the original bits in\nSET1 and SET2. If SET1 has fewer bits than SET2 then the\nadditional bits in SET2 are ignored. If SET1 has more bits than\nSET2, then the absent SET2 bits are treated as if present with\nzero value.\nelemental subroutine and_not(set1, set2)\n: Sets the bits in SET1 to the bitwise and of the original bits in\nSET1 with the bitwise negation of SET2. If SET1 has fewer bits\nthan SET2 then the additional bits in SET2 are ignored. If SET1\nhas more bits, then the absent SET2 bits are treated as if present\nwith zero value.\nelemental function any_bit(set)\n: Returns .TRUE. if any bit in SET is 1, .FALSE. otherwise\nelemental function bit_count(set)\n: Returns the number of non-zero bits in SET.\nelemental function bits(set)\n: Returns the number of bit positions in SET.\nelemental subroutine clear_bit(set, pos)\n: Sets to zero the POS position in SET. If POS is less than zero\nor greater than BITS(SET)-1 it is ignored.\npure subroutine clear_range(set, start_pos, stop_pos)\n: Sets to zero all bits from the START_POS to STOP_POS positions in\nSET. If STOP_POS < START_POS then no bits are modified. Positions\noutside the range 0 to BITS(SET)-1 are ignored.\nelemental subroutine eor(set1, set2)\n: Sets the bits in SET1 to the bitwise EOR of the original bits in\nSET1 and SET2. If SET1 has fewer bits than SET2 then the\nadditional bits in SET2 are ignored. If SET1 has more bits than\nSET2, then the absent SET2 bits are treated as if present with\nzero value.\nelemental function equiv(set1, set2)\n: Returns .TRUE. if all bits in SET1 and SET2 have the same\nvalue, .FALSE.  otherwise. If the sets differ in size a value true\nwill be returned if and only if the sets are equivalent in the\noverlapping range, and all bits outside the overlapping range are\nzero.\npure function extract(set, start_pos, stop_pos)\n: Creates a new bitset from a range, START_POS to STOP_POS, in\nbitset SET.\nelemental subroutine flip_bit(set, pos)\n: Flips the value at the POS position in SET, provided the\nposition is valid. If POS is less than 0 or greater than\nBITS(SET)-1, then no value is changed.\npure subroutine flip_range(set, start_pos, stop_pos)\n: Flips all valid bits from the START_POS to STOP_POS positions in\nSET. If STOP_POS < START_POS no bits are flipped. Positions less\nthan 0 or greater than BITS(SET)-1 are ignored.\nsubroutine input(unit, set, status)\n: Reads the components of the bitset, SET, from the logical unit,\nUNIT, assuming that the components were written using OUTPUT.\nelemental function max_set_bit( set )\n: Returns the maximum position with a set bit. If no bit is set\nreturns -1.\nelemental function none(set)\n: Returns .TRUE. if none of the bits in SET have the value 1.\nelemental subroutine or(set1, set2)\n: Sets the bits in SET1 to the bitwise OR of the original bits in\nSET1 and SET2. If SET1 has fewer bits than SET2 then the\nadditional bits in SET2 are ignored. If SET1 has more bits than\nSET2, then the absent SET2 bits are treated as if present with\nzero value.\nsubroutine output(unit, set, status)\n: Writes the components of the bitset, SET, to the logical unit,\nUNIT, in a unformatted sequence compatible with INPUT.\nsubroutine print_bitset_string(string, set)\n: Writes a BITSETS literal to the allocatable default character\nSTRING, representing the individual bit values in the bitsets,\nSET.\nsubroutine print_bitset_unit(unit, set, status, advance)\n: Writes a bitsets literal to the logical unit, UNIT, representing\nthe individual bit values in the bitsets, SET. If STATUS is not\npresent and an error occurs then processing stops with an error\nmessage. If STATUS is present then it has the error code SUCCESS\nif no error occurs, has the value ALLOC_FAULT if failure is due to\nthe allocation of a temporary and, has the value WRITE_FAULT if an\nerror occurs in the write to the unit. By default or if ADVANCE is\npresent with the value 'YES', advancing output is used. If ADVANCE\nis present with the value 'NO', then the current record is not\nadvanced by the write.\nsubroutine read_bitset_string(string, set, status)\n: Uses the bitsets literal in the default character STRING, to\ndefine the bitset, SET. The literal may be preceded by an an\narbitrary sequence of blank characters. If STATUS is not present\nthen an error results in the sending an error message to ERROR_UNIT\nand the termination of the program. If STATUS is present then it has\nthe error code SUCCESS if no error occurs, the value\nINVALID_STRING if the sequence of characters after an initial\nsequence of blanks is not a BITSETS literal, the value\nINVALID_ARRAY_SIZE if the literal's bit size is too large to be\nrepresented by the bit size integer kind, the value ALLOC_FAULT if\nallocation of SET failed for the specified BITSIZE, or\nINVALID_INTEGER if the HEX literal constant is too large to be\nrepresented by a bit size binary integer. If STATUS is present with\nthe value SUCCESS then SET is defined, otherwise it is not\ndefined.\nsubroutine read_bitset_unit(unit, set, status)\n: Uses the bitsets literal at the current position in the formatted\nfile with logical unit, UNIT, to define the bitset, SET. The\nliteral may be preceded by an an arbitrary sequence of blank\ncharacters. If STATUS is not present then an error results in the\nsending an error message to ERROR_UNIT and the termination of the\nprogram. If STATUS is present then it has the error code SUCCESS\nif no error occurs, the value INVALID_STRING if the sequence of\ncharacters after an initial sequence of blanks is not a BITSETS\nliteral, the value INVALID_ARRAY_SIZE if the literal's bitsize is\ntoo large to be represented by the bitsize integer kind, the value\nALLOC_FAULT if allocation of SET failed for the specified bitsize,\nor INVALID_INTEGER if the HEX literal constant is too large to be\nrepresented by a bitsize binary integer. If STATUS is present with\nthe value SUCCESS then SET is defined, otherwise it is not\ndefined.\nelemental subroutine set_bit(set, pos)\n: Sets the value at the POS position in SET, provided the position\nis valid. If the position is less than 0 or greater than BITS(SET)-1\nthen SET is unchanged.\npure subroutine set_range(set, start_pos, stop_pos)\n: Sets all valid bits to 1 from the START_POS to the STOP_POS\npositions in SET. If STOP_POS < START_POS no bits are\nchanged. Positions outside the range 0 to BITS(SET)-1 are ignored.\nelemental function test(set, pos)\n: Returns .TRUE. if the POS position is set, .FALSE.\notherwise. If POS is negative or greater than BITS(SET) - 1 the\nresult is .FALSE..\nelemental function value(set, pos)\n: Returns 1 if the POS position is set, 0 otherwise. If POS is\nnegative or greater than BITS(SET) - 1 the result is 0.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-07-18 07:41:55+00:00",
                    "text": "Thank you. Interesting proposition.\nI work quite often at the bit-level to spare memory (I must store large tables with values only equal to 0,1,2, or 3). Therefore, I wrote something similar but not as complete.\nCould it be that some procedures are available outside the DT? E.g. The olderFortran Standard does not provide a pop_count intrinsic function. Therefore, such a function outside the DT could be useful.\n\nThe module exports one constant, BITS_KIND, to be used as a KIND\nvalue in addressing bits in the bitset. This will initially be\nINT32.\n\nI guess that it could be easily extended to other kinds with fypp."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-18 13:06:21+00:00",
                    "text": "Maybe I am misunderstanding what you are saying, but I think you are misunderstanding what I am saying. I think that you think that BITS_KIND is the kind of integer used to store the bits when it is the kink of integer used to address the bits. You would want to change BITS_KIND only in two different circumstances:\n\n1. You will want to address more than about 2**31 bits in one entity, in which case you will want fo make it an INT64.\n\n2. You will only want to address about 32 bits, but want to address that number in a large number entities so the memory taken up by the BITS member is significant. However the memory taken up by the array descriptor for the BLOCK member of the type is even more significant. (Probably several INT64s.) In that case you want to go for a different type structure, with the BLOCK array a small fixed size array, with at least as many bits as the largest number of bits you want to address. Probably an array of INT8, with BITS also an INT8 to further minimize the memory footprint.\n\u2026\n On Jul 18, 2020, at 1:42 AM, Jeremie Vandenplas ***@***.***> wrote:\n\n\n Thank you. Interesting proposition.\n I work quite often at the bit-level to spare memory (I must store large tables with values only equal to 0,1,2, or 3). Therefore, I wrote something similar but not as complete.\n\n Could it be that some procedures are available outside the DT? E.g. The Fortran Standard does not provide a pop_count intrinsic function. Therefore, such a function outside the DT could be useful.\n\n The module exports one constant, BITS_KIND, to be used as a KIND\n value in addressing bits in the bitset. This will initially be\n INT32.\n\n I guess that it could be easily extended to other kinds with fypp.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOSW4F4XIBWR76NOBETR4FG47ANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-21 20:02:53+00:00",
                    "text": "Maybe I am misunderstanding what you are saying, but I think you are misunderstanding what I am saying.\n\nIndeed, I misundertood you. Sorry and thank you for the explanations.\nOn overall I am fine with the API."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-21 20:09:31+00:00",
                    "text": "Thanks! Now if only more people showed an interest in the topic. I can\u2019t see making this part of the standard library with this minimal show of interest.\n\u2026\n On Jul 21, 2020, at 2:03 PM, Jeremie Vandenplas ***@***.***> wrote:\n\n\n Maybe I am misunderstanding what you are saying, but I think you are misunderstanding what I am saying.\n\n Indeed, I misundertood you. Sorry and thank you for the explanations.\n\n On overall I am fine with the API.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOVXFEYVD2YI5LQJE5TR4XX73ANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "Romendakil",
                    "date": "2020-07-21 20:11:45+00:00",
                    "text": "Personally I never saw the need for a bitmaps type, however, it was an ever and ever recurring topic on c.l.f., so I am pretty sure it would be used if available. So you clearly have my endorsement. But I am pretty new here and just started to read the messages since 2 weeks or so. Your proposal for the API seems very good to me."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-23 18:26:41+00:00",
                    "text": "I'm not the target audience for this, but I don't object to it being part of stdlib. I think it's in scope and the API is clean and clear.\n@certik @aradi @arjenmarkus @MarDiehl do you mind offering your feedback?"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-23 18:44:21+00:00",
                    "text": "Sure, I will have a look :).\n\nOp do 23 jul. 2020 om 20:26 schreef Milan Curcic <notifications@github.com>:\n\u2026\n I'm not the target audience for this, but I don't object to it being part\n of stdlib. I think it's in scope and the API is clean and clear.\n\n @certik <https://github.com/certik> @aradi <https://github.com/aradi>\n @arjenmarkus <https://github.com/arjenmarkus> @MarDiehl\n <https://github.com/MarDiehl> do you mind offering your feedback?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#221 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR7SSTTR5IV3BBUFSYLR5B6HDANCNFSM4O7IG3CQ>\n ."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-23 20:21:09+00:00",
                    "text": "I have looked at the proposal and while I don't use bitsets myself, I can see that there are applications for them in Fortran. The specifications seem complete, but perhaps a bit overcomplete. Here are my detailed remarks:\n\nIn the introduction you mention ALL, but later it is called ALL_BITS\nI think a name like ANY_BITS is more consistent\nIs a function like NONE really needed? You can get the same effect with .NOT. ANY\nExclusive OR appears as .XOR., not as .EOR. - perhaps use \"XOR\"?\nEquivalent appears as .EQV. - I therefore suggest EQV\nThere is a max_set_bit function, but not a first_set_bit function - does that not have any use?\nThe description of the formatted input/output routines does not include the actual format for the bitsets. Only a vage mention is made of HEX. Is it really useful to only support hexadecimal input/output? Why not a sequence of 0 's and 1's? It would be much easier to specify in my opinion.\nThe elemental routines AND, AND_NOT etc. require some further explanation: if SET2 is smaller than SET1, then some convention must be used to deal with the extra bits in SET1. Am I correct in assuming that the design is such that SET2 is (at least conceptually) extended with 0 bits? An alternative could be to extend it (again conceptually) in such a way that the extra bits in SET1 are NOT changed.\n\nJust a few remarks and suggestions :)."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-23 23:29:11+00:00",
                    "text": "FWIW I suspect I should follow the names for Fortran\u2019s bit intrinsics, but I don\u2019t like the leading I. Fortran has ALL and ANY but they are not bit intrinsics. So maybe ALL_BITS, and ANY_BITS are better. I agree NONE is not needed. Fortran has IEOR for the original bit intrinsics, but the atomic ones are XOR, so maybe XOR is best. I\u2019ll go along with EQV. I am wondering if MAX_SET_BIT has any use. The problem with using just 0s and 1s is that the resulting string is an order of magnitude larger. FWIW I thought of the syntax for the bitset literal content as\n*bitset-literal-constant* is *bitsize-literal-constant* *hex-literal-constant*\nwhere\n*bitsize-literal-constant* is \u201cS'\u201d *digit* [*digit*\u2026]\nand\n*hex-literal-constant* is \u201cZ\u2019\u201d *hex-digit* [*hex-digit*\u2026]\n\nbut a binary literal constant is much easier to implement and more legible for small bit set sizes.\n\nFor different sized sets, there are two cases of procedures. For the comparison functions, e.g., EQV, the shorter bitset is treated as if padded with zeros. For thee routines that modify the first argument, if the second argument is larger the trailing bits are ignored, while if it is shorter it is treated as if  padded with zeros.\n\u2026\n On Jul 23, 2020, at 2:21 PM, Arjen Markus ***@***.***> wrote:\n\n\n I have looked at the proposal and while I don't use bitsets myself, I can see that there are applications for them in Fortran. The specifications seem complete, but perhaps a bit overcomplete. Here are my detailed remarks:\n\n In the introduction you mention ALL, but later it is called ALL_BITS\n I think a name like ANY_BITS is more consistent\n Is a function like NONE really needed? You can get the same effect with .NOT. ANY\n Exclusive OR appears as .XOR., not as .EOR. - perhaps use \"XOR\"?\n Equivalent appears as .EQV. - I therefore suggest EQV\n There is a max_set_bit function, but not a first_set_bit function - does that not have any use?\n The description of the formatted input/output routines does not include the actual format for the bitsets. Only a vage mention is made of HEX. Is it really useful to only support hexadecimal input/output? Why not a sequence of 0 's and 1's? It would be much easier to specify in my opinion.\n The elemental routines AND, AND_NOT etc. require some further explanation: if SET2 is smaller than SET1, then some convention must be used to deal with the extra bits in SET1. Am I correct in assuming that the design is such that SET2 is (at least conceptually) extended with 0 bits? An alternative could be to extend it (again conceptually) in such a way that the extra bits in SET1 are NOT changed.\n Just a few remarks and suggestions :).\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOV5ACEEUU4HEACYLIDR5CLULANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-24 10:20:13+00:00",
                    "text": "I think it is a good idea to stay close to the names of the Fortran\nintrinsics, indeed.\n\nThe reason I asked about the hexadecimal format is that I would find it\nmuch easier to specify or interpret a particular bit pattern using zeroes\nand ones than using hexadecimal notation. But I agree that hexadecimal is\nmuch shorter :). Supporting both seems to me the best way.\n\nFor the routines that deal with two sets, having a consistent philosophy -\nand documenting it :) - is important. It will be much easier to reason\nabout. It reminds me of an explanation I found in a book on (mainly) C by\nKernighan and Pike (IIRC, I did not try and look it up): they designed\nfunctions like memset() with assignments in mind - the first argument would\nget changed, as if you read an assignment from left to right. They\ncomplained though that many people did not figure this out.\n\nRegards,\n\nArjen\n\nOp vr 24 jul. 2020 om 01:29 schreef William B. Clodius <\nnotifications@github.com>:\n\u2026\n FWIW I suspect I should follow the names for Fortran\u2019s bit intrinsics, but\n I don\u2019t like the leading I. Fortran has ALL and ANY but they are not bit\n intrinsics. So maybe ALL_BITS, and ANY_BITS are better. I agree NONE is not\n needed. Fortran has IEOR for the original bit intrinsics, but the atomic\n ones are XOR, so maybe XOR is best. I\u2019ll go along with EQV. I am wondering\n if MAX_SET_BIT has any use. The problem with using just 0s and 1s is that\n the resulting string is an order of magnitude larger. FWIW I thought of the\n syntax for the bitset literal content as\n *bitset-literal-constant* is *bitsize-literal-constant*\n *hex-literal-constant*\n where\n *bitsize-literal-constant* is \u201cS'\u201d *digit* [*digit*\u2026]\n and\n *hex-literal-constant* is \u201cZ\u2019\u201d *hex-digit* [*hex-digit*\u2026]\n\n but a binary literal constant is much easier to implement and more legible\n for small bit set sizes.\n\n For different sized sets, there are two cases of procedures. For the\n comparison functions, e.g., EQV, the shorter bitset is treated as if padded\n with zeros. For thee routines that modify the first argument, if the second\n argument is larger the trailing bits are ignored, while if it is shorter it\n is treated as if padded with zeros.\n\n > On Jul 23, 2020, at 2:21 PM, Arjen Markus ***@***.***>\n wrote:\n >\n >\n > I have looked at the proposal and while I don't use bitsets myself, I\n can see that there are applications for them in Fortran. The specifications\n seem complete, but perhaps a bit overcomplete. Here are my detailed remarks:\n >\n > In the introduction you mention ALL, but later it is called ALL_BITS\n > I think a name like ANY_BITS is more consistent\n > Is a function like NONE really needed? You can get the same effect with\n .NOT. ANY\n > Exclusive OR appears as .XOR., not as .EOR. - perhaps use \"XOR\"?\n > Equivalent appears as .EQV. - I therefore suggest EQV\n > There is a max_set_bit function, but not a first_set_bit function - does\n that not have any use?\n > The description of the formatted input/output routines does not include\n the actual format for the bitsets. Only a vage mention is made of HEX. Is\n it really useful to only support hexadecimal input/output? Why not a\n sequence of 0 's and 1's? It would be much easier to specify in my opinion.\n > The elemental routines AND, AND_NOT etc. require some further\n explanation: if SET2 is smaller than SET1, then some convention must be\n used to deal with the extra bits in SET1. Am I correct in assuming that the\n design is such that SET2 is (at least conceptually) extended with 0 bits?\n An alternative could be to extend it (again conceptually) in such a way\n that the extra bits in SET1 are NOT changed.\n > Just a few remarks and suggestions :).\n >\n > \u2014\n > You are receiving this because you authored the thread.\n > Reply to this email directly, view it on GitHub <\n #221 (comment)>,\n or unsubscribe <\n https://github.com/notifications/unsubscribe-auth/APTQDOV5ACEEUU4HEACYLIDR5CLULANCNFSM4O7IG3CQ\n >.\n >\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#221 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR4OQPFBQJDAGGVQ7ZDR5DBVLANCNFSM4O7IG3CQ>\n ."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-24 18:29:07+00:00",
                    "text": "I now think it is a bad idea to have two formats for the BITSETS literal representation:\n1. It will be difficult to come up with two unique terms to describe two closely related concepts.\n2. Even with distinguishing names users will sometimes confuse them and feed the output of one write format to the input of the other read format\n3. I don\u2019t want to write and support four extra subroutines.\n\nI am really inclined to make the BITSETS literal a string of zeros and ones. Its intuitive and if people want to save memory they should use the binary representation.\n\u2026\n On Jul 24, 2020, at 4:20 AM, Arjen Markus ***@***.***> wrote:\n\n\n I think it is a good idea to stay close to the names of the Fortran\n intrinsics, indeed.\n\n The reason I asked about the hexadecimal format is that I would find it\n much easier to specify or interpret a particular bit pattern using zeroes\n and ones than using hexadecimal notation. But I agree that hexadecimal is\n much shorter :). Supporting both seems to me the best way.\n\n For the routines that deal with two sets, having a consistent philosophy -\n and documenting it :) - is important. It will be much easier to reason\n about. It reminds me of an explanation I found in a book on (mainly) C by\n Kernighan and Pike (IIRC, I did not try and look it up): they designed\n functions like memset() with assignments in mind - the first argument would\n get changed, as if you read an assignment from left to right. They\n complained though that many people did not figure this out.\n\n Regards,\n\n Arjen\n <snip>\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOUBNMANIVUN7BSI5DDR5FN7BANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-24 18:45:24+00:00",
                    "text": "I am really inclined to make the BITSETS literal a string of zeros and ones. Its intuitive and if people want to save memory they should use the binary representation.\n\nI have never used BITSETS, but using a string of zeros and ones seems odd to me. Why not use an array (of variable size) of logicals/booleans?"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-24 19:12:28+00:00",
                    "text": "Note I was writing about a BITSETS literal, a character string representation of the underlying values. A bitset is normally implemented as an array of large integers, with bit intrinsics used to read and manipulate them. The bit operations are used to save memory and reduce memory traffic, so the operations may be faster than say operations on byte sized logicals.\n\u2026\n On Jul 24, 2020, at 12:45 PM, Martin Diehl ***@***.***> wrote:\n\n\n I am really inclined to make the BITSETS literal a string of zeros and ones. Its intuitive and if people want to save memory they should use the binary representation.\n I have never used BITSETS, but using a string of zeros and ones seems odd to me. Why not use an array (of variable size) of logicals/booleans?\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOW32I67ON7HFNUVB33R5HJFHANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-25 11:46:59+00:00",
                    "text": "Speaking of BITSET literals, I don't see a reason why arrays of integers could not be used:\nuse stdlib_bitsets, only: bitsets, assignment(=)\ntype(bitsets) :: b\n\nb = [1,0,1,0,0,0,0,0] ! (overloaded assignment for assumed size arrays)\nb = \"10100000\"        ! (overloaded assignment for character literals)\nBut personally, I find using a string more attractive. Using logical literals .true./.false. is too verbose.\nIn the potential use case, where you would need to convert an array of zeros and ones (or a logical mask) to a string, you could probably do so using something along the lines of:\ncharacter(len=:), allocatable :: bstr\ninteger, allocatable :: ib(:), dc(:)\ninteger :: i\ndc = [(i,i=1,20)]\nallocate(ib,mold=dc)\nwhere (mod(dc,2)==0)\n  ib = 1\nelse where\n  ib = 0\nend where\n\nallocate(character(len=size(ib)) :: bstr)\nwrite(bstr,'(*(I1))') ib\n\nwrite(*,'(*(I1))') dc\nwrite(*,'(*(I1))') ib\nwrite(*,'(A)'), bstr\nwhich produces the output:\n12345678\n01010101\n01010101\n\nI haven't looked up the details on boz constants, so I don't know if this could be perhaps also allowed:\nb = b'10100000'\nb = z'A0'"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-25 14:51:04+00:00",
                    "text": "Ivan:\n\nMaybe I am misunderstanding what you wrote, but I think you are over interpreting what I wrote. Bitset literals are primarily for writing out the values for human readers, and not fro representing bit sets internally. For writing out for human readers arrays of integers are not useful. An array of zeros and ones are certainly memory wasteful for an internal representation\n\u2026\n On Jul 25, 2020, at 5:47 AM, Ivan ***@***.***> wrote:\n\n\n Speaking of BITSET literals, I don't see a reason why arrays of integers could not be used:\n\n use stdlib_bitsets, only: bitsets, assignment(=)\n type(bitsets) :: b\n\n b = [1,0,1,0,0,0,0,0] ! (overloaded assignment for assumed size arrays)\n b = \"10100000\"        ! (overloaded assignment for character literals)\n But personally, I find using a string more attractive. Using logical literals .true./.false. is too verbose.\n\n In the potential use case, where you would need to convert an array of zeros and ones (or a logical mask) to a string, you could probably do so using something along the lines of:\n\n character(len=:), allocatable :: bstr\n integer, allocatable :: ib(:), dc(:)\n integer :: i\n dc = [(i,i=1,20)]\n allocate(ib,mold=dc)\n where (mod(dc,2)==0)\n   ib = 1\n else where\n   ib = 0\n end where\n\n allocate(character(len=size(ib)) :: bstr)\n write(bstr,'(*(I1))') ib\n\n write(*,'(*(I1))') dc\n write(*,'(*(I1))') ib\n write(*,'(A)'), bstr\n which produces the output:\n\n 12345678\n 01010101\n 01010101\n I haven't looked up the details on boz constants, so I don't know if this could be perhaps also allowed:\n\n b = b'10100000'\n b = z'A0'\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOS3G7SFKFJPZFR2G3LR5LA4BANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-26 10:16:57+00:00",
                    "text": "My response was partially referring to the comment by @MarDiehl. I understand that the internal representation is different.\nMy understanding of literals though was:\n\nA literal is a source code representation of a fixed value. They are represented directly in the code without any computation.\n\nWith the currently proposed API, how do I initialize a bitset? Like this?\ntype(bitsets) :: bitset\ninteger :: stat\ncall read_bitset_string(\"1111111\",bitset,stat)"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-26 13:50:25+00:00",
                    "text": "There would be several ways to initialize a bitset. I was thinking a bitset literal would have the syntax \u2018S7B1111111\u2019, i.e., having the size as a prefix, as otherwise reading a literal out of a file could be ambiguous. I was going to avoid STATUS arguments. What would a user do if told their bitset literal was invalid, other than stop the code and rewrite it? I figure it is best to stop the code immediately with an informative message rather than continue.\n\nAs to initialization there would the following options\n\ncall read_bistset(\u201cS7B1111111\u201d, bitset) ! to read from a string\ncall read_bitset(lun, bitset) ! to read from a formatted file\ncall input(sun, bitset) ! to read from an unformatted file\ncall init(bitset, bits) ! to initialize as size bits with all zeros\ncall init(bitset, abitset, bits) ! to initialize as size bits copying the overlapping portions of a bitset\nand of course\nbitset = abitset ! to make bitset initially a duplicate of a bitset\n\u2026\n On Jul 26, 2020, at 4:17 AM, Ivan ***@***.***> wrote:\n\n\n My response was partially referring to the comment by @MarDiehl <https://github.com/MarDiehl>. I understand that the internal representation is different.\n\n My understanding of literals though was:\n\n A literal is a source code representation of a fixed value. They are represented directly in the code without any computation.\n\n With the currently proposed API, how do I initialize a bitset? Like this?\n\n type(bitsets) :: bitset\n integer :: stat\n call read_bitset_string(\"1111111\",bitset,stat)\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOT2F5IGVGVLZKSPCZLR5P7CLANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-26 19:08:11+00:00",
                    "text": "@wclodius2: thanks for the clarification\nI think with overloading = the following operations would be user friendly\ntype(bitset) :: b\nb = '101'\nb = [.True.,.False.,.True.]\nb = [1,0,1]\nb = 101\n\nThe skeleton code would then look like\nmodule bitset_m                                                                                     \n                                                                                                    \n implicit none                                                                                      \n                                                                                                    \n type, public :: bitset                                                                             \n end type bitset                                                                                    \n                                                                                                    \n interface assignment (=)                                                                           \n   module procedure assign_str                                                                      \n   module procedure assign_int                                                                      \n   module procedure assign_int_array                                                                \n   module procedure assign_bool_array                                                               \n end interface assignment (=)                                                                       \n                                                                                                    \ncontains                                                                                            \n                                                                                                    \npure subroutine assign_str(self,str)                                                                \n  type(bitset), intent(out)    :: self                                                              \n  character(len=*), intent(in) :: str                                                               \nend subroutine                                                                                      \n                                                                                                    \npure subroutine assign_int(self,i)                                                                  \n  type(bitset), intent(out) :: self                                                                 \n  integer,      intent(in)  :: i                                                                    \nend subroutine                                                                                      \n                                                                                                    \npure subroutine assign_int_array(self,i)                                                            \n  type(bitset),         intent(out) :: self                                                         \n  integer, dimension(:),intent(in)  :: i                                                            \nend subroutine                                                                                      \n                                                                                                    \npure subroutine assign_bool_array(self,b)                                                           \n  type(bitset),         intent(out) :: self                                                         \n  logical, dimension(:),intent(in)  :: b                                                            \nend subroutine                                                                                      \n                                                                                                    \nend module bitset_m"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-26 19:11:11+00:00",
                    "text": "I personally would prefer object oriented code:\ntype(bitset) :: b\ncall b%init(size=7) ! length of 7 bits\ncall b%from_formatted('file.txt') ! filename\ncall b%from_formatted(fh) ! filehandle"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-26 21:08:06+00:00",
                    "text": "The array of logicals as input seems reasonable to me, though I would have to do it for every logical kind, The others less so as I view them as error prone. What does `b=101` mean?.Do I treat it as a 3 bit bitset of 1,0, and 1 or a 32 bit bitset whose bits are those of the underlying INTEGER(INT32). For a long character string how do I ensure that the user hasn\u2019t accidentally dropped or added a character. That is why I am considering having the syntax for a bit string be S#B# here the first # is the length of the bitset, and the second # is a string of \u20180\u2019s and \u20181\u2019s. What do I do if the user enters O instead of 0? What if I am passed `b=[1,0,2]` or `b=[1,0,-1]`?\n\u2026\n On Jul 26, 2020, at 1:08 PM, Martin Diehl ***@***.***> wrote:\n\n\n @wclodius2 <https://github.com/wclodius2>: thanks for the clarification\n\n I think with overloading = the following operations would be user friendly\n\n type(bitset) :: b\n b = '101'\n b = [.True.,.False.,.True.]\n b = [1,0,1]\n b = 101\n The skeleton code would then look like\n\n module bitset_m\n\n  implicit none\n\n  type, public :: bitset\n  end type bitset\n\n  interface assignment (=)\n    module procedure assign_str\n    module procedure assign_int\n    module procedure assign_int_array\n    module procedure assign_bool_array\n  end interface assignment (=)\n\n contains\n\n pure subroutine assign_str(self,str)\n   type(bitset), intent(out)    :: self\n   character(len=*), intent(in) :: str\n end subroutine\n\n pure subroutine assign_int(self,i)\n   type(bitset), intent(out) :: self\n   integer,      intent(in)  :: i\n end subroutine\n\n pure subroutine assign_int_array(self,i)\n   type(bitset),         intent(out) :: self\n   integer, dimension(:),intent(in)  :: i\n end subroutine\n\n pure subroutine assign_bool_array(self,b)\n   type(bitset),         intent(out) :: self\n   logical, dimension(:),intent(in)  :: b\n end subroutine\n\n end module bitset_m\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOVIWM5J6YO6442LB4TR5R5KPANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-26 21:09:08+00:00",
                    "text": "It is easy to provide both.\n\u2026\n On Jul 26, 2020, at 1:11 PM, Martin Diehl ***@***.***> wrote:\n\n\n I personally would prefer object oriented code:\n\n type(bitset) :: b\n call b%init(size=7) ! length of 7 bits\n call b%from_formatted('file.txt') ! filename\n call b%from_formatted(fh) ! filehandle\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOUQ4GPTGWDBV5SRKTLR5R5VXANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-27 00:09:44+00:00",
                    "text": "What does b=101 mean?.Do I treat it as a 3 bit bitset of 1,0, and 1 or a 32 bit bitset whose bits are those of the underlying INTEGER(INT32). For a long character string how do I ensure that the user hasn\u2019t accidentally dropped or added a character. That is why I am considering having the syntax for a bit string be S#B# here the first # is the length of the bitset, and the second # is a string of \u20180\u2019s and \u20181\u2019s. What do I do if the user enters O instead of 0? What if I am passed b=[1,0,2] or b=[1,0,-1]?\n\nIn case of b = 101 it would have to be the underlying integer(int32) representation. This would allow usage of binary, octal, and hexadecimal boz constants. Upon more thought, I would avoid initialization using integer arrays altogether.\nI see many similarities in this discussion to the C++ std::bitset. They allow initialization from either integers or character strings (zeros and ones, or a custom pair of characters). An exception is raised for invalid arguments in the constructor. Interestingly, they do not overload the assignment operator (apart from creating copies).\nSeeing that the C++ bitset uses a template for the size, perhaps a solution using parametrized derived types would be also of interest.\n  integer, parameter :: bits_kind = int32\n  integer, parameter :: block_kind = int32\n\n  type :: bitsets(b)\n    integer, len :: b\n    integer(bits_kind) :: bits = b\n    integer(block_kind) :: block(b/storage_size(block_kind)+1)\n  end type\nThe downsides are that since block is not allocatable anymore, enlarging a bitset means declaring a second (larger) instance; and the compiler support might not be mature enough."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-27 06:45:40+00:00",
                    "text": "I have found out the C++ ecosystem also has a dynamic bitset: https://www.boost.org/doc/libs/1_35_0/libs/dynamic_bitset/dynamic_bitset.html"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-29 11:37:51+00:00",
                    "text": "This would allow usage of binary, octal, and hexadecimal boz constants.\n\nUpon reading a recent comp.lang.fortran discusssion, I came to realize that boz literals can only be used in data statements and intrinsic procedures, meaning these constants need to be passed through the conversion function int:\nopen(newunit=unit)\nwrite(unit,*) int(b'10110101')\ncall init(set=bs,bits=6)\ncall read_bitset(unit=unit,set=bs) ! bs contains '110101'\nclose(unit)"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-31 16:26:25+00:00",
                    "text": "Right now I feel stymied on this issue for several reasons:\n\nIt is hard to write much of the code without a decision on how to handle and propagate errors. Issue #224 could use a wider participation so that a consensus on that issue could be reached.\nPeople are suggesting changes in the API without commenting as to whether they would support the BITSET type with or without the changes.\nMost of the suggested changes involve additional ways to initialize a BITSET object, that I feel should have low priority. Collectively they will add a burden to the API and testing that will provide only incremental functionality.\nThe level of participation in this issue is small, so that even if all the participants in this issue supported the API it is not clear that the BITSET type has sufficient support to be worth adding to the library."
                },
                {
                    "user": "septcolor",
                    "date": "2020-08-01 00:27:20+00:00",
                    "text": "@wclodius2 As for Point 4, shall I post a related question to comp.lang.fortran and ask opinions about BITSET? I remember Ron Shepard wished such bit string types, but not very sure about details..."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-01 03:40:59+00:00",
                    "text": "Some outside interest might help. One person that in this forum has expressed interest in a bitset type in the past, but has not commented on this issue in particular is @FortranFan.\n\u2026\n On Jul 31, 2020, at 6:27 PM, septcolor ***@***.***> wrote:\n\n\n @wclodius2 <https://github.com/wclodius2> As for Point 4, shall I post a related question to comp.lang.fortran and ask opinions about BITSET? I remember Ron Shepard wished such bit string types, but not very sure about details...\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOSDA3Z65L5XG2UKOBTR6NOPNANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "certik",
                    "date": "2020-08-01 03:57:22+00:00",
                    "text": "@wclodius2 the reason why there is relatively low traffic here (although 8 participants is not bad!) is that I think most people (myself included) haven't needed this in Fortran. So I am fine to include it into stdlib if there is interest, but I will let others who actually use this to lead this particular effort."
                },
                {
                    "user": "Romendakil",
                    "date": "2020-08-01 09:09:54+00:00",
                    "text": "Is it much effort to include a base construction? If not, why not include it and see whether there is feedback in order to decide to extend it?"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-01 13:20:02+00:00",
                    "text": "What do you mean by base constructor? I see no need for an inheritance tree for this type. There is the default structure constructor for this type, but with private components it is only available in the source module, and it is difficult to use consistently. Other than that I had planned to have assignment of other entities of the bitset type, assignment of arrays of logical type, initialization as all zeros, initialization opting from an existing bitset entity, but not necessarily to the same size as the source entity, and initialization from a character string.\n\u2026\n On Aug 1, 2020, at 3:10 AM, J\u00fcrgen Reuter ***@***.***> wrote:\n\n\n Is it much effort to include a base construction? If not, why not include it and see whether there is feedback in order to decide to extend it?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOQU7QVZXTJTSYPHTFTR6PLXBANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-08-01 15:12:45+00:00",
                    "text": "Maybe I have misunderstood @Romendakil 's comment, but if by base construction he meant an abstract type, this would in principle allow us to have several different bitset implementations (fixed size, dynamic, fast...) all conforming to the same API.\nI've attached a small example for the two functions clear and set_bit. It compiles with no warnings using the Intel Fortran compiler.\nbitset_example.f90.txt\nAn example of using both a fixed size bitset and a dynamically allocated one:\nprogram bitset_example\n\n  use bitset_fixed\n  use bitset_dynamic\n  implicit none\n\n  type(bitset_f(bits=64)) :: bsf ! fixed size bitset\n  type(bitset_d) :: bsd          ! dynamic bitset\n\n  integer :: i\n\n  ! allocate 64 bits of storage, only temporary method\n  allocate(bsd%blocks(2))\n\n  do i = 0, 63\n    call bsf%set_bit(i)\n    call bsd%set_bit(i)\n  end do\n\n  do i = 0, 31, 2\n    call bsf%clear(i)\n    call bsd%clear(i)\n  end do\n\n  write(*,'(*(b32))') bsf%blocks(1), bsf%blocks(2)\n  write(*,'(*(b32))') bsd%blocks(1), bsd%blocks(2)\nend program\nOn my platform the output is:\n1010101010101010101010101010101011111111111111111111111111111111\n1010101010101010101010101010101011111111111111111111111111111111"
                },
                {
                    "user": "longb",
                    "date": "2020-08-02 20:31:26+00:00",
                    "text": "Just pointing out that a full-feature BITS intrinsic data type was proposed for F2008, but taken out at the last moment.  The J3 working document 07-007r2.pdf has the BITS feature incorporated.   Something like that would be significantly simpler, and better performing, than a library."
                },
                {
                    "user": "FortranFan",
                    "date": "2020-08-03 17:49:16+00:00",
                    "text": "@wclodius2 wrote July 31, 2020 11:40 PM EDT:\n\nSome outside interest might help. One person that in this forum has expressed interest in a bitset type in the past, but has not commented on this issue in particular is @FortranFan.\n\nThere are several reasons for this but none of them have to do with a lack of interest in the need for such facilities with Fortran whether it be as part of the base language itself or as part of a \"standard library\".\nI personally think there is tremendous value in having a type to manage a compact array of bit values where the bits might be stored efficiently than a typical consumer can figure out and where the consumer doesn't have to do the bit-shifting on their own, rather convenient and expressive options are available.  The last use I had was with library code that interfaces with multiphysics simulations of a complex process where the management, especially with the computation of certain state functions, their first and second derivatives as well as their quadrature in some instances, was a lot more convenient to achieve with such a type.\nToo bad the Fortran language fell deficient on this count (and also others) and the code was implemented using modern C++, Microsoft's 'managed' C++, as well as C#, rather successfully I grudgingly admit,.  The main point of this anecdote though is that the team's use case in that simulation library was met more than adequately using std:bitset in C++ as well as a similar [BitArray](https://docs.microsoft.com/en-us/dotnet/api/system.collections.bitarray?view=netcore-3.1) class in C#.  Thus a design toward an API for such a type in Fortran that looks to these C++ and C# options for guidance will be my recommendation.  Besides, there is a certain minimalist approach along the lines of Pareto Principle or the so-called 80/20 rule one can see in the C++ stdlib and the C# Framework facilities that will be always to keep in mind for content in Fortran stdlib."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-07 03:55:02+00:00",
                    "text": "After thinking about it I have decided to initially define an abstract base class with two realizations, a fixed size bitset that can hold up to 64 bits, and a variable sized bitset that can hold up to 2**31-1 bits. If  there is demand afterwards I might also provide a fixed size that can hold up to 128 bits and one that can hold up to 256 bits.  Do people have a preference as to whether the realizations should be in submodules of the module that contains the abstract base class, or in separate modules?"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-08-07 06:34:35+00:00",
                    "text": "I would say that this is a good opportunity for one module and submodules.\nThat will allow easy extension of the set of concrete types - having\nseparate modules for each type feels clumsy, even though you can provide a\nsingle overall module that merely exposes all specific ones.\n\nOp vr 7 aug. 2020 om 05:55 schreef William B. Clodius <\nnotifications@github.com>:\n\u2026\n After thinking about it I have decided to initially define an abstract\n base class with two realizations, a fixed size bitset that can hold up to\n 64 bits, and a variable sized bitset that can hold up to 2**31-1 bits. If\n there is demand afterwards I might also provide a fixed size that can hold\n up to 128 bits and one that can hold up to 256 bits. Do people have a\n preference as to whether the realizations should be in submodules of the\n module that contains the abstract base class, or in separate modules?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#221 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR337FZTESZT5H7LLX3R7N3KFANCNFSM4O7IG3CQ>\n ."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-08-07 09:39:49+00:00",
                    "text": "I would also put the specific realizations in submodules.\nWould the abstract type be public? I think this is necessary if users want to write procedures which can accept either fixed or variable-size bitsets (I don't know if there are any real use cases for this)."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-08-07 09:46:01+00:00",
                    "text": "Just pointing out that a full-feature BITS intrinsic data type was proposed for F2008, but taken out at the last moment. The J3 working document 07-007r2.pdf has the BITS feature incorporated. Something like that would be significantly simpler, and better performing, than a library.\n\nThanks @longb, I didn't know about this. Are there any other documents which summarize the features and reasoning of the proposed BITS intrinsic type on a simple level? I found the standard document a bit inconvenient for this purpose."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-08-07 09:52:02+00:00",
                    "text": "I am also in favor of one module and multiple submodules.\n\nLe ven. 7 ao\u00fbt 2020 \u00e0 08:34, Arjen Markus <notifications@github.com> a\n\u00e9crit :\n\u2026\n I would say that this is a good opportunity for one module and submodules.\n That will allow easy extension of the set of concrete types - having\n separate modules for each type feels clumsy, even though you can provide a\n single overall module that merely exposes all specific ones.\n\n Op vr 7 aug. 2020 om 05:55 schreef William B. Clodius <\n ***@***.***>:\n\n > After thinking about it I have decided to initially define an abstract\n > base class with two realizations, a fixed size bitset that can hold up to\n > 64 bits, and a variable sized bitset that can hold up to 2**31-1 bits. If\n > there is demand afterwards I might also provide a fixed size that can\n hold\n > up to 128 bits and one that can hold up to 256 bits. Do people have a\n > preference as to whether the realizations should be in submodules of the\n > module that contains the abstract base class, or in separate modules?\n >\n > \u2014\n > You are receiving this because you were mentioned.\n > Reply to this email directly, view it on GitHub\n > <\n #221 (comment)>,\n > or unsubscribe\n > <\n https://github.com/notifications/unsubscribe-auth/AAN6YR337FZTESZT5H7LLX3R7N3KFANCNFSM4O7IG3CQ\n >\n > .\n >\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#221 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD5RO7GAJ5R3AMFPXKCOAF3R7OOARANCNFSM4O7IG3CQ>\n ."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-03 20:31:12+00:00",
                    "text": "I now have an implementation of bitsets that I will start testing. The main module file, stdlib_bitsets.f90, defines an abstract type, bitset_t, with two descendants, bitset_64 which can handle bitsets up to 64 bits, and bitset_large, which can handle bitsets up to huge(0_bits_kind) bits, where bits_kind is currently int32. The implementations of bitset_64 and bitset_large are in the submodule files, stdlib_bitset_64.f90 and stdlib_bitset_large.f90. at this point I have two questions for potential users:\n\n\nAre the names of the descendant types and their submodule files acceptable?\n\n\nThere are a number of binary operations: and, and_not, eqv, or, and xor. Users I expect will normally want to use these with bitsets of the same size, but the current code allows the two arguments to differ in size effectively padding the smaller argument with zero bits where necessary. This results in significantly more complicated code for eqv, or, and xor, with a corresponding impact on the code robustness, runtime, and testing. Should I continue to allow arguments differing in size, or require the bitsets to be the same size and enforce it with if tests and error stops, or require the arguments to be the same size and simply leave the results undefined if the arguments differ in size?"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-07 08:43:56+00:00",
                    "text": "Hi Bill,\n\nto answer your questions:\nad 1.\nThese names look quite acceptable to me. While making the numerical size\n(64) part of the name is not something I would recommend in general, I\nthink in this case, as we are talking of a very specific data type, it is\nacceptable. (My hesitation wrt such numerical components has to do with\nsuch ancient types as REAL*4 and the unfortunate \"kind=4\" practice ;))\nad 2.\nI would say that the two are meant for very different purposes. If they\nshould be combined, why not do that explicitly via a conversion function?\nThat way, should the need arise for a third type, say, bitset_128, you\navoid the combinatorial explosion and you make it clearer that the data\ntypes are related but not merely different tastes of the same thing. If\nthey should be combined in one operation, then that should be done\nexplicitly. (You could also define a conversion from bitset_large to\nbitset_64, though that will necessarily truncate the bts beyond 64 or 63\n...)\n\nRegards,\n\nArjen\n\nOp do 3 sep. 2020 om 22:31 schreef William B. Clodius <\nnotifications@github.com>:\n\u2026\n I now have an implementation of bitsets that I will start testing. The\n main module file, stdlib_bitsets.f90, defines an abstract type, bitset_t,\n with two descendants, bitset_64 which can handle bitsets up to 64 bits,\n and bitset_large, which can handle bitsets up to huge(0_bits_kind) bits,\n where bits_kind is currently int32. The implementations of bitset_64 and\n bitset_large are in the submodule files, stdlib_bitset_64.f90 and\n stdlib_bitset_large.f90. at this point I have two questions for potential\n users:\n\n    1.\n\n    Are the names of the descendant types and their submodule files\n    acceptable?\n    2.\n\n    There are a number of binary operations: and, and_not, eqv, or, and xor.\n    Users I expect will normally want to use these with bitsets of the same\n    size, but the current code allows the two arguments to differ in size\n    effectively padding the smaller argument with zero bits where necessary.\n    This results in significantly more complicated code for eqv, or, and\n    xor, with a corresponding impact on the code robustness, runtime, and\n    testing. Should I continue to allow arguments differing in size, or require\n    the bitsets to be the same size and enforce it with if tests and error\n    stops, or require the arguments to be the same size and simply leave the\n    results undefined if the arguments differ in size?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#221 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YRZ4C5BMOF2UID7UMYTSD74KDANCNFSM4O7IG3CQ>\n ."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-09-07 12:48:57+00:00",
                    "text": "Regarding the abstract bitset_t, I think it's suitable for declaring polymorphic bitset variables such as:\nclass(bitset_t), allocatable :: foo ! could be bitset_64 or bitset_large\nIn my own codes I have someties prepended abstract, as in abstract_bitset_t, but here this would be unnecessarily verbose. Good documentation should lead users to the right type for their application.\nThe second usage of the abstract type name will occur in subroutine declaration blocks:\nsubroutine some_bitset_operation(b)\n  class(bitset_t), intent(in) :: b\n  select type(b)\n    type is (bitset_64)\n      ! do something\n    type is (bitset_large)\n      ! do something else\n  end select\nend function\nConcerning bitset_64 I wonder if dropping the underscore would be better? This would make it similar to the constants from iso_fortran_env, i.e int64, real64 (I realize this comparison is not totally correct as these are type constants and not the actual types). I understand the underscore is there for consistency with bitset_large, however bitset64 seems easier to use in practice.\nFrom the linguistic point of view, putting the adjective first - large_bitset, is more logical than bitset_large. In Boost they also put the adjective first (see dynamic_bitset). Perhaps a pair of adjective-derived names such as small_bitset for the one with 64 bits, and large_bitset for the variable one, would communicate the purpose of the derived types. Users can always rename upon import to use whatever they want, i.e.  use stdlib_bitset, bitset64 => small_bitset. A problem however arises with this kind of naming if other fixed-size bitsets are introduced (with 32 or 128 bits)."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-09-07 14:55:55+00:00",
                    "text": "I also agree with the answer to the second question by @arjenmarkus. Since the two sub-types will likely appear in different usage cases, I would initially go for an explicit conversion function. If I have understood correctly, the bitset_large can have variable size? For this type I would still expect the binary operators to work irrespective of the number of bits held internally. I would however (for now) avoid mixed binary operators between bitset_64 and bitset_large."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-07 17:46:25+00:00",
                    "text": "Hi Arjen:\n\nI may be misunderstanding you, but I think you misunderstood my second question. Entities of both the bitset_64 and bitset_large can behave as though they have different numbers of bits. For example one can declare one entity of type bitset_64 as having 16 bits and another entity as having 17 bits. For two different bit sizes of type bitset_64 I have to decide and describe how they interact for such binary ops as `and`, `and_not`, `or`, `xor`, `==`, `/=`, `>`,` >=`, `<`, and `<=`. The simplest description and implementation is to simply forbid using entities of different bit sizes in those binary ops. I then have to decide whether to enforce this restriction by a test and branch to an error stop, or leave the use of two bit sizes as undefined, eliminating the overhead of the test and branch., which can be significant for a `bitset_64`. If I decide to allow different bit sizes then it has the following consequences:\n\n1. The obvious description of how to treat different bit sizes (pad set2 with zeros if shorter than set1, and ignore the extra bits if longer than set1) for the logical operations `and`, `and_not`, `or`, and `xor` is different from the obvious description (pad the smaller bitset with zeros) of how to treat the comparison operations `==`, `/=`, `>`,` >=`, `<`, and `<=`.\n\n2. I have to have at least one branch in the individual procedures for `bits(set1)>= bits(set2)` vs. `bits(set1)<bits(set2)`\n\n3. In the final word of the bitset I often have to resort to bit level operations, rather than the word level operations I can consistently use if they have the same number of bits. This can have a large performance hit.\n\n4. The logic for each branch is tricky and easy to get wrong, particularly for the `bitset_large`.\n\n5. I have to triple the testing for those ops, in effect testing separately for `bits(set1)<bits(set2)`, `bits(set1)==bits(set2)`, and `bits(set1)>bits(set2)`.\n\nIn C++ and Java, the problem doesn\u2019t exist as the number of bits determines the type and the binary ops are forbidden to mix types, resulting in all binary ops requiring the same number of bits for each operand.\n\nGiven the complexity of mixing bit sizes, and to my mind, the black of usefulness for mixing bit sizes, I think there will be zero demand for the ability to mix bit sizes on the binary ops.\n\nThat being said a conversion function is useful and I\u2019ll see about implementing one.\n\u2026\n On Sep 7, 2020, at 2:44 AM, Arjen Markus ***@***.***> wrote:\n\n\n Hi Bill,\n\n to answer your questions:\n ad 1.\n These names look quite acceptable to me. While making the numerical size\n (64) part of the name is not something I would recommend in general, I\n think in this case, as we are talking of a very specific data type, it is\n acceptable. (My hesitation wrt such numerical components has to do with\n such ancient types as REAL*4 and the unfortunate \"kind=4\" practice ;))\n ad 2.\n I would say that the two are meant for very different purposes. If they\n should be combined, why not do that explicitly via a conversion function?\n That way, should the need arise for a third type, say, bitset_128, you\n avoid the combinatorial explosion and you make it clearer that the data\n types are related but not merely different tastes of the same thing. If\n they should be combined in one operation, then that should be done\n explicitly. (You could also define a conversion from bitset_large to\n bitset_64, though that will necessarily truncate the bts beyond 64 or 63\n ...)\n\n Regards,\n\n Arjen\n\n Op do 3 sep. 2020 om 22:31 schreef William B. Clodius <\n ***@***.***>:\n\n > I now have an implementation of bitsets that I will start testing. The\n > main module file, stdlib_bitsets.f90, defines an abstract type, bitset_t,\n > with two descendants, bitset_64 which can handle bitsets up to 64 bits,\n > and bitset_large, which can handle bitsets up to huge(0_bits_kind) bits,\n > where bits_kind is currently int32. The implementations of bitset_64 and\n > bitset_large are in the submodule files, stdlib_bitset_64.f90 and\n > stdlib_bitset_large.f90. at this point I have two questions for potential\n > users:\n >\n > 1.\n >\n > Are the names of the descendant types and their submodule files\n > acceptable?\n > 2.\n >\n > There are a number of binary operations: and, and_not, eqv, or, and xor.\n > Users I expect will normally want to use these with bitsets of the same\n > size, but the current code allows the two arguments to differ in size\n > effectively padding the smaller argument with zero bits where necessary.\n > This results in significantly more complicated code for eqv, or, and\n > xor, with a corresponding impact on the code robustness, runtime, and\n > testing. Should I continue to allow arguments differing in size, or require\n > the bitsets to be the same size and enforce it with if tests and error\n > stops, or require the arguments to be the same size and simply leave the\n > results undefined if the arguments differ in size?\n >\n > \u2014\n > You are receiving this because you were mentioned.\n > Reply to this email directly, view it on GitHub\n > <#221 (comment)>,\n > or unsubscribe\n > <https://github.com/notifications/unsubscribe-auth/AAN6YRZ4C5BMOF2UID7UMYTSD74KDANCNFSM4O7IG3CQ>\n > .\n >\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#221 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOQ36Y6JDMZGVIKWFJLSESMNZANCNFSM4O7IG3CQ>."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-08 06:34:59+00:00",
                    "text": "Indeed, I misunderstood your question! If we could rely on parameterised\nderived types, would that be a solution? I have never used them, I must\nadmit, given that support is rather precarious. I can imagine that a type\nwith 11 bits (the number of bits being a len parameter of the type) would\nbe considered differently than one with 12 bits. The len parameter does not\nneed to be used for an actual length. Then something along these lines\nmight work to distinguish the two types:\n\nlogical function equal( a, b )\n    type(bitset_64(nbits=*)) :: a\n    type(bitset_64(nbits=a%nbits)) :: b\nend function equal\n\nI have never tried anything of the sort, mind you.\n\nRegards,\n\nArjen\n\nOp ma 7 sep. 2020 om 19:46 schreef William B. Clodius <\nnotifications@github.com>:\n\u2026\n Hi Arjen:\n\n I may be misunderstanding you, but I think you misunderstood my second\n question. Entities of both the bitset_64 and bitset_large can behave as\n though they have different numbers of bits. For example one can declare one\n entity of type bitset_64 as having 16 bits and another entity as having 17\n bits. For two different bit sizes of type bitset_64 I have to decide and\n describe how they interact for such binary ops as `and`, `and_not`, `or`,\n `xor`, `==`, `/=`, `>`,` >=`, `<`, and `<=`. The simplest description and\n implementation is to simply forbid using entities of different bit sizes in\n those binary ops. I then have to decide whether to enforce this restriction\n by a test and branch to an error stop, or leave the use of two bit sizes as\n undefined, eliminating the overhead of the test and branch., which can be\n significant for a `bitset_64`. If I decide to allow different bit sizes\n then it has the following consequences:\n\n 1. The obvious description of how to treat different bit sizes (pad set2\n with zeros if shorter than set1, and ignore the extra bits if longer than\n set1) for the logical operations `and`, `and_not`, `or`, and `xor` is\n different from the obvious description (pad the smaller bitset with zeros)\n of how to treat the comparison operations `==`, `/=`, `>`,` >=`, `<`, and\n `<=`.\n\n 2. I have to have at least one branch in the individual procedures for\n `bits(set1)>= bits(set2)` vs. `bits(set1)<bits(set2)`\n\n 3. In the final word of the bitset I often have to resort to bit level\n operations, rather than the word level operations I can consistently use if\n they have the same number of bits. This can have a large performance hit.\n\n 4. The logic for each branch is tricky and easy to get wrong, particularly\n for the `bitset_large`.\n\n 5. I have to triple the testing for those ops, in effect testing\n separately for `bits(set1)<bits(set2)`, `bits(set1)==bits(set2)`, and\n `bits(set1)>bits(set2)`.\n\n In C++ and Java, the problem doesn\u2019t exist as the number of bits\n determines the type and the binary ops are forbidden to mix types,\n resulting in all binary ops requiring the same number of bits for each\n operand.\n\n Given the complexity of mixing bit sizes, and to my mind, the black of\n usefulness for mixing bit sizes, I think there will be zero demand for the\n ability to mix bit sizes on the binary ops.\n\n That being said a conversion function is useful and I\u2019ll see about\n implementing one.\n\n\n > On Sep 7, 2020, at 2:44 AM, Arjen Markus ***@***.***>\n wrote:\n >\n >\n > Hi Bill,\n >\n > to answer your questions:\n > ad 1.\n > These names look quite acceptable to me. While making the numerical size\n > (64) part of the name is not something I would recommend in general, I\n > think in this case, as we are talking of a very specific data type, it is\n > acceptable. (My hesitation wrt such numerical components has to do with\n > such ancient types as REAL*4 and the unfortunate \"kind=4\" practice ;))\n > ad 2.\n > I would say that the two are meant for very different purposes. If they\n > should be combined, why not do that explicitly via a conversion function?\n > That way, should the need arise for a third type, say, bitset_128, you\n > avoid the combinatorial explosion and you make it clearer that the data\n > types are related but not merely different tastes of the same thing. If\n > they should be combined in one operation, then that should be done\n > explicitly. (You could also define a conversion from bitset_large to\n > bitset_64, though that will necessarily truncate the bts beyond 64 or 63\n > ...)\n >\n > Regards,\n >\n > Arjen\n >\n > Op do 3 sep. 2020 om 22:31 schreef William B. Clodius <\n > ***@***.***>:\n >\n > > I now have an implementation of bitsets that I will start testing. The\n > > main module file, stdlib_bitsets.f90, defines an abstract type,\n bitset_t,\n > > with two descendants, bitset_64 which can handle bitsets up to 64 bits,\n > > and bitset_large, which can handle bitsets up to huge(0_bits_kind)\n bits,\n > > where bits_kind is currently int32. The implementations of bitset_64\n and\n > > bitset_large are in the submodule files, stdlib_bitset_64.f90 and\n > > stdlib_bitset_large.f90. at this point I have two questions for\n potential\n > > users:\n > >\n > > 1.\n > >\n > > Are the names of the descendant types and their submodule files\n > > acceptable?\n > > 2.\n > >\n > > There are a number of binary operations: and, and_not, eqv, or, and\n xor.\n > > Users I expect will normally want to use these with bitsets of the same\n > > size, but the current code allows the two arguments to differ in size\n > > effectively padding the smaller argument with zero bits where\n necessary.\n > > This results in significantly more complicated code for eqv, or, and\n > > xor, with a corresponding impact on the code robustness, runtime, and\n > > testing. Should I continue to allow arguments differing in size, or\n require\n > > the bitsets to be the same size and enforce it with if tests and error\n > > stops, or require the arguments to be the same size and simply leave\n the\n > > results undefined if the arguments differ in size?\n > >\n > > \u2014\n > > You are receiving this because you were mentioned.\n > > Reply to this email directly, view it on GitHub\n > > <\n #221 (comment)>,\n > > or unsubscribe\n > > <\n https://github.com/notifications/unsubscribe-auth/AAN6YRZ4C5BMOF2UID7UMYTSD74KDANCNFSM4O7IG3CQ\n >\n > > .\n > >\n > \u2014\n > You are receiving this because you were mentioned.\n > Reply to this email directly, view it on GitHub <\n #221 (comment)>,\n or unsubscribe <\n https://github.com/notifications/unsubscribe-auth/APTQDOQ36Y6JDMZGVIKWFJLSESMNZANCNFSM4O7IG3CQ\n >.\n >\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#221 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR45OKFL43NYTPMC6FDSEUL77ANCNFSM4O7IG3CQ>\n ."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-08 06:57:49+00:00",
                    "text": "I just tried: both gfortran and Intel Fortran ignore the condition I tried\nto impose. So that is not an option!\n\nOp di 8 sep. 2020 om 08:34 schreef Arjen Markus <arjen.markus895@gmail.com>:\n\u2026\n Indeed, I misunderstood your question! If we could rely on parameterised\n derived types, would that be a solution? I have never used them, I must\n admit, given that support is rather precarious. I can imagine that a type\n with 11 bits (the number of bits being a len parameter of the type) would\n be considered differently than one with 12 bits. The len parameter does not\n need to be used for an actual length. Then something along these lines\n might work to distinguish the two types:\n\n logical function equal( a, b )\n     type(bitset_64(nbits=*)) :: a\n     type(bitset_64(nbits=a%nbits)) :: b\n end function equal\n\n I have never tried anything of the sort, mind you.\n\n Regards,\n\n Arjen\n\n Op ma 7 sep. 2020 om 19:46 schreef William B. Clodius <\n ***@***.***>:\n\n> Hi Arjen:\n>\n> I may be misunderstanding you, but I think you misunderstood my second\n> question. Entities of both the bitset_64 and bitset_large can behave as\n> though they have different numbers of bits. For example one can declare one\n> entity of type bitset_64 as having 16 bits and another entity as having 17\n> bits. For two different bit sizes of type bitset_64 I have to decide and\n> describe how they interact for such binary ops as `and`, `and_not`, `or`,\n> `xor`, `==`, `/=`, `>`,` >=`, `<`, and `<=`. The simplest description and\n> implementation is to simply forbid using entities of different bit sizes in\n> those binary ops. I then have to decide whether to enforce this restriction\n> by a test and branch to an error stop, or leave the use of two bit sizes as\n> undefined, eliminating the overhead of the test and branch., which can be\n> significant for a `bitset_64`. If I decide to allow different bit sizes\n> then it has the following consequences:\n>\n> 1. The obvious description of how to treat different bit sizes (pad set2\n> with zeros if shorter than set1, and ignore the extra bits if longer than\n> set1) for the logical operations `and`, `and_not`, `or`, and `xor` is\n> different from the obvious description (pad the smaller bitset with zeros)\n> of how to treat the comparison operations `==`, `/=`, `>`,` >=`, `<`, and\n> `<=`.\n>\n> 2. I have to have at least one branch in the individual procedures for\n> `bits(set1)>= bits(set2)` vs. `bits(set1)<bits(set2)`\n>\n> 3. In the final word of the bitset I often have to resort to bit level\n> operations, rather than the word level operations I can consistently use if\n> they have the same number of bits. This can have a large performance hit.\n>\n> 4. The logic for each branch is tricky and easy to get wrong,\n> particularly for the `bitset_large`.\n>\n> 5. I have to triple the testing for those ops, in effect testing\n> separately for `bits(set1)<bits(set2)`, `bits(set1)==bits(set2)`, and\n> `bits(set1)>bits(set2)`.\n>\n> In C++ and Java, the problem doesn\u2019t exist as the number of bits\n> determines the type and the binary ops are forbidden to mix types,\n> resulting in all binary ops requiring the same number of bits for each\n> operand.\n>\n> Given the complexity of mixing bit sizes, and to my mind, the black of\n> usefulness for mixing bit sizes, I think there will be zero demand for the\n> ability to mix bit sizes on the binary ops.\n>\n> That being said a conversion function is useful and I\u2019ll see about\n> implementing one.\n>\n>\n> > On Sep 7, 2020, at 2:44 AM, Arjen Markus ***@***.***>\n> wrote:\n> >\n> >\n> > Hi Bill,\n> >\n> > to answer your questions:\n> > ad 1.\n> > These names look quite acceptable to me. While making the numerical size\n> > (64) part of the name is not something I would recommend in general, I\n> > think in this case, as we are talking of a very specific data type, it\n> is\n> > acceptable. (My hesitation wrt such numerical components has to do with\n> > such ancient types as REAL*4 and the unfortunate \"kind=4\" practice ;))\n> > ad 2.\n> > I would say that the two are meant for very different purposes. If they\n> > should be combined, why not do that explicitly via a conversion\n> function?\n> > That way, should the need arise for a third type, say, bitset_128, you\n> > avoid the combinatorial explosion and you make it clearer that the data\n> > types are related but not merely different tastes of the same thing. If\n> > they should be combined in one operation, then that should be done\n> > explicitly. (You could also define a conversion from bitset_large to\n> > bitset_64, though that will necessarily truncate the bts beyond 64 or 63\n> > ...)\n> >\n> > Regards,\n> >\n> > Arjen\n> >\n> > Op do 3 sep. 2020 om 22:31 schreef William B. Clodius <\n> > ***@***.***>:\n> >\n> > > I now have an implementation of bitsets that I will start testing. The\n> > > main module file, stdlib_bitsets.f90, defines an abstract type,\n> bitset_t,\n> > > with two descendants, bitset_64 which can handle bitsets up to 64\n> bits,\n> > > and bitset_large, which can handle bitsets up to huge(0_bits_kind)\n> bits,\n> > > where bits_kind is currently int32. The implementations of bitset_64\n> and\n> > > bitset_large are in the submodule files, stdlib_bitset_64.f90 and\n> > > stdlib_bitset_large.f90. at this point I have two questions for\n> potential\n> > > users:\n> > >\n> > > 1.\n> > >\n> > > Are the names of the descendant types and their submodule files\n> > > acceptable?\n> > > 2.\n> > >\n> > > There are a number of binary operations: and, and_not, eqv, or, and\n> xor.\n> > > Users I expect will normally want to use these with bitsets of the\n> same\n> > > size, but the current code allows the two arguments to differ in size\n> > > effectively padding the smaller argument with zero bits where\n> necessary.\n> > > This results in significantly more complicated code for eqv, or, and\n> > > xor, with a corresponding impact on the code robustness, runtime, and\n> > > testing. Should I continue to allow arguments differing in size, or\n> require\n> > > the bitsets to be the same size and enforce it with if tests and error\n> > > stops, or require the arguments to be the same size and simply leave\n> the\n> > > results undefined if the arguments differ in size?\n> > >\n> > > \u2014\n> > > You are receiving this because you were mentioned.\n> > > Reply to this email directly, view it on GitHub\n> > > <\n> #221 (comment)\n> >,\n> > > or unsubscribe\n> > > <\n> https://github.com/notifications/unsubscribe-auth/AAN6YRZ4C5BMOF2UID7UMYTSD74KDANCNFSM4O7IG3CQ\n> >\n> > > .\n> > >\n> > \u2014\n> > You are receiving this because you were mentioned.\n> > Reply to this email directly, view it on GitHub <\n> #221 (comment)>,\n> or unsubscribe <\n> https://github.com/notifications/unsubscribe-auth/APTQDOQ36Y6JDMZGVIKWFJLSESMNZANCNFSM4O7IG3CQ\n> >.\n> >\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <#221 (comment)>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAN6YR45OKFL43NYTPMC6FDSEUL77ANCNFSM4O7IG3CQ>\n> .\n>"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-08 13:35:33+00:00",
                    "text": "@arjenmarkus I have also never tried parameterized derived types. Support is more widespread than I expected, http://fortranwiki.org/fortran/show/Fortran+2003+status, but it has always sounded more quirky than I like."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-09 01:57:01+00:00",
                    "text": "In thinking further a bitset type is about as close as you can come to a type suited for parameterized derived types, if there is one that is suited for PDTs. I am going to experiment a little with using PDTs for bitsets."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-09 20:22:48+00:00",
                    "text": "After experimenting I have found a problem with gfortran 10.2's implementation of PDTs for which I cannot find a workaround. Also I had hoped to be able to declare bitsets with their bitesize initialized to zero and ifort's error messages seem to be indicate that that would be non-standard. So I have given up on using PDTs for bitsets."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-09-09 23:06:20+00:00",
                    "text": "In thinking further a bitset type is about as close as you can come to a type suited for parameterized derived types, if there is one that is suited for PDTs. I am going to experiment a little with using PDTs for bitsets.\n\nA PDT could bring bitsets very close to the C++ std:bitset. I've also done some testing, reaching the same conclusion - compiler support is not good enough.\nWith ifort 19.1 I am able to compile the following type hierarchy:\nmodule stdlib_abstract_bitset\n\n  implicit none\n  private\n\n  public :: bitset_t\n\n  type, abstract :: bitset_t\n  end type\n\nend module\n\nmodule stdlib_small_bitset\n\n  use stdlib_abstract_bitset, only: bitset_t\n  use iso_fortran_env, only: int32, int64\n  implicit none\n\n  integer, parameter :: block_kind = int32\n  integer, parameter :: bits_per_block = storage_size(block_kind)\n\n  type, extends(bitset_t) :: small_bitset(len)\n    integer, len :: len = 0\n    integer(block_kind) :: m_bits(ceiling(real(len)/real(bits_per_block)))\n  end type\n\ncontains\n...\nend module\nThe part that started to bother me was in functions similar to the example from @arjenmarkus:\n  function small_bitset_and(a,b) result(new)\n    type(small_bitset(*)), intent(in) :: a\n    type(small_bitset(a%len)), intent(in) :: b\n    type(small_bitset(a%len)) :: new \n    integer :: i, nblocks\n\n    nblocks = size(a%m_bits)\n    do i = 1, nblocks\n        new%m_bits(i) = iand(b%m_bits(i),a%m_bits(i))\n    end do\n  end function\n\nAssuming I now bind this function to the operator .and. and use it as follows:\n  type(small_bitset(64)) :: a, b, c\n  type(small_bitset(32)) :: d\n\n  c = a .and. b ! valid\n  d = a .and. b ! expected it to be invalid, but compiler produces no error message\n\nthe value of d%len after the assignment becomes 64!"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-17 02:39:46+00:00",
                    "text": "I now have an implementation of bitset_t, bitset_64, and bitset_large that passes what I consider to be extensive testing. Before I consider doing a PR for it I would like to have opinions on the following questions:\n\nShould I change bitset_t to bitset_type?\nShould I add an _t or _type to bitset_64 or bitset_large?\nCurrently I assume without checking that for the binary ops and, and_not, or, xor, ==, /=, <, <=, >, and >= that the arguments have the same size. Should I enforce requiring the same size by adding a branch to error stop?"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-20 03:26:56+00:00",
                    "text": "@ivan-pi before I even consider using PDTs I need to be able to compile with both of the two most widely used compilers ifort and gfortran, and preferably versions of both compilers more than a couple of years old. Gfortran will not let me combine inheritance and PDTs, giving unrelated error messages. Ifort will accept combining inheritance and PDTs, but will not let me initialize at declaration the arrays holding the bits, i.e. will not accept code such as\nmodule stdlib_abstract_bitset\n\n  implicit none\n  private\n\n  public :: bitset_t\n\n  type, abstract :: bitset_t\n  end type\n\n end module\n\nmodule stdlib_small_bitset\n\n  use stdlib_abstract_bitset, only: bitset_t\n  use iso_fortran_env, only: int32, int64\n  implicit none\n\n  integer, parameter :: block_kind = int32\n  integer, parameter :: bits_per_block = storage_size(block_kind)\n\n type, extends(bitset_t) :: small_bitset(len)\n    integer, len :: len = 0\n    integer(block_kind) :: m_bits(ceiling(real(len)/real(bits_per_block)))=0 ! note the initialization\n  end type\n\ncontains\n...\nend module\n\nIf I have to explicitly initialize the arrays I see no advantage to PDTs."
                },
                {
                    "user": "FortranFan",
                    "date": "2020-09-20 11:30:37+00:00",
                    "text": "@wclodius2 wrote:\n\n..\ntype, extends(bitset_t) :: small_bitset(len)\ninteger, len :: len = 0\ninteger(block_kind) :: m_bits(ceiling(real(len)/real(bits_per_block)))=0 ! note the initialization\nend type\n..\n.. If I have to explicitly initialize the arrays I see no advantage to PDTs.\n\nFrom what I understand, it's the Fortran standard that disallows the initialization shown above, Intel Fortran implementation is simply trying to conform.\nBut now, I don't understand the comment, \"If I have to explicitly initialize the arrays I see no advantage to PDTs.\"\nWhat is the alternate \"design\" option with bitset_large?  The ALLOCATABLE attribute for the array component of the derived type toward \"bitset\"?  If so, that too will need to be explicitly initialized."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-20 22:27:34+00:00",
                    "text": "FWIW I was tired when I wrote that. I know it is the Fortran standard that forbids it, Ifort's error messages are clear on that. I just think it was an unfortunate decision for the standard to forbid it. It has an obvious interpretation, that looks to me very implementable. It is equivalent to character strings, by default, always being blank padded. I know that an allocatable array would also require an explicit initialization. I also know that users are human, and will forget to perform an initialization. I also know that trying to access unallocated memory is more likely to generate a useful error message, than accessing allocated, but uninitialized, memory. All of this is moot though, since my implementation uses inheritance, gfortran will not let me combine inheritance and PDTs, and I consider compilation by gfortran critical."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-09-25 19:19:01+00:00",
                    "text": "@ivan-pi before I even consider using PDTs I need to be able to compile with both of the two most widely used compilers ifort and gfortran, and preferably versions of both compilers more than a couple of years old. Gfortran will not let me combine inheritance and PDTs, giving unrelated error messages.\n\nThat is a major drawback indeed. The example I produced above could only be compiled with ifort. It is a shame the compiler support is not mature enough, as I think this would be a compelling use case for PDTs. Maybe writing a post about this on the Intel Fortran Forum or comp.lang.fortran could help grab some attention."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-27 22:09:18+00:00",
                    "text": "I am now ready to do a PR if there is demand. Is there anyone ready to do a review of a PR with the following files?\nstdlib_bitsets.f9 - 2131 lines, the module\nstdlib_bitset_64.f90 - 1347 lines, a submodule implementing a bitset_64 type\nstdlib_bitset_large.f90 - 1580 lines, a submodule implementing a bitset_large type\nstdlib_bitsets.md - 1975 lines, a markdown document documenting the code\nI also have two test programs that may or may not need review:\ntest_stdlib_bitset_64.f90 - 745 lines\ntest_stdlib_bitset_large.f90 - 1477 has lines"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-28 06:47:43+00:00",
                    "text": "I am now ready to do a PR if there is demand. Is there anyone ready to do a review of a PR with the following files?\nstdlib_bitsets.f9 - 2131 lines, the module\nstdlib_bitset_64.f90 - 1347 lines, a submodule implementing a bitset_64 type\nstdlib_bitset_large.f90 - 1580 lines, a submodule implementing a bitset_large type\nstdlib_bitsets.md - 1975 lines, a markdown document documenting the code\nI also have two test programs that may or may not need review:\ntest_stdlib_bitset_64.f90 - 745 lines\ntest_stdlib_bitset_large.f90 - 1477 has lines\n\nThank you for these contributions. I think you can submit the PR.\nI will be a reviewer ;)"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-09-28 07:47:56+00:00",
                    "text": "Thank you for the large effort! I would also be happy to review the PR . (At latest I will find the necessary time next weekend.)"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-28 14:22:42+00:00",
                    "text": "I have now created a PR. The code is in my branch https://github.com/wclodius2/stdlib/tree/bitsets . I made the branch from my logger branch which may have been a mistake as it is showing the changes not only for the bitsests, but also for the logger. Let me know if I need to change that, and how to change that if necessary. FWIW I have done I think a reasonable job of better matching the undocumented aspects of the styles for the source code and markdown document, so I think it will require fewer changes than the logger branch, even though it is more than twice as large."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-28 15:42:02+00:00",
                    "text": "I have now created a PR. The code is in my branch https://github.com/wclodius2/stdlib/tree/bitsets . I made the branch from my logger branch which may have been a mistake as it is showing the changes not only for the bitsests, but also for the logger. Let me know if I need to change that, and how to change that if necessary.\n\nThank you @wclodius2 for the PR #236 . Indeed, it would be good to remove the logger code from #236. But I am not sure how to remove the logger code from this branch. @certik @milancurcic Any idea?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-28 15:46:54+00:00",
                    "text": "@wclodius2 I think the best way to do it is to:\n\nClose #236\nCreate a new branch that is even with master\nAdd bitsets code to the new branch\nOpen a new PR\n\nBut somebody more experienced with git and GitHub may know a better way."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-28 16:17:19+00:00",
                    "text": "The PR seems to have broken the build process. I can see two possible causes:\n\n\nTesting with gfortran 10.2 is not sufficient. I will try testing with ifort 17 to see if that finds a problem.\n\n\nI failed to properly update a CMakeLists.txt or Makefile.manual file."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-28 19:02:39+00:00",
                    "text": "Checking the error reports it looks like one problem is having error stop in pure procedures. I will fix that in the declarations of stdlib_bitsets.f90 and the actual code of stdlib_bitset_64.f90 and stdlib_bitset_large.f90."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-28 23:21:33+00:00",
                    "text": "I now have the code passing the build process. Ifort also caught a problem with an uninitialized block in bitset_64, that I suspect gfortran was initializing to zero, as intended, but not specified. However now the document builder (FORD?) is failing with an internal error on macOS, but not ubuntu. FWIW the error message is\n\"GitHub Actions has encountered an internal error when running your job.\""
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-30 03:00:46+00:00",
                    "text": "I have created a PR for a branch called bitsets3. The PR had one one that failed on ubuntu, out of six attempts, three on ubuntu and three on macOS.."
                }
            ]
        },
        {
            "number": 220,
            "user": "aradi",
            "date": "2020-07-16 21:01:22+00:00",
            "title": "API for file system operations: directory manipulation",
            "text": "So, following the suggestion in #201, let's start to discuss file system access API. In order to keep it focused, I'd suggest to start with the directory related operations first. My proposal:\nopen_directory(dirname, dirdesc, status): Opens a directory and returns a descriptor\ntype(dirdesc_t): Type containing the data of an opened directory\ndirdesc_t%get_next(): Returns the next entry in the open directory or \"\" if\nthere are no more entries.\nmake_directory(dirname, parents, status): Makes a directory. If parents is .true.\nalso parent directories are created in case they do not exist yet.\nremove_directory(dirname, content, status): Removes a directory. If content is\n.true. also the directory content is removed (recursive delete).\nchange_directory(dirname, status): Changes to the given directory\nget_working_dir() -> char(:), allocatable: Returns the current working directory.\nis_dir(fname) -> logical: GIve .true. if fname is a directory.\nA few notes:\n\n\nThe functionality above can be easily realized with a libc-interface (should work on all POSIX systems) and a bit of C-code. The big question is Windows, as I have no clue how to implement this functionality on WIndows.\n\n\nAs for error handling we could have a status argument. I'd argue for having a derived type type(status_t) containg the result of the operation (OK/Error) and a string with the error message in case of error. Whether the status argument should be optional or not is open for discussions.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-07-16 21:55:57+00:00",
                    "text": "We should survey Python, Rust, Julia, Matlab, etc. to see what API they use for this."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-17 06:59:34+00:00",
                    "text": "That looks like a good start :). I would like to add though:\n\ndirdesc_t%get_first() - to get the first entry or to restart the search.\n\nShould it be possible to specify a filter?\n\nAs for Windows, as that is the main OS I work with, I might give that a\ntry. While the function names differ, the functionality is largely the same.\n\nWrt the type of the various arguments such as dirname, these would be\nsimple strings? Then I suggest we use the forward slash as the directory\nseparator - it is accepted by all the major OSs and anything else can be\nsolved inside the implementation (notably the C bit).\n\nRegards,\n\nArjen\n\nOp do 16 jul. 2020 om 23:01 schreef B\u00e1lint Aradi <notifications@github.com>:\n\u2026\n So, following the suggestion in #201\n <#201>, let's start to\n discuss file system access API. In order to keep it focused, I'd suggest to\n start with the directory related operations first. My proposal:\n\n open_directory(dirname, dirdesc, status): Opens a directory and returns a\n descriptor\n\n type(dirdesc_t): Type containing the data of an opened directory\n\n dirdesc_t%get_next(): Returns the next entry in the open directory or \"\"\n if\n there are no more entries.\n\n make_directory(dirname, parents, status): Makes a directory. If parents\n is .true.\n also parent directories are created in case they do not exist yet.\n\n remove_directory(dirname, content, status): Removes a directory. If\n content is\n .true. also the directory content is removed (recursive delete).\n\n change_directory(dirname, status): Changes to the given directory\n\n get_working_dir() -> char(:), allocatable: Returns the current working\n directory.\n\n is_dir(fname) -> logical: GIve .true. if fname is a directory.\n\n A few notes:\n\n    -\n\n    The functionality above can be easily realized with a libc-interface\n    (should work on all POSIX systems) and a bit of C-code. The big question is\n    Windows, as I have no clue how to implement this functionality on WIndows.\n    -\n\n    As for error handling we could have a status argument. I'd argue for\n    having a derived type type(status_t) containg the result of the\n    operation (OK/Error) and a string with the error message in case of error.\n    Whether the status argument should be optional or not is open for\n    discussions.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#220>, or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR3UW3EBFNYXV2PRHWTR35TDHANCNFSM4O45YWQA>\n ."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-07-17 16:11:07+00:00",
                    "text": "I think we should start with just the file path bit. See the Rust library, or the Haskell library.\nAlso, I don't particularly like the manual iterator design for open_directory. I'd much rather have a function get_contents(directory) -> type(file_path), allocatable :: paths(:). To me, open_directory and dirdesc%get_next() smacks of object-oriented assembly, in an attempt to satisfy primitive obsession."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-17 16:26:34+00:00",
                    "text": "I'd much rather have a function get_contents(directory) -> type(file_path), allocatable :: paths(:)\n\n\ud83d\udc4d +1\nAlso, I see inconsistent naming, e.g. is_dir() and dirdesc_t, but change_directory and remove_directory. I like shorter names if they're common enough. In this case, I think they are. What do you think about:\n\nchange_directory -> chdir\nmake_directory -> mkdir\nremove_directory -> rmdir\nget_working_dir -> get_cwd or getcwd\n\nPython API reference: https://docs.python.org/3/library/os.html"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-17 16:33:06+00:00",
                    "text": "I think we should start with just the file path bit. See the Rust library, or the Haskell library.\n\nShould this be a separate thread? I think in this one we discuss only directory stuff, plus I think most directory operations here are independent of file path."
                },
                {
                    "user": "aradi",
                    "date": "2020-07-19 15:45:34+00:00",
                    "text": "@everythingfunctional The interface here is basically a 1-1 mapping of  the libc API, which also uses an iterator. (Works in Rust also similarly) But sure, if we have a decent file path type, we could have a convenience funtion on top of it which returns an allocatable array instead.\n@milancurcic Although I'd be very happy to go with Pythons naming convention, it would not be consistent with Fortrans recent naming strategy (e.g. execute_command_line instead of exec or even command_argument_count). For sake of adoption, I'd probably prefer the style which is more Fortran like, even if I am not big fan of it. We could use _dir everywhere to make it more consistent and somehwat shorter, though: create_dir (or make_dir), remove_dir, change_dir, etc..."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-07-20 23:15:04+00:00",
                    "text": "I see. In that case the question becomes one of philosophy for stdlib. Does stdlib provide lots of low level stuff for people to build abstractions on top of, or does it aim to provide useful abstractions and ergonomic APIs?"
                },
                {
                    "user": "aradi",
                    "date": "2020-07-23 16:32:02+00:00",
                    "text": "@everythingfunctional I agree, it is a philosophical question. And given the traditional reluctance of Fortran to delve into the depths of the underlying operating system, a higher level solution would indeed be probably more appropriate.\nIf we return an array, we have to decide on the element type. I see 3 different options:\n\ncharacters of some fixed length (e.g. max path length size on the system, or similar)\na string derived type (offering variable string sizes and maybe also some string capabilties)\na path derived type (offering path manipulation and path-query capabilties).\n\nI am working on Option 3 at the moment, but as discussed in #224, we should decide, whether and if yes how many derived types we want to impose on the users of stdlib..."
                },
                {
                    "user": "certik",
                    "date": "2020-07-23 16:41:37+00:00",
                    "text": "@everythingfunctional regarding the goal of stdlib, I consider it both:\n\nprovide reusable low level functionality that gets the job done and people can use it to build more high level interfaces, or just use it directly; ideally these are just raw functions / subroutines that do not use derived types\nnicely designed high level interfaces (perhaps OO based) that use the low level blocks; this is designed to be ergonomic and can use derived types or other OO features\n\nThat way everybody gets what they want, both people who prefer more OO, as well as people who prefer more direct low level API."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-07-23 16:52:06+00:00",
                    "text": "In that case, I think the original proposal is perfectly suitable as low-level building blocks. It wouldn't be difficult to build a more ergonomic API using them."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-30 05:13:13+00:00",
                    "text": "Since this is related to #201, I want to explain the rational why I prefer to rely on standard types and no type bound procedures for low level operations:\nIn Fortran, one cannot chain function calls (and array access), so an object oriented approach will result in something like:\ntype(t_path) :: filename\nfilename = getcwd()\ncall filename%join('my_file.ext)\nprint*, filename%islink()\n\n\nwhile the functional/procedural way gives:\nprint*, islink(join(getcwd(),'my_file.ext'))\n\nI acknowledge that this is not the most elaborate example, but in generally I think that a procedural approach is often more natural for Fortran."
                },
                {
                    "user": "certik",
                    "date": "2020-07-30 05:36:57+00:00",
                    "text": "@MarDiehl I am a big fan of simple functions / subroutines also over object oriented approach. In general, we can have both to satisfy everybody."
                },
                {
                    "user": "aradi",
                    "date": "2020-07-30 14:44:04+00:00",
                    "text": "@MarDiehl Yes, your reasoning is very convincing and indeed, that approach fits definitely better to Fortran.\nBut giving the suggested directory API above, which part would you propose to be change? The only type bound procedure we have so far is get_next(this) so far. As this changes the internal state of the directory, it must be implemented as a subroutine, so we have the choice between\ncall get_next(mydir, nextentry)\n\nand\ncall mydir%get_next(nextentry)\n\nI don't know, whether there is any esthetic difference between the two....\nIf you refer to the type(path) suggestion, I am with you, that we should rather use intrinsic types (e.g. allocatable chars here) whenever possible.\n@milancurcic , @MarDiehl As for being \"fortranic\": Then getcwd() should be rather get_working_dir() or similar, as especially recently introduced Fortran functions handling the environment (e.g. execute_command_line, command_argument_count tend to be rather verbose than abbreviated. I am not saying, that we should be that verbose, but I'd propose to introduce names which are more consistent with the naming philosophy of the already existing language."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-30 14:48:42+00:00",
                    "text": "Actually, if you have a type-bound procedure, then you can use both forms\n:). o it will be down to taste then.\n\nOp do 30 jul. 2020 om 16:44 schreef B\u00e1lint Aradi <notifications@github.com>:\n\u2026\n @MarDiehl <https://github.com/MarDiehl> Yes, your reasoning is very\n convincing and indeed, that approach fits definitely better to Fortran.\n\n But giving the suggested directory API above, which part would you propose\n to be change? The only type bound procedure we have so far is\n get_next(this) so far. As this changes the internal state of the\n directory, it must be implemented as a subroutine, so we have the choice\n between\n\n call get_next(mydir, nextentry)\n\n and\n\n call mydir%get_next(nextentry)\n\n I don't know, whether there is any esthetic difference between the two....\n\n If you refer to the type(path) suggestion, I am with you, that we should\n rather use intrinsic types (e.g. allocatable chars here) whenever possible.\n\n @milancurcic <https://github.com/milancurcic> , @MarDiehl\n <https://github.com/MarDiehl> As for being \"fortranic\": Then getcwd()\n should be rather get_working_dir() or similar, as especially recently\n introduced Fortran functions handling the environment (e.g.\n execute_command_line, command_argument_count tend to be rather verbose\n than abbreviated. I am not saying, that we should be *that* verbose, but\n I'd propose to introduce names which are more consistent with the naming\n philosophy of the already existing language.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#220 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YRZ5RMFWDCVYSOZPLGDR6GBMRANCNFSM4O45YWQA>\n ."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-30 21:36:04+00:00",
                    "text": "@aradi\nwhat about an interface like the following:\nfunction list_directory(path)\n\n    character(len=*), intent(in)  :: path\n    character(len=:), allocatable, dimension(:) :: list_directory\n    ...\n\nend function list_directory\n\nthis would simply return a array of strings containing the file names, an optional argument could specify the search order (creation time, name). This is similar go https://docs.python.org/2/library/os.html#os.listdir, again with the drawback that Fortran has no list type and we need to use an array."
                },
                {
                    "user": "certik",
                    "date": "2020-07-30 21:56:39+00:00",
                    "text": "I don't think that works in Fortran, I think you have to use a derived type to have an array of strings, like I did here:\nhttps://github.com/fortran-lang/fpm/blob/fcb7f675a8203f0ab518b20e9e11ee6dd49c3186/fpm/src/fpm.f90#L78"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-30 22:08:14+00:00",
                    "text": "I don't think that works in Fortran, I think you have to use a derived type to have an array of strings, like I did here:\nhttps://github.com/fortran-lang/fpm/blob/fcb7f675a8203f0ab518b20e9e11ee6dd49c3186/fpm/src/fpm.f90#L78\n\nIt works. You just need to figure out the maximum length among all strings and the number of strings:\nallocate(character(len=max_len)::list_directory(N_files))\n\nImplementing such a function is of course a little bit cumbersome, but the advantage of stdlib is that it has to be done only once."
                },
                {
                    "user": "certik",
                    "date": "2020-07-30 22:11:58+00:00",
                    "text": "Ah I see. Ok, that can be a possibility. A bit wasteful, but simpler, and perhaps even more performing than the allocatable in allocatable approach."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-07-31 04:41:58+00:00",
                    "text": "I use an interface similar to what is being described, and looking over the list, three more that I find I use extensively are\none for getting the current scratch directory by assuming it is set by $TEMPDIR, $TMP, $TEMP or /tmp; but it would be nice to get what opening a Fortran SCRATCH file is using; something to set what that directory is; and when getting a directory listing as a standard array if you also want to return the length, which can increase processing speed versus trim() and also lets you handle outliers like trailing spaces in the name (an alternative is adding a null character to the name like C). I happen to use the prefix system_ for just about anything that requires an ISO_C_BINDING and is calling a \"standard\" library; but have no problem with the names above, except that some of the simpler ones like chdir, mkdir, ... are often common extensions so you have the potential problem of referring to the extensions if you forget the USE statement, and/or confusion over which one is being called for those familiar with the extention.\nFor reference my names are:\n833  get_tmp (3m_io)      - [M_io] Return the name of the scratch directory(LICENSE:PD)\n835  system_dir (3m_io)   - [M_io] return filenames in a directory matching specified wildcard string(LICENSE:PD)\n1018  system_getcwd (3m_system) - [M_system] call getcwd(3c) to get the pathname of the current working directory(LICENSE:PD)\n1016  system_chdir (3m_system) - [M_system] call chdir(3c) from Fortran to change working directory(LICENSE:PD)\n1019  system_mkdir (3m_system) - [M_system] call mkdir(3c) to create a new directory(LICENSE:PD)\n1024  system_rewinddir (3m_system) - [M_system] call rewinddir(3c) to rewind directory stream(LICENSE:PD)\n1031  system_isdir (3m_system) - [M_system] checks if argument is a directory path(LICENSE:PD)\n1036  system_closedir (3m_system) - [M_system] close a directory stream by calling closedir(3c)(LICENSE:PD)\n1043  system_opendir (3m_system) - [M_system] open directory stream by calling opendir(3c)(LICENSE:PD)\n1047  system_readdir (3m_system) - [M_system] read a directory using readdir(3c)(LICENSE:PD)"
                },
                {
                    "user": "urbanjost",
                    "date": "2020-07-31 04:46:59+00:00",
                    "text": "PS:  setting and querying where the scratch files go is not an issue for most programs, but can be a big issue due to performance and space issues when huge scratch files are requred in HPC appiications. I but some notes about that and some of the major portability problems concering scratch files on Blevin's Fortran WIKI page a long time ago."
                },
                {
                    "user": "aradi",
                    "date": "2020-07-31 07:22:42+00:00",
                    "text": "@MarDiehl Yes, the allocated character array is as \"fortranic\" as only possible. \ud83d\ude04  Three remarks:\n\n\nIt is not that cumbersome to implement. The algorithm would have first to loop over all entries of a directory anyway (to find out how many there are) and then once more to put their names in the allocated array. In he first loop one can then also easily determine the max file name length.\n\n\nConsumers would have to trim() the entries to find out the true file names. As long as the file names are just passed to intrinsic statements, like open, this is OK, as open automatically trims the passed character variable, but it may be still error prone and annoying if the user tries to manipulate the file name (e.g. checking whether it ends with a given suffix, or when an additional suffix should be added to the file name).\n\n\nShould other file manipulation commands automatically trim character variables containing file names? It would be quite convenient (one would spare a lot of trim()s and 100% compatible with current Fortran. However it also would inherit consequence, that it is impossible to treat file names ending on whitespaces, or to be more precise, impossible to distinguish between file names differing only in the nr. of whitespaces at the end of their file names. (But, since we can not fix that problem in the existing open statement anyway, probably the best thing is to have a \"consistently broken\" implementation of the other features in stdlib anyway...)"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-31 11:17:39+00:00",
                    "text": "@aradi:\n\nTrue, it is actually not that bad. I do the same in the split function.\nYes, further manipulation would always require a trim. At least for all the os/os_path functions I would do that for all intent(in) strings\nThis is a important point I totally missed. The hack used for URL encoding (replace by + or %20) is quite ugly. I agree with you that we should simply document this behavior since we cannot change the behavior of trim/open anyways. Better we have a simple and easy to user function that works for 99% of the users than something complicated that handles corner cases but is hard to use for the vast majority. Spaces on the shell are anyways a nightmare and trailing spaces are even difficult for graphical file explorers."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-07 09:10:54+00:00",
                    "text": "I have picked up work on the Windows version again. While I made good\nprogress over the weekend, I am not there yet. The most important issue I\nam currently facing is this:\nThe implementation stops via ERROR STOP when a function or routine\nencounters an error. This prevents the user from taking corrective action.\nIt also prevents the program from ignoring the problem of course. Is this\nwhat we want? I can imagine a sort of dual API, much like the OPEN\nstatement. If you do not provide an argument to store any error condition\nin, then the ERROR STOP action is taken. Otherwise it is left to the\nprogrammer to properly deal with the error. Something along these lines:\n\nsubroutine chdir(path, error)\n\n    character(len=*), intent(in) :: path\n    logical, intent(out), optional :: error\n    if ( present(error) ) then\n        error = .false.\n    endif\n    if(chdir_c(f_c_string(path)) /= 0_C_INT) then\n      if ( present(error) ) then\n         error = .true.\n      else\n         error stop 'chdir: cannot change directory'\n     endif\n   endif\n\nThe test program is currently also using the routine symlink. As on Windows\nlinks have a very different purpose, the current implementation returns an\nerror and therefore fails. I have introduced a mechanism to check the\noperating system and so we can avoid a call to symlink we know is going to\nfail. But that only avoids the above issue.\n\nSome other things worth mentioning:\n- I found out why CMake was not creating the appropriate makefiles on\nWindows (spaces in the path to the compiler, yes, those abominable spaces).\nIn fact the CMakeLists.txt file at the highest level can be made much\nsimpler. The result: it works on all three Windows platforms (plain\nWindows, Cygwin and MinGW)\n- I do not think the test program should rely on the present of a Python\ninstallation :). The use it currently makes of it is very limited and\neasily done in Fortran.\n- It may be useful to know the type of OS, so that is now (in my copy of\nthe repository) caught via a bit of CMake manipulation.\n\nRegards,\n\nArjen\n\n\nOp vr 31 jul. 2020 om 13:17 schreef Martin Diehl <notifications@github.com>:\n\u2026\n @aradi <https://github.com/aradi>:\n\n    1. True, it is actually not that bad. I do the same in the split\n    function.\n    2. Yes, further manipulation would always require a trim. At least for\n    all the os/os_path functions I would do that for all intent(in) strings\n    3. This is a important point I totally missed. The hack used for URL\n    encoding (replace by + or %20) is quite ugly. I agree with you that we\n    should simply document this behavior since we cannot change the behavior of\n    trim/open anyways. Better we have a simple and easy to user function\n    that works for 99% of the users than something complicated that handles\n    corner cases but is hard to use for the vast majority. Spaces on the shell\n    are anyways a nightmare and trailing spaces are even difficult for\n    graphical file explorers.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#220 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR4W7F5UDOVL4EEJO7TR6KR6FANCNFSM4O45YWQA>\n ."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-07 11:22:29+00:00",
                    "text": "Oh, and one thing I forgot: on Windows the usual character used to separate\ndirectory names in a path is the backslash, not the forward slash. While a\nforward slash is perfectly acceptable (in most cases anyway and certainly\nin Fortran programs), I can imagine people will expect a \"\\\" to work when\nsplitting up a path name.\n\nRegards,\n\nArjen\n\nOp ma 7 sep. 2020 om 11:10 schreef Arjen Markus <arjen.markus895@gmail.com>:\n\u2026\n I have picked up work on the Windows version again. While I made good\n progress over the weekend, I am not there yet. The most important issue I\n am currently facing is this:\n The implementation stops via ERROR STOP when a function or routine\n encounters an error. This prevents the user from taking corrective action.\n It also prevents the program from ignoring the problem of course. Is this\n what we want? I can imagine a sort of dual API, much like the OPEN\n statement. If you do not provide an argument to store any error condition\n in, then the ERROR STOP action is taken. Otherwise it is left to the\n programmer to properly deal with the error. Something along these lines:\n\n subroutine chdir(path, error)\n\n     character(len=*), intent(in) :: path\n     logical, intent(out), optional :: error\n     if ( present(error) ) then\n         error = .false.\n     endif\n     if(chdir_c(f_c_string(path)) /= 0_C_INT) then\n       if ( present(error) ) then\n          error = .true.\n       else\n          error stop 'chdir: cannot change directory'\n      endif\n    endif\n\n The test program is currently also using the routine symlink. As on\n Windows links have a very different purpose, the current implementation\n returns an error and therefore fails. I have introduced a mechanism to\n check the operating system and so we can avoid a call to symlink we know is\n going to fail. But that only avoids the above issue.\n\n Some other things worth mentioning:\n - I found out why CMake was not creating the appropriate makefiles on\n Windows (spaces in the path to the compiler, yes, those abominable spaces).\n In fact the CMakeLists.txt file at the highest level can be made much\n simpler. The result: it works on all three Windows platforms (plain\n Windows, Cygwin and MinGW)\n - I do not think the test program should rely on the present of a Python\n installation :). The use it currently makes of it is very limited and\n easily done in Fortran.\n - It may be useful to know the type of OS, so that is now (in my copy of\n the repository) caught via a bit of CMake manipulation.\n\n Regards,\n\n Arjen\n\n\n Op vr 31 jul. 2020 om 13:17 schreef Martin Diehl ***@***.***\n >:\n\n> @aradi <https://github.com/aradi>:\n>\n>    1. True, it is actually not that bad. I do the same in the split\n>    function.\n>    2. Yes, further manipulation would always require a trim. At least\n>    for all the os/os_path functions I would do that for all intent(in)\n>    strings\n>    3. This is a important point I totally missed. The hack used for URL\n>    encoding (replace by + or %20) is quite ugly. I agree with you that\n>    we should simply document this behavior since we cannot change the behavior\n>    of trim/open anyways. Better we have a simple and easy to user\n>    function that works for 99% of the users than something complicated that\n>    handles corner cases but is hard to use for the vast majority. Spaces on\n>    the shell are anyways a nightmare and trailing spaces are even difficult\n>    for graphical file explorers.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <#220 (comment)>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAN6YR4W7F5UDOVL4EEJO7TR6KR6FANCNFSM4O45YWQA>\n> .\n>"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-09-07 14:18:04+00:00",
                    "text": "@arjenmarkus sorry for the late response, I've been busy with other things.\n\nerror handling: I have a branch with an optional stat argument. If that is given, it's return value can be used for checking the success of a function. Otherwise, error stop is called if something goes wrong. This behavior is similar to the behavior of standard language featurs.\nwindows path handling: We can make set the parameter defining the path separator depending on the OS. That would leave the question if there should be a standardize function (i.e. all user input with / would be translated to \\ on Windows). In python, there are actually two implementation to handle these subtle differences (posixpath/ntpath)\nIs there a difference between \"real windows\" and MingGW regarding the expected behavior on Windows?\nI will continue to work on the library on the weekend. Should we exchange ideas via skype or zoom then? I think that would be easier."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-07 14:33:14+00:00",
                    "text": "No problem, I have been busy too.\n\nThe question of distinguishing \"real/plain Windows\" from MinGW is not very\nsimple to answer. If you use the console it is rather unixy in behaviour,\nbut MinGW tries to be windowish. I guess we can refine this later, should\ndifferences become relevant in the context of a Fortran program trying to\ncooperate with the operating system.\n\nAs for exchanging ideas via Zoom or Skype, that would normally be quite\nconvenient, but I cannot plan ahead right now (unforeseen and unforeseeable\nevents in my family).\n\nRegards,\n\nArjen\n\nOp ma 7 sep. 2020 om 16:18 schreef Martin Diehl <notifications@github.com>:\n\u2026\n @arjenmarkus <https://github.com/arjenmarkus> sorry for the late\n response, I've been busy with other things.\n\n    1. error handling: I have a branch with an optional stat argument. If\n    that is given, it's return value can be used for checking the success of a\n    function. Otherwise, error stop is called if something goes wrong.\n    This behavior is similar to the behavior of standard language featurs.\n    2. windows path handling: We can make set the parameter defining the\n    path separator depending on the OS. That would leave the question if there\n    should be a standardize function (i.e. all user input with / would be\n    translated to \\ on Windows). In python, there are actually two\n    implementation to handle these subtle differences (posixpath/ntpath)\n    3. Is there a difference between \"real windows\" and MingGW regarding\n    the expected behavior on Windows?\n    4. I will continue to work on the library on the weekend. Should we\n    exchange ideas via skype or zoom then? I think that would be easier.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#220 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YRYJM7BHBK4SB6NVJVDSETTSZANCNFSM4O45YWQA>\n ."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-09-08 06:16:52+00:00",
                    "text": "ok, then it's best if you contact me via email: m.diehl@mpie.de if you have time."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-08 06:46:34+00:00",
                    "text": "WIll do, asap - I should be able to find time, if nothing else as a\ndistraction.\n\nRegards,\n\nArjen\n\nOp di 8 sep. 2020 om 08:17 schreef Martin Diehl <notifications@github.com>:\n\u2026\n ok, then it's best if you contact me via email: ***@***.*** if you\n have time.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#220 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR32SPX7BXSVA63VBQ3SEXD6HANCNFSM4O45YWQA>\n ."
                }
            ]
        },
        {
            "number": 219,
            "user": "wclodius2",
            "date": "2020-07-16 03:38:57+00:00",
            "title": "Standard library error reporting",
            "text": "Currently my default approach to dealing with errors is to have an\noptional status flag for the procedure in which the error is found,\none or more routines for writing an error message, and a branch for\neither setting the status flag or reporting the error while stopping\nprocessing, e.g., the psuedo code\nsubroutine example(..., status )\n    ...\n    integer, intent(out), optional :: status\n    ...\n    if (present(status)) status = success ! Set default value\n    ...\n    if (bad stuff is found) go to label\n    ...\n! Error handling is placed at the end of the routine\nlabel if (present status) then\n        status = bad_stuff_flag\n\t    return\n    else\n        call report_error_and_stop(...)\n    end if\n    ...\nend subroutine example\n\nI want to write some code for the Standard Library that will have to\nhandle errors. This prompts the following questions:\n\n\nIs this a good approach for handling errors in the Standard Library\ngiven the limitations of Fortran?\n\n\nIf this is not a good approach what is a better approach?\n\n\nIf this is a good approach should the Standard Library have a\nmodule supporting this approach?\n\n\nIf it should have a module what should be the API of that module?\n\n\nIn thinking about the API I have been looking at the error handling of\nFutility and its inspiration FLIBS. My examination so far has been\nsuperficial. My current approach is to send all information to the\nSTD_ERR of ISO_FORTRAN_ENV. Futility and FLIBS send it to a log\nfile. Futility has an object based system that allows it to send\nmessages to multiple log files. This prompts the following questions:\n\n\nIs supporting a log file separate  from STD_ERR useful?\n\n\nIf it is useful should a log file be required or should the default\nbe STD_ERR?\n\n\nWould more than one log file be useful?\n\n\nShould there be an option to report to both the log file and\nSTD_ERR?\n\n\nFutility and FLIBS also focus on the severity of the error, providing\nfive levels of error reporting: INFORMATION, WARNING, ERROR, FATAL\nERROR, and FAILURE. I have tended to have just WARNING and the\nequivalent of FATAL ERROR. Are multiple levels of error that useful?\nI have focussed on reporting the location where the error was\ndiscovered, providing optional MODULE and PROCEDURE arguments for\nreporting the MODULE and PROCEDURE in which the call was made> Would\nothers find that useful? If the error is discovered in an internal\nprocedure of a module procedure would an optional INTERNAL_PROCEDURE\nargument be useful?\nI have also focussed on enumerating various sources of errors, e.g.,\nALLOC_FAULT, CONSISTENCY_FAULT, CONVERGENCE_FAILURE,\nMISSING_FILE, etc., to provide a consistent nomenclature for the\nSTATUS flags and an informative string for the ERROR STOP\ncode. Would other people find such an enumeration useful? If it is useful\nis the enumeration best as a simple INTEGER or as a derived type, say\nERRORS?",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-07-16 03:57:42+00:00",
                    "text": "Error handling is something that we were not able to reach an agreement what the best approach is as a community yet.\nWe have discussed this several times in issues (I don't have time right now to look them up).\nIn general, if you are writing new code that requires error handling, then I would recommend to discuss the API of that code, and see if we can agree what error handling would best make sense for that code.\nAs an example, if you are writing a find function for strings, then the best error handling might be to simply return -1 if the given substring cannot be found, as in Python. If you are writing something else, then other error handling mechanisms might be more appropriate."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-16 04:08:22+00:00",
                    "text": "This seems related to #193."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-21 20:07:15+00:00",
                    "text": "This seems related to #193.\n\nThis is also related to #95.\nThis issue seems to come back quite often. How can we move forward and fix it ? :)\nThe approaches of the propositions of the different issues #95, #193 ,#219 seem to be also all similar."
                }
            ]
        },
        {
            "number": 218,
            "user": "aarograh",
            "date": "2020-07-10 17:10:57+00:00",
            "title": "Consider incorporating or contributing to Futility",
            "text": "This package is of interest to me and I think there's a lot of value in having something like this for Fortran.  I did want to make a note of the package https://github.com/CASL/Futility which overlaps a lot with the stated goals of fortran-lang/stdlib.  This isn't really a specific issue/suggestion, but more of an initial contact regarding the similar goals of the 2 projects.  I thought there might be some value to discussing the similarities/differences, potentially contributing to both projects instead of both of them being developed completely independently, etc.  I'd be interested to hear the thoughts of some of the fortran-lang/stdlib developers.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-07-13 18:18:16+00:00",
                    "text": "Hi Aaron, welcome and thank you for pointing out the Futility project (not to be confused with https://github.com/cmacmackin/futility).\nI took a look and definitely see Futility as more mature and with somewhat narrower scope than stdlib. Let's discuss which, if any, parts of Futility could be adapted into stdlib. Overall, the scope of stdlib is similar to that of SciPy + general purpose tools and algorithms. IMO general stuff like geometry, strings, and file I/O are more in scope than implementation-specific like HDF5, PetSc, or Trilinos interfaces. Also, could down the road stdlib be a dependency to Futility for some common functionality? Let's discuss what we'd need to do for that to happen.\nWe'll have a monthly call this week, see: https://fortran-lang.discourse.group/t/fortran-monthly-call-july-2020/195/5. It'd be great if you and your colleagues can join.\nI also suggest adding Futility to the index of Fortran packages on the website: https://fortran-lang.org/packages/. Would you mind submitting a PR to https://github.com/fortran-lang/fortran-lang.org? See this doc on how to add a package to the registry."
                },
                {
                    "user": "certik",
                    "date": "2020-07-13 20:13:11+00:00",
                    "text": "I also added Futility to the long list of similar projects at #1."
                }
            ]
        },
        {
            "number": 217,
            "user": "vmagnin",
            "date": "2020-07-10 12:45:04+00:00",
            "title": "Very slow building of stdlib, and high memory usage",
            "text": "I have git cloned the repository in a Fedora 32 virtual machine.\nI have encountered two problems, one minor, one critical:\n\nThe README.md file told me to install fypp using $ pip install fypp but I obtained that error:\n\n...\n    copying build/lib/fypp.py -> /usr/local/lib/python3.8/site-packages\n    error: could not create '/usr/local/lib/python3.8/site-packages/fypp.py': Permission denied\n...\nIt was easily fixed by using sudo: $ sudo pip install fypp\n\nThen I typed: $ cmake -B build, then $ cmake --build build but the stdlib_experimental_stats_moment.f90 gives a lot of warnings (hundreds ?) and is freezing the build process:\n\n/home/osboxes/stdlib/build/src/stdlib_experimental_stats_moment.f90:47:12:\n\n   47 |         n = size(x, kind = int64)\n      |            1\nWarning: Possible change of value in conversion from INTEGER(8) to REAL(4) at (1) [-Wconversion]\n/home/osboxes/stdlib/build/src/stdlib_experimental_stats_moment.f90:24:12:\n\n   24 |         n = size(x, kind = int64)\n      |            1\nWarning: Possible change of value in conversion from INTEGER(8) to REAL(4) at (1) [-Wconversion]\nI have waited several minutes, but it is still frozen. The compiler is burning the CPU.\nThe gfortran version is:\n[osboxes@localhost stdlib]$ gfortran --version\nGNU Fortran (GCC) 10.1.1 20200507 (Red Hat 10.1.1-1)\nCopyright (C) 2020 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-07-10 13:21:20+00:00",
                    "text": "It was easily fixed by using sudo: $ sudo pip install fypp\n\nYou could also do\npip install --user fypp\n\nwhich does not require root access.\nI guess this should probably mentioned in the README.md\nThe submodule stdlib_experimental_stats_moment contains hundreds  (800?) functions (and also about the same numbers for other stats submodules). If make uses parallelization, this might take some times and RAM indeed.\nYou may want to limit the number of dimensions to a smaller number than 15 (e.g., 7), by adding the CMake -DCMAKE_MAXIMUM_RANK=7"
                },
                {
                    "user": "vmagnin",
                    "date": "2020-07-10 13:25:18+00:00",
                    "text": "The submodule stdlib_experimental_stats_moment contains hundreds (800?) functions (and also about the same numbers for other stats submodules). If make uses parallelization, this might take some times and RAM indeed.\nYou may want to limit the number of dimensions to a smaller number than 15 (e.g., 7), by adding the CMake -DCMAKE_MAXIMUM_RANK=7\n\nThanks for information.\nYes, the build finally succeeded, but it took a long time (probably more than 10 minutes).\nI have had the same experience with Kubuntu 20.04. Very long, and it used 75% of my 8 GB RAM.\nI think the README.md should give some information on this, because I really thought the build was frozen on the stdlib_experimental_stats_moment.f90 file...\nNote that my machine is not a big workstation, but not ridiculous too: a 4 cores Intel(R) Core(TM) i7-5500U CPU @ 2.40GHz"
                },
                {
                    "user": "vmagnin",
                    "date": "2020-07-10 13:31:56+00:00",
                    "text": "Concerning fypp, under Ubuntu I didn't need sudo:\n$ pip3 install fypp\nbut I needed adding its path to PATH:\n$ PATH=\"${PATH}:/home/mylogin/.local/bin\"\nbefore building."
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-10 02:23:32+00:00",
                    "text": "In my machine I couldn't compile the library since the SO killed the process due the high amount of memory needed at same point. There's something odd in the compilation process of stdlib_stats_moment.f90.\nEDIT: Yeah... 55,673 lines of generated code...\nEDIT2: Didn't noticed the DCMAKE_MAXIMUM_RANK option.\nf95: fatal error: Kill signal terminated program f951\ncompilation terminated.\nmake[2]: *** [src/CMakeFiles/fortran_stdlib.dir/build.make:290: src/CMakeFiles/fortran_stdlib.dir/stdlib_stats_moment.f90.o] Error 1\nmake[1]: *** [CMakeFiles/Makefile2:307: src/CMakeFiles/fortran_stdlib.dir/all] Error 2\nmake: *** [Makefile:160: all] Error 2"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-10 02:39:52+00:00",
                    "text": "@14NGiestas Try limiting the maximum rank of generated procedures. You can go as low as 4. For example, from stdlib directory:\nmkdir build\ncd build\ncmake .. -DCMAKE_MAXIMUM_RANK=4\n\nMy 2014 laptop can't build the default rank (15) either, but with -DCMAKE_MAXIMUM_RANK=4 it builds in just over a minute."
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-10 02:44:47+00:00",
                    "text": "Thank you @milancurcic. I think this option should be mentioned to warn future contributers with low end machines, in the readme."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-10 03:51:02+00:00",
                    "text": "I agree--we'll fix that."
                }
            ]
        },
        {
            "number": 216,
            "user": "wclodius2",
            "date": "2020-07-05 02:41:09+00:00",
            "title": "Suggested change in directory structure",
            "text": "I find the current directory/source file structure awkward. Rather than a src directory with lots of files with the term experimental in their names and module names, I suggest two directories: src with the validated source files, and experimental_src, with the source code under development. Only a few people should have commit privileges in the src directory, everyone in the experimental_src. None of the files/modules should have the term experimental in their names. That way when they have matured the developers can notify the src maintainers, and the maintainers can simply copy the files unmodified from experimental_src to src to commit. FWIW I suggest that the more mature src files be committed to src once they have been renamed and had their use statements modified to deal with the renaming.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-07-05 14:40:53+00:00",
                    "text": "Hi WIlliam, I don't find the structure awkward, but I find the \"experimental\" in file names and modules unnecessary. We discussed this some time ago but now I can't find the thread. I think there was majority agreement to go with the \"experimental\" naming scheme, and it wasn't a big deal for me. However, I don't know why it's needed.\nActually, I personally find your proposal awkward as well. My preferred solution is to:\n\nDrop the \"experimental\" from file and module names\nKeep the source file where they are\nStart tracking the semantic version, e.g. 0.x.x is always \"experimental\", 1.x.x becomes stable.\nBegin making tagged and versioned releases\n\nThe agreed upon Workflow remains the same."
                },
                {
                    "user": "certik",
                    "date": "2020-07-05 14:49:22+00:00",
                    "text": "Once we reach version 1.0.0, and if we drop the experimental namespace, then when we merge a PR, it immediately becomes part of stable, so we have to support it forever.\n\nWe need an experimental namespace, where we land all new features and then we graduate them into main.\n\nHow we manage the experimental namespace is for discussion, we can use a different scheme.\n\u2026\nOn Sun, Jul 5, 2020, at 8:41 AM, Milan Curcic wrote:\n\n\n Hi WIlliam, I don't find the structure awkward, but I find the\n \"experimental\" in file names and modules unnecessary. We discussed this\n some time ago but now I can't find the thread. I think there was\n majority agreement to go with the \"experimental\" naming scheme, and it\n wasn't a big deal for me. However, I don't know why it's needed.\n\n Actually, I personally find your proposal awkward as well. My preferred\n solution is to:\n\n  * Drop the \"experimental\" from file and module names\n  * Keep the source file where they are\n  * Start tracking the semantic version, e.g. 0.x.x is always\n \"experimental\", 1.x.x becomes stable.\n  * Begin making tagged and versioned releases\n The agreed upon Workflow\n <https://github.com/fortran-lang/stdlib/blob/master/WORKFLOW.md>\n remains the same.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#216 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWCUEJ6CORZGHIPLEJ3R2CGIBANCNFSM4OQVFNMA>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-05 17:12:08+00:00",
                    "text": "I think the experimental namespace is important. I also like having the word \"experimental\" in the name of the module. It reminds the user that changes might happen in the API and implementations of the procedures.\nHowever, having the word \"experimental\" in the name of the module might be an issue when we will reach the version 1.0.0 (for example, how will we add a new procedure (in the experimental namespace) to a module released in version 1.0.0?)."
                },
                {
                    "user": "certik",
                    "date": "2020-07-05 17:21:48+00:00",
                    "text": "You do it by having both stable io and experimental_io modules.\n\u2026\nOn Sun, Jul 5, 2020, at 11:12 AM, Jeremie Vandenplas wrote:\n\n\n I think the experimental namespace is important. I also like having the\n word \"experimental\" in the name of the module. It reminds the user that\n changes might happen in the API and implementations of the procedures.\n  However, having the word \"experimental\" in the name of the module\n might be an issue when we will reach the version 1.0.0 (for example,\n how will we add a new procedure (in the experimental namespace) to a\n module released in version 1.0.0?).\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#216 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWD6WDBTVKQKYA7NAYLR2CX7HANCNFSM4OQVFNMA>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-05 17:32:51+00:00",
                    "text": "You do it by having both stable io and experimental_io modules.\n\nI agree with that. However, if there are experimental and released procedures of a same topic, we could end up with something like:\nuse stdlib_stats, only: mean\nuse stdlib_experimental_stats, only: var\nThis situation could be awkward.\nFurthermore, if var calls mean, we will have something like:\nmodule stdlib_experimental_stats\n use stdlib_stats, only: mean\n...\nend module stdlib_experimental_stats\nNote that I prefer this situation (and again I believe we need an experimental namespace) over a situation where we would add \"experimental\" to the name of the procedures."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-05 18:02:49+00:00",
                    "text": "We need an experimental namespace, where we land all new features and then we graduate them into main.\n\nCouldn't this be done with feature branches? (and as far as I can tell, it's how it's most commonly done)\n\nthen when we merge a PR, it immediately becomes part of stable, so we have to support it forever.\n\nNo, only until 2.x.x. I don't think the version number or release mode should drive development, but the other way around.\nIs perhaps the experimental namespace intended to be used alongside stable (as Jeremie did in his example), and that's why you need it to be a separate namespace?\nIf we do maintain 2 namespaces side by side, I don't think any single module should exist in both at the same time. For example, once stats is moves to stable, it's immediately removed from experimental."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-05 18:35:31+00:00",
                    "text": "If we do maintain 2 namespaces side by side, I don't think any single module should exist in both at the same time. For example, once stats is moves to stable, it's immediately removed from experimental.\n\nHmmm... how would it be possible to add a new procedure in this situation? Feature branches would probably be more appropriate for such a situation than the current approach."
                },
                {
                    "user": "certik",
                    "date": "2020-07-05 19:06:19+00:00",
                    "text": "Once stats move to stable, they will get removed from experimental. Once a new function gets proposed to stats, it goes back to experimental. Furthermore, we should do it on a function by function basis.\n\nSome functions are stable, some are experimental.\n\nFeature branches will make it very hard for people to actually test the code, unless we'll do releases for each feature branch. Also maintaining all feature branches to ensure they still build as we update the build system in master is extra work.\n\nThe current approach is the easiest in terms of work, getting features to users while still ensuring that we do not \"standardize\" something that didn't get wide use beforehand.\n\u2026\nOn Sun, Jul 5, 2020, at 12:03 PM, Milan Curcic wrote:\n\n\n > We need an experimental namespace, where we land all new features and then we graduate them into main.\n\n Couldn't this be done with feature branches? (and as far as I can tell,\n it's how it's most commonly done)\n\n > then when we merge a PR, it immediately becomes part of stable, so we have to support it forever.\n\n No, only until 2.x.x. I don't think the version number or release mode\n should drive development, but the other way around.\n\n Is perhaps the experimental namespace intended to be used alongside\n stable (as Jeremie did in his example), and that's why you need it to\n be a separate namespace?\n\n If we do maintain 2 namespaces side by side, I don't think any single\n module should exist in both at the same time. For example, once stats\n is moves to stable, it's immediately removed from experimental.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#216 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWGMB3JQ3JLSK2X32RDR2C55JANCNFSM4OQVFNMA>."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-06 19:20:17+00:00",
                    "text": "I'm re-reading this thread and I think I'm starting to understand better what we're trying to do. But as I do, I have growing concerns / confusion about why it's done the way it is, especially with explicit namespacing of the modules with their version number.\nPlease, let's take a step back. Rather than stating how we're going to do something, let's set our requirements. I don't think we've done this in the past, but again, I can't find the thread so please correct me if I'm wrong. Once we agree on the requirements, we can discuss the simplest way to accomplish what we need.\nRequirements\nBased on this thread and what I think we need, these are our requirements: (for brevity, I'll refer to experimental as v0 and stable as v1)\n\nv0 and v1 coexist in the same codebase / repo. In other words, part of stdlib is v0, and some other part is v1.\nWe want to clearly communicate to the user which procedures are v0  and which are v1.\nThere are no overlapping procedures between v0 and v1. In other words, a procedure promoted to v1 is removed from v0.\nA module can exist in both v0 and v1, but it must not have overlapping procedures between the two.\nA procedure from v0 can depend on a procedure from v1 but not the other way around.\nA procedure can only go up in major version. For example, a procedure in v1 can't go back to v0, but it can go up to v2.\n\nQuestions:\n\nDo you agree with these requirements?\nAre there any that I missed?\n\nProposed solution\nGiven these requirements, can't we simply put a comment header in each procedure indicating which is experimental and which is stable? For example:\nmodule stdlib_stats\n  ...\ncontains\n  ...\n  function mean(x)\n    ! version 1.0.3 (stable)\n    ...\n  end function mean\n  \n  function var(x)\n    ! version 0.1.2 (experimental)\n    ...\n  end function var\n...\nOf course, the version is not only documented in the source comment, but also in the API docs by FORD. Then the users can clearly see what's in stable and what's in experimental.\nProblems (that I see) with the current approach\n\nOnce a procedure moves from experimental to stable, users need to change their code.\nMore than one user have expressed it seems or feels awkward\nIt works now because we have only experimental, but how will it work when we have stable+experimental (issue raised by Jeremie above, pretty awkward IMO)\n\nProblem with terminology\nI also think we should revisit the choice of \"experimental\" over some other words. @jvdp1  wrote:\n\nI also like having the word \"experimental\" in the name of the module. It reminds the user that changes might happen in the API and implementations of the procedures.\n\nTo me personally, \"experimental\" means \"crazy ideas we're trying out\". But we really want to communicate clearly and precisely that \"this API may or may not change in the future\". We know that an unstable API is less attractive to most users. Coupled with a strong word (experimental), we may be effectively discouraging users from trying it out, and having them just wait and watch the project from the side until something matures. But we can't mature without users.\nI'd like to propose a gentler word that we use to signal unstable API. My favorite is to simply use semantic versioning (0.x.x vs 1.x.x). But if that's not acceptable, perhaps we can use \"dev\" as in, API in development?\nI'm sorry to badger you with all this but I think it's important and I don't think we have asked enough many whys before making a decision."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-07-06 19:36:42+00:00",
                    "text": "Having explicit name changes in module names, and even file names, seems less maintainable long term than using branches of the repo.  Why not have a master branch with limited write permissions, a develop branch for everything experimental with more permissive permissions, and feature branches off the develop branch?\nSure features can only be worked on if they are independent of each other, but that might force a more logical order of development of the required functions/subs. Like having a quick select first before a median function for example, both of which could be feature branches during dev.\nWith a robust module naming convention, we could eliminate temporary file names, and simply have a \"maths\" module that persists throughout the branches.\nDoes it make sense to explicitly keep track of individual function versions? This seems like a lot of work!  Is this standard practice for other standard libraries?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-06 19:50:05+00:00",
                    "text": "@leonfoks I like that too.\n\nDoes it make sense to explicitly keep track of individual function versions? This seems like a lot of work! Is this standard practice for other standard libraries?\n\nI don't think it's a common practice. It's a consequence of requiring both stable and experimental procedures in the same codebase, and that they can't repeat in the two release tracks. (now as I write it out, I think this is our most problematic requirement). You wouldn't need to keep track of minor and bug-fix version numbers, but you need to keep track of the major one.\nIf instead the stable track was a subset of experimental track (I think a much more common development model), then it'd be much more practical to use git branches to manage the code."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-07-06 20:04:30+00:00",
                    "text": "I see about versioning.  It would help with reverting any functions if the need comes up.\nThe master could be the stable track, which by definition of the tree structure is a subset of the develop branch (which could also be called the experimental branch).  If any bugs are identified in a \"stable\" master function, we would still want to branch off develop, PR and merge with develop, and then release to master once a release is ready on develop."
                },
                {
                    "user": "certik",
                    "date": "2020-07-06 20:40:16+00:00",
                    "text": "The way we talked about stdlib in the past is that it is to become a de-facto unofficial extension of the Fortran Standard, so once we \"standardize\" something using https://github.com/fortran-lang/stdlib/blob/0cd354ae87a61dcbfee432657f3b1bc3bd0bb335/WORKFLOW.md, we do not change it and keep supporting it pretty much forever, just like the Fortran Standard is very strictly backwards compatible for decades. We can discuss this of course and not do things this way, but so far that has been my understanding.\nThis has really good advantages.\nFrom this it follows that there is v0 and v1, but there is never a v2 or any other version. Once a function is in, it's in. We can add things in a backwards compatible manner (such as more optional arguments), but if we want to change the API, we have to rename the function, or introduce a new module (Python does this all the time, such as the old optparse and a new  argparse modules).\nI personaly like experimental, just like the C++ experimental stdlib, but we can use other names for v0.\nv1 is called stable, again, we can discuss the name.\nYes, you need to change your code if you use something from experimental --- by removing the name \"experimental\" in most (but not all!) cases. When a function is v0, we can change the API a bit after we gain experience from actually using it, so users who depend on v0 functions have to be ready to change / update their code anyway. As such, having the word \"experimental\" in the name of the module reminds them of this. Once the word \"experimental\" is removed by graduating a function from v0 to v1, then we commit to never change the API, and thus user's code will forever continue to work. There is no v2 that would somehow break code.\nYour proposal of having semantic versioning on a function level I think is even more confusing than the experimental / stable naming of modules.\nDo you want to do a video call to discuss these issues? It might be faster to get on the same page."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-06 21:15:59+00:00",
                    "text": "I think that requirements 3 and 4 are just different ways of saying the same thing. I also think that what they are describing is a requirement for failure. There is nothing more experimental than removing functionality from a module. Nothing would piss off users more than having them use non-experimental code, and then having that usage break because procedures they depend on are removed from the module. I think v0 must maintain the API of v1, but the detailed implementation of that API may differ in v0 as v0 experiments with optimizations, more correct treatment of corner cases., or additions to the API.\n\nAs to naming I suggest alpha for modules whose API might change, and beta for a stable API, but whose implementation is not as well tested.\n\nNote that you haven\u2019t been consistent with the experimental, e.g., src has two submodules, f08estop.f90 and f18estop.f90 without experimental in their names.\n\u2026\n On Jul 6, 2020, at 1:20 PM, Milan Curcic ***@***.***> wrote:\n\n\n I'm re-reading this thread and I think I'm starting to understand better what we're trying to do. But as I do, I have growing concerns / confusion about why it's done the way it is, especially with explicit namespacing of the modules with their version number.\n\n Please, let's take a step back. Rather than stating how we're going to do something, let's set our requirements. I don't think we've done this in the past, but again, I can't find the thread so please correct me if I'm wrong. Once we agree on the requirements, we can discuss the simplest way to accomplish what we need.\n\n Requirements\n\n Based on this thread and what I think we need, these are our requirements (for brevity, I'll refer to experimental as v0 and stable as v1.\n\n v0 and v1 coexist in the same codebase / repo. In other words, part of stdlib is v0, and some other part is v1.\n We want to clearly communicate to the user which procedures are v0 and which are v1.\n There are no overlapping procedures between v0 and v1. In other words, a procedure promoted to v1 is removed from v0.\n A module can exist in both v0 and v1, but it must not have overlapping procedures between the two.\n A procedure from v0 can depend on a procedure from v1 but not the other way around.\n A procedure can only go up in major version. For example, a procedure in v1 can't go back to v0, but it can go up to v2.\n Questions:\n\n Do you agree with these requirements?\n Are there any that I missed?\n Proposed solution\n\n Given these requirements, can't we simple put a comment header in each procedure indicating which is experimental and which is stable? For example:\n\n module stdlib_stats\n   ...\n contains\n   ...\n   function mean(x)\n     ! version 1.0.3 (stable)\n     ...\n   end function mean\n\n   function var(x)\n     ! version 0.1.2 (experimental)\n     ...\n   end function var\n ...\n Of course, the version is not only documented in the source comment, but also in the API docs by FORD. Then the users can clearly see what's in stable and what's in experimental.\n\n Problems (that I see) with the current approach\n\n Once a procedure moves from experimental to stable, users need to change their code.\n More than one user have expressed it seems or feels awkward\n It works now because we have only experimental, but how will it work when we have stable+experimental (issue raised by Jeremie above, pretty awkward IMO)\n Problem with terminology\n\n I also think we should revisit the choice of \"experimental\" over some other words. @jvdp1 <https://github.com/jvdp1> wrote:\n\n I also like having the word \"experimental\" in the name of the module. It reminds the user that changes might happen in the API and implementations of the procedures.\n\n To me personally, \"experimental\" means \"crazy ideas we're trying out\". But we really want to communicate clearly and precisely that \"this API may or may not change in the future\". We know that an unstable API is less attractive to most users. Coupled with a strong word (experimental), we may be effectively discouraging users from trying it out, and having them just wait and watch the project from the side until something matures. But we can't mature without users.\n\n I'd like to propose a gentler word that we use to signal unstable API. My favorite is to simply use semantic versioning (0.x.x vs 1.x.x). But if that's not acceptable, perhaps we can use \"dev\" as in, API in development?\n\n I'm sorry to be annoy you with all this but I think it's important and I don't think we have asked enough many whys before making a decision.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub <#216 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDORWHDXYY224NRB7V3TR2IPX7ANCNFSM4OQVFNMA>."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-06 21:18:47+00:00",
                    "text": "@certik Okay, yes, I am not opposed to freezing the API at v1 (no v2) but I forgot about it in this thread. This probably only means that it will take much longer to stabilize a procedure. I don't know if this is a positive or a negative. There's definitely a positive in maintaining backward compatibility and we can ensure that by allowing only optional arguments to be added, as you said.\nI think a call would be helpful. I can't do this week and next week it's already time for a monthly call. So I suggest we dedicate 15 minutes to this issue, or have a separate call the week after (July 20-24)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-06 21:25:07+00:00",
                    "text": "I think that requirements 3 and 4 are just different ways of saying the same thing. I also think that what they are describing is a requirement for failure.\n\nNo, requirement 4 has a statement about module overlap. Indeed, the 2nd part of requirement 4 is an affirmation of requirement 3. I also don't like this solution, and think that we should have overlapping release tracks (stable a subset of experimental).\n\nNothing would piss off users more than having them use non-experimental code, and then having that usage break because procedures they depend on are removed from the module.\n\nI agree and this doesn't happen with the current requirements. What do you see that I don't see?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-06 21:26:34+00:00",
                    "text": "In yet another words, if a user is working with the experimental release, they have full access to stable. A user shouldn't have to work with two builds of the library in order to work with experimental features."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-06 22:13:53+00:00",
                    "text": "+1 to discuss this issue during the next call.  I am still a bit confused how we will add  new/experimental/v0 procedures in a v1 module."
                },
                {
                    "user": "certik",
                    "date": "2020-07-06 22:24:19+00:00",
                    "text": "@milancurcic :\n\nA user shouldn't have to work with two builds of the library in order to work with experimental features.\n\nExactly. Which I think excludes feature branches, as those would not be present in the build of the latest master.\n@jvdp1 :\n\nI am still a bit confused how we will add new/experimental/v0 procedures in a v1 module.\n\nAn experimental/v0 module is stdlib_experimental_io and a stable/v1 module is stdlib_io. Say the function open graduates from experimental to stable: then it gets moved from stdlib_experimental_io.f90 to stdlib_io.f90. Let's say we propose a new function loadtxt: then it first goes into experimental, so it will go into stdlib_experimental_io.f90. The module stdlib_experimental_io can use stdlib_io, but not the other way round. Users will use stdlib_io once we have it, and that's stable. If they want to use an experimental feature such as loadtxt, then they will import it from stdlib_experimental_io. Once loadtxt graduates to stable, then we'll move it to stdlib_io."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-06 22:35:41+00:00",
                    "text": "Iread too fast an misread."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-06 22:40:35+00:00",
                    "text": "A user shouldn't have to work with two builds of the library in order to work with experimental features.\n\n\n\nExactly. Which I think excludes feature branches, as those would not be present in the build of the latest master.\n\nIf we organize this as stable \u2286 experimental \u2286 feature as @leonfoks suggested, then we can do it."
                },
                {
                    "user": "certik",
                    "date": "2020-07-06 22:44:44+00:00",
                    "text": "If we organize this as stable \u2286 experimental \u2286 feature\n\nSo we would release the \"feature\" branch, that way users can try things out, and perhaps compiler vendors can only ship the \"stable\" one? Yes, that would be fine me, but still more work than having everything in one branch, just speaking from my experience doing this in the past."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-06 23:18:57+00:00",
                    "text": "Okay, I didn't consider that we would literally tag and release every feature branch, beyond what git checkout feature-branch-name gives you.\nIf you intend to \"ship\" all experimental features to end-users as a tarball, then all code in one branch is easier. I am not convinced we really need this, not until we actually hear from users asking for it."
                },
                {
                    "user": "certik",
                    "date": "2020-07-07 02:02:00+00:00",
                    "text": "Let's discuss at our monthly call, and if more time is needed to discuss this, let's do a dedicated call just for stdlib."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-07-07 02:40:17+00:00",
                    "text": "If there\u2019s a dedicated stdlib call I would get on it too if that\u2019s okay???"
                },
                {
                    "user": "certik",
                    "date": "2020-07-07 02:57:59+00:00",
                    "text": "@leonfoks please join us. We will discuss this at our regular Fortran monthly call. If you sign up at our mailinglist or follow our Discourse, the call will be announced there. Links to both are at https://fortran-lang.org/"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-07 06:18:09+00:00",
                    "text": "An experimental/v0 module is stdlib_experimental_io and a stable/v1 module is stdlib_io. Say the function open graduates from experimental to stable: then it gets moved from stdlib_experimental_io.f90 to stdlib_io.f90. Let's say we propose a new function loadtxt: then it first goes into experimental, so it will go into stdlib_experimental_io.f90. The module stdlib_experimental_io can use stdlib_io, but not the other way round. Users will use stdlib_io once we have it, and that's stable. If they want to use an experimental feature such as loadtxt, then they will import it from stdlib_experimental_io. Once loadtxt graduates to stable, then we'll move it to stdlib_io.\n\nIt is the way I understood it (and as commented it here), but I have been confused with this thread.\nThis approach has 2 advantages for me: 1) the end-user can use all available procedures, and 2) he is aware of the risks when using an experimental procedure (including changing his/her code).\n\nIf you intend to \"ship\" all experimental features to end-users as a tarball, then all code in one branch is easier. I am not convinced we really need this, not until we actually hear from users asking for it.\n\nIf the vendors/we want to ship onlty the stable version, they/we could just ignore the experimental modules (since stable modules don't depend on experimental modules), and provide stable tarballs."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-07 14:34:21+00:00",
                    "text": "@wclodius2 it'd be great if you can join the call too. We'll set up a schedule this week."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-14 02:58:11+00:00",
                    "text": "I suspect that it is too late for this particular call, but how do you go about participating in a call?\n\u2026\n On Jul 7, 2020, at 8:34 AM, Milan Curcic ***@***.***> wrote:\n\n\n @wclodius2 <https://github.com/wclodius2> it'd be great if you can join the call too. We'll set up a schedule this week.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub <#216 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOTTXGCSTME2KP3GSTDR2MW73ANCNFSM4OQVFNMA>."
                },
                {
                    "user": "certik",
                    "date": "2020-07-14 03:11:02+00:00",
                    "text": "It's not late: the call happens on Thursday, here are the details:\n\nhttps://fortran-lang.discourse.group/t/fortran-monthly-call-july-2020/195/5\n\nDo you know how to use Zoom? If not, I can help.\n\u2026\nOn Mon, Jul 13, 2020, at 8:58 PM, William B. Clodius wrote:\n\n\n  I suspect that it is too late for this particular call, but how do you\n go about participating in a call?\n\n  > On Jul 7, 2020, at 8:34 AM, Milan Curcic ***@***.***>\n wrote:\n  >\n  >\n  > @wclodius2 <https://github.com/wclodius2> it'd be great if you can\n join the call too. We'll set up a schedule this week.\n  >\n  > \u2014\n  > You are receiving this because you were mentioned.\n  > Reply to this email directly, view it on GitHub\n <#216 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOTTXGCSTME2KP3GSTDR2MW73ANCNFSM4OQVFNMA>.\n  >\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#216 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWFXLT63HGTQPCWYABLR3PCVBANCNFSM4OQVFNMA>."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-17 17:55:25+00:00",
                    "text": "@wclodius2 We discussed this yesterday on the call and came to a tentative agreement. It can still change as we go but this is what we currently agreed to:\n\nAdopt semantic versioning for stdlib (major.minor.bugfix). We'd start at 0.1.0.\nBoth experimental (API may or may not change) and stable (API won't change) procedures reside together in modules\nExperimental vs. stable status of a procedure is documented in the code and documentation, not in the module name. So the first practical step would be to have a PR that removes experimental from module names and marks each function as such in docstrings.\nWe continue working with PR's directly into master branch.\n\nThis largely follows the Rust development model, I put some links here.\nWhat I think is still unclear is when does stdlib as a whole move in major version from 0.x.x to 1.x.x. We can look how others (like Rust) did this and decide what makes most sense for us. Perhaps when some large fraction of procedures are stabilized?\nWhat do you think? Does it seem like a good development model to you?"
                },
                {
                    "user": "certik",
                    "date": "2020-07-17 19:22:52+00:00",
                    "text": "Even when stdlib moves to 1.0, it will still have some functions that are unstable / experimental, just like Rust's stdlib.\n\u2026\nOn Fri, Jul 17, 2020, at 11:55 AM, Milan Curcic wrote:\n\n\n @wclodius2 <https://github.com/wclodius2> We discussed this yesterday\n on the call and came to a tentative agreement. It can still change as\n we go but this is what we currently agreed to:\n\n  * Adopt semantic versioning for stdlib (major.minor.bugfix). We'd\n start at 0.1.0.\n  * Both experimental (API may or may not change) and stable (API won't\n change) procedures reside together in modules\n  * Experimental vs. stable status of a procedure is documented in the\n code and documentation, not in the module name. So the first practical\n step would be to have a PR that removes `experimental` from module\n names and marks each function as such in docstrings.\n  * We continue working with PR's directly into master branch.\n This largely follows the Rust development model, I put some links here\n <https://fortran-lang.discourse.group/t/stabilization-of-rust-language-and-stdlib-features/212>.\n\n What I think is still unclear is when does stdlib as a whole move in\n major version from 0.x.x to 1.x.x. We can look how others (like Rust)\n did this and decide what makes most sense for us. Perhaps when some\n large fraction of procedures are stabilized?\n\n What do you think? Does it seem like a good development model to you?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#216 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWHH3DNDLHVIZYXZGLTR4CGB3ANCNFSM4OQVFNMA>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-21 20:17:05+00:00",
                    "text": "Adopt semantic versioning for stdlib (major.minor.bugfix). We'd start at 0.1.0.\nBoth experimental (API may or may not change) and stable (API won't change) procedures reside together in modules\nExperimental vs. stable status of a procedure is documented in the code and documentation, not in the module name. So the first practical step would be to have a PR that removes experimental from module names and marks each function as such in docstrings.\nWe continue working with PR's directly into master branch.\n\nThis largely follows the Rust development model, I put some links here.\nWhat I think is still unclear is when does stdlib as a whole move in major version from 0.x.x to 1.x.x. We can look how others (like Rust) did this and decide what makes most sense for us. Perhaps when some large fraction of procedures are stabilized?\n\nIt is indeed unclear when sdtlib will move in major version 1.0.0. However, I think this is conditional on users' feedback. And if we want that users start to use stdlib, I think we should first apply the following discussed change:\n\n\nExperimental vs. stable status of a procedure is documented in the code and documentation, not in the module name. So the first practical step would be to have a PR that removes experimental from module names and marks each function as such in docstrings.\n\n\nI am currently trying to finish the implementation of a fonction for stdlib skewness (similar API to mean, corr,...) for stdlib_experimental_stats. But instead I could first submit this PR to remove experimental and mark each procedure as experimantal in the specs, fi the community agrees on these changes."
                },
                {
                    "user": "certik",
                    "date": "2020-07-21 20:21:40+00:00",
                    "text": "@jvdp1 that's fine with me. (Just don't lump unrelated changes into the same PR, so if you have to move other functions from experimental, please do it in a dedicated PR.)\nRegarding stdlib moving to 1.0.0, I think that's quite simple: we move it when it is ready and the community agrees it's time. Right now that is distant future, so I don't think we have to worry about it."
                }
            ]
        },
        {
            "number": 215,
            "user": "MuellerSeb",
            "date": "2020-07-02 15:46:37+00:00",
            "title": "Template Project depending on stdlib",
            "text": "My question from FortranCon:\nIt would be nice to provide a template for a Fortran package/project that depends on the stdlib, so that it is low-threshold for new users to adopt to your implementations. This could also automatically integrate fpm.\nWhat do you think? Or is there already such a template?",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-07-02 19:35:31+00:00",
                    "text": "@MuellerSeb thanks for the idea. I think we'll provide an example with fpm. We first have to get fpm working with stdlib. Then to use it would be just adding stdlib to your dependencies."
                }
            ]
        },
        {
            "number": 214,
            "user": "ivan-pi",
            "date": "2020-06-23 16:46:09+00:00",
            "title": "Cube root of a real number",
            "text": "Related to #150 (non-special mathematical functions)\ncbrt - Cube root of a real number\nDescription\nReturns the cube root of the real number (x), that is a number (y) such that (y^3 = x).\nSyntax\ny = cbrt(x)\nArguments\nx: A real number (x).\nReturn value\nReturns the value (\\sqrt[3]{x}), the result is of the type real and has the same kind as x.\nExample\nprogram demo_cbrt\nuse stdlib_experimental_math, only: cbrt\nprint *, cbrt(27.), cbrt(-27.)  ! outputs 3, -3\nend program\n\nAs seen from the discussion on Discourse this function is semantically more accurate than writing  x**(1./3.) which only works for positive real numbers and returns NaN otherwise.\nA possible extension would be to allow complex arguments, the return value would then be an array with 3 elements for the 3 cube roots (if the number is real and non-zero, there is one real root and a conjugate pair of complex roots; a complex non-zero value will have three distinct cube roots)",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2020-06-23 16:50:09+00:00",
                    "text": "I've already got an implementation ready based upon the NSWC Mathematical Library version and using Fypp for templating of different real kinds."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-23 17:15:41+00:00",
                    "text": "Thanks.\n\nA possible extension would be to allow complex arguments, the return value would then be an array with 3 elements for the 3 cube roots (if the number is real and non-zero, there is one real root and a conjugate pair of complex roots; a complex non-zero value will have three distinct cube roots)\n\nI don't use usually complex numbers, neither cube roots. However, to be in agreement with the intrinsic function sqrt, I think it should accept complex arguments. In this case, is a function still possible, or should it be a subroutine?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-23 19:46:00+00:00",
                    "text": "Personally, I also don't have a foreseeable usage for complex cube roots.\nIt should however, be possible to have the the same interface for real and complex cube roots:\ninterface cbrt\nfunction cbrt_sp(x) result(cbrt)\n  complex(sp), intent(in) :: x\n  complex(sp) :: cbrt\nend function\nfunction cbrt_complex_sp(x) result(cbrt)\n  complex(sp), intent(in) :: x\n  complex(sp) :: cbrt(3)\nend function\nend interface\nA better option might be to follow the IMSL library CBRT(X) function:\n\nFor complex arguments, the branch cut for the cube root is taken along the negative real axis. The argument of the result, therefore, is greater than \u2013\u03c0/3 and less than or equal to \u03c0/3. The other two roots are obtained by rotating the principal root by 3 \u03c0/3 and \u03c0/3.\n\nLahey/Fujitsu Fortran also provides a CBRT function, which returns a single number for real or complex variables.\nIn a thread on the Intel Fortran Forum, @sblionel shows the compiler does in fact call a special cube root routine for a**(1./3.), but this only works for a positive argument. This makes me wonder whether a simple implementation for real numbers could be simply:\nfunction cbrt_v1(x) result(cbrt)\n  real, intent(in) :: x\n  real :: cbrt\n  if (x >= 0.0) then\n    cbrt = x**(1.0/3.0)\n  else\n    cbrt = -((-x)**(1.0/3.0))\n  end if\nend function\nDigging back further, the behavior of the a**(1./3.) has changed on occasion in the Intel Fortran compiler:\n\nChange in floating point rounding between Versions 11 and 12 of Fortran compiler\nWhy does Version 19 change how cube root is calculated?\n\nAlso the gfortran mailing list contains an interesting discussion on cbrt:\n\nGfortran and using C99 cbrt for X ** (1./3.)\n\n@certik Do you have an opinion on this one? My understanding is that the goal of providing a CBRT function is to be \"mathematically\" correct, in the sense that it can also accept negative arguments. The problem however is can the behavior of CBRT differ from X**(1./3.) in terms of representation/accuracy/speed."
                },
                {
                    "user": "certik",
                    "date": "2020-06-24 05:03:54+00:00",
                    "text": "See my comment on precisely this issue (and the subsequent discussion there): symengine/symengine#1644 (comment)\nWe should do whatever is the most consistent and document it well. It could be that we need two cbrt functions for the two most common conventions."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-06-24 17:14:12+00:00",
                    "text": "How about an optional argument to decide which branch you want?\nf = cbrt(z) always has 0 <= arg(f) < 2*pi/3\nf = cbrt(z, k) has 2*pi*k/3 <= arg(f) < 2*pi*(k+1)/3"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-06-24 18:38:33+00:00",
                    "text": "As for negative real arguments, I am inclined to have cbrt(-x) == -cbrt(x) (for positive x).\nUpshot: this is what we learn in school before getting introduced to complex numbers. It's what most people would expect when working with reals only.\nDrawback: introduces some \"gotcha\" potential for people who use mix reals and complex numbers without reading the docs."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-24 19:00:47+00:00",
                    "text": "How about an optional argument to decide which branch you want?\nf = cbrt(z) always has 0 <= arg(f) < 2*pi/3\nf = cbrt(z, k) has 2*pi*k/3 <= arg(f) < 2*pi*(k+1)/3\n\nWith an elemental procedure, you could pass an array of k's if you wanted different branches. Not sure, if it is useful in practice."
                },
                {
                    "user": "certik",
                    "date": "2020-06-24 22:35:19+00:00",
                    "text": "The c++ cbrt has the property of cbrt(-x) == -cbrt(x) for positive x, which makes it not compatible with complex functions. It is equivalent to the Surd function in Mathematica, and specifically to the CubeRoot function. So one option is to simply have cbrt to do the same thing, returning a real number.\nAnd if you want the complex number, you can just use **, as in cmplx(x, dp)**(1._dp/3) where x is some real (or complex) variable."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-06-24 23:59:34+00:00",
                    "text": "Or better yet, cast it to complex first. I have in mind:\ncbrt(-8.) == -2.\ncbrt(cmplx(-8.)) == (1., sqrt(3.))\ncbrt(cmplx(-8.), k=1) == (-2., 0.)"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-25 05:32:47+00:00",
                    "text": "The c++ cbrt has the property of cbrt(-x) == -cbrt(x) for positive x, which makes it not compatible with complex functions. It is equivalent to the Surd function in Mathematica, and specifically to the CubeRoot function. So one option is to simply have cbrt to do the same thing, returning a real number.\nAnd if you want the complex number, you can just use **, as in cmplx(x, dp)**(1._dp/3) where x is some real (or complex) variable.\n\nThis is also the behavior of Octave cbrt"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-26 13:13:27+00:00",
                    "text": "MATLAB on the other hand does not provide a cbrt function (see How do you enter the command for a cube root?). It does however have the following behavior:\n>> (8)^(1/3)\n\nans =\n\n     2\n\n>> (-8)^(1/3)\n\nans =\n\n   1.0000 + 1.7321i\n\n>> nthroot(-8,3)\n\nans =\n\n    -2\n\n>> help nthroot\n nthroot Real n-th root of real numbers.\n \n    nthroot(X, N) returns the real Nth root of the elements of X.\n    Both X and N must be real, and if X is negative, N must be an odd integer.\n \n    Class support for inputs X, N:\n       float: double, single"
                },
                {
                    "user": "certik",
                    "date": "2020-06-26 15:33:11+00:00",
                    "text": "It seems Matlab's ^ operator behaves like Fortran's ** operator for complex numbers. The nthroot seems to be like like Mathematica's Surd."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-28 12:15:43+00:00",
                    "text": "Let's keep the ball rolling. The way I see it now, there are essentially two choices:\n\nSimple version (no branch argument) - Code example\nWith optional branch variable - Code example\n\nComments:\n\nFor a complex root of a real variable the cbrt is more compact than using the power operator\n\ny = cbrt(cmplx(x))\ny = cmplx(x)**(1._sp/3)\n\ny = cbrt(z)\ny = z**(1._sp/3)\n\nIf we go with the 1st option the user can always retrieve the other two complex roots by rotating the principal root by 3\u03c0/3 and \u03c0/3. This can be documented with an example:\n\nr = cmplx(-1.,sqrt(3.))/2.\nj = cmplx(0.,1.)\n\nz = -8 + 0*j\n\ny1 = cbrt(z)       !  1.0000 + 1.7321i \ny2 = y1 * r        ! -2.0000 - 0.0000i\ny3 = y1 * conjg(r) !  1.0000 - 1.7321i \n\nWith the second option,  users who know exactly what they want, can easily recover a complex root from a either real or complex number, e.g.\n\n  write(*,'(A)')  \"real to real\"\n  \n  write(*,fmtr) \"cbrt( 8._sp) = \", cbrt(8._sp)\n  write(*,fmtr) \"cbrt(-8._sp) = \", cbrt(-8._sp)\n\n  write(*,'(/,A)')  \"real to complex\"\n\n  write(*,fmtc) \"cbrt(8._sp,k=0) = \", cbrt(8._sp,k=0)\n  write(*,fmtc) \"cbrt(8._sp,k=1) = \", cbrt(8._sp,k=1)\n  write(*,fmtc) \"cbrt(8._sp,k=2) = \", cbrt(8._sp,k=2)\n\n  write(*,'(/,A)')  \"complex to complex\"\n\n  z = cmplx(-8._sp)\n  write(*,fmtc) \"z = \", z\n  write(*,fmtc) \"cbrt(z) = \", cbrt(z)\n  write(*,fmtc) \"cbrt(z,k=0) = \",cbrt(z,k=0)\n  write(*,fmtc) \"cbrt(z,k=1) = \",cbrt(z,k=1)\n  write(*,fmtc) \"cbrt(z,k=2) = \",cbrt(z,k=2)\n  write(*,fmtc) \"cbrt(z,k=3) = \",cbrt(z,k=3)\nproduces the following output:\nreal to real\ncbrt( 8._sp) =  2.0000\ncbrt(-8._sp) = -2.0000\n\nreal to complex\ncbrt(8._sp,k=0) =  2.0000+0.0000j\ncbrt(8._sp,k=1) = -1.0000+1.7321j\ncbrt(8._sp,k=2) = -1.0000-1.7321j\n\ncomplex to complex\nz = -8.0000+0.0000j\ncbrt(z) =  1.0000+1.7321j\ncbrt(z,k=0) =  1.0000+1.7321j\ncbrt(z,k=1) = -2.0000-0.0000j\ncbrt(z,k=2) =  1.0000-1.7321j\ncbrt(z,k=3) =  1.0000+1.7321j"
                },
                {
                    "user": "vmagnin",
                    "date": "2020-06-28 12:44:31+00:00",
                    "text": "There is acbrt() function in Java, described here:\nhttps://docs.oracle.com/javase/1.5.0/docs/api/java/lang/Math.html#cbrt(double)\n\nReturns the cube root of a double value. For positive finite x, cbrt(-x) == -cbrt(x); that is, the cube root of a negative value is the negative of the cube root of that value's magnitude. Special cases:\nIf the argument is NaN, then the result is NaN.\nIf the argument is infinite, then the result is an infinity with the same sign as the argument.\nIf the argument is zero, then the result is a zero with the same sign as the argument. \n\nThe computed result must be within 1 ulp of the exact result."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-28 12:53:16+00:00",
                    "text": "Thanks @vmagnin, we should also have tests for the special cases."
                },
                {
                    "user": "vmagnin",
                    "date": "2020-06-28 19:18:19+00:00",
                    "text": "@ivan-pi\nA simple implementation could be something like:\nmodule functions\n    use iso_fortran_env, only: dp=>real64\n    implicit none\n\n    contains\n\n    pure real(dp) function cbrt(x)\n        real(dp), intent(in) :: x\n        cbrt = sign(abs(x)**(1.0_dp / 3.0_dp), x)\n    end function\nend module functions\n\nprogram main\n    use functions\n    real(dp) :: x\n\n    x = 27.0_dp\n    print *, x, cbrt(x), cbrt(x)*cbrt(x)*cbrt(x)\n\n    x = -27.0_dp\n    print *, x, cbrt(x), cbrt(x)*cbrt(x)*cbrt(x)\n\n    x = -0.0_dp\n    print *, x, cbrt(x), cbrt(x)*cbrt(x)*cbrt(x)\n    x = 0.0_dp\n    print *, x, cbrt(x), cbrt(x)*cbrt(x)*cbrt(x)\n\n    ! Infinity:\n    x = 1.0_dp/x\n    print *, x, cbrt(x), cbrt(x)*cbrt(x)*cbrt(x)\n\n    ! NaN:\n    x = sqrt(-x)\n    print *, x, cbrt(x), cbrt(x)*cbrt(x)*cbrt(x)\n\n    ! -Infinity:\n    x = 0.0_dp\n    x = -1.0_dp/x\n    print *, x, cbrt(x), cbrt(x)*cbrt(x)*cbrt(x)\nend program main\nwhich yields the following results in agreement with the Java specifications:\n$ gfortran essai_cbrt.f90 && ./a.out\n   27.000000000000000        3.0000000000000000        27.000000000000000     \n  -27.000000000000000       -3.0000000000000000       -27.000000000000000     \n  -0.0000000000000000       -0.0000000000000000       -0.0000000000000000     \n   0.0000000000000000        0.0000000000000000        0.0000000000000000     \n                  Infinity                  Infinity                  Infinity\n                       NaN                       NaN                       NaN\n                 -Infinity                 -Infinity                 -Infinity\nBut I don't know if it would be the fastest implementation. We call three functions in each case: SIGN(), ABS(), **\nTreating each case, from the most probables to the least, with an if...else if... structure would perhaps be faster."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-28 21:06:46+00:00",
                    "text": "That looks good. My naive implementation would be:\n  pure real function cbrt(x)\n    real, intent(in) :: x\n    if (x >= 0.) then\n      cbrt = x**(1./3)\n    else\n      cbrt = -((-x)**(1./3))\n    end if\n  end function\nUnfortunately, for the value zero it does not preserve the sign:\n   27.0000000       3.00000000       27.0000000    \n  -27.0000000      -3.00000000      -27.0000000    \n  -0.00000000       0.00000000       0.00000000    \n   0.00000000       0.00000000       0.00000000    \n         Infinity         Infinity         Infinity\n              NaN              NaN              NaN\n        -Infinity        -Infinity        -Infinity\n\nConcerning speed, I've prepared a small benchmark and the difference is not that large. I've used Fypp to create some simple benchmarking macros:\n#:def NTIC(n=1000)\n  #:global BENCHMARK_NREPS\n  #:set BENCHMARK_NREPS = n\n  block\n    use, intrinsic :: iso_fortran_env, only: int64, dp => real64\n    integer(int64) :: benchmark_tic, benchmark_toc, benchmark_count_rate\n    integer(int64) :: benchmark_i\n    real(dp) :: benchmark_elapsed\n    call system_clock(benchmark_tic,benchmark_count_rate)\n    do benchmark_i = 1, ${BENCHMARK_NREPS}$\n#:enddef\n\n#:def NTOC(*args)\n    #:global BENCHMARK_NREPS\n    end do\n    call system_clock(benchmark_toc)\n    benchmark_elapsed = real(benchmark_toc - benchmark_tic)/real(benchmark_count_rate)\n    benchmark_elapsed = benchmark_elapsed/${BENCHMARK_NREPS}$\n  #:if len(args) > 0\n    ${args[0]}$ = benchmark_elapsed\n  #:else\n    write(*,*) \"Average time is \",benchmark_elapsed,\" seconds.\"\n  #:endif\n  end block\n  #:del BENCHMARK_NREPS\n#:enddef\n\nmodule cbrt_mod\n\n  implicit none\n  public\n\ncontains\n\n  elemental real function cbrt1(x)\n    real, intent(in) :: x\n    if (x >= 0.) then\n      cbrt1 = x**(1./3)\n    else\n      cbrt1 = -((-x)**(1./3))\n    end if\n  end function\n\n  elemental real function cbrt2(x)\n    real, intent(in) :: x\n    cbrt2 = sign(abs(x)**(1.0 / 3.0), x)\n  end function\n\nend module\n\nprogram main\n\n  use cbrt_mod\n  implicit none\n  integer, parameter :: n = 1000000\n  real :: x(n), y(n), z(n)\n\n  call random_number(x)\n\n  @:NTIC(1000)\n  y = cbrt1(x)\n  @:NTOC()\n\n  @:NTIC(1000)\n  z = cbrt2(x)\n  @:NTOC()\n\n  ! We need to print something, otherwise the compiler\n  ! seems to skip the calculation completely...\n  print *, maxval(abs(y-z)), sum(abs(y-z))\n\nend program\nOutput:\n$ fypp cbrt_benchmark.fypp > cbrt_benchmark.f90\n$ gfortran -Wall -O3 ./cbrt_benchmark.f90 -o cbrt_benchmark\n$ ./cbrt_benchmark \n Average time is    1.4338764190673828E-002  seconds.\n Average time is    1.6593759536743163E-002  seconds.\n   0.00000000       0.00000000"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-28 21:14:24+00:00",
                    "text": "With the Intel Fortran compiler there is practically no difference:\n$ fypp cbrt_benchmark.fypp > cbrt_benchmark.f90\n$ ifort -O3 ./cbrt_benchmark.f90 -o cbrt_benchmark\n$ ./cbrt_benchmark \n Average time is   3.396259069442749E-003  seconds.\n Average time is   3.438067913055420E-003  seconds.\n  0.0000000E+00  0.0000000E+00\n\nEdit: I realized I was only sampling positive values... If I add an extra line with x = 54*x - 27 after the call to random_number to make the x values span the range [-27,27), I get slightly different timings:\n$ fypp cbrt_benchmark.fypp > cbrt_benchmark.f90\n$ gfortran -O3 ./cbrt_benchmark.f90 -o cbrt_benchmark\n$ time ./cbrt_benchmark \n Average time is    1.7529647827148439E-002  seconds.\n Average time is    1.6589702606201170E-002  seconds.\n   0.00000000       0.00000000    \n\nreal\t0m34,137s\nuser\t0m34,131s\nsys\t0m0,004s\n$ ifort -O3 ./cbrt_benchmark.f90 -o cbrt_benchmark\n$ time ./cbrt_benchmark \n Average time is   1.533928298950195E-002  seconds.\n Average time is   3.471867084503174E-003  seconds.\n  0.0000000E+00  0.0000000E+00\n\nreal\t0m18,838s\nuser\t0m18,821s\nsys\t0m0,008s\n\nYour sign/abs/** version looks like the clear winner now. :)"
                },
                {
                    "user": "vmagnin",
                    "date": "2020-06-29 07:11:09+00:00",
                    "text": "Very counter-intuitive... We don't know what do exactly the compilers. With -O3 there is probably inlining in cbrt2().\nConsidering only ifort, my cbrt2() does not change with negative values. Normal.\nBut why your cbrt1() is x5 longer !? There is a jump to the negative case, and two sign changes, but 5x times longer seems unreasonable... The gfortran behavior seems therefore OK, but ifort ???\nIt is also amazing that in most cases ifort gives a 5x faster code than gfortran for such simple calculations. Does ifort forces some kind of parallelism inside the processor ? (SSE vectorisation ?)\nPerhaps it could be interesting to add -mtune=native -march=native to the gfortran command."
                },
                {
                    "user": "vmagnin",
                    "date": "2020-06-29 08:54:49+00:00",
                    "text": "Precision loss with very big and small values:\n    x = 1d300\n    print *, x, cbrt(x), cbrt(x)*cbrt(x)*cbrt(x)\n\n    x = 1d-300\n    print *, x, cbrt(x), cbrt(x)*cbrt(x)*cbrt(x)\n   1.0000000000000001E+300   9.9999999999998719E+099   9.9999999999996154E+299\n   1.0000000000000000E-300   1.0000000000000128E-100   1.0000000000000385E-300"
                },
                {
                    "user": "LKedward",
                    "date": "2020-06-29 09:02:44+00:00",
                    "text": "Which version of ifort are you running @ivan-pi?\nPlaying around on godbolt.org (https://godbolt.org/z/ZLaUcW) shows ifort vectorizing over 4 elements by calling a cbrtf4 function (presumably from the Intel library) for both implementations. For some reason the branching implementation appears to call cbrtf4 twice?\ngfortran (https://godbolt.org/z/PYTBfE) calls powf and compiling with -fopt-info-vec-missed shows that neither implementation is vectorized.\nApart from any clever compiler optimisations, I would expect the sign(abs(x)) implementation to be faster since it does not require a conditional. Branch prediction isn't possible for this random test case, so there will be many branch mispredictions which each stall the CPU pipeline. This may be hurting the vectorized version more in ifort than the unvectorized version in gfortran maybe?"
                },
                {
                    "user": "vmagnin",
                    "date": "2020-06-29 10:13:08+00:00",
                    "text": "@LKedward\nthank you, very interesting!\nYes, if the sign is always changing ifort can't use vectors with the branching version...\nIt's amazing to see what such a simple example can reveal !\nhttps://arcb.csc.ncsu.edu/~mueller/cluster/ps3/SDK3.0/docs/accessibility/simdmath/ppu_spu/cbrtf4.html\n\nThe cbrtf4 function computes the real cube root of each element in the input vectors.\n\nhttps://www.ibm.com/support/knowledgecenter/en/SSGH4D_15.1.2/com.ibm.xlf151.aix.doc/proguide/mass_simd.html"
                },
                {
                    "user": "vmagnin",
                    "date": "2020-06-29 11:36:13+00:00",
                    "text": "It reveals also the limits of benchmarking: one implementation could be better with some compilers, some CPU but not with other (Intel, AMD, ARM...). And worse, one implementation could be better with deterministic algorithm, and another implementation with Monte Carlo algorithms... Those branch prediction mechanisms not only introduce security problems but also make benchmarking very delicate...."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-29 11:54:53+00:00",
                    "text": "Nice findings!\nIndeed, apart from different processors and compiler settings there are also more subtle issues with benchmarking related to noise and measurement statistics and how the process interacts with the operating system. The README of the BenchmarkingTools.jl Julia package contains some information.\nAs @certik has said in a few earlier issues, but I've come to understand now, it is important we agree on an intuitive API and provide a reference implementation with the correct behavior. Optimized implementations for different platforms will hopefully come in later as more users or even hardware vendors get involved."
                },
                {
                    "user": "LKedward",
                    "date": "2020-06-29 13:24:09+00:00",
                    "text": "Yes, if the sign is always changing ifort can't use vectors with the branching version\n\nInterestingly, it looks like the ifort version is actually able to vectorise the branching version, using a mask (cbrtf4_mask); but this means calling cbrtf4 twice with branching logic which together probably causes the slow down.\n\nIt reveals also the limits of benchmarking: one implementation could be better with some compilers\n\nYep, this is a good point.\n\nAs @certik has said in a few earlier issues, but I've come to understand now, it is important we agree on an intuitive API and provide a reference implementation with the correct behavior. Optimized implementations for different platforms will hopefully come in later as more users or even hardware vendors get involved.\n\nI agree, optimization isn't the focus for stdlib currently, but as @vmagnin has pointed out different numerical implementations may also have different edge-case behaviours such as loss of precision which are worth being aware of."
                },
                {
                    "user": "vmagnin",
                    "date": "2020-06-29 13:52:39+00:00",
                    "text": "different numerical implementations may also have different edge-case behaviours such as loss of precision which are worth being aware of.\n\nIt implies that if a \"naive\" implementation is used at first, its limits should be clearly stated in the source code and documentation.\nPrecision problems caused the Patriot missile bug: http://www-users.math.umn.edu/~arnold/disasters/patriot.html"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-07-10 06:16:20+00:00",
                    "text": "As for implementation, it seems good enough to pass abs(x) to the C math.h cbrt/cbrtf/cbrtl function, and then multiply by the appropriate sign or phase factor, using ieee_copy_sign if we really want to be sure that infinities and signed zeros are handled correctly (modulo whatever floating-point sins the compiler commits in the name of optimization)."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-10 08:50:07+00:00",
                    "text": "As far as I can understand, the C version already works correctly for negative numbers.\n(As a side note: I've tried porting the C version to Fortran: https://gist.github.com/ivan-pi/5cf86ba198bc497331fba3d3a1a07c59 with promising results. There are however issues with portability due to the endianness.)\nThis leaves us to figure out our own version for complex roots."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-10 10:27:49+00:00",
                    "text": "@ivan Jose Pulido Sanchez <ijpulidos@unal.edu.co>\nI tried your code with this tes codet:\n\n  do i = 1,100\n      call random_number( x )\n      x = x * 10.0_dp**i\n      x3 = cbrt(x)\n\n      write(*,*) i, x, abs(x - x3**3), abs(x - x3**3)/x\n  enddo\n\nand the relative error was either zero or at most 3.1e-16 over the whole\nrange. I guess that this shows that the function is sufficiently accurate.\n\n(Note: this restores the original value instead of comparing two different\nways of calculating the cube root)\n\nRegards,\n\nArjen\n\nOp vr 10 jul. 2020 om 10:50 schreef Ivan <notifications@github.com>:\n\u2026\n As far as I can understand, the C version already works correctly for\n negative numbers.\n (As a side note: I've tried porting the C version to Fortran:\n https://gist.github.com/ivan-pi/5cf86ba198bc497331fba3d3a1a07c59 with\n promising results.)\n\n This leaves us to figure out our own version for complex roots.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#214 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR55FQ2XQ3QCUZTYO5TR23I45ANCNFSM4OF3DRVQ>\n ."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-10 11:25:45+00:00",
                    "text": "Thanks @arjenmarkus for the test! I reran it with the original C libm version by the side:\n  interface\n    pure function c_cbrt(x) bind(c,name=\"cbrt\")\n      use iso_c_binding, only: c_double\n      real(c_double), value :: x\n      real(c_double) :: c_cbrt\n    end function\n  end interface\n\n  do i = 1, 100\n    call random_number(x)\n    x = x*10._dp**i\n    x3 = cbrt(x)\n    cx3 = c_cbrt(x)\n    write(*,*) i, x, abs(x - x3**3)/x, abs(x - cx3**3)/x\n  end do\n\nI get some small differences in the last places:\n          76   4.0638919578662523E+075   1.9770924779982508E-016   1.9770924779982508E-016\n          77   7.6742391032182145E+076   1.6751503544737001E-016   3.3503007089474002E-016\n          78   7.0211150593663916E+076   0.0000000000000000        0.0000000000000000\n          79   5.1811233562026912E+078   1.5879804862696962E-016   1.5879804862696962E-016\n          80   3.6709083775467760E+079   1.7930216590378397E-016   1.7930216590378397E-016\n          81   1.2689247125165195E+080   0.0000000000000000        4.1496666677608811E-016\n          82   1.9609377628799389E+081   4.2964052674018527E-016   4.2964052674018527E-016\n          83   6.0802906214348435E+082   0.0000000000000000        0.0000000000000000\n          84   5.4375757115883662E+083   1.9832328300050751E-016   3.9664656600101501E-016\n          85   6.0508530767420035E+084   2.8515592178725947E-016   1.4257796089362973E-016\n          86   5.3970844933448210E+085   1.2787916059682132E-016   1.2787916059682132E-016\n          87   3.7468781425583570E+086   1.4735993185149220E-016   1.4735993185149220E-016\n          88   9.1656756575841826E+087   1.9276779266309714E-016   1.9276779266309714E-016\n          89   6.2174751629903578E+088   2.2733949308498420E-016   2.2733949308498420E-016\n          90   8.4055194736970552E+089   0.0000000000000000        0.0000000000000000\n          91   8.1811243675954609E+090   2.2114947934287768E-016   2.2114947934287768E-016\n          92   2.1849450318528865E+091   1.6561070122654541E-016   3.3122140245309081E-016\n          93   5.0864521082672201E+092   1.1382402387030692E-016   4.5529609548122767E-016\n          94   6.6274040704877999E+093   0.0000000000000000        2.7954737753913594E-016\n          95   2.1064887821671668E+094   1.7590157075425002E-016   1.7590157075425002E-016\n          96   1.6334791213177604E+094   2.2683772368054151E-016   2.2683772368054151E-016\n          97   5.3161169157241797E+096   1.7843264361368490E-016   1.7843264361368490E-016\n          98   6.4011877353899199E+097   1.1854909860403442E-016   3.5564729581210328E-016\n          99   4.0327657707019941E+098   1.5053788475170072E-016   4.5161365425510220E-016\n         100   4.7072761867901112E+099   0.0000000000000000        4.1269490362120304E-016\n\nIf I output as hexadecimals, I can indeed see some differences do remain, meaning my port is not a perfect match to the C one available on my platform."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-10 11:43:04+00:00",
                    "text": "I pretty much doubt you can get closer: the Fortran and C compilers are\nlikely to use slightly different ordering of the machine instructions. I\ntried with gfortran and Intel Fortran and they also gave slightly different\nresults, but always in the order of the last few bytes.\n\nBTW, gfortran complained about overflow in some of the constants, so I had\nto use -fno-range-check to compile the code. Not a showstopper, but still\nit might be a complication.\n\nRegards,\n\nArjen\n\nOp vr 10 jul. 2020 om 13:26 schreef Ivan <notifications@github.com>:\n\u2026\n Thanks @arjenmarkus <https://github.com/arjenmarkus> for the test! I\n reran it with the original C libm version by the side:\n\n   interface\n     pure function c_cbrt(x) bind(c,name=\"cbrt\")\n       use iso_c_binding, only: c_double\n       real(c_double), value :: x\n       real(c_double) :: c_cbrt\n     end function\n   end interface\n\n   do i = 1, 100\n     call random_number(x)\n     x = x*10._dp**i\n     x3 = cbrt(x)\n     cx3 = c_cbrt(x)\n     write(*,*) i, x, abs(x - x3**3)/x, abs(x - cx3**3)/x\n   end do\n\n I get some small differences in the last places:\n\n           76   4.0638919578662523E+075   1.9770924779982508E-016   1.9770924779982508E-016\n           77   7.6742391032182145E+076   1.6751503544737001E-016   3.3503007089474002E-016\n           78   7.0211150593663916E+076   0.0000000000000000        0.0000000000000000\n           79   5.1811233562026912E+078   1.5879804862696962E-016   1.5879804862696962E-016\n           80   3.6709083775467760E+079   1.7930216590378397E-016   1.7930216590378397E-016\n           81   1.2689247125165195E+080   0.0000000000000000        4.1496666677608811E-016\n           82   1.9609377628799389E+081   4.2964052674018527E-016   4.2964052674018527E-016\n           83   6.0802906214348435E+082   0.0000000000000000        0.0000000000000000\n           84   5.4375757115883662E+083   1.9832328300050751E-016   3.9664656600101501E-016\n           85   6.0508530767420035E+084   2.8515592178725947E-016   1.4257796089362973E-016\n           86   5.3970844933448210E+085   1.2787916059682132E-016   1.2787916059682132E-016\n           87   3.7468781425583570E+086   1.4735993185149220E-016   1.4735993185149220E-016\n           88   9.1656756575841826E+087   1.9276779266309714E-016   1.9276779266309714E-016\n           89   6.2174751629903578E+088   2.2733949308498420E-016   2.2733949308498420E-016\n           90   8.4055194736970552E+089   0.0000000000000000        0.0000000000000000\n           91   8.1811243675954609E+090   2.2114947934287768E-016   2.2114947934287768E-016\n           92   2.1849450318528865E+091   1.6561070122654541E-016   3.3122140245309081E-016\n           93   5.0864521082672201E+092   1.1382402387030692E-016   4.5529609548122767E-016\n           94   6.6274040704877999E+093   0.0000000000000000        2.7954737753913594E-016\n           95   2.1064887821671668E+094   1.7590157075425002E-016   1.7590157075425002E-016\n           96   1.6334791213177604E+094   2.2683772368054151E-016   2.2683772368054151E-016\n           97   5.3161169157241797E+096   1.7843264361368490E-016   1.7843264361368490E-016\n           98   6.4011877353899199E+097   1.1854909860403442E-016   3.5564729581210328E-016\n           99   4.0327657707019941E+098   1.5053788475170072E-016   4.5161365425510220E-016\n          100   4.7072761867901112E+099   0.0000000000000000        4.1269490362120304E-016\n\n If I output as hexadecimals, I can indeed see some differences do remain,\n meaning my port is not a perfect match to the C one available on my\n platform.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#214 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR2TSBWQTZVITOB7T53R233EPANCNFSM4OF3DRVQ>\n ."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-10 12:04:21+00:00",
                    "text": "BTW, gfortran complained about overflow in some of the constants, so I had to use -fno-range-check to compile the code. Not a showstopper, but still it might be a complication.\n\nI have learned from @kargl that the -fno-range-check flag is not needed with gfortran 10.1."
                }
            ]
        },
        {
            "number": 213,
            "user": "EverLookNeverSee",
            "date": "2020-06-20 19:55:26+00:00",
            "title": "ENH: Using OpenMP",
            "text": "Hi there\nI started learning OpenMP library couple weeks ago and would like to parallelize and speed up fortran standard library codebase.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-06-20 20:13:20+00:00",
                    "text": "OpenMP is specified using pragmas which are comments, so if the file is compiled without openmp enabled, it will just be ignored. So I think it's fine if we allow openmp in our code base, because if users do not want stdlib to be parallelized using openmp, they'll just compile the stdlib files without openmp enabled.\nHowever, some others think that stdlib should not use openmp, and rather users should parallelize themselves:\nhttps://github.com/fortran-lang/stdlib/pull/189/files#r426173077\nAlthough it's not clear to me how to do it in the context of the csr_matvec routine, as if it is to run in parallel, it needs to be parallelized from inside. Perhaps we could provide two versions of the subroutine, one serial, one parallel.\n@zerothi, do you want to discuss it more here?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-20 20:25:02+00:00",
                    "text": "If OpenMP is used in stdlib, I think it should be with orphaned procedures. The user can then control the parallelization (e.g. to call a stdlib procedure inside or outside a parallel region). Using parallel regions inside stdlib procedures will limit their utility."
                },
                {
                    "user": "certik",
                    "date": "2020-06-20 20:28:03+00:00",
                    "text": "Can you give an example? What is an orphaned procedure?\n\u2026\nOn Sat, Jun 20, 2020, at 2:25 PM, Jeremie Vandenplas wrote:\n\n\n If OpenMP is used in `stdlib`, I think it should be with orphaned\n procedures. The user can then control the parallelization (e.g. to call\n a `stdlib` procedure inside or outside a parallel region). Using\n parallel regions inside `stdlib` procedures will limit their utility.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#213 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWG6DMCQRHLS6B6Y6CDRXULKTANCNFSM4ODQTKIA>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-20 20:47:04+00:00",
                    "text": "Here is an example with an orphaned subroutine (the example is stupid but it is to illustrate an OpenMP orphaned procedure):\nprogram test\n  !$ use omp_lib\n  implicit none\n  integer :: i\n  real :: a(5)\n\n  a = [(i, i=1, 5)]\n\n  print*,' Outside a parallel region'\n  call printa(a)\n\n  print*,' Inside a parallel region'\n  !$omp parallel\n  call printa(a)\n  !$omp end parallel\n\ncontains\n\nsubroutine printa(a)\n  real, intent(in) :: a(:) \n\n  integer :: i, rang\n\n  rang = -1\n\n  !$omp do\n  do i=1,size(a)\n    !$ rang =  omp_get_thread_num()\n    print*,'value: ',a(i),' at thread ', rang\n  end do\n  !$omp end do\n\nend subroutine\n\nend program\nCompiled without OpenMP, the output is:\n Outside a parallel region\n value:    1.00000000      at thread           -1\n value:    2.00000000      at thread           -1\n value:    3.00000000      at thread           -1\n value:    4.00000000      at thread           -1\n value:    5.00000000      at thread           -1\n  Inside a parallel region\n value:    1.00000000      at thread           -1\n value:    2.00000000      at thread           -1\n value:    3.00000000      at thread           -1\n value:    4.00000000      at thread           -1\n value:    5.00000000      at thread           -1\n\nCompiled with OpenMP (and run with 3 threads):\n Outside a parallel region\n value:    1.00000000      at thread            0\n value:    2.00000000      at thread            0\n value:    3.00000000      at thread            0\n value:    4.00000000      at thread            0\n value:    5.00000000      at thread            0\n  Inside a parallel region\n value:    3.00000000      at thread            1\n value:    4.00000000      at thread            1\n value:    1.00000000      at thread            0\n value:    2.00000000      at thread            0\n value:    5.00000000      at thread            2"
                },
                {
                    "user": "certik",
                    "date": "2020-06-20 20:53:31+00:00",
                    "text": "Ah I see, that's what @zerothi meant in the comment at https://github.com/fortran-lang/stdlib/pull/189/files#r426173077. The idea is to use openmp, but never to use the omp parallel pragma inside stdlib and always compile with openmp. That way, if users just call stdlib, it will run in serial. But if they introduce a parallel region themselves, then stdlib will run parallel out of the box. I like this approach a lot."
                },
                {
                    "user": "EverLookNeverSee",
                    "date": "2020-06-21 07:25:28+00:00",
                    "text": "Here is an example with an orphaned subroutine (the example is stupid but it is to illustrate an OpenMP orphaned procedure):\nprogram test\n  !$ use omp_lib\n  implicit none\n  integer :: i\n  real :: a(5)\n\n  a = [(i, i=1, 5)]\n\n  print*,' Outside a parallel region'\n  call printa(a)\n\n  print*,' Inside a parallel region'\n  !$omp parallel\n  call printa(a)\n  !$omp end parallel\n\ncontains\n\nsubroutine printa(a)\n  real, intent(in) :: a(:) \n\n  integer :: i, rang\n\n  rang = -1\n\n  !$omp do\n  do i=1,size(a)\n    !$ rang =  omp_get_thread_num()\n    print*,'value: ',a(i),' at thread ', rang\n  end do\n  !$omp end do\n\nend subroutine\n\nend program\nCompiled without OpenMP, the output is:\n Outside a parallel region\n value:    1.00000000      at thread           -1\n value:    2.00000000      at thread           -1\n value:    3.00000000      at thread           -1\n value:    4.00000000      at thread           -1\n value:    5.00000000      at thread           -1\n  Inside a parallel region\n value:    1.00000000      at thread           -1\n value:    2.00000000      at thread           -1\n value:    3.00000000      at thread           -1\n value:    4.00000000      at thread           -1\n value:    5.00000000      at thread           -1\n\nCompiled with OpenMP (and run with 3 threads):\n Outside a parallel region\n value:    1.00000000      at thread            0\n value:    2.00000000      at thread            0\n value:    3.00000000      at thread            0\n value:    4.00000000      at thread            0\n value:    5.00000000      at thread            0\n  Inside a parallel region\n value:    3.00000000      at thread            1\n value:    4.00000000      at thread            1\n value:    1.00000000      at thread            0\n value:    2.00000000      at thread            0\n value:    5.00000000      at thread            2\n\n\nThat's exactly what i meant so that our stdlib subroutines has parallel features but without using parallel region in order to control parallelism by user."
                },
                {
                    "user": "zerothi",
                    "date": "2020-06-22 07:21:38+00:00",
                    "text": "Agreed, this was my idea, let the user decide how parallelism is enabled :)"
                },
                {
                    "user": "rjfarmer",
                    "date": "2020-08-03 09:28:32+00:00",
                    "text": "What happens when a user calls a function (which they want to parallelize and control the parallelization of) which then calls a stdlib function?\nprogram test\n  !$ use omp_lib\n  implicit none\n  integer :: i\n  real :: a(5)\n\n  call expensive_sub()\n \ncontains\n\nsubroutine expensive_sub()\n  integer :: i\n\n  !$omp parallel\n  do i=1,100\n  ! Other expensive calculations\n  call printa(a)\n  end do\n  !$omp end do\n\nend subroutine expensive_sub\n\nsubroutine printa(a)\n  real, intent(in) :: a(:) \n\n  integer :: i, rang\n\n  rang = -1\n\n  !$omp do\n  do i=1,size(a)\n    !$ rang =  omp_get_thread_num()\n    print*,'value: ',a(i),' at thread ', rang\n  end do\n  !$omp end do\n\nend subroutine\n\nend program\n\nDo you not end up with nested parallelization? which i doubt is what people expect."
                },
                {
                    "user": "zerothi",
                    "date": "2020-08-03 09:32:55+00:00",
                    "text": "What happens when a user calls a function (which they want to parallelize and control the parallelization of) which then calls a stdlib function?\n...\nDo you not end up with nested parallelization? which i doubt is what people expect.\n\nYour example works exactly as intended (only 1 level of parallelism is used):\nEDIT: oh sorry, there was an error (you didn't have parallel do, only parallel so didn't see it.\nHowever, if you do:\nprogram test\n  !$ use omp_lib\n  implicit none\n  integer :: i\n  real :: a(5)\n  !$omp parallel\n\n  call expensive_sub()\n !$omp end parallel\ncontains\n\nsubroutine expensive_sub()\n  integer :: i\n\n  !$omp parallel do\n  do i=1,100\n  ! Other expensive calculations\n  call printa(a)\n  end do\n  !$omp end do\n\nend subroutine expensive_sub\n\nsubroutine printa(a)\n  real, intent(in) :: a(:) \n\n  integer :: i, rang\n\n  rang = -1\n\n  !$omp do\n  do i=1,size(a)\n    !$ rang =  omp_get_thread_num()\n    print*,'value: ',a(i),' at thread ', rang\n  end do\n  !$omp end do\n\nend subroutine\n\nend program\nyou'll get nesting. Either we should implement omp on a orphaning way (as proposed), or supply threaded variants of the methods with some common suffix.\nEDIT: you can control inside omp do if(...) if we want to disallow too many nested levels, but that may also come as a surprise."
                },
                {
                    "user": "rjfarmer",
                    "date": "2020-08-03 09:35:30+00:00",
                    "text": "EDIT: oh sorry, there was an error (you didn't have parallel do, only parallel so didn't see it.\n\nSorry that was my mistake i meant parrallel do."
                },
                {
                    "user": "zerothi",
                    "date": "2020-08-04 06:55:24+00:00",
                    "text": "Ok, so this can still easily be mitigated.\nprogram test\n!$ use omp_lib\n  implicit none\n\n  logical :: nested\n  integer :: imax_nested, it, il\n\n!$omp parallel default(shared), private(it,il,nested,imax_nested)\n\n  nested = omp_get_nested()\n  imax_nested = omp_get_max_active_levels()\n\n  it = omp_get_thread_num()\n  il = omp_get_active_level()\n\n!$omp master\n  print *, \"Allow nested: \",nested, imax_nested\n!$omp end master\n\n!$omp barrier\n  \n  call sub_a(it,il)\n\n!$omp barrier\n!$omp single\n  print *,''\n  flush(6)\n!$omp end single\n\n  call sub_a_limit(it,il)\n\n!$omp end parallel\n \ncontains\n\n  subroutine sub_a(ot, ol)\n    integer, intent(in) :: ot, ol\n    integer :: it, il\n\n!$omp parallel default(shared), private(it,il)\n    it = omp_get_thread_num()\n    il = omp_get_active_level()\n    call sub_b(ot, ol, it, il)\n!$omp end parallel\n\n  end subroutine sub_a\n\n  subroutine sub_a_limit(ot, ol)\n    integer, intent(in) :: ot, ol\n    integer :: it, il\n\n!$omp parallel default(shared), private(it,il)\n    it = omp_get_thread_num()\n    il = omp_get_active_level()\n    call omp_set_max_active_levels(il)\n    call sub_b(ot, ol, it, il)\n!$omp end parallel\n\n  end subroutine sub_a_limit\n\n  subroutine sub_b(ot, ol, it, il)\n    integer, intent(in) :: ot, ol, it, il\n    integer :: ct, cl\n\n!$omp parallel default(shared), private(ct,cl)\n    ct = omp_get_thread_num()\n    cl = omp_get_active_level()\n    print '(a,tr2,5(tr2,i0,\"/\",i0))','sub_b: ', ot, ol, it, il, ct, cl\n!$omp end parallel\n\n  end subroutine sub_b\n\nend program test\nI.e. users can use call omp_set_max_active_levels(...) to control number of nested levels.\nPerhaps I should clarify runned parameters.\nIn pre OpenMP 5, one should do:\nOMP_NUM_THREADS=2 OMP_MAX_ACTIVE_LEVELS=3 OMP_NESTED=true ./a.out\nwhere OMP_MAX_ACTIVE_LEVELS controls the overall number of levels.\nIn OpenMP 5 OMP_NESTED is deprecated and only OMP_MAX_ACTIVE_LEVELS are needed."
                }
            ]
        },
        {
            "number": 212,
            "user": "nshaffer",
            "date": "2020-06-12 13:32:48+00:00",
            "title": "Handling runtime errors/exceptions",
            "text": "This issue is to discuss approaches to handle runtime errors and exceptions in stdlib. I have in mind scenarios such as\n\nAn iterative solver algorithm fails to converge\nA negative number is passed to a routine that requires a nonnegative one\nNot enough memory for an array allocation\n\nThese are conditions which cannot be identified at compile time, but if left alone will either cause user code to crash or be erroneous. Currently in stdlib, we have check, which can print error messages and optionally terminate execution. I think it is not sufficient for general-purpose runtime checking. To me, there are a few major considerations when thinking about runtime checking\n\n\nUsers must be given the opportunity to recover from the error if at all possible. This is especially important for library code, which may be difficult to debug depending on the installation/distribution. It is also generally rude for library code to kill execution without giving the user any say in the matter.\n\n\nIt should be possible to recover from runtime errors without sacrificing purity. If a routine is manifestly pure, then it should not have to sacrifice the pure attribute just to have some error checking. If I write a factorial function, making it pure and handling negative arguments should not have to be an either/or proposition.\n\n\nChecking and handling errors should not be unduly burdensome to users. If a function call requires one line, and handling its possible error conditions requires ten, users will simply not bother with error checking.\n\n\nThis list of criteria is not exhaustive, but they are the three that are most important to me. That stated, here are the runtime checking approaches I am most familiar with and how they stack up:\n\n\nReturn error code and message as optional out-params.\n\nDoes not play nicely with pure functions (pure subroutines OK, though)\nIntrinsic functions do not do this (but statements do, e.g., iostat, iomsg)\nPasses the buck to the user to interpret and handle the error code/message\n\n\n\nDie with error stop\n\nAs of f2018, can be used in pure functions\nKind of rude for library code to kill execution without chance of recovery\n\n\n\nReturn a special value\n\nThis is what intrinsics usually do, e.g., index returning -1\nSome algorithms may not have a natural \"obviously wrong\" value (maybe NaN?)\nWorks with pure functions/subroutines\n\n\n\nRaise an exception\n\nMaybe in 2045?\n\n\n\nOf these, my preference is strongly toward approach 3 whenever possible.",
            "comments": [
                {
                    "user": "epagone",
                    "date": "2020-06-12 19:00:35+00:00",
                    "text": "Very nice description and, FWIW, I prefer approach 3 as well.\nOne problem that I have faced a few times in the design of such routines is how this API communicates when nested at multiple levels of depth. Say the user is running a numerical integrator within a root-finding problem that is, in turn, used to solve a system of a differential equations. We might have three levels of depth in this case (admittedly, probably rare and fictitious), but I have personally used (within the scope of stdlib) two levels of depth in several cases. I'd guess OO design would help in this sense (with separate instances of the \"error handler class\") but I know it is discouraged in stdlib."
                },
                {
                    "user": "certik",
                    "date": "2020-06-12 19:15:55+00:00",
                    "text": "One thing that we should try to avoid is to force every user to be checking every single function from stdlib to ensure it succeeded. We should figure out how to allow users to check it if they want to and handle the error themselves, but we should also allow users to just call a given stdlib function and it would fail with a nice error message if something goes wrong.\nSo I would say a combination of 3. and 1. is the way to go.\nThe option 2. should be combined with the option 1. I.e., if the optional stat argument is not present, then it will fail with error stop. If stat is present, it would allow the user to handle the error. This is great for functions such as open or allocate.\nThe option 3. is great for functions such as find to find an element in an array or a string, and return -1 if it does not exist."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-15 21:11:16+00:00",
                    "text": "Thank you for these clear propositions. It is related to #95 too.\nThe options 1., 2., and 3. could be used for different purposes/procedures. For example, returning -1 or even NaN for one of the statistical procedure when a dim > 15 is provided would make no sense, and would not help the user. In such a case, I think it is better that the program fails with error stop and an informative message."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-07 19:13:54+00:00",
                    "text": "There are two related questions raised by @nshaffer original post:\n\nWhat infrastructure should the library provide for handling errors?\nWhat coding guidelines should the authors of the library follow to best handle errors?\n\nTo address the first question I have written a module, that I have tentatively named STDLIB_ERROR_REPORTING, and a markdown document describing the module's API in some detail. The module consists of a number of named constants and five subroutines.\nThe module defines 80+ unique named constants to serve as error codes for reporting errors in a consistent manner. The constants can be defined as integers or a derived type, but are currently defined as a derived type named ERRORS, whose sole public component is named CODE. The advantages and disadvantages of the different means of defining the constants are:\n\n\nIntegers\na. Advantage:\n * It is what the Fortran standard currently uses for reporting errors, and is what its users are used to,\n * It requires less typing to enter `INTEGER` than to enter `TYPE(NAME)`, and\n * They can easily be used in a `SELECT CASE` construct\n\nb. Disadvantage: the users may be tempted to use the processor's STATUS values as their flags.\n * the `STATUS` values the processor returns may duplicate values for the error codes, but with very different meanings\n * the meanings of the processor's `STATUS` values are not readily apparent\n\n\n\nDerived type with a public component:\na. Advantage:\n * The name of the type can be intuitive\n * With a public component it can be used in `SELECT CASE` constructs\n * More difficult to confuse with `STATUS` values\n\nb. Disadvantage:\n * It is not what users are used to\n * `TYPE(NAME)` requires more typing than `INTEGER`\n\n\n\nDerived type with a private component\na. Advantage\n * The name of the type can be intuitive\n * Very difficult to confuse with STATUS values\n\nb. Disadvantage\n * It is not what users are used to\n * Cannot be used in `SELECT CASE` constructs\n * `TYPE(NAME)` requires more typing than `INTEGER`\n\n\n\nFour of the five subroutines have ERROR as an optional argument for passing error codes. For the fifth ERROR is mandatory. Three subroutines, have optional MODULE and PROCEDURE arguments for specifying the location where the error was discovered. One of the procedures, ASSERT, is similar in intent to CHECK in STDLIB_ERROR, while another, SEND_STOP, is similar in intent to ERROR_STOP in the same module. A summary of the subroutines is as follows:\nASSERT( TEST, MESSAGE [, MODULE, PROCEDURE, ERROR ] ): If TEST is .TRUE. does nothing, otherwise it writes text to the ERROR_UNIT, with an ERROR dependent string as the stop code.\nREPORT_ERROR( MESSAGE [, MODULE, PROCEDURE, STAT, ERRMSG, ERROR ] ): Writes the character string, MESSAGE, to ERROR_UNIT, with an ERROR dependent string as the stop code.\nREPORT_IO_ERROR( MESSAGE [, MODULE, PROCEDURE, IOSTAT, IOMSG, ERROR ] ): Writes the character string, MESSAGE, to ERROR_UNIT, with an ERROR dependent string as the stop code.\nREPORT_TEXT_ERROR( LINE, START_INDEX, DESCRIP [, FILENAME,  LINE_NUMBER, WRITE_UNIT, ERROR ] ): Sends a message to WRITE_UNIT describing an error found in a line of text.\nSEND_STOP( ERROR ):  Stops processing with an ERROR specific string as the stop code. Note this subroutine would be PURE in F2018, but is not PURE in F2008.\nAs to the second question as to what guidelines programmers should  follow I have a few strong opinions on user and memory allocation errors and pure procedures. Programmers should not report user errors up the call chain. They should simply stop with an informative message, or if purity or elemental attributes are important and F2008 compatibility is important, they should do nothing at all. Programmers should almost never attempt to handle memory allocation problems. With virtual memory, allocation should almost never fail, and with lazy allocation on Linux, failure need not be discovered at the invocation of an ALLOCATE statement. They should only attempt to handle an allocation error if:\n\nA large amount of memory is likely to be allocated,\nAn alternative less memory intensive algorithm is available, and\nMost memory is used near the ALLOCATE statement.\n\nFinally as to purity, there is currently nothing to be done to handle errors in F2018 for ELEMENTAL procedures. For PURE procedures in 2018 you can invoke ERROR STOP, or pass a STATUS flag. For the nominal, elemental factorial function with a negative argument, I would return a NaN."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-10 02:35:09+00:00",
                    "text": "FWIW here is some example code illustrating how I view the module being used:\nMODULE EXAMPLE_MOD\n  ...\n  USE STDLIB_ERROR_REPORTING\n  ...\n  MODULE_NAME = 'EXAMPLE_MOD'\n  ...\nCONTAINS\n  ...\n  SUBROUTINE EXAMPLE_SUB(..., STATUS, ... )\n    ...\n    TYPE(ERRORS), INTENT(OUT), OPTIONAL :: STATUS\n    ...\n    SELECT CASE (FLAG)\n    ...\n    CASE DEFAULT\n      IF ( PRESENT(STATUS) ) THEN\n        STATUS = CONSISTENCY_FAULT\n        RETURN\n      ELSE\n        CALL REPORT_ERROR('Illegal FLAG value.', &\n          MODULE = MODULE_NAME,                  &\n          PROCEDURE = 'EXAMPLE_SUB',             &\n          ERROR = CONSISTENCY_FAULT )\n      END IF\n    END SELECT\n    ...\n    OPEN ( UNIT=LUN, FILE=FILENAME, STATUS='OLD', &\n      ERR=99, IOSTAT=STAT, IOMSG=MESSAGE )\n    ...\n 99 IF (PRESENT(STATUS)) THEN\n      STATUS = OPEN_FAULT\n      RETURN\n    ELSE\n      CALL REPORT_IO_ERROR ( TRIM(FILENAME) // &\n        \" could not be opened as 'OLD'.\",      &\n        MODULE = MODULE_NAME,                  &\n        PROCEDURE = 'EXAMPLE_SUB',             &\n        IOSTAT = STAT,                         &\n        IOMSG = MESSAGE,                       &\n        ERROR = OPEN_FAULT )\n    END IF\n    ...\n100 READ ( UNIT=LUN, END=190, EOR=192, ERR=194,&\n           IOMSG=IOMSG, IOSTAT=STAT ) A\n    ...\n    IF ( PRESENT(STATUS) ) THEN\n      STATUS = SUCCESS\n    END IF\n    RETURN\n    ...\n190 IF ( PRESENT(STATUS) ) THEN\n      STATUS = EOF_FAULT\n      RETURN\n    END IF\n    CALL REPORT_IO_ERROR(\"End-of-File occurred\"//&\n      \"reading from file '\"//TRIM(FILENAME)//\"'.\",&\n      MODULE = MODULE_NAME,                       &\n      PROCEDURE = 'EXAMPLE_SUB',                  &\n      IOSTAT = STAT,                              &\n      IOMSG = MESSAGE,                            &\n      ERROR = EOF_FAULT )\n192 IF ( PRESENT(STATUS) ) THEN\n      STATUS = EOR_FAULT\n      RETURN\n    END IF\n    CALL REPORT_IO_ERROR(\"End-of-Record occurred reading \"//&\n      \"from file '\"//TRIM(FILENAME)//\"'.\",     &\n      MODULE = MODULE_NAME,                    &\n      PROCEDURE = 'EXAMPLE_SUB',               &\n      IOSTAT = STAT,                           &\n      IOMSG = MESSAGE,                         &\n      ERROR = EOR_FAULT )\n194 IF ( PRESENT(STATUS) ) THEN\n      STATUS = READ_FAULT\n      RETURN\n    END IF\n    CALL REPORT_IO_ERROR(\"Read fault occurred reading \"//&\n      \"from file '\"//TRIM(FILENAME)//\"'.\",      &\n      MODULE = MODULE_NAME,                     &\n      PROCEDURE = 'EXAMPLE_SUB',                &\n      IOSTAT = STAT,                            &\n      IOMSG = MESSAGE,                          &\n      ERROR = READ_FAULT )\n  END SUBROUTINE EXAMPLE_SUB\n  ...\nEND MODULE EXAMPLE_MOD"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-07-10 06:04:47+00:00",
                    "text": "@wclodius2 Thank you for the carefully considered post. I hope you can clarify a few things for me about your approach.\n\n\nI do not fully understand your comments on processor-defined status values, e.g., for the stat= specifier in allocate statements or the iostat= specifier of I/O statements. At least in the case of iostat values, the named constants in iso_fortran_env seem quite suitable.\n\n\nIn your example, is it intended that users only test for error codes that they expect to handle and let all others fall to the default case? What do they do if they think none of the predefined error codes makes sense for them?\n\n\nIt is not clear to me what is gained from this approach compared to defining and testing for my own status codes. It provides pre-defined status codes and a few utility routines, but does this facilitate error handling in user code or just formalize it?"
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-07-10 17:19:50+00:00",
                    "text": "@wclodius2 , your example usage looks very similar to a library I developed: erloff\nI don't have the routines that output the errors and stop the program, but those are easy to add."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-12 21:32:00+00:00",
                    "text": "@nshaffer thank you for your kind words.\n\n\nThank you for reminding me of the error flags in ISO_FORTRAN_ENV. It has given me a few more error\ncodes to add to my initial list of eighty two. The one problem with the ISO_FORTRAN_ENV flags is that\ntheir values can vary arbitrarily between processors, so if you want to pass status flags for multiple\ncategories of problems, ensuring that your values are different for each cause requires replacing their\nvalues with your own any way.\n\n\nIt is expected that the writer of the routine that reports the errors to the user documents what errors\nit passes, that the user decides whether he wants to handle any of them or let failure occur in the\ncalled routine,  and that the user decide which errors he wants to handle or let fail in the calling routine.\nI have tried to be very thorough in identifying categories of errors. If a user decides that none of the\ncodes are suitable they can do any of: ask me to add an appropriate error code; if the code were\nadded to the standard library he could add them himself, use the generic FAILURE code; or define\ntheir own (presumably integer) flags and document them.\n\n\nI think a standard library should formalize its error reporting so that users have a consistent interface.\nAs a starting point, I think that having utility routines that report the location of the errors are useful.\nI want to contribute to the library, but don't want each module to have its own error reporting."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-12 21:35:48+00:00",
                    "text": "@everythingfunctional I'm glad I am not the only one that approaches error handling this way."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-13 06:40:02+00:00",
                    "text": "Wrt the error codes defined in ISO_FORTRAN_ENV we could use code like this\nto ensure that the error codes in the library do not interfere with the\npredefined ones for any processor:\n\n! errorcodes.f90 --\n!     Use simple calculations to ensure a range outside all predefined\nerror codes\n!\nprogram errorcodes\n    use iso_fortran_env\n\n    integer, parameter :: error_base = 1 + max(abs(iostat_end),\nabs(iostat_eor), abs(iostat_inquire_internal_unit) ) ! TODO: add the STAT_*\ncodes\n\n    write(*,*) error_base\n\nend program errorcodes\n\nOut of laziness I have left out the STAT_* error codes :). The program is\naccepted by both gfortran and Intel Fortran and produces two very different\nvalues, 5019 and 91, respectively.\n\nRegards,\n\nArjen\n\nOp zo 12 jul. 2020 om 23:32 schreef William B. Clodius <\nnotifications@github.com>:\n\u2026\n @nshaffer <https://github.com/nshaffer> thank you for your kind words.\n\n    1.\n\n    Thank you for reminding me of the error flags in ISO_FORTRAN_ENV. It\n    has given me a few more error\n    codes to add to my initial list of eighty two. The one problem with\n    the ISO_FORTRAN_ENV flags is that\n    their values can vary arbitrarily between processors, so if you want\n    to pass status flags for multiple\n    categories of problems, ensuring that your values are different for\n    each cause requires replacing their\n    values with your own any way.\n    2.\n\n    It is expected that the writer of the routine that reports the errors\n    to the user documents what errors\n    it passes, that the user decides whether he wants to handle any of\n    them or let failure occur in the\n    called routine, and that the user decide which errors he wants to\n    handle or let fail in the calling routine.\n    I have tried to be very thorough in identifying categories of errors.\n    If a user decides that none of the\n    codes are suitable they can do any of: ask me to add an appropriate\n    error code; if the code were\n    added to the standard library he could add them himself, use the\n    generic FAILURE code; or define\n    their own (presumably integer) flags and document them.\n    3.\n\n    I think a standard library should formalize its error reporting so\n    that users have a consistent interface.\n    As a starting point, I think that having utility routines that report\n    the location of the errors are useful.\n    I want to contribute to the library, but don't want each module to\n    have its own error reporting.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#212 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YRYAUBOTHIYVDT2SVMTR3ITV3ANCNFSM4N4KVJSA>\n ."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-07-13 13:42:41+00:00",
                    "text": "FWIW my version of gfortran (10.1.0 on the Mac) doesn't define the most recent addition to ISO_FORTRAN_ENV, STAT_FAILED_IMAGE, so an enumeration of error codes that included those defined in ISO_FORTRAN_ENV beyond the I/O ones would have to be processor specific. However, there doesn't seem to be much interest in an enumeration of error codes, whether or not they included those in ISO_FORTRAN_ENV. If there is I could post my enumeration as a starting point."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-13 14:18:16+00:00",
                    "text": "Re gfortran 10.1 not defining STAT_FAILED_IMAGE: I was afraid of that\n;). And there doesn't seem to be a way to provide a fallback value.\n\nRegards,\n\nArjen\n\nOp ma 13 jul. 2020 om 15:42 schreef William B. Clodius\n<notifications@github.com>:\n\u2026\n\n FWIW my version of gfortran (10.1.0 on the Mac) doesn't define the most recent addition to ISO_FORTRAN_ENV, STAT_FAILED_IMAGE, so an enumeration of error codes that included those defined in ISO_FORTRAN_ENV beyond the I/O ones would have to be processor specific. However, there doesn't seem to be much interest in an enumeration of error codes, whether or not they included those in ISO_FORTRAN_ENV. If there is I could post my enumeration.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub, or unsubscribe."
                }
            ]
        },
        {
            "number": 211,
            "user": "jvdp1",
            "date": "2020-06-04 16:43:24+00:00",
            "title": "Remove some unused variables and simplify use of ieee_value",
            "text": "I removed some unused variables and I modified the call to ieee_value in stdlib_experimental_stats_mean.fypp to be in agreement with the other submodules.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-06-05 15:39:45+00:00",
                    "text": "Thanks @certik .\nBecause it only removes some unused variables and fixes an issue for ifort, I'll merge it after solving the conflicting file."
                }
            ]
        },
        {
            "number": 210,
            "user": "sakamoti",
            "date": "2020-06-04 15:26:08+00:00",
            "title": "fix build failure with nagfor7.0 because of using \"complex\" function",
            "text": "\"complex\" function which is not a fortran standard causes an error like below in nagfor.\n(for example)\n\"Error: test_linalg.f90, line 445: Implicit type for COMPLEX in TEST_TRACE_CQP\"\nSo, \"complex\" is replaced with \"cmplx\" which is one of the fortran standard function.\nAt the same time, I specified the \"kind\" value so that it has the same precision as the \"cmplx\" function argument.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-06-04 16:00:21+00:00",
                    "text": "Thank you @sakamoti! This is in part covered by #205, and to your PR also adds the explicit kind parameter to cmplx.\nI suggest we wait to merge #205, then rebase this with master and merge. @certik does this sound reasonable?"
                },
                {
                    "user": "certik",
                    "date": "2020-06-04 16:04:40+00:00",
                    "text": "@sakamoti thank you for the fixes! I apologize that it took us longer to merge #205. We just did. Is there anything still failing in the latest master? If so, would you mind sending a PR or rebasing this one?\nI apologize for this. Thank you again for our PR. Let me know if you need any help."
                },
                {
                    "user": "sakamoti",
                    "date": "2020-06-04 21:09:04+00:00",
                    "text": "The latest version \"48b28e8\" resolved compilation error. But some \"Questionable\" message appeare from nagfor.\n(example)\n\"Questionable: fortran-lang_stdlib/src/tests/io/test_savetxt.f90, line 106: Intrinsic function CMPLX with double precision argument and no KIND= argument returns single precision result\"\nSo, adds the explicit kind parameter to cmplx is still meaningfull I think. How do you think about this?\nIf it is preffer to add kind parameter, I'll try it according to compiler message and send new PR."
                },
                {
                    "user": "certik",
                    "date": "2020-06-04 21:11:53+00:00",
                    "text": "Yes, I think if the standard says that the result can be single precision (I think that's correct), we have to add the kind parameters. If you wouldn't mind doing it, we would really appreciate it. Thank you!"
                },
                {
                    "user": "sakamoti",
                    "date": "2020-06-04 22:32:24+00:00",
                    "text": "Please wait a moment, I just editing. (It is my first time to rebase...)\nwhen finish, I will add the comment."
                },
                {
                    "user": "sakamoti",
                    "date": "2020-06-04 23:23:57+00:00",
                    "text": "Rebase is over. Please review."
                }
            ]
        },
        {
            "number": 209,
            "user": "nshaffer",
            "date": "2020-06-03 06:06:11+00:00",
            "title": "Quadrature: spec tweaks & Simpson's rule",
            "text": "Implementation of simps and simps_weights\nInterfaces and implementations are for 1d real arrays. The included tests exercise the routines for integrands which are (analytically) exactly integrated by Simpson's rule. Known edge cases (length 0, 1, or 6) arrays are explicitly tested as well. There is a lot of new code, and it is not always simple, but hopefully the tests stand as an empirical demonstration of correctness.\nQ: To simplify the implementation, simps and simps_weights have been made recursive. This is only an implementation detail. Am I right to think pure recursive does not limit the routines' usability any more than just pure, e.g., in do concurrent or where constructs?\nChanges to simps and simps_weights optional argument even\nIn the current spec, the optional argument even is an integer that is supposed to let the user specify the index at which to insert a Simpson's 3/8 rule so that even-length arrays can be treated. In implementation, this introduced too many corner cases to be worthwhile. In this implementation, even is still an integer, but its meaning is different. If it is negative, the 3/8 rule is used for the leftmost abscissas. If it is positive, the 3/8 rule is used for the rightmost abscissas. If it is zero or absent, the result is as if the even<0 and even>0 cases were averaged. There are still corner cases and complicated control flow, but it's much simpler than the alternative. The spec has been revised to reflect this new behavior.\nImproved fypp style\nLooking toward future extensions to complex types and multiple ranks, the fypp style has been changed to more closely match that of other heavily preprocessed modules.\ntrapz_weights example \"bugfix\"\nIn the spec for trapz_weights, the example had a typo and also used dot_product to evaluate the integral. Looking toward implementation for complex integrands, this seems wrong (introduces a complex conjugate), so the example is changed to use sum instead.",
            "comments": [
                {
                    "user": "nshaffer",
                    "date": "2020-06-03 06:12:04+00:00",
                    "text": "It looks like the error tolerance is too strict in some of the tests in the CI. Of course they all pass on my machine ;) (resolved)"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-03 14:46:02+00:00",
                    "text": "Thanks for the answers. I have additional minor comments. In the specs, could you:\n\nremove \"to be implemented\" in the titles?\nreplace simps in result = simps... by something like result = [[stdlib_experimental_quadrature(module):simps(interface)]](....) for the docs?"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-06-04 14:10:14+00:00",
                    "text": "Thanks for the answers. I have additional minor comments. In the specs, could you:\n* remove \"to be implemented\" in the titles?\n\n* replace `simps` in `result = simps...` by something like `result = [[stdlib_experimental_quadrature(module):simps(interface)]](....)` for the docs?\n\n\nSure, no problemo. I see that there are now also links for the docs in stdlib_experimental_quadrature.fypp for the trapz and trapz_weights interfaces. I suppose we want the same for simps and simps_weights, but I don't know how to get the URL right. Do you know what to do?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-04 14:22:15+00:00",
                    "text": "I suppose we want the same for simps and simps_weights\n\nIt would be good, indeed. You can use a similar link as for trapz:\n        !! Integrates sampled values using trapezoidal rule\n        !! ([Specification](../page/specs/stdlib_experimental_quadrature.html#description))\t\nThe word description must be adapted (e.g., description_2)"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-06-04 14:48:28+00:00",
                    "text": "I suppose we want the same for simps and simps_weights\n\nIt would be good, indeed. You can use a similar link as for trapz:\n        !! Integrates sampled values using trapezoidal rule\n        !! ([Specification](../page/specs/stdlib_experimental_quadrature.html#description))\t\nThe word description must be adapted (e.g., description_2)\n\nCool beans, made sense after I installed FORD and built the docs. Should be taken care of now."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-04 18:09:57+00:00",
                    "text": "Cool beans, made sense after I installed FORD and built the docs. Should be taken care of now.\n\nNote that you can load it from here."
                },
                {
                    "user": "certik",
                    "date": "2020-06-07 17:55:53+00:00",
                    "text": "I would recommend to recommend to use error_stop and open another issue to get rid of it all over stdlib, if desired.\n\u2026\nOn Sun, Jun 7, 2020, at 10:04 AM, Jeremie Vandenplas wrote:\n\n\n ***@***.**** commented on this pull request.\n\n In src/stdlib_experimental_quadrature_simps.fypp\n <#209 (comment)>:\n\n > +#:for k1, t1 in REAL_KINDS_TYPES\n +\n +    pure recursive module function simps_x_${k1}$(y, x, even)\n result(integral)\n +        ${t1}$, dimension(:), intent(in) :: y\n +        ${t1}$, dimension(:), intent(in) :: x\n +        integer, intent(in), optional :: even\n +        ${t1}$ :: integral\n +\n +        integer :: i\n +        integer :: n\n +\n +        ${t1}$ :: h1, h2\n +        ${t1}$ :: a, b, c\n +\n +        n = size(y)\n +        if (size(x) /= n) error stop \"simps: Arguments `x` and `y`\n must be the same size.\"\n I don't think reverting to declaring `x` to be `dimension(size(y))` is\n a good idea, as mentioned in earlier comments.\n\n It has been agreed that Gfortran <=7 were not supported for stdlib.\n However, recent versions of other compilers may not support the 2018\n `error stop` yet. I am perfectly ok to use the 2018 `error stop`, but\n this will restrict stdlib to very recent compilers.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#209 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWHJR7OUKKKYDXBNKUDRVO3B3ANCNFSM4NRLGEBA>."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-06-07 23:24:54+00:00",
                    "text": "I would recommend to recommend to use error_stop and open another issue to get rid of it all over stdlib, if desired.\n\u2026\nOn Sun, Jun 7, 2020, at 10:04 AM, Jeremie Vandenplas wrote: @.**** commented on this pull request. In src/stdlib_experimental_quadrature_simps.fypp <#209 (comment)>: > +#:for k1, t1 in REAL_KINDS_TYPES + + pure recursive module function simps_x_${k1}$(y, x, even) result(integral) + ${t1}$, dimension(:), intent(in) :: y + ${t1}$, dimension(:), intent(in) :: x + integer, intent(in), optional :: even + ${t1}$ :: integral + + integer :: i + integer :: n + + ${t1}$ :: h1, h2 + ${t1}$ :: a, b, c + + n = size(y) + if (size(x) /= n) error stop \"simps: Arguments x and y must be the same size.\" I don't think reverting to declaring x to be dimension(size(y)) is a good idea, as mentioned in earlier comments. It has been agreed that Gfortran <=7 were not supported for stdlib. However, recent versions of other compilers may not support the 2018 error stop yet. I am perfectly ok to use the 2018 error stop, but this will restrict stdlib to very recent compilers. \u2014 You are receiving this because you commented. Reply to this email directly, view it on GitHub <#209 (comment)>, or unsubscribe https://github.com/notifications/unsubscribe-auth/AAAFAWHJR7OUKKKYDXBNKUDRVO3B3ANCNFSM4NRLGEBA.\n\nOk, done. I've replaced the size check using error_stop with a call to check and dropped the pure attributed from simps_x_* and trapz_x_*."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-15 21:21:14+00:00",
                    "text": "All comments were answered. I'll merge it.\nThank you @nshaffer"
                },
                {
                    "user": "certik",
                    "date": "2020-06-15 21:22:17+00:00",
                    "text": "@nshaffer do you want to open a new issue for the \"error_stop\" thing we discussed above?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-15 21:30:41+00:00",
                    "text": "@nshaffer do you want to open a new issue for the \"error_stop\" thing we discussed above?\n\nRelated to #212"
                }
            ]
        },
        {
            "number": 208,
            "user": "jvdp1",
            "date": "2020-05-30 21:48:09+00:00",
            "title": "Fix for an issue in stdlib_experimental_linalg_diag with Intel compiler",
            "text": "Mentioned by @MarDiehl in #205\nifort message:\n     function diag_cdp_mat(A) result(res)\n---------------^\n/home/jvandenp/stdlib/build/src/stdlib_experimental_linalg_diag.f90(350): error #6645: The name of the module procedure conflicts with a name in the encompassing scoping unit.   [DIAG_CQP_MA\nT]\n      function diag_cqp_mat(A) result(res)\n---------------^\n/home/jvandenp/stdlib/build/src/stdlib_experimental_linalg_diag.f90(358): error #6645: The name of the module procedure conflicts with a name in the encompassing scoping unit.   [DIAG_IINT8_\nMAT]",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-05-31 14:34:54+00:00",
                    "text": "Since it is a correction, I'll merge."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-31 14:37:22+00:00",
                    "text": "Fixes one of the issues in #205"
                }
            ]
        },
        {
            "number": 207,
            "user": "MarDiehl",
            "date": "2020-05-30 20:37:20+00:00",
            "title": "explicitly state that unit tests are required",
            "text": "@milancurcic\nas discussed in #5",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-06-04 16:02:14+00:00",
                    "text": "There haven't been objections to this so I will merge it."
                }
            ]
        },
        {
            "number": 206,
            "user": "jvdp1",
            "date": "2020-05-30 20:10:14+00:00",
            "title": "proposition for solving an issue with optval",
            "text": "Proposition to solve the issue raised in the comment of PR #205 by @MarDiehl\nThe elemental is removed and fypp is used to generate the different ranks.\n@milancurcic\nWe should probably match that the shape of x is the same as of default. The pure might need to be removed too.\nNote: this is only a proposition for a possible issue. However, the issue must be clarified first.\nNote: the issue seems to be a bug in Gfortran (see bug 95446. Therefore, this issue should be closed without being merged.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-05-31 16:17:17+00:00",
                    "text": "Indeed, based on the development and Martin's bug report, it looks like this won't be needed after all, which I'm very happy about."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-01 08:15:29+00:00",
                    "text": "Because it is due to a bug in gfortran, I close this PR."
                }
            ]
        },
        {
            "number": 205,
            "user": "MarDiehl",
            "date": "2020-05-30 17:14:03+00:00",
            "title": "test for standard conformance",
            "text": "There are several compiler options that help to detect non-standard conformant code.\nI have included some of them (only for Intel and GNU compiler).\nUnfortunately, the result is that the code does not compile:\nIntel compiler:\n/tmp/stdlib/build/src/stdlib_experimental_linalg_diag.f90(7): error #6645: The name of the module procedure conflicts with a name in the encompassing scoping unit.   [DIAG_RSP]\n      function diag_rsp(v) result(res)\nGNU compiler\n/tmp/stdlib/src/tests/optval/test_optval.f90:252:15:\n\n  252 |     z = optval(x, [2.0_qp, -2.0_qp])\n        |               1\n        Error: \u2018x\u2019 at (1) is an array and OPTIONAL; IF IT IS MISSING, it\n        cannot be the actual argument of an ELEMENTAL procedure unless\n        there is a non-optional argument with the same rank (12.4.1.5)\n        [-Werror=pedantic]\n\nThere is also a high number of warnings related to type conversions.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-05-30 17:53:11+00:00",
                    "text": "Martin, thank you and welcome! I think this will be a great step forward. I suggest that we work our way through the errors raised in this PR and fix them until all tests pass."
                },
                {
                    "user": "certik",
                    "date": "2020-05-30 18:05:41+00:00",
                    "text": "In Fortran, are you supposed to use cmplx or complex?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-30 18:15:51+00:00",
                    "text": "cmplx is an intrinsic conversion function (like int, real, and char) and complex is the name of the type. I confused this myself many times before but the compiler always corrected me (I don't remember which one). In this case, it's a GNU extension."
                },
                {
                    "user": "certik",
                    "date": "2020-05-30 18:25:13+00:00",
                    "text": "Another pitfall the compiler should provide a nice error / warning message. Thanks!"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-30 18:43:54+00:00",
                    "text": "Thank you for starting this.\nI am not a huge fan of -Wconversion because it reports many implicit conversions. Others will help us to avoif pitfalls like complex vs cmplx."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 18:56:50+00:00",
                    "text": "Martin, thank you and welcome! I think this will be a great step forward. I suggest that we work our way through the errors raised in this PR and fix them until all tests pass.\n\nFor gfortran, the optval tests fail:\nError: \u2018x\u2019 at (1) is an array and OPTIONAL; IF IT IS MISSING, it cannot be the actual argument of an ELEMENTAL procedure unless there is a non-optional argument with the same rank (12.4.1.5)\n\nI'm also not sure if you are even allowed to pass in an optional argument into a function. Is x in optval present or not?"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 18:58:17+00:00",
                    "text": "Thank you for starting this.\nI am not a huge fan of -Wconversion because it reports many implicit conversions. Others will help us to avoif pitfalls like complex vs cmplx.\n\nI would say for a statically typed language, these warnings are reasonable. Once just has to carefully set the types (5 is not 5.)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-30 19:43:23+00:00",
                    "text": "I'm also not sure if you are even allowed to pass in an optional argument into a function. Is x in optval present or not?\n\nYou can pass it to a procedure if the corresponding dummy argument is also declared optional.\nIt looks like we'll need to remove the elemental attribute from optval and use fypp to create specific procedures for all ranks."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-30 19:46:27+00:00",
                    "text": "It looks like we'll need to remove the elemental attribute from optval and use fypp to create specific procedures for all ranks.\n\nI am currently trying this option. However, we then must check is the actual arguments have the same dimension, and use stop error if it is not the case. This was ensure by the elementatal function. The pure statement might need to be removed if a message is provided."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 20:23:37+00:00",
                    "text": "It looks like we'll need to remove the elemental attribute from optval and use fypp to create specific procedures for all ranks.\n\nI am currently trying this option. However, we then must check is the actual arguments have the same dimension, and use stop error if it is not the case. This was ensure by the elementatal function. The pure statement might need to be removed if a message is provided.\n\nTo be honest, I have problems to understand the error of gfortran. What does there is means? Does it refer to the calling functions or to the called (elemental) function? optval has a second, non-optional argument."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-30 20:46:05+00:00",
                    "text": "It looks like we'll need to remove the elemental attribute from optval and use fypp to create specific procedures for all ranks.\n\nI am currently trying this option. However, we then must check is the actual arguments have the same dimension, and use stop error if it is not the case. This was ensure by the elementatal function. The pure statement might need to be removed if a message is provided.\n\nTo be honest, I have problems to understand the error of gfortran. What does there is means? Does it refer to the calling functions or to the called (elemental) function? optval has a second, non-optional argument.\n\nMy first impression was that the message was clear (to me at least). To be sure, I went to the gcc source code.\nNow with this comment in this code:\n/* If it is an array, it shall not be supplied as an actual argument\n     to an elemental procedure unless an array of the same rank is supplied\n     as an actual argument corresponding to a nonoptional dummy argument of\n     that elemental procedure(12.4.1.5).  */\n, I am doubting."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 21:25:42+00:00",
                    "text": "It looks like we'll need to remove the elemental attribute from optval and use fypp to create specific procedures for all ranks.\n\nI am currently trying this option. However, we then must check is the actual arguments have the same dimension, and use stop error if it is not the case. This was ensure by the elementatal function. The pure statement might need to be removed if a message is provided.\n\nTo be honest, I have problems to understand the error of gfortran. What does there is means? Does it refer to the calling functions or to the called (elemental) function? optval has a second, non-optional argument.\n\nMy first impression was that the message was clear (to me at least). To be sure, I went to the gcc source code.\nNow with this comment in this code:\n/* If it is an array, it shall not be supplied as an actual argument\n     to an elemental procedure unless an array of the same rank is supplied\n     as an actual argument corresponding to a nonoptional dummy argument of\n     that elemental procedure(12.4.1.5).  */\n, I am doubting.\n\nSame here. In case that an optional argument is not given, there is still the other argument to determine the properties of the return value.\nWe should discuss report it to the gfortran developers. I will also check if it compiles with Intel."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-30 21:28:58+00:00",
                    "text": "From the Fortran Standard (15.5.2.12):\n3 An optional dummy argument that is not present is subject to the following restrictions.\n.....\n(6) If it is an array, it shall not be supplied as an actual argument to an elemental procedure unless an\narray of the same rank is supplied as an actual argument corresponding to a nonoptional dummy\nargument of that elemental procedure.\n....\n\nI understand the same from this sentence.\n\nWe should discuss report it to the gfortran developers. I will also check if it compiles with Intel.\n\nI agree. Btv, which version of gfortran did you use (I used GFortran9.3)?"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 21:30:32+00:00",
                    "text": "I agree. Btv, which version of gfortran did you use (I used GFortran9.3)?\n\n10.1"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-30 21:49:47+00:00",
                    "text": "Intel compiler:\n/tmp/stdlib/build/src/stdlib_experimental_linalg_diag.f90(7): error #6645: The name of the module procedure conflicts with a name in the encompassing scoping unit.   [DIAG_RSP]\nfunction diag_rsp(v) result(res)\n\nThis issue related to the Intel compiler should be solved by #208"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 22:47:12+00:00",
                    "text": "Gfortran issue reported as bug on https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95446"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-31 21:26:46+00:00",
                    "text": "in general, ready to merge.\nBut please discuss whether you are ok with all the warnings. I usually prefer to turn on all compiler warnings and remove them step by step. A few false positives will always remain.\nThe most of the warnings here are related to type conversions and can be easily fixed by introducing explicit type conversions."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-31 21:47:48+00:00",
                    "text": "For the false positives, would it be possible/adequate to output a warning for the users?\nWhich false positives do you mean?\n\nFrom my side, it was just a general comment that sometimes compilers give warnings despite the code is valid code. For example there are warnings about uninitialized variables even though the the choice of variables of the calling function makes it impossible to use a variable without initialization.\nThere are at least three ways to solve this:\n\nWrite some boilerplate code that silences the compiler\nTurn off the warning selectively (not always possible)\nHave two build configurations. A picky one for development (developers need to get used to a certain amount of warnings) and one for production that does not scares normal users."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-01 07:29:24+00:00",
                    "text": "For the false positives, would it be possible/adequate to output a warning for the users?\nWhich false positives do you mean?\n\nFrom my side, it was just a general comment that sometimes compilers give warnings despite the code is valid code. For example there are warnings about uninitialized variables even though the the choice of variables of the calling function makes it impossible to use a variable without initialization.\n\n# prevent false positive (https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95446)\nif(CMAKE_Fortran_COMPILER_ID STREQUAL GNU)\n  set_source_files_properties(\"test_optval.f90\" PROPERTIES COMPILE_FLAGS \"-Wno-error=pedantic\")\nendif()\n\nI meant such false positives, that are due to, e.g. a bug in the compiler. If someone introduces new procedures in this test, he/she might want to know that these warnings are removed. However, if there is no warnings, he will need to check the CMakefile to know it.\n\nThere are at least three ways to solve this:\n\nWrite some boilerplate code that silences the compiler\nTurn off the warning selectively (not always possible)\nHave two build configurations. A picky one for development (developers need to get used to a certain amount of warnings) and one for production that does not scares normal users.\n\n\nIMO we should go for the 3rd option. The 1st option should never be taken, and the 2nd option should be avoided as much as possible."
                },
                {
                    "user": "certik",
                    "date": "2020-06-04 16:03:03+00:00",
                    "text": "3 positive reviews, merging."
                }
            ]
        },
        {
            "number": 204,
            "user": "MarDiehl",
            "date": "2020-05-30 09:38:12+00:00",
            "title": "Gfortran 10 compile error",
            "text": "When trying to compile the library with Gfortran 10, i get a bunch of error messages like\n/home/m/upstream/stdlib/src/stdlib_experimental_ascii.f90:18:55:\n\n   18 |     character(len=1), public, parameter :: NUL = achar(z'00') !! Null\n      |                                                       1\nError: A BOZ literal constant at (1) cannot appear as an actual argument in a function reference\n\nand\n/home/m/upstream/stdlib/src/stdlib_experimental_ascii.f90:169:41:\n\n  169 |         is_blank = (c == ' ') .or. (ic == z'09');\n      |                                         1\nError: BOZ literal constant near (1) cannot appear as an operand of a relational operator [see \u2018-fno-allow-invalid-boz\u2019]",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-05-30 15:59:22+00:00",
                    "text": "@MarDiehl thanks for reporting it, we have to fix it."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-01 08:11:01+00:00",
                    "text": "From here:\nUp to Fortran 95, BOZ literals were only allowed to initialize integer variables in DATA statements. Since Fortran 2003 BOZ literals are also allowed as argument of REAL, DBLE, INT and CMPLX; the result is the same as if the integer BOZ literal had been converted by TRANSFER to, respectively, real, double precision, integer or complex.\n\nTherefore, If I understand it well, the bug could be solved with\n    character(len=1), public, parameter :: NUL = achar(int(z'00')) !! Null"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-06-01 08:26:08+00:00",
                    "text": "Therefore, If I understand it well, the bug could be solved with\n    character(len=1), public, parameter :: NUL = achar(int(z'00')) !! Null\n\nyes, I've fixed this already in my latest commit in the standard-checks branch"
                }
            ]
        },
        {
            "number": 203,
            "user": "MarDiehl",
            "date": "2020-05-30 08:49:12+00:00",
            "title": "Distribution packages",
            "text": "To gain momentum, I would be important that the library is available to many users without much effort. HPC maintainers can of course compile the library on their own, but for most of the users this would increase the entry barrier. I guess most Python and C users have never compiled the respective standard library. Therefore, we should try to release distribution packages (Debian/Ubuntu, Fedora, Conda, MacOS) as early as possible.\nI would volunteer to do that for Arch Linux, but I think Ubuntu and MacOS would be more relevant.\nIn this context, I also believe in the \"release early, release often\" philosophy. The GIMP developers also state:\n\n2019 was the second year in a row where we shipped updates with new features in the stable branch. Our assumption was that this could change the public\u2019s perception of the ongoing development efforts and shift the balance towards having more contributors. Here is why.\n\n\nBetween 2012 and 2018 (v2.8 and v2.10 releases respectively), we worked hard and added a ton of improvements and new features, we demoed them on social networks, mentioned them in annual reports etc., and yet we kept hearing how GIMP was dead because those changes were not in any stable releases. The same thing was happening before in the four years between v2.6 and v2.8.\n\n\nMoreover, this was preventing people from contributing as they would have to wait a long time to see their contribution actually used. That wasn\u2019t sparking an interest really.\n\n\nHence, after the v2.10 release, we kept adding new features at the same pace and started producing regular updates with those features, and all of a sudden we started hearing how we \u201cpicked up the pace\u201d!\n\n\nSo this could be a lesson for other projects: arguing against the irrational is futile. Just don\u2019t keep people waiting. If you did something good, share it!\n\nFrom https://www.gimp.org/news/2020/01/04/gimp-and-gegl-in-2019/\nTherefore, having in the initial rapid growth period a new release very often (let's say 4 times a year) would be a good marketing instrument. If people get the updates from their respective package managers, they will also serve as beta testers. We would need of course to clearly state that the API might change.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-05-30 14:28:55+00:00",
                    "text": "@MarDiehl thanks for the feedback.\nIn the long run, we are hoping our Fortran Package Manager (fpm) will be successful. So the distribution will become very simple on all platforms.\nIn addition to fpm however, we still want to make regular releases and generate a source tarball that contains the pre-generated files (the git repository requires the fypp pre-processor, but the tarball would not), automatically built by our CI.\nAnd it would be this tarball that would go into distributions.\nIf you want to help us with this process, that would be really awesome! Thank you."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 15:05:51+00:00",
                    "text": "@certik\nSure, I have experience with generating packages for Arch linux, Ubuntu, and Fedora.\nOne further advantage of having distribution packages is that we benefit from their CI tools. Conda forge for example automatically creates packages for different operating systems.\nI have another question regarding the distribution: How will the standard lib be used and versioned?\nI assume we would have something like\nuse stdlib\n\nand link with\n-lstd\n\nat least on Unix-like operation systems. How would support for different versions work in that case? According to semver, API changes are fine between major versions. That could mean that something like\nuse stdlib1\n\nwould be needed. At least I'm not aware of any other OS-indendent mechanism to select the correct Fortran mod file"
                },
                {
                    "user": "certik",
                    "date": "2020-05-30 15:54:21+00:00",
                    "text": "Regarding versioning, I suggest to use fpm in the long run, which will allow to use different versions.\nRegarding the API, currently we have separate modules such as stdlib_io, or stdlib_linalg, and because we always put new functionality into the \"experimental\" namespace first, the modules are called stdlib_experimental_io and stdlib_experimental_linalg.\nOnce we move it from \"experimental\", it will just become stdlib_io, or stdlib_linalg. Finally, we will have to see if it makes sense to have some flat namespace such as stdlib. The general issue with that, and experience from Python packages is that once you put stuff in stdlib, you cannot take it away as it would break people's codes. So for now we chose not to introduce such a flat namespace, and that always gives us the option to do so in the future, as we gain more experience and usage of stdlib and have a better idea of what would make sense to put there, if anything."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 17:38:31+00:00",
                    "text": "@certik\nthanks for the clarification.\nI would still raise awareness for the issue of different versions. Even if at one point in future fpm is there, linux distributions will use their own package managers. Giving them the possibility to install stdlib in different versions would be really beneficial. Breaking changes to interfaces will certainly come and if that breaks existing code, people won't use stdlib again.\nIf different versions can be installed in parallel, developers can migrate to a new version if they like to. Unmaintained code will still work as before, just at the cost that an additional version of stdlib needs to be installed. This would also ease us from spending too much time and efforts on keeping backward compatibility."
                },
                {
                    "user": "certik",
                    "date": "2020-05-30 18:14:13+00:00",
                    "text": "@MarDiehl yes, for distributions we definitely want to allow installing any way they like, not force fpm on them.\nRegarding the versions, what are the possible paths forward?\n\n\nDo nothing in the API itself and just rely on the package version. Breaking change would require to install an older version.\n\n\nVersion the modules, so stdlib_io_v1 would be right now, and in the future if an incompatible API change has to happen, do stdlib_io_v2.\n\n\nAre there other ways to handle this?\nNote that our goal is not to change the API once it is settled. That is why we have a rigorous process how the API gets adopted, and first it goes into experimental so that people can start using it and we can ensure that the API will work. We haven't reached that point yet, but eventually we'll be ready to move some functionality from experimental to main. At that point, our expectation is that we will be supporting the API essentially forever. Just like standard Fortran does not change APIs in the backwards incompatible manner. If there ever comes a need for a new API, we would have to create a new module, or a function with a new name. So for now, I think we all mostly assumed we would use the option 1.\nBut we are open to discuss this, maybe the option 2 or some other alternative is better."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 19:46:46+00:00",
                    "text": "@certik\nI think a stable API is the ultimate goal one should aim for, but I doubt that it can be reached under all circumstances. At least I often figure out the best way of doing something much later. In such a situation, it would be foolish to use the initial, non-optimal solution instead of the new, better solution.\nAlso, I think breaking changes are not a bad thing in general. What is bad are unpredictable changes. Semver is exactly designed to handle this situation: An increase in the major version indicates breaking changes. This is transparent to the user. There are many applications that use python 2 and they happily coexist with python 3\nTherefore, I would prefer to have a clear plan for handling the case that backward compatibility can not be maintained. It will come earlier than one hopes. But to be honest, I currently don't have a good idea how plan B should look like. Making the version part of the module name is certainly a possibility. The so-name concept with symbolic links on linux is similar in spirit. Using names like stdlib_io1 (which might be a symlink pointing to stdlib_io1.1) would be explicit and clear. If the version your application needs does not exists, it will not compile.\nAs a final, personal comment I would like to add that I have the impression that the 'holy grail' of backward compatibility is a reason for the decline of Fortran. Of course there exists a lot of valuable old code, but always consider the interests of the slow ones is annoying for the innovative players. If you don't bother to update your application that is fine, but that should not stop others from doing so."
                }
            ]
        },
        {
            "number": 202,
            "user": "MarDiehl",
            "date": "2020-05-30 08:22:04+00:00",
            "title": "Minimum Fortran standard and compiler bugs",
            "text": "Excuse me if I have missed an existing discussion on this question, but I think it is rather important to explicitly state the minimum Fortran standard that is required to use the library.\nAccording to http://fortranwiki.org/fortran/show/Fortran+2008+status a reasonable amount of F2008 is available in Cray, GNU, IBM, Intel, and PGI compilers. Flang is certainly also a candidate for modern Fortran.\nI have tried Intel, GNU, and PGI (community edition) and made the following experiences:\n\nGNU: Can handle most of the syntax, but has issues with variable-length strings, user-defined IO, and derived types (finalize)\nIntel: Among the three tested compilers the most reliable one\nPGI: Feature-wise behind Intel and GNU, severe bugs.\n\nBased on this, I use only code that compiles and runs with Intel and GNU.\nI think for a standard library, it is of utmost importance to have clear rules on the following questions:\n\nWhich Fortran standard is required. While this question sounds simple, most of the compilers implement even older standards only partly and a few corner case statements are missing (see e.g. https://gcc.gnu.org/wiki/Fortran2008Status)\nWhat do we do if a compiler knows a certain statement, but execution crashes during runtime or gives wrong results (I experienced that for do concurrent)\n\nFor applications, it is practicable to specify a minimum compiler version (Requires Intel > 18.1, but note that 18.2 has a bug, or GNU > 8.1). If we would do something like that with a standard library, we are easily involved in politics with the compiler vendors. They might not be happy to hear that the standard library is not compatible with their product because they have not implemented statement XY.\nOn the long term, if the standard library project is successful, missing features are probably more relevant than actual compiler bugs. Let's assume that the Compiler update from version X to Y results in invalid code for do concurrent, but do concurrent is used in the standard library. Hopefully, the compiler vendors will run the test suite of the standard library before releasing version Y and know that they have to fix their product. However, I don't want to waive the use of error stop just because some of the compiler vendors think that F77 is modern enough",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-05-30 15:58:16+00:00",
                    "text": "Great points. I believe this is a duplicate of #15. Do you want to merge the two issues, for example by copying your arguments there and closing this one?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-30 17:49:38+00:00",
                    "text": "We mentioned this briefly in #188 but didn't make further progress. Yes, I think this is needed, especially regarding compilers and supported versions, less so for standard revisions.\nI think error stop and newunit are the only F2008 features we use, the rest is F2003 or earlier. I don't think we're using anything F2018 yet."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 21:38:08+00:00",
                    "text": "duplicate"
                }
            ]
        },
        {
            "number": 201,
            "user": "MarDiehl",
            "date": "2020-05-30 07:29:11+00:00",
            "title": "File system operations",
            "text": "While some functionality for file system related operations exist in Fortran, some rather relevant operations are not standardized.\nFor example, figuring out whether a path is a directory:\nhttps://stackoverflow.com/questions/9522933\nA function like \"isDirectory\" can be based on the corresponding C-functionality. Would that be an appropriate solution? I would certainly require a bunch of #ifdefs in the C-side of the implementation",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-05-30 16:03:41+00:00",
                    "text": "This is related to #14. I think we agreed that file system operations are in the scope. The naming convention should probably be is_directory or is_dir, and we should also look at how Python, Julia and Matlab name such functions. We are always trying to be consistent with other languages where it makes sense.\nThe main goal of stdlib is to figure out and document (in a spec) the API. The underlying implementation is secondary --- stdlib will provide a reference implementation and then compiler vendors are free to provide their own, different or more optimized implementation if they want. The only requirement is that it must run on all platforms, but probably calling into C if we have to would do it."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-30 17:44:38+00:00",
                    "text": "#22 for POSIX systems is also related."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-06-03 21:43:11+00:00",
                    "text": "I have thought a little bit about a possible contribution from my side, and I propose to add general path related functionality. Since the other language I am frequently using is python, I got my inspiration from\n\nos.path\npathlib\n\nIn python, the object oriented approach of pathlib is often favored over os.path. However, unless I overlooked something, I believe that the os.path approach is better suited for Fortran because one can not chain function calls.\n\nPython: p = path.absolute(),is_file()\nFortran: p = path_is_file(path_absolute(Str))\n\nWith Fortran variable length strings (allocatable), most operations are easily performed. However, there is one exception:\nos.path.commonpath(paths) takes a list of strings, in Fortran this would be an array of strings/characters and all of them would need to have the same length. Alternatively, one can use an interface for a series of fpp generated functions with signatures of type path_commonpath(path1,path2),  path_commonpath(path1,path2,path3), ...\nWhile most functionality will be implemented in pure Fortran, certain operations require file system functions from C.\nThere is one more thing I need to mention: If Windows support is needed, someone else has to provide it. I've never compiled a Fortran program on windows and the path operations differ significantly. pathlib has essentially two implementations and I assume we are in the same situation. If someone volunteers, I would prefer that we work in parallel on both implementation. My time budget is about 4h/week and I would hope to finish the whole implementation in 3 months."
                },
                {
                    "user": "epagone",
                    "date": "2020-06-03 22:10:22+00:00",
                    "text": "With Fortran variable length strings (allocatable), most operations are easily performed. However, there is one exception:\nos.path.commonpath(paths) takes a list of strings, in Fortran this would be an array of strings/characters and all of them would need to have the same length. Alternatively, one can use an interface for a series of fpp generated functions with signatures of type path_commonpath(path1,path2), path_commonpath(path1,path2,path3), ...\n\nOr it can be solved by an implementation of the iso_varying_string module or advanced libraries of string handling routines as summarised in this other issue."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-15 21:35:42+00:00",
                    "text": "However, there is one exception:\nos.path.commonpath(paths) takes a list of strings, in Fortran this would be an array of strings/characters and all of them would need to have the same length. Alternatively, one can use an interface for a series of fpp generated functions with signatures of type path_commonpath(path1,path2), path_commonpath(path1,path2,path3), ...\n\nfypp could be used for that too.\nHowever, implementing and using iso_varying_string module would be the best option IMO."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-06-19 21:11:08+00:00",
                    "text": "FYI:\nI have some related modules (M_path, M_io, and M_system) in the GPF\n(General Purpose Fortran) site on github if you are looking for ideas\non how the API might look from a Fortran perspective.\nhttps://github.com/urbanjost\nInstead of the entire GPF, self-contained subsets of two of the modules\nare available:\nhttps://github.com/urbanjost/M_io\nhttps://github.com/urbanjost/M_system\nThe M_path module description (actually all the GPF routines) can be\nfound in the manpage index:\nGPF manpages\nI do not have a stand-alone M_path.f90. It is currently only in the GPF\ncollection, as it uses a number of string routines from M_strings.f90."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-06-21 10:29:31+00:00",
                    "text": "@urbanjost Nice code, thanks for the hint."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-06-21 18:31:19+00:00",
                    "text": "Thanks. No problem. Some is better than others.  Seeded it with a lot of code I had around with the hopes of getting a development community started to expand it and clean it up but it did not catch on as I had hoped. stdlib(3f) seems to have far more momentum behind it. If you find anything useful in it feel free to use it for stdlib(3f)."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-16 11:41:13+00:00",
                    "text": "The Oracle Fortran Library seems to have covered some file system operations: https://docs.oracle.com/cd/E19957-01/805-4942/index.html\nBased upon the function names, it looks like it is actually implemented in C. Perhaps it can serve as reference.\nEdit: The Absoft Compiler also has similar compatibility libraries - https://www.absoft.com/wp-content/uploads/2015/08/Support-Libraries.pdf\nEdit2: Compaq Fortran also had it's own library of C-like functions - http://h30266.www3.hpe.com/odl/unix/progtool/cf95au56/dfumroutines.htm#overview_lib_rout"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-16 12:44:20+00:00",
                    "text": "Perhaps the  Fortyxima project (https://bitbucket.org/aradi/fortyxima/src/develop/fortyxima/filesys/) from @aradi could serve as a starting point?"
                },
                {
                    "user": "aradi",
                    "date": "2020-07-16 14:52:00+00:00",
                    "text": "If there is interest, I am happy to clean it up a bit, so that it meets the stdlib coding standards. \ud83d\ude09"
                },
                {
                    "user": "certik",
                    "date": "2020-07-16 15:34:14+00:00",
                    "text": "@urbanjost don't feel bad, a lot of us tried to do the same. Thanks for the pointer, I added it to #1, thanks for sharing the link. As you can see there, we list 10 such libraries that people did (mine is there too), and we all tried to get a community started around it. It's extremely hard. But I think we finally succeeded this time with stdlib and with fortran-lang.org. I should write a blog post about this --- Fortran is far from being saved, but just the fact that we managed to get the community together is the first necessary step, and it looked impossible to me just a year ago. And yet I think we succeeded at this first step at this point.\n@ivan-pi thanks for the pointers, @aradi I think there will be interested, let's discuss the API."
                },
                {
                    "user": "aradi",
                    "date": "2020-07-16 21:01:58+00:00",
                    "text": "Sure, I opened a separate issue for this (#220)"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-26 18:37:03+00:00",
                    "text": "I have a first prototype of a library that has functions from pythons os and os.path: https://github.com/MarDiehl/stdlib_os\nPure Fortran where possible, but most file system related operations rely on C routines.\nWorks on linux with GNU and Intel compilers.\nExceptions in python translate into error stop. Currently without a message, but that can be changed."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-29 19:47:30+00:00",
                    "text": "I have a first prototype of a library that has functions from pythons os and os.path: https://github.com/MarDiehl/stdlib_os\nPure Fortran where possible, but most file system related operations rely on C routines.\nWorks on linux with GNU and Intel compilers.\nExceptions in python translate into error stop. Currently without a message, but that can be changed.\n\n@MarDiehl I looked to the code. There are already quite a bunch of procedures for Linux OS. Nicely done. Would it be an idea to submit a PR to discuss further the API?"
                },
                {
                    "user": "certik",
                    "date": "2020-07-29 20:09:22+00:00",
                    "text": "Thanks @MarDiehl for this!"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-29 20:47:48+00:00",
                    "text": "Thank you, I reviewed the repo and recommend moving forward with the PR. We just need to decide how to not build it on Windows."
                },
                {
                    "user": "certik",
                    "date": "2020-07-29 21:06:24+00:00",
                    "text": "The goal is to have the file system operations working on Windows also eventually, correct?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-29 21:10:21+00:00",
                    "text": "Thank you, I reviewed the repo and recommend moving forward with the PR. We just need to decide how to not build it on Windows.\n\nOr we should try to find a volunteer fluent with Windows ;)\nIf the API is already discussed and decided, this should facilite the development right?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-29 21:21:08+00:00",
                    "text": "Thanks @MarDiehl for the prototype. Is it possible to identify the common functionality with respect to the API proposal by @aradi in #220?  @arjenmarkus left a comment there on how to deal with Windows."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-29 22:03:18+00:00",
                    "text": "@certik Sorry I had assumed that Martin's implementation depended on POSIX, but on second look I don't see it in the code. If this relies only on C stdlib, I think it should work fine on Windows. But perhaps some OS-specific extensions are used. @MarDiehl did you try it on Windows?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-29 22:06:01+00:00",
                    "text": "Good point, @ivan-pi. I suggest @MarDiehl and @aradi join forces and present a coherent API. I like Martin's as is, it's clear and familiar to me from Python's API."
                },
                {
                    "user": "certik",
                    "date": "2020-07-29 23:08:09+00:00",
                    "text": "If it relies on Linux specific things, then we can extend it using ifdefs to also use Windows API to work on Windows."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-30 04:27:17+00:00",
                    "text": "Please find the answers to the questions below:\n\nThe goal is to have the file system operations working on Windows also eventually, correct?\n\nYes, it would be nice if someone contributes this. The actual implementation should not be too difficult, but it needs to be done by a windows native.\n\nThank you, I reviewed the repo and recommend moving forward with the PR. We just need to decide how to not build it on Windows.\n\nOn python, the actual implementation of is called posixpath on posix and ntpath on Windows and will be then mapped to os.path. I would recommend to do the same thing here, but the implementation depends on whether a standard C preprocessor is a prerequisite for compilation stdlib or whether fypp should be used exclusively. Also, the integration into fpm is still a very open topic to me.\n\nSorry I had assumed that Martin's implementation depended on POSIX, but on second look I don't see it in the code. If this relies only on C stdlib, I think it should work fine on Windows. But perhaps some OS-specific extensions are used. @MarDiehl did you try it on Windows?\n\nI have not tried on Windows but the implementation it is certainly POSIX specific (/ for path separation, ~ for the home directory). Some C headers (e.g. unistd.h) are also not available on Windows. But I have not tried to build it on windows.\n\nIf it relies on Linux specific things, then we can extend it using ifdefs to also use Windows API to work on Windows.\n\nI think there is less common code between POSIX and C than it seems on first glance. Most of the C code is probably OS specific and a all the path routines subtly depend on details of path names. Therefore, I opt to have two fully independent implementations."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-30 04:47:44+00:00",
                    "text": "Thanks for all the feedback. Actually, before opening a PR I probably add a few more functions and certainly do some testing.\nI also have three direct questions:\n\n\nIs the following naming convention ok:\nuse stdlib_os\nuse stdlib_os_path\n\ncall chdir('/home') ! function from stdlib_os, no stdlib_os prefix\nprint*, islink('/home') ! function from stdlib_os_path, no stdlib_os_path prefix\n\n\n\nI am using allocatable strings from the Fortran standard.\nAs discussed in the last monthly call, I don't see a reason to use specific string implementations (e.g.  iso_varying_string). But the decision whether stdlib should have a special string (or even path) type goes beyond the scope of implementing os and os_path. I hope my implementation shows that allocatable strings are all we need. The consequence of this decision is that we can't have object oriented string libraries.\nThe only inconvenience of the current implementation is the behavior of split/splitext/splitdrive: They return an size 2 array with length of its strings beeing the maximum length of head and tail. I would attribute this flaw to the lack of a tuple or list type, not to a limitation of allocatable strings.\n\n\nCould a MacOS user test the code?"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-30 06:35:12+00:00",
                    "text": "Hi everyone,\n\nI volunteer to contribute the Windows side of things - while I usually\navoid Windows-specific stuff, I do use that platform all the time, as well\nas the ingressions of Linux (or Unix?) on that platform - Cygwin and\nMinGW.  So I should be able to test that it all works on these platforms. I\nhave no access to MacOS unfortunately, so that will have to be someone else.\n\nRegards,\n\nArjen\n\nOp do 30 jul. 2020 om 06:47 schreef Martin Diehl <notifications@github.com>:\n\u2026\n Thanks for all the feedback. Actually, before opening a PR I probably add\n a few more functions and certainly do some testing.\n I also have three direct questions:\n\n    1.\n\n    Is the following naming convention ok:\n\n    use stdlib_os\n    use stdlib_os_path\n\n    call chdir('/home') ! function from stdlib_os, no stdlib_os prefix\n    print*, islink('/home') ! function from stdlib_os_path, no stdlib_os_path prefix\n\n    2.\n\n    I am using allocatable strings from the Fortran standard.\n    As discussed in the last monthly call, I don't see a reason to use\n    specific string implementations (e.g. iso_varying_string). But the\n    decision whether stdlib should have a special string (or even path) type\n    goes beyond the scope of implementing os and os_path. I hope my\n    implementation shows that allocatable strings are all we need. The\n    consequence of this decision is that we can't have object oriented string\n    libraries.\n    The only inconvenience of the current implementation is the behavior\n    of split/splitext/splitdrive: They return an size 2 array with length\n    of its strings beeing the maximum length of head and tail. I would\n    attribute this flaw to the lack of a tuple or list type, not to a\n    limitation of allocatable strings.\n    3.\n\n    Could a MacOS user test the code?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#201 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR2UPKQFZN5WQ6ZRHSLR6D3P3ANCNFSM4NOSR3IA>\n ."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-30 21:20:03+00:00",
                    "text": "Hi everyone, I volunteer to contribute the Windows side of things - while I usually avoid Windows-specific stuff, I do use that platform all the time, as well as the ingressions of Linux (or Unix?) on that platform - Cygwin and MinGW. So I should be able to test that it all works on these platforms. I have no access to MacOS unfortunately, so that will have to be someone else. Regards, Arjen\n\nGreat! I think in such system-dependent operations, windows specific things are unavoidable and I would not consider them to be a bad thing as long as they are compiler independent. Probably the actual modifications to the code (changing separator, using difference C headers and functions) are not very difficult. Getting a system-dependent build configuration to work is probably the more time consuming task.\nWe also need to agree on the handling of line endings in the repository. I assume currently it is UNIX style. Would it make sense to enforce UNIX style line endings via git configuration in general? And do you want an exception for windows-only code then?\nI gave you access to the repository, please create a new branch for windows changes or simply fork the whole repository."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-30 21:24:07+00:00",
                    "text": "As pointed out by @aradi, the python naming conventions are not very 'fortranig'. I therefore suggest the following names:\nos\npython        Fortran\n\n\nchdir         change_directory\ngetcwd        get_current_working_directory\nmkdir         make_directory\nrename      \nrmdir         remove_directory\nsymlink       create_symlink?\nunlink        remove_File\n\n\nos.path\npython        Fortran\n\nabspath       abs_path\nbasename      base_name\ncommonpath    common_path\ncommonprefix  common_prefix\ndirname       dir_name\nexists\nexpanduser    expand_user\nexpandvars    expand_vars\ngetatime      get_atime\ngetctime      get_ctime \ngetmtime      get_mtime      \ngetsize       get_size\nisabs         is_abs\nisdir         is_dir\nisfile        is_file\nislink        is_link\nismount       is_mount\njoin \nnormcase      norm_case\nnormpath      norm_path\nsamefile      same_file\nrelpath       rel_path/relative_path?\nsplit\nsplitdrive    split_drive\nsplitext      split_ext"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-30 21:51:04+00:00",
                    "text": "@MarDiehl Your suggestions all look good to me. Suggestion for consistency:\n\ncreate_symlink -> create_symbolic_link\nabs_path -> absolute_path\ndir_name -> directory_name\nexpand_vars -> expand_variables\nis_dir -> is_directory"
                },
                {
                    "user": "certik",
                    "date": "2020-07-30 22:03:10+00:00",
                    "text": "I think the two syllables words should be just joined, I think that is actually very fortranic. So abspath over abs_path and basename over base_name. Not everybody agrees with this recommendation, but I know a lot of Fortran programmers do agree, so that is what we recommend here:\nhttps://www.fortran90.org/src/best-practices.html#naming-convention\nThe underscores should be used if you want to join several syllables or words such as in get_command_argument. But if you can make it just two syllables like getarg, then that works too and I think it looks much better without underscores.\nSo both of these work: dirname, directory_name. But dir_name I think is suboptimal."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-31 06:20:25+00:00",
                    "text": "I have most of it working now, with some quirks and limitations (symbolic\nlinks on Windows are different than on Linux - in a similar way I guess\nthat pointers in Fortran and C are different ;) - so that is not supported\nin this version), but one severe problem: a coredump on renaming files.\n\nWell, let me summarise:\n\n   - Cygwin: no problem, it all worked out of the box, as they say.\n   (gfortran compiler: 9.3.0)\n\n\n   - MinGW: the gfortran compiler I have available is too old: 7.3.0, so it\n   does not have -std=f2018 and to compile the Fortran code I should probably\n   eliminate that flag. (I tried with -std=f2008)\n   - On plain/bare Windows: some changes to the C code, though most of the\n   functions work in quite the same way, with just a twist (_getcwd() instead\n   of getcwd() for instance and some macros and include files). Curiously\n   enough the CMake build says to build the test program, but it does not. I\n   have to do that manually.\n   - All tests seem fine, except renaming - that leads to a crash. Not sure\n   yet where this happens or which compiler is responsible.\n\n\n\nOp do 30 jul. 2020 om 23:20 schreef Martin Diehl <notifications@github.com>:\n\u2026\n Hi everyone, I volunteer to contribute the Windows side of things - while\n I usually avoid Windows-specific stuff, I do use that platform all the\n time, as well as the ingressions of Linux (or Unix?) on that platform -\n Cygwin and MinGW. So I should be able to test that it all works on these\n platforms. I have no access to MacOS unfortunately, so that will have to be\n someone else. Regards, Arjen\n\n Great! I think in such system-dependent operations, windows specific\n things are unavoidable and I would not consider them to be a bad thing as\n long as they are compiler independent. Probably the actual modifications to\n the code (changing separator, using difference C headers and functions) are\n not very difficult. Getting a system-dependent build configuration to work\n is probably the more time consuming task.\n\n We also need to agree on the handling of line endings in the repository. I\n assume currently it is UNIX style. Would it make sense to enforce UNIX\n style line endings via git configuration in general? And do you want an\n exception for windows-only code then?\n\n I gave you access to the repository, please create a new branch for\n windows changes or simply fork the whole repository.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#201 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR6VXVUCC7I7OOBFU7TR6HPZJANCNFSM4NOSR3IA>\n ."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-31 06:32:53+00:00",
                    "text": "The problem lies with the f_c_string function. Very odd. I have reduced the\nprogram to little more than a call to that function and I get a crash.\n\nOp vr 31 jul. 2020 om 08:20 schreef Arjen Markus <arjen.markus895@gmail.com\n\u2026\n:\n I have most of it working now, with some quirks and limitations (symbolic\n links on Windows are different than on Linux - in a similar way I guess\n that pointers in Fortran and C are different ;) - so that is not supported\n in this version), but one severe problem: a coredump on renaming files.\n\n Well, let me summarise:\n\n    - Cygwin: no problem, it all worked out of the box, as they say.\n    (gfortran compiler: 9.3.0)\n\n\n    - MinGW: the gfortran compiler I have available is too old: 7.3.0, so\n    it does not have -std=f2018 and to compile the Fortran code I should\n    probably eliminate that flag. (I tried with -std=f2008)\n    - On plain/bare Windows: some changes to the C code, though most of\n    the functions work in quite the same way, with just a twist (_getcwd()\n    instead of getcwd() for instance and some macros and include files).\n    Curiously enough the CMake build says to build the test program, but it\n    does not. I have to do that manually.\n    - All tests seem fine, except renaming - that leads to a crash. Not\n    sure yet where this happens or which compiler is responsible.\n\n\n\n Op do 30 jul. 2020 om 23:20 schreef Martin Diehl ***@***.***\n >:\n\n> Hi everyone, I volunteer to contribute the Windows side of things - while\n> I usually avoid Windows-specific stuff, I do use that platform all the\n> time, as well as the ingressions of Linux (or Unix?) on that platform -\n> Cygwin and MinGW. So I should be able to test that it all works on these\n> platforms. I have no access to MacOS unfortunately, so that will have to be\n> someone else. Regards, Arjen\n>\n> Great! I think in such system-dependent operations, windows specific\n> things are unavoidable and I would not consider them to be a bad thing as\n> long as they are compiler independent. Probably the actual modifications to\n> the code (changing separator, using difference C headers and functions) are\n> not very difficult. Getting a system-dependent build configuration to work\n> is probably the more time consuming task.\n>\n> We also need to agree on the handling of line endings in the repository.\n> I assume currently it is UNIX style. Would it make sense to enforce UNIX\n> style line endings via git configuration in general? And do you want an\n> exception for windows-only code then?\n>\n> I gave you access to the repository, please create a new branch for\n> windows changes or simply fork the whole repository.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <#201 (comment)>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAN6YR6VXVUCC7I7OOBFU7TR6HPZJANCNFSM4NOSR3IA>\n> .\n>"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-31 10:19:08+00:00",
                    "text": "Of course it was NOT in f_c_string. It was not even in the rename routine\nor its brethren. It was in ismount_c() which is called slightly later in\nthe program. The line\n  parent = (char *) malloc(strlen(path)+3);\nshould be:\n  parent = (char *) malloc(strlen(path)+4);\n\nWith that found, the crash makes sense - strlen() does not count the\nrequired NUL character. So the construction of the parent will cause an\never so slightly memory overflow.\nNext step: consolidate all my changes and only the necessary ones ;).\n\nOp vr 31 jul. 2020 om 08:32 schreef Arjen Markus <arjen.markus895@gmail.com\n\u2026\n:\n The problem lies with the f_c_string function. Very odd. I have reduced\n the program to little more than a call to that function and I get a crash.\n\n Op vr 31 jul. 2020 om 08:20 schreef Arjen Markus <\n ***@***.***>:\n\n> I have most of it working now, with some quirks and limitations (symbolic\n> links on Windows are different than on Linux - in a similar way I guess\n> that pointers in Fortran and C are different ;) - so that is not supported\n> in this version), but one severe problem: a coredump on renaming files.\n>\n> Well, let me summarise:\n>\n>    - Cygwin: no problem, it all worked out of the box, as they say.\n>    (gfortran compiler: 9.3.0)\n>\n>\n>    - MinGW: the gfortran compiler I have available is too old: 7.3.0, so\n>    it does not have -std=f2018 and to compile the Fortran code I should\n>    probably eliminate that flag. (I tried with -std=f2008)\n>    - On plain/bare Windows: some changes to the C code, though most of\n>    the functions work in quite the same way, with just a twist (_getcwd()\n>    instead of getcwd() for instance and some macros and include files).\n>    Curiously enough the CMake build says to build the test program, but it\n>    does not. I have to do that manually.\n>    - All tests seem fine, except renaming - that leads to a crash. Not\n>    sure yet where this happens or which compiler is responsible.\n>\n>\n>\n> Op do 30 jul. 2020 om 23:20 schreef Martin Diehl <\n> ***@***.***>:\n>\n>> Hi everyone, I volunteer to contribute the Windows side of things -\n>> while I usually avoid Windows-specific stuff, I do use that platform all\n>> the time, as well as the ingressions of Linux (or Unix?) on that platform -\n>> Cygwin and MinGW. So I should be able to test that it all works on these\n>> platforms. I have no access to MacOS unfortunately, so that will have to be\n>> someone else. Regards, Arjen\n>>\n>> Great! I think in such system-dependent operations, windows specific\n>> things are unavoidable and I would not consider them to be a bad thing as\n>> long as they are compiler independent. Probably the actual modifications to\n>> the code (changing separator, using difference C headers and functions) are\n>> not very difficult. Getting a system-dependent build configuration to work\n>> is probably the more time consuming task.\n>>\n>> We also need to agree on the handling of line endings in the repository.\n>> I assume currently it is UNIX style. Would it make sense to enforce UNIX\n>> style line endings via git configuration in general? And do you want an\n>> exception for windows-only code then?\n>>\n>> I gave you access to the repository, please create a new branch for\n>> windows changes or simply fork the whole repository.\n>>\n>> \u2014\n>> You are receiving this because you were mentioned.\n>> Reply to this email directly, view it on GitHub\n>> <#201 (comment)>,\n>> or unsubscribe\n>> <https://github.com/notifications/unsubscribe-auth/AAN6YR6VXVUCC7I7OOBFU7TR6HPZJANCNFSM4NOSR3IA>\n>> .\n>>\n>"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-07-31 11:22:30+00:00",
                    "text": "Of course it was NOT in f_c_string. It was not even in the rename routine or its brethren. It was in ismount_c() which is called slightly later in the program. The line parent = (char *) malloc(strlen(path)+3); should be: parent = (char *) malloc(strlen(path)+4); With that found, the crash makes sense - strlen() does not count the required NUL character. So the construction of the parent will cause an ever so slightly memory overflow.\n\ngood catch. My C knowledge is quite bad, it's almost 15 years since I've learned it at university"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-31 11:27:10+00:00",
                    "text": "It is one of the easiest mistakes to make in C - I have had my share of\nthem. Which is one reason I do like Fortran :).\n\nOp vr 31 jul. 2020 om 13:22 schreef Martin Diehl <notifications@github.com>:\n\u2026\n Of course it was NOT in f_c_string. It was not even in the rename routine\n or its brethren. It was in ismount_c() which is called slightly later in\n the program. The line parent = (char *) malloc(strlen(path)+3); should be:\n parent = (char *) malloc(strlen(path)+4); With that found, the crash makes\n sense - strlen() does not count the required NUL character. So the\n construction of the parent will cause an ever so slightly memory overflow.\n\n good catch. My C knowledge is quite bad, it's almost 15 years since I've\n learned it at university\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#201 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YRZKCVPG72TRLUKNRWLR6KSQJANCNFSM4NOSR3IA>\n ."
                },
                {
                    "user": "aradi",
                    "date": "2020-08-01 10:44:19+00:00",
                    "text": "@MarDiehl Looks good to me. I'd propose to use dir instead of directory though (consistently everywhere) as \"directory\" is a very long word...\n@certik I really like your idea as it almost 100% matches the rules on using dashes in composed nouns in my native language (Hungarian) \ud83d\ude04 . However, I think, it would be still confusing for newcomers. Also, it does not match current Fortran naming practice (e.g. type(c_ptr), move_alloc, compiler_version, character_kinds, num_images, etc)."
                }
            ]
        },
        {
            "number": 200,
            "user": "jvdp1",
            "date": "2020-05-24 15:09:45+00:00",
            "title": "Small re-organizations and additions",
            "text": "",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-05-24 15:49:35+00:00",
                    "text": "I think the CoC should stay in the root location for better visibility and also GitHub I think links to it from the UI in some circumstances.\n\u2026\nOn Sun, May 24, 2020, at 9:09 AM, Jeremie Vandenplas wrote:\n\n You can view, comment on, or merge this pull request online at:\n\n #200\n\n Commit Summary\n\n  * docreag\n File Changes\n\n  * *M* API-doc-FORD-file.md\n <https://github.com/fortran-lang/stdlib/pull/200/files#diff-6cd537095fc5651e430618f903fb71f9> (33)\n  * *R* doc/contributing/CodeOfConduct.md\n <https://github.com/fortran-lang/stdlib/pull/200/files#diff-2f25d9979e032155c2fbc4e588cd8b64> (0)\n  * *R* doc/contributing/StyleGuide.md\n <https://github.com/fortran-lang/stdlib/pull/200/files#diff-728d6876b30ca7b6a7ed426d7d9f5c8c> (0)\n  * *R* doc/contributing/Workflow.md\n <https://github.com/fortran-lang/stdlib/pull/200/files#diff-52a60fd4d560eb9ba7c49f5a832d0286> (0)\n  * *A* doc/contributing/index.md\n <https://github.com/fortran-lang/stdlib/pull/200/files#diff-206333ee285e49e9c0e445faf87cdc7c> (7)\n  * *M* doc/index.md\n <https://github.com/fortran-lang/stdlib/pull/200/files#diff-5db2c860d4e7e5ef74eb7cfc33d99f8e> (2)\n Patch Links:\n\n  * https://github.com/fortran-lang/stdlib/pull/200.patch\n  * https://github.com/fortran-lang/stdlib/pull/200.diff\n \u2014\n You are receiving this because your review was requested.\n Reply to this email directly, view it on GitHub\n <#200>, or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAAFAWFK26GFXD4NGR62WCTRTE2ENANCNFSM4NI5SLTA>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-25 16:35:26+00:00",
                    "text": "I think the CoC should stay in the root location for better visibility and also GitHub I think links to it from the UI in some circumstances.\n\nI inserted a note about the CoC in the first page."
                },
                {
                    "user": "certik",
                    "date": "2020-05-25 19:23:20+00:00",
                    "text": "Ah, my bad -- I thought you moved the CoC file from the root directory, but you only moved the one from doc/ directory (I did the initial review from my phone). However, your small note that you added at the main API page helps, I think it fits there.\nSo +1 to merge as is."
                }
            ]
        },
        {
            "number": 199,
            "user": "jvdp1",
            "date": "2020-05-23 15:05:21+00:00",
            "title": "Addition of links for Ford",
            "text": "",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2020-05-26 15:15:58+00:00",
                    "text": "Also, just FYI, you can download the FORD documentation generated to get a preview and double check formatting etc. The build for your latest push is here: https://github.com/fortran-lang/stdlib/actions/runs/113339579 and if you click the artifact archive it will download to your local machine."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-26 18:01:11+00:00",
                    "text": "Also, just FYI, you can download the FORD documentation generated to get a preview and double check formatting etc. The build for your latest push is here: https://github.com/fortran-lang/stdlib/actions/runs/113339579 and if you click the artifact archive it will download to your local machine.\n\nThanks for the tip."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-26 18:12:48+00:00",
                    "text": "@zbeekman Thank you for your review. I modified the files as suggested."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-27 19:33:31+00:00",
                    "text": "Good. I'll merge it."
                }
            ]
        },
        {
            "number": 198,
            "user": "zbeekman",
            "date": "2020-05-19 16:50:10+00:00",
            "title": "Speed up doc builds & improve documentation",
            "text": "The main motivation for this PR is to speed up non-deployment builds which has been accomplished via:\n\nOnly documenting public/protected entities, not private ones\nReduce MAXRANK from 4 to 3\nTurn off graph and search generation on non-deployment builds\n\nIn addition, the documentation was fleshed out & improved, primarily in the FORD \"pages\" section. I used the markdown include capabilities to duplicate/include the LICENSE, WORKFLOW.md, STYLE_GUIDE.md etc. in the \"pages\" documentation. I also improved the main index.md \"pages\" landing page and the \"specs\" landing page.\nFurthermore I edited the stdlib_experimental_error spec to illustrate the usage of FORD's linking syntax as requested by @jvdp1. It should be noted that we may want to remove the links from the headings as they break the markdown-toc extension (the TOC does not include a link to the section if the header has a link in it).\nFinally I prettified and edited the FORD markdown in the implementation of stdlib_experimental_error.f90 a little bit and linked it back to the spec.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-05-19 17:06:58+00:00",
                    "text": "Thanks for this work!\nI don't understand the failures --- they seem unrelated to this PR?"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-19 17:34:28+00:00",
                    "text": "I don't understand the failures --- they seem unrelated to this PR?\n\nSeems like the canonical/ubuntu website went down or something. I can take a look."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-19 17:55:29+00:00",
                    "text": "There's an issue in the documentation workflow file... debugging."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-19 18:19:50+00:00",
                    "text": "Things should be ready to merge pending review by interested parties.\nEDIT: NOTE: Documentation build time down to 13s from ~13.5 minutes! (For non-release builds, i.e. PRs.) We could try re-enabling the graphs to see what impact that makes."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-19 21:13:38+00:00",
                    "text": "Typo fixed, should be ready to merge. I'll leave it here a bit longer in case anyone else has feedback, but feel free to merge if you like."
                },
                {
                    "user": "certik",
                    "date": "2020-05-19 21:16:41+00:00",
                    "text": "@zbeekman go ahead and merge it. I think we are all in agreement. Thank you again for your work on this, we all appreciate it."
                }
            ]
        },
        {
            "number": 197,
            "user": "zbeekman",
            "date": "2020-05-18 21:05:46+00:00",
            "title": "Set CNAME in github actions",
            "text": "Fixes #195",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-05-18 21:47:05+00:00",
                    "text": "Deployment just finished. It works."
                }
            ]
        },
        {
            "number": 196,
            "user": "milancurcic",
            "date": "2020-05-18 20:53:52+00:00",
            "title": "remove docs/API.md",
            "text": "Minimal PR to test docs deployment.",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2020-05-18 21:07:57+00:00",
                    "text": "LGTM."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-18 21:08:19+00:00",
                    "text": "well, actually, if you want to test the deployment,  you may need my PR (#197)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-18 21:10:49+00:00",
                    "text": "Yes, I'm waiting for yours to finish and then merge it into this."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-18 21:11:56+00:00",
                    "text": "I just pushed again removing the file on my branch, hope that's ok."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-18 21:19:53+00:00",
                    "text": "Actually, your PR is sufficient to prove that it works. If your merged PR keeps the CNAME, then this PR not needed and I will close it."
                }
            ]
        },
        {
            "number": 195,
            "user": "milancurcic",
            "date": "2020-05-18 20:07:50+00:00",
            "title": "stdlib-docs action deletes CNAME",
            "text": "You may have noticed that stdlib-docs are not served at stdlib.fortran-lang.org anymore, and are back at https://fortran-lang.github.io/stdlib-docs.\nThis is because the GH Action that builds and deploys the docs deletes the CNAME.\n@zbeekman how do we fix this?",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-05-18 20:09:35+00:00",
                    "text": "We just have to add the CNAME back in."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-18 20:47:43+00:00",
                    "text": "Okay, I will test it now."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-18 20:59:21+00:00",
                    "text": "There is a mechanism to add the CNAME when building... I'll PR"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-18 21:05:33+00:00",
                    "text": "FYI: https://github.com/peaceiris/actions-gh-pages#%EF%B8%8F-cname"
                }
            ]
        },
        {
            "number": 194,
            "user": "jvdp1",
            "date": "2020-05-18 06:44:59+00:00",
            "title": "Addition of description for Ford",
            "text": "Addition of small descriptions of the different modules for Ford.\nQuestions: Should we add descritpions for the different functions in the code? Or only in the specs? Or is it possible to combine specs and code through Ford?\n@zbeekman @milancurcic @certik",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-05-18 20:12:14+00:00",
                    "text": "Thank you @jvdp1. This a small and straightforward PR, so I will merge it."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-18 21:49:11+00:00",
                    "text": "LGTM. I typically put spaces between the double bang and text but as long as it builds and renders correctly I have no objections."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-18 21:54:56+00:00",
                    "text": "I typically put spaces between the double bang and text\n\nIndeed, I agree, we should aim for the docstrings to be readable from the code as well."
                }
            ]
        },
        {
            "number": 193,
            "user": "mobius-eng",
            "date": "2020-05-17 18:50:22+00:00",
            "title": "Logger",
            "text": "Will a logger be a part of stdlib? For my projects I've written this logger\nhttps://gist.github.com/mobius-eng/16d2a309f80eeee25547d6725334a1a1\nIt is intended to be used through macros: if the logging level is set to\n#define LOGERROR\n\nthis statement will produce no code\n _DEBUG_('TIMESTEP: Calling STEPLSODA')\n\nI would like to contribute it to stdlib if there is a scope for it.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-05-17 20:07:51+00:00",
                    "text": "Hi @mobius-eng, according to our current agreed-upon scope, logging does belong in stdlib. I personally am very interested in it.\nTake a look at the workflow. You can go ahead and propose the API (step 2), and we'll discuss it. In the API proposal, please also list prior art for logging in Fortran (I'm aware of flogging), and also some examples of how other languages do it (e.g. Python, MATLAB, Julia, Rust)."
                },
                {
                    "user": "mobius-eng",
                    "date": "2020-05-20 09:47:43+00:00",
                    "text": "I looked at flogging. I am also familiar with the Julia's logger. There is one important and one not-so-important decisions that need to be made:\n\n\n(IMPORTANT) flogger uses local variable to keep the information about the logger (most importantly, where to log to). In my implementation, I used private global variable initialized by default with ERROR_UNIT. Which one to use? See below for trade offs.\n\n\n(NOT-SO-IMPORTANT) Use of colors. flogger and Julia's logger use colors. I didn't add this to my logger.\n\n\nLocal vs global local variable\nLocal is generally better, we know it. However, global logger state allows individual modules not to think about where to log to, but rather use program's log output. Are there use cases where a program might need multiple logger outputs? We can also have a hybrid system with the global logger used by default and local loggers setup on request.\nColors\nJulia (and Python and R) are meant to be used interactively. Thus, colors play an important role with the output to the terminal. By contrast, Fortran programs are meant to be run in the \"batch mode\" with log going to the file. Colors seem to work on most terminals, but I am not that familiar with the exact functionality and where it can break.\nAnd one more thing... Asynchronous IO. My thinking is to avoid it as writing out the log might be the last thing the program can do before crashing. In this case the output might not reach the file if async is enabled. Thoughts?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-23 16:37:45+00:00",
                    "text": "Are there use cases where a program might need multiple logger outputs?\n\nSometimes I use multiple logger outputs. e.g, for large programs with multiple phases.\nAlso, I would suggest to use local variables, to avoid possible clashs with user-defined variables.\nColors are not needed for me."
                },
                {
                    "user": "aradi",
                    "date": "2020-05-24 15:03:41+00:00",
                    "text": "As for colors: I am fine, as long as they are optional. I think most people typically run Fortran programs in batch systems with redirected output. Seeing a lot of color control sequences when opening the output files is rather disturbing..."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-05-24 15:27:27+00:00",
                    "text": "Are there use cases where a program might need multiple logger outputs?\n\nSometimes I use multiple logger outputs. e.g, for large programs with multiple phases.\n\nSame here. In my case that comes to mind the \"phases\" are multiple concurrent (but independent) instances of some solver. I think it is generally a bad idea to use global variables in any code that aims to be used as a library procedure, for doing so will limit it to single-threaded contexts."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-05-24 16:12:06+00:00",
                    "text": "We can also have a hybrid system with the global logger used by default and local loggers setup on request.\n\nThis is the approach I've taken in my own logger and timer modules and I think it works pretty well. For example, a local logger might be an instance of a DT that holds the local variable(s) that need to be hauled around (which is a nuisance as @mobius-eng pointed out), with the DT perhaps something like this\ntype logger\n  integer :: unit\ncontains\n  procedure :: message\nend type\nAnd the global logger is simply module procedures that operate on a private module variable (a singleton):\ntype(logger) :: global_logger ! private module variable\npublic :: log_message\n...\nsubroutine log_message(...)\n  call global_logger%message(...)\nend subroutine\nI know there's a real push to avoid OO stuff (even DT) at the low level and build OO stuff on top of that. This flips things around in this case."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-28 18:56:13+00:00",
                    "text": "This is the approach I've taken in my own logger and timer modules and I think it works pretty well. For example, a local logger might be an instance of a DT that holds the local variable(s) that need to be hauled around (which is a nuisance as @mobius-eng pointed out), with the DT perhaps something like this\ntype logger\n  integer :: unit\ncontains\n  procedure :: message\nend type\nAnd the global logger is simply module procedures that operate on a private module variable (a singleton):\ntype(logger) :: global_logger ! private module variable\npublic :: log_message\n...\nsubroutine log_message(...)\n  call global_logger%message(...)\nend subroutine\nI know there's a real push to avoid OO stuff (even DT) at the low level and build OO stuff on top of that. This flips things around in this case.\n\nI would think this is a manageagle solution. For the low-level, DT would be hidden to the user, and accessible with public procedures. In this sense, there would be no global variables. For an higher level, DT would be accessible by the user."
                },
                {
                    "user": "certik",
                    "date": "2020-05-28 19:22:22+00:00",
                    "text": "@nncarlson's design seems fine to me."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-19 19:05:31+00:00",
                    "text": "I think that this could move to the step 2 of the workflow: API proposal.\n@mobius-eng  would you like to open a PR with an initial implementation to discuss the API?"
                },
                {
                    "user": "mobius-eng",
                    "date": "2020-06-23 09:50:01+00:00",
                    "text": "Yes. Never done the PR thing before. Just need to figure out the technicalities."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-06-23 15:16:51+00:00",
                    "text": "I have my own journal/logger/unit test routines, but they are in need of an update. I find it very useful to use class(*) and some optional variables to simplify putting variable values into the messages without having to do internal writes first.  If class(*) is not supported by enough variables I had an older generic routine that optionally did not generate a line terminator that let you compose a longer message with multiple values. Just to give a sense of what I mean I included an example program that uses the same concept. It works quite nicely for standard scalar types and is easily extended for other types.  So is something using class(*) in the running?\nmodule m_debug\nuse, intrinsic :: iso_fortran_env, only : ERROR_UNIT,OUTPUT_UNIT \nimplicit none\nprivate\npublic stderr\ncontains\nsubroutine stderr(msg, generic0, generic1, generic2, generic3, generic4, generic5, generic6, generic7, generic8, generic9)\nimplicit none\nclass(*),intent(in),optional :: msg\nclass(*),intent(in),optional :: generic0, generic1, generic2, generic3, generic4\nclass(*),intent(in),optional :: generic5, generic6, generic7, generic8, generic9\ninteger                      :: ios\n   if(present(msg))     call print_generic(msg)\n   if(present(generic0))call print_generic(generic0)\n   if(present(generic1))call print_generic(generic1)\n   if(present(generic2))call print_generic(generic2)\n   if(present(generic3))call print_generic(generic3)\n   if(present(generic4))call print_generic(generic4)\n   if(present(generic5))call print_generic(generic5)\n   if(present(generic6))call print_generic(generic6)\n   if(present(generic7))call print_generic(generic7)\n   if(present(generic8))call print_generic(generic8)\n   if(present(generic9))call print_generic(generic9)\n   write(error_unit,'(a)',iostat=ios)\n   flush(unit=output_unit,iostat=ios)\n   flush(unit=error_unit,iostat=ios)\ncontains\n!===================================================================================================================================\nsubroutine print_generic(generic)\n!use, intrinsic :: iso_fortran_env, only : int8, int16, int32, biggest=>int64, real32, real64, dp=>real128\nuse,intrinsic :: iso_fortran_env, only : int8, int16, int32, int64, real32, real64, real128\nclass(*),intent(in) :: generic\n   write(error_unit,'(1x)',advance='no')\n   select type(generic)\n      type is (integer(kind=int8));     write(error_unit,'(i0)',advance='no') generic\n      type is (integer(kind=int16));    write(error_unit,'(i0)',advance='no') generic\n      type is (integer(kind=int32));    write(error_unit,'(i0)',advance='no') generic\n      type is (integer(kind=int64));    write(error_unit,'(i0)',advance='no') generic\n      type is (real(kind=real32));      write(error_unit,'(1pg0)',advance='no') generic\n      type is (real(kind=real64));      write(error_unit,'(1pg0)',advance='no') generic\n      type is (real(kind=real128));     write(error_unit,'(1pg0)',advance='no') generic\n      type is (logical);                write(error_unit,'(1l)',advance='no') generic\n      type is (character(len=*));       write(error_unit,'(a)',advance='no') trim(generic)\n      type is (complex);                write(error_unit,'(\"(\",1pg0,\",\",1pg0,\")\")',advance='no') generic\n      class default\n         stop 'unknown type in *print_generic*'\n   end select\nend subroutine print_generic\nend subroutine stderr\nend module m_debug\nprogram demo_stderr\nuse M_debug, only: stderr\nimplicit none\ninteger :: least=10, most=999, ival=-10\n    call stderr('A simple message')\n    call stderr('error: RVALUE=', 3.0/4.0, 'IVALUE=', 123456789, 'LVALUE=', .true.)\n    call stderr('error: value',ival,'should be between',least,'and',most)\nend program demo_stderr"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-08-26 18:39:25+00:00",
                    "text": "In #227 I have proposed a fairly comprehensive API for a global logging system, but it can be adapted to provide both local and global logging capabilities using a derived type as suggested by @nncarlson. It got some favorable comments at the monthly meeting so I suspect it will become part of STDLIB. But before I submit a PR for a more formal API document, I would like some more feedback on what I have proposed. In summary:\nThis module defines procedures and constants to be used for reporting\nof errors and other information. The reports normally go to formatted\noutput units represented by the array of logical unit, LOG_UNITS. An\narbitrary number of log units can be open at a time. LOG_UNITS may\nbe associated with files dedicated to STDLIB_LOGGER or may be\nassociated with independently opened files. If LOG_UNITS is empty\nthen the output goes to OUTPUT_UNIT of ISO_FORTRAN_ENV. Otherwise\nreports go to OUTPUT_UNIT only if it has been explicitly added to\nLOG_UNITS with ADD_LOG_UNIT.  It currently provides no capability to\ncolorize output.\nThe logger has the options to:\n\nchange which units receive the log messages;\nreport which units receive the log messages;\nprecede messages by a blank line;\nprecede messages by a time stamp of the form\nyyyy-mm-dd hh:mm:ss.sss;\nprecede messages with the names of a module and procedure;\nfollow a message with the STAT and ERRMSG of the error report\nthat prompted the log message;\nfollow a message with the IOSTAT and IOMSG of the I/O error\nreport that prompted the log message;\nlabel a message with one of 'INFORMATION: ', 'WARNING: ',\n'ERROR: ', or 'I/O ERROR: ';\nindent subsequent lines of the messages; and\nformat the text to fit within a maximum column width."
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-07 17:42:30+00:00",
                    "text": "(NOT-SO-IMPORTANT) Use of colors. flogger and Julia's logger use colors. I didn't add this to my logger.\n\nColors\nJulia (and Python and R) are meant to be used interactively. Thus, colors play an important role with the output to the terminal. By contrast, Fortran programs are meant to be run in the \"batch mode\" with log going to the file. Colors seem to work on most terminals, but I am not that familiar with the exact functionality and where it can break.\n\nI think this should be proposed as a new module stdlib_colors.f90, and then include the support in the logger. The main issue is to support non-ANSI terminals (Like DOS for instance).\nrelated project: FACE by @szaghi\nPS: It seems windows 10 support ansi escapes link here and here too"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-07 17:56:40+00:00",
                    "text": "A problem with using colors is that `output_unit` can be directed to a file where the \"color codes\u201d will be distracting.\n\u2026\n On Sep 7, 2020, at 11:42 AM, Ian Giestas Pauli ***@***.***> wrote:\n\n\n (NOT-SO-IMPORTANT) Use of colors. flogger and Julia's logger use colors. I didn't add this to my logger.\n Colors\n\n Julia (and Python and R) are meant to be used interactively. Thus, colors play an important role with the output to the terminal. By contrast, Fortran programs are meant to be run in the \"batch mode\" with log going to the file. Colors seem to work on most terminals, but I am not that familiar with the exact functionality and where it can break.\n\n I think this should be proposed as a new module stdlib_colors.f90, and then include the support in the logger. The main issue is to support non-ANSI terminals (Like DOS for instance).\n related project: FACE by @szaghi <https://github.com/szaghi/FACE>\n PS: It seems windows 10 support ansi escapes link here <https://gist.github.com/mlocati/fdabcaeb8071d5c75a2d51712db24011> and here too <https://docs.microsoft.com/en-us/windows/console/console-virtual-terminal-sequences?redirectedfrom=MSDN>\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub <#193 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOTSDT6M5LTRR3PPZVTSEULRJANCNFSM4NDQDTPA>."
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-07 18:12:40+00:00",
                    "text": "A problem with using colors is that output_unit can be directed to a file where the \"color codes\u201d will be distracting.\n\nYou are right, we would require a isatty function in fortran (as linked here) and I'm not aware if this can be done in fortran (bind C, maybe?)"
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-07 18:19:18+00:00",
                    "text": "Interesting... a lot of compilers vendors support this function already:\n\nGNU isatty\nIntel isatty\nPGI isatty\nOracle's isatty\nUnfortunately is not a standard (However I think this kind of function also fits the stdlib scope).\nI did a proof-of-concept here."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-09-08 06:39:26+00:00",
                    "text": "For colours you could also consider a library as Foul -\nhttp://foul.sourceforge.net/. Although, its license is set as GPLv3, which\nmight conflict with the purposes of the standard library.\n\n\n\nOp ma 7 sep. 2020 om 20:19 schreef Ian Giestas Pauli <\nnotifications@github.com>:\n\u2026\n Interesting... there is a GNU extension and a intel compiler support to\n this function already:\n\n    - GNU isatty <https://gcc.gnu.org/onlinedocs/gfortran/ISATTY.html>\n    - Intel isatty\n    <https://software.intel.com/content/www/us/en/develop/documentation/fortran-compiler-developer-guide-and-reference/top/language-reference/a-to-z-reference/h-to-i/isatty.html>\n    Unfortunately is not a standard, but it would fix this issue.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#193 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR3KQW76QHOU2LLYPM3SEUP3JANCNFSM4NDQDTPA>\n ."
                }
            ]
        },
        {
            "number": 192,
            "user": "jvdp1",
            "date": "2020-05-17 15:02:50+00:00",
            "title": "Addition of tests and clarification for cov",
            "text": "I added some tests for cov and modified 2 functions (when a mask array is provided).",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-05-18 20:14:04+00:00",
                    "text": "Thank you!"
                }
            ]
        },
        {
            "number": 191,
            "user": "jvdp1",
            "date": "2020-05-17 13:32:37+00:00",
            "title": "Pearson correlation among elements of an array",
            "text": "Related to the functions cov and var\nAs usual, everything can/must be discussed.\nOther implementations\n\nOctave corr\nMatlab corr\nR cor\nJulia cor\nNumpy corrcoef\n\nSpecs:\ncorr - Pearson correlation of array elements\nDescription\nReturns the Pearson correlation of the elements of array along dimension dim if the corresponding element in mask is true.\nThe Pearson correlation between two rows (or columns), say x and y, of array is defined as:\n corr(x, y) = cov(x, y) / sqrt( var(x) * var(y))\n\nSyntax\nresult = corr(array, dim [, mask])\nArguments\narray: Shall be a rank-1 or a rank-2 array of type integer, real, or complex.\ndim: Shall be a scalar of type integer with a value in the range from 1 to n, where n is the rank of array.\nmask (optional): Shall be of type logical and either a scalar or an array of the same shape as array.\nReturn value\nIf array is of rank 1 and of type real or complex, the result is of type real corresponding to the type of array.\nIf array is of rank 2 and of type real or complex, the result is of the same type as array.\nIf array is of type integer, the result is of type real(dp).\nIf array is of rank 1 and of size larger than 1, a scalar equal to 1 is returned. Otherwise, IEEE NaN is returned.\nIf array is of rank 2, a rank-2 array  with the corresponding correlations is returned.\nIf mask is specified, the result is the Pearson correlation of all elements of array corresponding to true elements of mask. If every element of mask is false, the result is IEEE\nNaN.\nExample\nprogram demo_corr\n    use stdlib_experimental_stats, only: corr\n    implicit none\n    real :: x(1:6) = [ 1., 2., 3., 4., 5., 6. ]\n    real :: y(1:2, 1:3) = reshape([ -1., 40., -3., 4., 10., 6. ], [ 2, 3])\n    print *, corr(x, 1)           !returns 1.\n    print *, corr(y, 2)           !returns reshape([ 1., -.32480, -.32480, 1. ], [ 2, 3])\nend program demo_corr",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-06-08 05:27:04+00:00",
                    "text": "If there are no other objections/comments to this PR, I will then merge this evening."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-08 19:21:05+00:00",
                    "text": "Thank you for your inputs. I'll merge."
                }
            ]
        },
        {
            "number": 190,
            "user": "epagone",
            "date": "2020-05-16 18:18:54+00:00",
            "title": "optval fails with concatenation of character variables",
            "text": "Consider the following\nprogram bug_optval\n  use stdlib_experimental_optval, only: optval \n  implicit none\n  \n  call optval_fail\n  call optval_fail(\"two\")\n  \ncontains\n\n  subroutine optval_fail(foo)\n    character(len=*), intent(in), optional  :: foo\n    character(len=:), allocatable :: bar\n    \n    bar = \"one\"//optval(\"_\"//foo, \"\")\n    \n    print *, bar\n    \n  end subroutine optval_fail\nend program bug_optval\nI am expecting\none\none_two\n\nbut it returns wrongly\n$ ./a.out \n one_\n one_two\n\nI'm compiling with\n$ gfortran-9 -v\nUsing built-in specs.\nCOLLECT_GCC=gfortran-9\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/9/lto-wrapper\nOFFLOAD_TARGET_NAMES=nvptx-none:hsa\nOFFLOAD_TARGET_DEFAULT=1\nTarget: x86_64-linux-gnu\nConfigured with: ../src/configure -v --with-pkgversion='Ubuntu 9.3.0-10ubuntu2' --with-bugurl=file:///usr/share/doc/gcc-9/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++,gm2 --prefix=/usr --with-gcc-major-version-only --program-suffix=-9 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib=auto --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none,hsa --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\nThread model: posix\ngcc version 9.3.0 (Ubuntu 9.3.0-10ubuntu2) \n\nPS: using if blocks and present() instead of optval works fine (in other words, I don't think it's a compiler bug)",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2020-05-16 18:54:21+00:00",
                    "text": "Could you also show the implementation using if blocks and present()?\nIt seems that when you pass \"_\"//foo to optval, it is not a null pointer like needed for the compiler to verify the argument is not present."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-05-16 19:11:35+00:00",
                    "text": "The issue here has nothing to do with optval.  The expression \"_\"//foo is illegal if the actual argument for foo isn't present."
                },
                {
                    "user": "epagone",
                    "date": "2020-05-16 20:28:21+00:00",
                    "text": "Could you also show the implementation using if blocks and present()?\nIt seems that when you pass \"_\"//foo to optval, it is not a null pointer like needed for the compiler to verify the argument is not present.\n\nprogram bug_optval\n  use stdlib_experimental_optval, only: optval \n  implicit none\n  \n  call optval_fail\n  call optval_fail(\"two\")\n  \ncontains\n\n  subroutine optval_fail(foo)\n    character(len=*), intent(in), optional  :: foo\n    character(len=:), allocatable :: bar\n    \n    if ( present(foo) ) then\n      bar = \"one_\"//foo\n    else\n      bar = \"one\"\n    end if\n    \n    print *, bar\n    \n  end subroutine optval_fail\nend program bug_optval\nworks correctly."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-05-16 20:39:32+00:00",
                    "text": "Yes, here the \"one_\"//foo expression is protected by if (present(foo)) block."
                },
                {
                    "user": "epagone",
                    "date": "2020-05-16 21:17:28+00:00",
                    "text": "I admit I struggle to follow.\nTake the example from the specs:\nprogram demo_optval\n    use stdlib_experimental_optval, only: optval\n    implicit none\n    print *, root(64.0)\n! 8.0\n    print *, root(64.0, 3)\n! 4.0\ncontains\n    real function root(x, n)\n\treal, intent(in) :: x\n        integer, intent(in), optional :: n\n        root = x**(1.0/optval(n, 2))\n    end function root\nend program demo_optval\nIs then also n illegal in optval(n, 2) when root is invoked without the corresponding actual argument (i.e. root(64.0))?"
                },
                {
                    "user": "certik",
                    "date": "2020-05-16 21:21:12+00:00",
                    "text": "N is not present, but you can pass it to the optval subroutine, which checks if it is present before using it.\n\u2026\nOn Sat, May 16, 2020, at 3:17 PM, epagone wrote:\n\n\n I admit I struggle to follow.\n\n Take the example from the specs:\n\n program demo_optval\n     use stdlib_experimental_optval, only: optval\n     implicit none\n     print *, root(64.0)\n ! 8.0\n     print *, root(64.0, 3)\n ! 4.0\n contains\n     real function root(x, n)\n \treal, intent(in) :: x\n         integer, intent(in), optional :: n\n         root = x**(1.0/optval(n, 2))\n     end function root\n end program demo_optval\n Is then also `n` illegal when `root` is invoked without the\n corresponding actual argument (i.e. `root(64.0)`)?\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#190 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWDHZFQWMLKX5PLXFGLRR37HHANCNFSM4NDAWXFQ>."
                },
                {
                    "user": "epagone",
                    "date": "2020-05-16 21:35:44+00:00",
                    "text": "Yep. Got it now. Sometimes looking at the implementation helps \ud83d\ude01 Sorry for the red herring."
                }
            ]
        },
        {
            "number": 189,
            "user": "certik",
            "date": "2020-05-16 15:31:35+00:00",
            "title": "Initial implementation of COO / CSR sparse format",
            "text": "The key of this is the API, as shown with examples in test_sparse.f90.\nIn particular, I am proposing the following functions / API:\nConversion Dense <-> COO:\n\ndense2coo\ncoo2dense\n\nConversion COO -> CSR:\n\ncoo2csr\ncsr_sort_indices\ncsr_sum_duplicates\ncoo2csr_canonical (calls the previous three functions)\ncsr_has_canonical_format\n\nCSR functionality:\n\ncsr_matvec\ncsr_getvalue\n\nDense functionality:\n\ngetnnz\n\nIn these algorithms, it seems it is possible to just have one (best)\nimplementation with one exception: sorting of indices (as implemented by\ncsr_sort_indices), where different algorithms give different\nperformance and it depends on the actual matrix. As such, it might make\nsense to provide a default in csr_sort_indices that is called by\ncoo2csr_canonical that is as fast as we can make it for most cases (currently it\nuses quicksort, but there are other faster algoritms for our use case\nthat we should switch over) and then provide other implementations such\nas csr_sort_indices_mergesort, csr_sort_indices_timsort, etc. for\nusers so that they can choose the algorithm for sorting indices, or even\nprovide their own.\nThe file stdlib_experimental_sparse.f90 provides an example\nimplementation of these algorithms that was inspired by SciPy. We can\nalso discuss the details of that, but the key that I would like to\ndiscuss is the API itself.\nSee #38.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-05-16 15:36:34+00:00",
                    "text": "@sfilippone I would really be interested in your feedback on the API, based on your work on psblas3. This is a serial API, which I think we should have, in addition to a parallel API that we'll tackle later."
                },
                {
                    "user": "certik",
                    "date": "2020-05-16 19:19:44+00:00",
                    "text": "Great comments! Thank you.\n\nI'll reply later, I'll just point out a general design that we figured out that will satisfy almost everybody in the community: have a low level API that is procedural with no side effects (some people call it functional) as in this PR. And then have a high level API that is object oriented and hides complexity in a class or derived types and that uses the low level API to do the work.\n\nIf you want, you can help suggest some good high level API for this.\n\u2026\nOn Sat, May 16, 2020, at 11:38 AM, Nick R. Papior wrote:\n\n\n ***@***.**** commented on this pull request.\n\n FYI, I have a somewhat related project https://github.com/siesta-project/buds\n  which also has CSR matrices and some quite nice features I think.\n\n I would be very happy to move this into stdlib in one way or the other.\n\n Some notes:\n\n  * I think such a *complex* data structure should be hidden in a type\n (class) to allow more stuff\n  * Some times it may be beneficial if the data contained isn't\n necessarily a single dimension (consider a 3D matrix with 2D sparsity\n and 1D dense).\n  * Many external interfaces (in C) require 0-based indexing, and hence\n it would be nice with a retrieval method of the `type` to a 0-based\n index (basically only doing this on the index arrays and returning with\n a pointer to the actual data array)\n  * My implementation allows very efficient addition of elements by\n having an additional counter. This allows one to have *empty* elements\n in each row and thus only re-allocate when one tries to add more terms\n than this. If some forms of the csr matrix becomes an issue it *may* be\n beneficial to have a 2nd format that has a list (each row) of lists\n (with data). In this way one need only reallocate the row that needs to\n be bigger.\n I probably have some more comments if you want?\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +    r1 = Ap(i)\n +    r2 = Ap(i+1)-1\n +    l = r2-r1+1\n +    idx(:l) = iargsort_quicksort(Aj(r1:r2))\n +    Aj(r1:r2) = Aj(r1+idx(:l)-1)\n +    Ax(r1:r2) = Ax(r1+idx(:l)-1)\n +end do\n +end subroutine\n +\n +function csr_matvec(Ap, Aj, Ax, x) result(y)\n +! Compute y = A*x for CSR matrix A and dense vectors x, y\n +integer, intent(in) :: Ap(:), Aj(:)\n +real(dp), intent(in) :: Ax(:), x(:)\n +real(dp) :: y(size(Ap)-1)\n +integer :: i\n +!$omp parallel default(none) shared(Ap, Aj, Ax, x, y) private(i)\n Generally I think `omp` should be orphaned. In that way it is the user\n who controls the parallelization, and not the stdlib.\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +integer, intent(out) :: Ai(:), Aj(:)\n +real(dp), intent(out) :: Ax(:)\n +integer :: i, j, idx\n +idx = 1\n +do j = 1, size(B, 2)\n +    do i = 1, size(B, 1)\n +        if (abs(B(i, j)) < tiny(1._dp)) cycle\n +        Ai(idx) = i\n +        Aj(idx) = j\n +        Ax(idx) = B(i, j)\n +        idx = idx + 1\n +    end do\n +end do\n +end subroutine\n +\n +integer function getnnz(B) result(nnz)\n Also, perhaps these methods should allow `integer(8)` to allow very\n large matrices.\n\n Perhaps this should be `get_nnz`?\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +    idx(:l) = iargsort_quicksort(Aj(r1:r2))\n +    Aj(r1:r2) = Aj(r1+idx(:l)-1)\n +    Ax(r1:r2) = Ax(r1+idx(:l)-1)\n +end do\n +end subroutine\n +\n +function csr_matvec(Ap, Aj, Ax, x) result(y)\n +! Compute y = A*x for CSR matrix A and dense vectors x, y\n +integer, intent(in) :: Ap(:), Aj(:)\n +real(dp), intent(in) :: Ax(:), x(:)\n +real(dp) :: y(size(Ap)-1)\n +integer :: i\n +!$omp parallel default(none) shared(Ap, Aj, Ax, x, y) private(i)\n +!$omp do\n +do i = 1, size(Ap)-1\n +    y(i) = dot_product(Ax(Ap(i):Ap(i+1)-1), x(Aj(Ap(i):Ap(i+1)-1)))\n This will create a temporary which *could* potentially be very large. I\n would try to avoid this since the temporary still needs to traverse the\n copied elements.\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +l = 1\n +i = size(A)\n +! Now we always have A(l) < val; A(i) >= val and we must make sure that \"i\" is\n +! the lowest possible such index.\n +do while (l + 1 < i)\n +    idx = (l+i) / 2\n +    if (A(idx) < val) then\n +        l = idx\n +    else\n +        i = idx\n +    end if\n +end do\n +end function\n +\n +\n +real(dp) function csr_getvalue(Ap, Aj, Ax, i, j) result(r)\n `csr_get_value`?\n\n I have never really liked `get` when intent is obvious, I may be wrong.\n  But `csr_value` is just as clear to me. ;)\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#189 (review)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWDCCRCJHEQQTQ6PAFTRR3FSPANCNFSM4NC62JUA>."
                },
                {
                    "user": "sfilippone",
                    "date": "2020-05-17 06:51:38+00:00",
                    "text": "Re: int32 vs int64.\nYou'll need both. Let me elaborate.\nThe most common application of sparse matrices is in the inner steps of\nsome PDE solver, dealing with a discretization on a mesh. Such problems can\nindeed reach sizes that need indices with int64; however in those cases\nthey are tackled through parallel solution strategies mostly based on MPI.\nThe parallelization strategy is to assign a subdomain to each MPI process;\neach subdomain is most likely of a size that fits comfortably in an int32,\nprovided that you apply a local numbering scheme, as well as a global\nnumbering scheme. And you occasionally need to convert the indices of the\nlocal portion into global numbering for some processing, and back; examples\ninclude data exchanges among processes within a transpose operation.\nThe solution that I have now in the development branch of PSBLAS is the\nfollowing: there are 4 integer kinds:\nint32==psb_mpk_ <= psb_ipk_ <= psb_lpk_ <= psb_epk_== int64\nIPK is the integer kind used for *LOCAL indices, which are the ones for the\nlocal portion of the matrices involved in numerical operators such as\nMatrix-Vector product,\nLPK is the integer kind used for GLOBAL indices, which are used in pre- and\npost-processing.\nIPK and LPK can be specified at configure time within the constraints abov,\nwith the default being IPK=int32 and LPK=int64.\n\nSalvatore\n\u2026\nOn Sat, May 16, 2020 at 11:32 PM Jeremie Vandenplas < ***@***.***> wrote:\n ***@***.**** commented on this pull request.\n\n The different API look good to me.\n\n My major concern is about the declaration of the pointer array of CSR.\n This array can easily contain values larger than integer(int32).\n Therefore, I wonder if it would not be advisable to declare it as\n integer(int64).\n ------------------------------\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +real(dp), intent(out) :: Ax(:)\n\n +integer :: i, j, idx\n\n +idx = 1\n\n +do j = 1, size(B, 2)\n\n +    do i = 1, size(B, 1)\n\n +        if (abs(B(i, j)) < tiny(1._dp)) cycle\n\n +        Ai(idx) = i\n\n +        Aj(idx) = j\n\n +        Ax(idx) = B(i, j)\n\n +        idx = idx + 1\n\n +    end do\n\n +end do\n\n +end subroutine\n\n +\n\n +integer function getnnz(B) result(nnz)\n\n +real(dp), intent(in) :: B(:, :)\n\n\n This is for dense matrices.\n Since we are in a module for sparse matrices, should it return nnz only\n for sparse matrices?\n ------------------------------\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +        if (abs(B(i, j)) < tiny(1._dp)) cycle\n\n +        nnz = nnz + 1\n\n +    end do\n\n +end do\n\n +end function\n\n +\n\n +! COO\n\n +\n\n +subroutine coo2dense(Ai, Aj, Ax, B)\n\n +integer, intent(in) :: Ai(:), Aj(:)\n\n +real(dp), intent(in) :: Ax(:)\n\n +real(dp), intent(out) :: B(:, :)\n\n +integer :: n\n\n +B = 0\n\n +do n = 1, size(Ai)\n\n +    B(Ai(n), Aj(n)) = B(Ai(n), Aj(n)) + Ax(n)\n\n\n This implies that all elements in Ai and Aj are filled, which is not\n always the case because COO is often used as a temporary format.\n ------------------------------\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +nnz = 0\n\n +do j = 1, size(B, 2)\n\n +    do i = 1, size(B, 1)\n\n +        if (abs(B(i, j)) < tiny(1._dp)) cycle\n\n +        nnz = nnz + 1\n\n +    end do\n\n +end do\n\n +end function\n\n +\n\n +! COO\n\n +\n\n +subroutine coo2dense(Ai, Aj, Ax, B)\n\n +integer, intent(in) :: Ai(:), Aj(:)\n\n +real(dp), intent(in) :: Ax(:)\n\n +real(dp), intent(out) :: B(:, :)\n\n +integer :: n\n\n\n I would suggest to always use integer(int64) when going through a sparse\n matrix.\n ------------------------------\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +real(dp), intent(in) :: Ax(:)\n\n +real(dp), intent(out) :: B(:, :)\n\n +integer :: n\n\n +B = 0\n\n +do n = 1, size(Ai)\n\n +    B(Ai(n), Aj(n)) = B(Ai(n), Aj(n)) + Ax(n)\n\n +end do\n\n +end subroutine\n\n +\n\n +subroutine coo2csr(Ai, Aj, Ax, Bp, Bj, Bx)\n\n +! Converts from COO (Ai, Aj, Ax) into CSR (Bp, Bj, Bx)\n\n +! Row and column indices are *not* assumed to be ordered.\n\n +! Duplicate entries are carried over to the CSR representation.\n\n +integer, intent(in) :: Ai(:), Aj(:)\n\n +real(dp), intent(in) :: Ax(:)\n\n +integer, intent(out) :: Bp(:), Bj(:)\n\n\n I suggest to declare Bp(:) as integer(int64) to avoid any troubles with\n large sparse matrices.\n However, we may want to be compatible to e.g., psblas3 (I didn't check\n what is the default declaration in psblas3).\n ------------------------------\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +! Converts from COO (Ai, Aj, Ax) into CSR (Bp, Bj, Bx)\n\n +! Row and column indices are *not* assumed to be ordered.\n\n +! Duplicate entries are summed up and the indices are ordered.\n\n +integer, intent(in) :: Ai(:), Aj(:)\n\n +real(dp), intent(in) :: Ax(:)\n\n +integer, allocatable, intent(out) :: Bp(:), Bj(:)\n\n +real(dp), allocatable, intent(out) :: Bx(:)\n\n +logical, optional, intent(in) :: verbose\n\n +integer :: Bj_(size(Ai))\n\n +real(dp) :: Bx_(size(Ai))\n\n +integer :: nnz\n\n +logical :: verbose_\n\n +verbose_ = .false.\n\n +if (present(verbose)) verbose_ = verbose\n\n +allocate(Bp(maxval(Ai)+1))\n\n +if (verbose_) print *, \"coo2csr\"\n\n\n optval can be used here ;)\n ------------------------------\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +integer :: Bj_(size(Ai))\n\n +real(dp) :: Bx_(size(Ai))\n\n +integer :: nnz\n\n +logical :: verbose_\n\n +verbose_ = .false.\n\n +if (present(verbose)) verbose_ = verbose\n\n +allocate(Bp(maxval(Ai)+1))\n\n +if (verbose_) print *, \"coo2csr\"\n\n +call coo2csr(Ai, Aj, Ax, Bp, Bj_, Bx_)\n\n +if (verbose_) print *, \"csr_sort_indices\"\n\n +call csr_sort_indices(Bp, Bj_, Bx_)\n\n +if (verbose_) print *, \"csr_sum_duplicates\"\n\n +call csr_sum_duplicates(Bp, Bj_, Bx_)\n\n +if (verbose_) print *, \"done\"\n\n +nnz = Bp(size(Bp))-1\n\n +allocate(Bj(nnz), Bx(nnz))\n\n\n This line can be removed with Fortran2003 and>, right?\n ------------------------------\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +! conditions facilitate faster matrix computations.\n\n +integer, intent(in) :: Ap(:), Aj(:)\n\n +integer :: i, j\n\n +r = .false.\n\n +do i = 1, size(Ap)-1\n\n +    if (Ap(i) > Ap(i+1)) return\n\n +    do j = Ap(i)+1, Ap(i+1)-1\n\n +        if (Aj(j-1) >= Aj(j)) return\n\n +    end do\n\n +end do\n\n +r = .true.\n\n +end function\n\n +\n\n +subroutine csr_sum_duplicates(Ap, Aj, Ax)\n\n +! Sum together duplicate column entries in each row of CSR matrix A\n\n +! The column indicies within each row must be in sorted order.\n\n\n \u2b07\ufe0f Suggested change\n\n -! The column indicies within each row must be in sorted order.\n\n +! The column indices within each row must be in sorted order.\n\n\n ------------------------------\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +subroutine csr_sort_indices(Ap, Aj, Ax)\n\n +! Sort CSR column indices inplace\n\n +integer, intent(inout) :: Ap(:), Aj(:)\n\n +real(dp), intent(inout) :: Ax(:)\n\n +integer :: i, r1, r2, l, idx(size(Aj))\n\n +do i = 1, size(Ap)-1\n\n +    r1 = Ap(i)\n\n +    r2 = Ap(i+1)-1\n\n +    l = r2-r1+1\n\n +    idx(:l) = iargsort_quicksort(Aj(r1:r2))\n\n +    Aj(r1:r2) = Aj(r1+idx(:l)-1)\n\n +    Ax(r1:r2) = Ax(r1+idx(:l)-1)\n\n +end do\n\n +end subroutine\n\n +\n\n +function csr_matvec(Ap, Aj, Ax, x) result(y)\n\n\n I suggest to follow the API of Sparse BLAS.\n ------------------------------\n\n In src/stdlib_experimental_sparse.f90\n <#189 (comment)>:\n\n > +real(dp), intent(in) :: Ax(:)\n\n +integer, intent(in) :: i, j\n\n +integer :: row_start, row_end, offset\n\n +row_start = Ap(i)\n\n +row_end = Ap(i+1)-1\n\n +offset = lower_bound(Aj(row_start:row_end), j) + row_start - 1\n\n +if (offset <= row_end) then\n\n +    if (Aj(offset) == j) then\n\n +        r = Ax(offset)\n\n +        return\n\n +    end if\n\n +end if\n\n +r = 0\n\n +end function\n\n +\n\n +pure elemental subroutine swap_int(x,y)\n\n\n I think this subroutine should be moved to another module of stdlib.\n ------------------------------\n\n In src/tests/sparse/test_sparse.f90\n <#189 (comment)>:\n\n > +call check(all(Bj == [1, 1, 3, 3, 4, 2]))\n\n +call check(all(abs(Bx - [1, 4, 2, 5, 1, 3]) < 1e-12_dp))\n\n +call csr_sum_duplicates(Bp, Bj, Bx)\n\n +nnz = Bp(size(Bp))-1\n\n +call check(all(Bp == [1, 2, 4, 5]))\n\n +call check(all(Bj(:nnz) == [1, 3, 4, 2]))\n\n +call check(all(abs(Bx(:nnz) - [5, 7, 1, 3]) < 1e-12_dp))\n\n +call check(csr_has_canonical_format(Bp, Bj(:nnz)))\n\n +\n\n +call coo2csr_canonical(Ai, Aj, Ax, Bp, Bj, Bx)\n\n +call check(all(Bp == [1, 2, 4, 5]))\n\n +call check(all(Bj == [1, 3, 4, 2]))\n\n +call check(all(abs(Bx - [5, 7, 1, 3]) < 1e-12_dp))\n\n +call check(csr_has_canonical_format(Bp, Bj))\n\n +\n\n +call check(abs(csr_getvalue(Bp, Bj, Bx, 1, 1) - 5) < tiny(1._dp))\n\n\n By experience, tiny(1._dp) can be too severe.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#189 (review)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD274T4OGJKXS6GJTVKGM3TRR4A7RANCNFSM4NC62JUA>\n ."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-17 07:18:58+00:00",
                    "text": "Re: int32 vs int64. You'll need both. Let me elaborate. The most common application of sparse matrices is in the inner steps of some PDE solver, dealing with a discretization on a mesh. Such problems can indeed reach sizes that need indices with int64; however in those cases they are tackled through parallel solution strategies mostly based on MPI. The parallelization strategy is to assign a subdomain to each MPI process; each subdomain is most likely of a size that fits comfortably in an int32, provided that you apply a local numbering scheme, as well as a global numbering scheme. And you occasionally need to convert the indices of the local portion into global numbering for some processing, and back; examples include data exchanges among processes within a transpose operation. The solution that I have now in the development branch of PSBLAS is the following: there are 4 integer kinds: int32==psb_mpk_ <= psb_ipk_ <= psb_lpk_ <= psb_epk_== int64 IPK is the integer kind used for *LOCAL indices, which are the ones for the local portion of the matrices involved in numerical operators such as Matrix-Vector product, LPK is the integer kind used for GLOBAL indices, which are used in pre- and post-processing. IPK and LPK can be specified at configure time within the constraints abov, with the default being IPK=int32 and LPK=int64. Salvatore\n\nThank you Salvatore for your input. I should have a closer look to psblas.\nFor stdlib: would it not be of interest to integrate psblas3 (if allowed) in stdlib directly? Or through fpm? In comparison to the other implementations, psblas3 is well tested, is associated to peer-reviewed publications and is parallelized (also with Coarray Fortran?) if we want to support parallelization in stdlib. If something is missing, we could identify it and maybe collaborate with psblas to implement the missing parts there?\nThis is just a question to be sure that we don't start into something that is similar to reinventing the wheel."
                },
                {
                    "user": "sfilippone",
                    "date": "2020-05-17 07:45:43+00:00",
                    "text": "I am OK with integrating PSBLAS in stdlib (with proper handling of\ncopyright for me and my collaborators), at least the parts that make sense\ntoday (I suspect I have a lot of stuff that should not be included just\nyet).  In the project there are a set of facilities marked at SERIAL\n(admittedly, they should be packaged better because they are split in\ntwo-three subdirs) which are the ones you are probably most interested in.\nNote that I also use a home-grown set of sed scripts to have a crude\nemulation of macros/templates to avoid rewriting things multiple times; if\nthat could be morphed into something robust I'd be more than happy, while\nwaiting for the Fortran standard committee to decide on a template facility\n(I have seen more than one proposal in this direction, but it's not yet\ndecided AFAIK).\n\nA few additional comments:\n1. Storage formats.\nI have a set of additional storage formats in psblas3-ext; they also\nsupport CUDA, accessed through the  C interoperability.\n\n2. Coarrays.\nI have a preliminary version with CoArrays (in fact, I am one of the\nfounders of the OpenCoArrays project which is used to provide CoArrays in\nGNU). However, there is a big issue and that is constraints C825. The\neffect of the constraint is that the set of entities that can have a\ncoarray component is fixed at compile time; in other words, you cannot have\nan allocatable array of derived types that contains a(n allocatable)\ncoarray component.\nI have reported this to the Fortran standard committee  (see\nhttps://j3-fortran.org/doc/year/18/18-280r1.txt ) and indeed my proposal\nhas been approved; however there is no telling when it will appear in\ncompilers, hence I am not going to use this in production code any time\nsoon.\n\nSalvatore\n\u2026\nOn Sun, May 17, 2020 at 9:19 AM Jeremie Vandenplas ***@***.***> wrote:\n Re: int32 vs int64. You'll need both. Let me elaborate. The most common\n application of sparse matrices is in the inner steps of some PDE solver,\n dealing with a discretization on a mesh. Such problems can indeed reach\n sizes that need indices with int64; however in those cases they are tackled\n through parallel solution strategies mostly based on MPI. The\n parallelization strategy is to assign a subdomain to each MPI process; each\n subdomain is most likely of a size that fits comfortably in an int32,\n provided that you apply a local numbering scheme, as well as a global\n numbering scheme. And you occasionally need to convert the indices of the\n local portion into global numbering for some processing, and back; examples\n include data exchanges among processes within a transpose operation. The\n solution that I have now in the development branch of PSBLAS is the\n following: there are 4 integer kinds: int32==psb_mpk_ <= psb_ipk_ <=\n psb_lpk_ <= psb_epk_== int64 IPK is the integer kind used for *LOCAL\n indices, which are the ones for the local portion of the matrices involved\n in numerical operators such as Matrix-Vector product, LPK is the integer\n kind used for GLOBAL indices, which are used in pre- and post-processing.\n IPK and LPK can be specified at configure time within the constraints abov,\n with the default being IPK=int32 and LPK=int64. Salvatore\n\n Thank you Salvatore for your input. I should have a closer look to psblas.\n\n For stdlib: would it not be of interest to integrate psblas3 (if allowed)\n in stdlib directly? Or through fpm? In comparison to the other\n implementations, psblas3 is well tested, is associated to peer-reviewed\n publications and is parallelized (also with Coarray Fortran?) if we want to\n support parallelization in stdlib. If something is missing, we could\n identify it and maybe collaborate with psblas to implement the missing\n parts there?\n This is just a question to be sure that we don't start into something that\n is similar to reinventing the wheel.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#189 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD274T4E5LRQPHUNASHTN53RR6FW3ANCNFSM4NC62JUA>\n ."
                },
                {
                    "user": "certik",
                    "date": "2020-05-17 13:46:34+00:00",
                    "text": "Finally got to my computer. Thanks everybody for the feedback, I'll first address the high level feedback: do we want this at all, or should stdlib just use psblas3?\nMy own view is that stdlib should not be competing with or reimplementing well established libraries, whether LAPACK, psblas3, or others.\nJust linking against psblas3 but not providing any additional functionality or API I think is also not worth it. As the Fortran Package Manager becomes more successful, it will be very easy to depend on any library such as psblas3 in users projects, and we should be encouraging people to do exactly that. It will be good for users, good for developers of such libraries and the whole ecosystem.\nWhere I see the role of stdlib is to standardize API and provide a reference implementation to functionalities that are repeated from project to project with slightly different API each. There are many implementations of CSR and other functionality, see #38 for a partial list, and there are many codes that use this in some form. We should see if there is a way to figure out an API that each of these codes could use.\nThe other aspect where I see stdlib as contributing is when people just want to quickly use some functionality in their research / new projects, or later on interactively in the Jupyter notebook for example, having a nice and well documented API that is very easy to use for new users would be beneficial. Later on, for big specialized production codes, one can always use specialized libraries. As an example, most electronic structure codes have their own custom specialized eigensolver. But I think it is still worth having a nice API to dense eigensolver via Lapack, and a sparse eigensolver on top of this sparse functionality, so that people who just want to prototype some algorithm in Fortran can do so as easily as with SciPy, Matlab or Julia.\nIn order to move the conversation forward, we have to have both non-OO low level api as well as a high level OO API. The reason is that I know many people (myself included) who do not want to use the OO API, just simple subroutines that do the job. But I also know a lot of people who would prefer the OO API. By providing both, we can capture most of the Fortran community and make stdlib useful for almost everybody.\n@sfilippone at the very least I can see that we can use your sorting algorithms. I am hoping there is more that we can figure out how to reuse.\nAlso, I just want to start with a serial implementation, we can overload the subroutines to work with both int32 and int64 etc. I am really hoping we can figure out an API that we would all agree would make sense to have in stdlib."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-17 15:11:23+00:00",
                    "text": "But I think it is still worth having a nice API to dense eigensolver via Lapack, and a sparse eigensolver on top of this sparse functionality, so that people who just want to prototype some algorithm in Fortran can do so as easily as with SciPy, Matlab or Julia.\n\n@certik I totally agree with your comments.However, I wonder if this could be achieved by interfacing with the serial version of psblas, even partially. If it is not possible (e.g., because of no non-OO low level API), then I am fine with this, and I will help as good as I can."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-17 15:16:33+00:00",
                    "text": "I don't think that stdlib should just gulp up existing libraries and expose them under different name.\nFirst, decide if sparse matrix algebra is in scope or not. I'm not the target user (although I use SMM through ESMF under the hood daily), but if we agreed that a SciPy-like functionality is in scope, then this is too.\nSecond, if you do add it to stdlib, I think that it should provide added value over any existing library. In this case, I see that the added value could be ease of installation, and ease of use (simpler API).\nThis resonated with me personally the most:\n\nThe other aspect where I see stdlib as contributing is when people just want to quickly use some functionality in their research / new projects, or later on interactively in the Jupyter notebook for example, having a nice and well documented API that is very easy to use for new users would be beneficial. Later on, for big specialized production codes, one can always use specialized libraries."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-17 15:31:55+00:00",
                    "text": "Just to be clear, I personally think that SciPy-like scope is included in the scope of Fortran stdlib."
                }
            ]
        },
        {
            "number": 188,
            "user": "certik",
            "date": "2020-05-16 15:09:58+00:00",
            "title": "test_var fails in master",
            "text": "On my computer, Ubuntu 18.04, the test_var test fails in master:\n 1/20 Test #17: var ..............................***Failed    0.01 sec\nAt line 60 of file test_var.f90\nFortran runtime error: Array bound mismatch for dimension 1 of array 's' (281470681751419/4)\n\nError termination. Backtrace:\n#0  0x7f9b1b0b62ed in ???\n#1  0x7f9b1b0b6ed5 in ???\n#2  0x7f9b1b0b72a7 in ???\n#3  0x55b929a32134 in test_var\n\tat /home/ondrej/repos/stdlib/src/tests/stats/test_var.f90:60\n#4  0x55b929a711b9 in main\n\tat /home/ondrej/repos/stdlib/src/tests/stats/test_var.f90:2",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-05-16 15:15:16+00:00",
                    "text": "It seems to be the same issue as in #171 with the bug reported here for Gfortran 7:\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=94585\nWhich compiler/version did you use?"
                },
                {
                    "user": "certik",
                    "date": "2020-05-16 15:16:00+00:00",
                    "text": "Yes, I use GFortran 7.5.0.\nDid we agree that we will not support version 7? I am fine with that, I just need to upgrade."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-16 15:16:58+00:00",
                    "text": "Did we agree that we will not support version 7? I am fine with that, I just need to upgrade.\n\nYes, it was the conclusion I got from #171"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-16 15:22:14+00:00",
                    "text": "Now that at least 2 people stepped on this, it'd be useful that we add a note to the README.md about what compiler versions are supported."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-23 16:39:52+00:00",
                    "text": "it'd be useful that we add a note to the README.md about what compiler versions are supported.\n\nShould we add a section called \"Supported compilers\", or \"Tested compilers\" where we would report all the compilers we tested and if they are compatible with stdlib or not?"
                }
            ]
        },
        {
            "number": 187,
            "user": "ghwilliams",
            "date": "2020-05-15 17:08:33+00:00",
            "title": "Sparse matrix/vectors library",
            "text": "I believe that a library of sparse matrix/vectors operations would be of great utility in stdlib.\nSo I would like to propose the creation of such a library (It looks like there is not such a library yet in stdlib). Of course I'm making myself avaiable in designing and coding.\nregards\nWilliams",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-05-15 17:13:21+00:00",
                    "text": "@ghwilliams that's a great idea. Is what you propose different to #38? If not, then we can close this issue and continue the discussion at #38."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-15 17:33:47+00:00",
                    "text": "Looks like the same. I will jump to #38 and see what is the current state of development of it.\nI think you can close this issue @certik .\nThanks"
                },
                {
                    "user": "certik",
                    "date": "2020-05-15 18:05:23+00:00",
                    "text": "Cool thanks."
                }
            ]
        },
        {
            "number": 186,
            "user": "ashwinvis",
            "date": "2020-05-15 12:02:16+00:00",
            "title": "Enforce fortran syntax highlighting on fypp files",
            "text": "Fixes #185",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-05-15 17:28:58+00:00",
                    "text": "Thanks @ashwinvis !"
                },
                {
                    "user": "certik",
                    "date": "2020-05-15 17:30:03+00:00",
                    "text": "How does it work? I don't see any change here:\nhttps://github.com/fortran-lang/stdlib/blob/8be4bc0db4417bfe90b60e5e4d671e3047cd557a/src/stdlib_experimental_io.fypp"
                },
                {
                    "user": "ashwinvis",
                    "date": "2020-05-15 22:15:11+00:00",
                    "text": "Beats me... some other files work though:\n\nhttps://github.com/fortran-lang/stdlib/blob/ce987d2a4a215d8410f809cc1510d7eac24bd11d/src/common.fypp\nhttps://github.com/fortran-lang/stdlib/blob/ce987d2a4a215d8410f809cc1510d7eac24bd11d/src/stdlib_experimental_optval.fypp"
                },
                {
                    "user": "certik",
                    "date": "2020-05-15 22:23:03+00:00",
                    "text": "Weird. Your change should not hurt anything, so we'll keep it."
                }
            ]
        },
        {
            "number": 185,
            "user": "ashwinvis",
            "date": "2020-05-15 10:57:41+00:00",
            "title": "Add syntax highlighting to fypp source files",
            "text": "Since fypp is not officially supported:\n\nhttps://github.com/github/linguist/blob/master/lib/linguist/languages.yml\n\nIt could be worthwhile to override syntax hightlighting in github. It would make it easier to browse the source code online. See:\n\nhttps://github.com/github/linguist#overrides\ngithub/linguist#1792\n\nTo do this one could add a .gitattributes file:\n *.fypp linguist-language=fortran \n\nThoughts?",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-05-15 11:24:41+00:00",
                    "text": "Thank you. It sounds good to me if it can help the users."
                },
                {
                    "user": "ashwinvis",
                    "date": "2020-05-15 11:46:21+00:00",
                    "text": "Unfortunately it does not seem to work... \ud83d\ude15"
                },
                {
                    "user": "ashwinvis",
                    "date": "2020-05-15 11:58:38+00:00",
                    "text": "I do not understand how this works. I get some highlighting (somewhat garbled, but better than nothing) in a fresh repo:\n\nhttps://github.com/ashwinvis/test-fypp-syntax/blob/master/checks.fypp\n\nBut not if I add it to a fork of stdlib\n\nhttps://github.com/ashwinvis/stdlib/blob/patch-1/src/stdlib_experimental_io.fypp\n\nPerhaps GitHub does not render forks"
                }
            ]
        },
        {
            "number": 184,
            "user": "certik",
            "date": "2020-05-14 23:07:49+00:00",
            "title": "Zb documentation",
            "text": "Opening this per @zbeekman's request at #183.",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2020-05-15 00:21:32+00:00",
                    "text": "I think #183 is in good shape now. I was able to test deployment by adding the SSH secret key to my fork."
                }
            ]
        },
        {
            "number": 183,
            "user": "zbeekman",
            "date": "2020-05-14 21:43:50+00:00",
            "title": "Add automatic API-doc generation & deployment",
            "text": "EDIT: Preview the documentation here: https://fortran-lang.github.io/stdlib-docs/index.html\nNOTE: Autodeploy failed, not sure if it's due to this being a PR from a fork, or if ${{ secrets.ACTIONS_DEPLOY_KEY }} was never setup, or if it is incompatible with cross-repository deployment.\nPR to automatically generate and deploy documentation using FORD published via GH pages.\nNotes:\n\nI think we should move the specs to a dedicated directory, and then they can be rendered by FORD.\nIt would be nice to deploy these to something like stdlib.fortran-lang.org.\n\nI can make this happen but we need a DNS entry so I can add a CNAME file in the deployed gh-pages repo CC: @milancurcic @certik\n\n\nMay want to move the WORKFLOW.md and STYLEGUIDE.md documents into the FORD pages dir\n\nFor now this PR is a WIP.\nBegins to address issues:\n\n#4\n#182\n#94",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-05-14 22:01:48+00:00",
                    "text": "Thanks, Zaak! I think this is a great first step forward.\nPending others' reviews, let's move this forward and I can tackle the DNS record. I agree stdlib.fortran-lang.org is a good subdomain for this.\nAfter this is merged, then the GH actions will push to stdlib-docs repo. Then we can simply enable it to serve at the default location (fortran-lang.github.io/stdlib-docs), check that it looks good, then we can set up the CNAME record."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-14 22:10:49+00:00",
                    "text": "After this is merged, then the GH actions will push to stdlib-docs repo. Then we can simply enable it to serve at the default location (fortran-lang.github.io/stdlib-docs), check that it looks good, then we can set up the CNAME record.\n\nYeah, that was my thinking too. Currently it will deploy aggressively because I want to check that it's all working. (Assuming the ACTIONS_DEPLOY_KEY secret is properly set and I haven't mucked something up in the workflow file. I think @certik set it for me a while ago, but someone with admin should double check.)"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-14 22:43:10+00:00",
                    "text": "@milancurcic or @certik (or anyone else with full admin) can you please check and confirm that the ACTIONS_DEPLOY_KEY secret is properly set?\nThe deployment failed, but I'm not 100% sure why. If needed I can switch to a personal token."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-14 22:49:31+00:00",
                    "text": "@milancurcic or @certik (or anyone else with full admin) can you please check and confirm that the ACTIONS_DEPLOY_KEY secret is properly set?\nThe deployment failed, but I'm not 100% sure why. If needed I can switch to a personal token.\n\nI think this is due to this being a PR from a fork because secrets are not available in this context. Would it be OK to push this branch to the main repo and try the PR again to confirm deployment will work?"
                },
                {
                    "user": "certik",
                    "date": "2020-05-14 23:08:13+00:00",
                    "text": "I pushed it in #184. Let me know if you have rights to push into that branch."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-15 00:17:50+00:00",
                    "text": "Thanks @certik. I found a good work around for testing purposes: I added the secret to my fork which let me deploy successfully. If CI turns green here I'm happy to merge."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-15 17:43:39+00:00",
                    "text": "@zbeekman The CI is green and I will now merge this. Thank you!"
                }
            ]
        },
        {
            "number": 182,
            "user": "melissawm",
            "date": "2020-05-14 18:46:56+00:00",
            "title": "User-facing documentation",
            "text": "I'd like to suggest a difference between user-facing documentation (Tutorials, How-tos) and Reference/API docs. In #4 , most of the comments apply to Reference, but I don't see mentions of user-facing documentation. Are you interested in that?\nI'm working for a few months at the Documentation Team for NumPy, and we have been using the concepts described in this article which has been extremely helpful in organizing and writing new docs for NumPy. For reference, we also wrote a NumPy Enhancement Proposal to elaborate on it.\nI'm not saying stdlib should go in the same direction; that's for the community to decide. But I'd like to propose a discussion on whether the community wants this kind of content, how to organize it and how can we contribute to it.\nThis kind of documentation can be done with Sphinx, github pages or some other tool; Sphinx has the disadvantage of being a bit cumbersome in syntax, but it's easy to use it to integrate with the API documentation (including cross-linking etc). Markdown is easier and allows for other people to contribute with a lower barrier of entry.\nWhat I'm proposing in this issue is\n\nA discussion around the best tool (even if temporary) for writing user-facing documentation for stdlib\nWhich documents are high priority that people could start writing right now.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-05-14 19:19:39+00:00",
                    "text": "@melissawm thank you for proposing it. For sure we want a nice user facing documentation.\nI recently learned of this project:\nhttps://myst-parser.readthedocs.io/\nWhich allows you to use Sphinx, but with Markdown syntax! I've been looking for something like that for years. I haven't tried it yet, but I am hoping it will work great.\nSo I am going to try it and set it up, and if it works, I propose we use that. As that way we can just use Markdown."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-14 19:34:01+00:00",
                    "text": "Hi I can help writing some tutorials using stdlib. What tools do I need to use? I can start writing the fortran codes (necessary for the tutorials) and the text in simple MS Word."
                },
                {
                    "user": "certik",
                    "date": "2020-05-14 19:36:01+00:00",
                    "text": "@ghwilliams awesome, thank you! Write it in Markdown and put it into our wiki: https://github.com/fortran-lang/stdlib/wiki\nThen as we setup a website / Sphinx, we can easily port it."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-14 19:37:18+00:00",
                    "text": "Great. I will try it."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-18 21:26:21+00:00",
                    "text": "The FORD documentation is getting deployed now. We could try writing user-facing, prose-like documentation in the FORD pages directory. Please see the \"Writing Pages\" documentation on the FORD wiki.\nI am open to other ideas too, but consolidating things in one place might be nice. Also, anyone who wants to help keep FORD maintained/up-to-date is welcome to help out."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-18 21:38:15+00:00",
                    "text": "Yes, I think this is the way to go. Having the user-facing docs and the API-like docs under the same system will make it easier to maintain."
                },
                {
                    "user": "certik",
                    "date": "2020-05-18 22:54:14+00:00",
                    "text": "In the long run, can FORD become a plug into Sphinx? Sphinx has many more contributors (https://github.com/sphinx-doc/sphinx/). FORD could be used to handle extracting the documentation out of Fortran, and Sphinx for the rest, together with the Markdown parser for Sphinx I mentioned above (https://myst-parser.readthedocs.io/), if it works. There are additional features that you want to use (I would argue), such as citations, cross references, label math equations, pdf export, etc. The Sphinx / myst-parser supports that, but FORD doesn't seem so.\nThis would have the advantage that we don't have to maintain our own documentation tool. We can still have our own template / style.\nIt might be too much work to get it working with Sphinx and thus not worth it, but the motivation to maintain our own documentation tool should be better explained I feel. We already have to develop and maintain so many tools around Fortran, that I feel it would be very helpful to piggy back on Sphinx and have one less thing to worry about.\nAlso, if FORD is to become our main tool to handle documentation, I would recommend to relicense it to MIT or BSD to be compatible with the rest of the tools that we are trying to develop for Fortran (and generally compatible with the Python ecosystem also)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-18 23:31:50+00:00",
                    "text": "Also, if FORD is to become our main tool to handle documentation, I would recommend to relicense it to MIT or BSD to be compatible with the rest of the tools that we are trying to develop for Fortran (and generally compatible with the Python ecosystem also).\n\nDoes this matter if we're not distributing the source or linking to it? We're using it as a tool in CD.\n@cmacmackin are you open to relicensing? We've talked about this before and I know you like GPL, but some time has passed."
                },
                {
                    "user": "certik",
                    "date": "2020-05-19 00:35:07+00:00",
                    "text": "Does this matter if we're not distributing the source or linking to it?\n\nFirst of all I think we should distribute it as part of FPM so that users can build documentation of their projects (probably as a Conda package that FPM will simply install).\nIt does not technically matter right now. But it might in the future, and we might want to reuse some code from it in other projects as well as distribute it, and these relicensing efforts are best done at the beginning, otherwise it becomes a nightmare later, because you have to ask each contributor for a permission. Furthermore, I think we should play nicely with the Python ecosystem, FORD being a Python package, so I suggest to read this \"BSD pitch\" from the author of Matplotlib:\nhttp://nipy.sourceforge.net/nipy/stable/faq/johns_bsd_pitch.html\nas he says, we want to make it easy for companies to use our work and to embrace Fortran. If FORD becomes the documentation tool for Fortran, companies will sooner or later start asking about the GPL license, and by being MIT or BSD, it's one less obstacle to worry about. (I am well aware that GPL allows commercial distribution, but I am also aware that lawyers in big corporations must analyze and approve or deny each case.)"
                },
                {
                    "user": "cmacmackin",
                    "date": "2020-05-19 07:02:12+00:00",
                    "text": "In the long run, can FORD become a plug into Sphinx?\n\nI've actually been thinking about this a bit already and it probably is the right way to go. No immediate plans to work on it, however.\n\nAlso, if FORD is to become our main tool to handle documentation, I would recommend to relicense it to MIT or BSD to be compatible with the rest of the tools that we are trying to develop for Fortran (and generally compatible with the Python ecosystem also).\n\nAbsolutely not. I am a firm believer in the GPL. If I were to spin off some of FORD into a library then I would be open to releasing that under the LGPL, but that is as permissive as I'll get. Even that may be difficult in practice, however, as there are a number of other contributors to FORD who never assigned their copyright to me and would thus have to agree to the change.\nI am willing to accept that this could mean you won't be able to reuse FORD code in other tools (unless they're willing to go GPL). However, there is absolutely nothing to stop you from running or packaging FORD. If you refuse to package GPL code then you will be denying yourself some very good software, such as FFTW3, which doesn't seem sensible to me.\nGPL shouldn't be a serious impediment to companies running FORD. After all, the most popular compiler out there (GCC) is under a GPL license."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-19 15:57:41+00:00",
                    "text": "The way we're using FORD right now, I think it's okay. However, @certik's points are valid and we can't anticipate how we'd want to work and/or distribute the documentation system in the future. For this reason, we should start looking into alternatives immediately: Sphinx + Myst? Mkdocs? Readthedocs?\nBtw, even packaging FORD would be problematic, the way we're designing fpm now. As far as I understand this, If FORD is pulled as a Conda binary distribution, we have to also bring in the source, and the whole parent package needs to be GPL'd. So I personally don't think we should go down this road."
                },
                {
                    "user": "cmacmackin",
                    "date": "2020-05-19 16:42:50+00:00",
                    "text": "I can't speak for the legalities of Conda distributions as I don't know much about how they work. However, in general it is not necessary to distribute a copy of the source code with binary, so long as the source code is publicly accessible and instructions are provided to access it (section 6e of the licence):\n\n... If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source....\n\nI can't remember off the top of my head whether FORD would include any such instructions at present, but I'd be happy to add them.\nI note that distributing GPL code in a Conda binary is already done in the case of FFTW3."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-19 16:43:19+00:00",
                    "text": "I hope my efforts weren't in vain. I still don't fully understand why we can't LGPL it (under v2) as Chris mentioned. It's a tool (or plug in to a tool) so we should be able to find a way to use an LGPL version, no? There won't be any runtime dependency, and the docs that it generates are under whatever license the user wants."
                },
                {
                    "user": "cmacmackin",
                    "date": "2020-05-19 16:57:43+00:00",
                    "text": "Found an FAQ entry which seems to address this: https://www.gnu.org/licenses/gpl-faq.en.html#MereAggregation\nIt shouldn't be an issue."
                },
                {
                    "user": "certik",
                    "date": "2020-05-19 16:58:48+00:00",
                    "text": "Thanks @cmacmackin for explaining your view. You should choose the license that you see fit for FORD, and just to make clear, I am not questioning your choice of license for your library. That's why I didn't post this comment in the FORD repository. I very strongly believe that if you start a library and do all the work, you have every right to choose any license you want.\nIn the same way, for fortran-lang repositories and the related tools, I very strongly believe it is best for the community and the ecosystem if we use permissive licenses and I explained the reasons above.\nBeyond licensing, I do not think we should be maintaining a general documentation / website generator. Rather, we should pick a well maintained tool and only maintain a plugin to extract comments from Fortran source codes. As Milan mentioned, Sphinx + Myst, Mkdocs, Readthedocs are all options we should explore. They have large communities.\n@zbeekman your efforts were not in vain. We have something to get started and that is always important."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-19 19:24:40+00:00",
                    "text": "I just hope we can find/make something with Fortran support that is as good as FORD's is. I'm doubtful we'll find anything with first class Fortran support. I still don't fully understand why an LGPL version of FORD couldn't be turned into a Sphinx plugin and used. But \u00af_(\u30c4)_/\u00af"
                },
                {
                    "user": "certik",
                    "date": "2020-05-19 21:22:55+00:00",
                    "text": "Right now FORD seems to be the best tool there is, so that's why we are using it (I am a big fan of having something even if imperfect, rather than nothing). That does not mean it must necessarily be the best approach in the long run, as discussed above.\nAll I am asking is that we keep our options open."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-19 21:28:46+00:00",
                    "text": "EDIT: I left out a word or two\nI'm completely open to that. If there's something more appropriate and close to as good or better than FORD, then sign me up! (I just haven't seen it yet.)"
                }
            ]
        },
        {
            "number": 181,
            "user": "vansnyder",
            "date": "2020-05-06 19:13:54+00:00",
            "title": "Documentation style for stdlib",
            "text": "The stdlib should be packaged in modules, each one a coherent set of related procedures (and types and constants). These should ultimately all be described in a consistent style, as (or at least as if) an optional part of the standard. Procedures should be described in the same format as in subclause 16.9 of part 1 of the standard. Constants and opaque types can be described as in subclause 16.10. Types that have public components and bindings could be described by a type definition that shows only type parameters, and the public components and bindings. Type-bound procedures should be described as in subclause 16.9. I prepared my proposal for special functions in this format.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-05-06 19:33:08+00:00",
                    "text": "Thank you @vansnyder for your comments.\n\nProcedures should be described in the same format as in subclause 16.9 of part 1 of the standard.\n\nGood point. The current format (see example here for stdlib_experimental_stats ) should probably slightly modified if we want to follow exactly the same format as in the standard."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-06 19:54:49+00:00",
                    "text": "I think this is a good plan for the specification docs. It would also ease the transition to the standard if and when it's proposed. Then we could evolve a specification doc -> J3 paper.\nWe'll also need a separate set of user friendly docs but we're not there yet."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-05-07 13:28:24+00:00",
                    "text": "I must admit I am not a huge fan of the format required by the standard. The priority should be the user-facing documentation, which needs to be dynamic, web based, should have syntax highlighting, links, etc. Nobody is going to be printing this stuff out in book form, so we shouldn't be limited to that format."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-07 15:53:05+00:00",
                    "text": "I don't like the standard format either, but both are important. One of the original motivations behind stdlib is to implement and evaluate in practice functions before proposing them to J3. Documenting the spec in the standard format would save us from a lot of work later. Another question is whether there is much value to have a built-in function if there is one in a stable and portable stdlib (I don't think so).\nI agree that user-docs are higher priority. But we haven't done any work toward that, except some docstrings inside the code itself, which I don't think is the best solution either.\nJacob, can you help with the user-docs?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-07 16:03:59+00:00",
                    "text": "I agree that the standard format is too minimalist and that the user-docs is more important.\nBut it would be nice if we could extract what is needed for the standard directly from stdlib user-docs, and I think that the current format (that contains e.g. more verbose examples) is quite close to allow it."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-18 21:29:25+00:00",
                    "text": "The specs and user documentation don't need to be the same. User documentation could be less formal and have more/richer examples and point to the spec for detailed reference? It's hard to have an exceedingly strong opinion without also being willing to work up a PR (or two... or a dozen) to prototype and/or implement the proposal."
                }
            ]
        },
        {
            "number": 180,
            "user": "p-costa",
            "date": "2020-05-06 09:02:44+00:00",
            "title": "fixed precision of variable ans",
            "text": "",
            "comments": []
        },
        {
            "number": 179,
            "user": "certik",
            "date": "2020-05-04 18:28:39+00:00",
            "title": "List of special mathematical functions to include",
            "text": "Here is a paper from 2007 that was submitted to the Fortran Committee, but ultimately rejected:\nhttps://wg5-fortran.org/N1651-N1700/N1688.pdf\nThe functions there seem to be exactly in the scope of stdlib, so we should include them and we can use this paper as a starting point.",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2020-05-04 23:19:05+00:00",
                    "text": "Indeed, this document looks like a nice starting point. Would this go to stdlib_experimental_specfun (or stdlib_experimental_special_functions) for now or would we borrow the name iso_fortran_special_functions?\nI suppose many of these functions could be adapted from the following sources:\n\nSLATEC Library (public domain)\nFullerton Function library (later part of Slatec!?)\nNSWC Mathematics Subroutine Library (\"approved for public release\")\nJPL MATH77 Library (custom license)\nspecfun (license unclear; edit: this is TOMS 715, so not usable)\nFaddeeva Package (MIT) by Steven Johnson\nAmos (falls under the SLATEC license, see here)\n\nAlso the scipy.special module gives references to many of these older codes."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-05 19:49:27+00:00",
                    "text": "Here is a paper from 2007 that was submitted to the Fortran Committee, but ultimately rejected:\n\nDo we know why it was rejected? Maybe the author(s) of this proposal has/have already some implementations that could be integrated in stdlib. Of course, @ivan-pi 's list will be useful too.\nAnyway, I think it would be nice to have them in stdlib.\nI am in favor of the name stdlib_experimental_special_functions."
                },
                {
                    "user": "certik",
                    "date": "2020-05-05 20:12:54+00:00",
                    "text": "It was @vansnyder's proposal. Van, do you know why it was rejected?"
                },
                {
                    "user": "vansnyder",
                    "date": "2020-05-05 20:29:09+00:00",
                    "text": "I don't remember why it was rejected. It was eleven years ago.\n\nMight have been as simple as \"We don't like optional parts of the\nstandard. The first two didn't do anything useful.\"\n\u2026\nOn Tue, 2020-05-05 at 13:13 -0700, Ond\u0159ej \u010cert\u00edk wrote:\n It was @vansnyder's proposal. Van, do you know why it was rejected?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe."
                },
                {
                    "user": "vansnyder",
                    "date": "2020-05-06 18:54:12+00:00",
                    "text": "JPL Math77 is now available without license from netlib."
                },
                {
                    "user": "vansnyder",
                    "date": "2020-05-06 19:03:59+00:00",
                    "text": "I've revised my 2009 proposal to correspond to Fortran 2020. ISO doesn't allow the kind of revision suffix that J3 allows, but I did it anyway. I just can't ask Steve to put it on the WG5 server with that number.\nI think the stdlib should be packaged in modules, each one a coherent set of related procedures (and types and constants). These should ultimately all be described in a consistent style, as an optional part of the standard. Procedures should be described in the same format as in subclause 16.9 of part 1 of the standard. Constants and opaque types can be described as in subclause 16.10. Types that have public components and bindings could be described by a type definition that shows only type parameters, and the public components and bindings. Type-bound procedures should be described as in subclause 16.9.\nN1688r2.pdf"
                },
                {
                    "user": "certik",
                    "date": "2020-05-06 23:21:37+00:00",
                    "text": "Thanks @vansnyder for the updated document. Yes, that is our goal to have stdlib organized as modules with coherent set of procedures and documented in a Standard compatible way. Thanks for the tips how to do that."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-05-07 11:12:18+00:00",
                    "text": "I've found this post from 2017 on Julia Discourse by Steven Johnson, where he comments on the implementation of special functions in Fortran vs Julia:\n\nFor example, I implemented an erfinv function Julia (JuliaLang/julia#2987 35), and it was about 3x faster than Matlab or SciPy\u2019s erfinv function, both of which are taken from standard Fortran libraries. (This is benchmarking single-threaded vectorized calls on large arrays where the Matlab/Python overhead should be negligible.) The underlying algorithm is similar to those used in the Fortran routines (in Matlab\u2019s case this is only a guess), because almost everyone uses the same rational-function approximations published in the 1970s.\nI have found similar gains (compared to Fortran code called in SciPy) for other special functions, e.g. polygamma functions (JuliaLang/julia#7125 14) and exponential integrals (JuliaMath/SpecialFunctions.jl#19 11).\nThe reason Julia can beat the Fortran code is that metaprogramming makes it easy to apply performance optimizations that are awkward in Fortran. We have metaprogramming macros (@evalpoly) that can easily inline polynomial evaluations, whereas the Fortran code makes function calls that loop over look-up tables of polynomial coefficients. Even greater speedups are possible for evaluating polynomials of complex arguments, where there is a fancy recurrence from Knuth that is almost impossible to use effectively without code generation. In principle, the Fortran authors could have done the same inlining and gotten similar performance, but the code would have been much more painful to write by hand. (They could even have written a program to generate Fortran code, but that is even more painful.)\n\nWhile I don't think we should focus strongly on optimization to begin with, it would be interesting to see if we can do something similar with fypp."
                },
                {
                    "user": "certik",
                    "date": "2020-05-07 16:51:22+00:00",
                    "text": "@ivan-pi nice find. Initially indeed we should focus on functionality, but later our goal should definitely be to be as fast or faster than Julia. It might be a nice benchmark for Flang and LFortran also."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-21 20:32:52+00:00",
                    "text": "As my weekend project, I had a go at implementing Horner's algorithm with fypp (see mentioned issue aradi/fypp#8). This way polynomials can be efficiently inlined.\nThe syntax looks like\n        @:horner(p,t,0.160304955844066229311e2,&\n                      -0.90784959262960326650e2,&\n                       0.18644914861620987391e3,&\n                      -0.16900142734642382420e3,&\n                       0.6545466284794487048e2,&\n                      -0.864213011587247794e1,&\n                       0.1760587821390590,prec=dp)\n\nand gets expanded into\n  p = ((((((0.1760587821390590_dp*t + (-0.864213011587247794e1_dp))*t + (0.6545466284794487048e2_dp))*t +&\n      & (-0.16900142734642382420e3_dp))*t + (0.18644914861620987391e3_dp))*t + (-0.90784959262960326650e2_dp))*t +&\n      & (0.160304955844066229311e2_dp))\n\nThere is still some space for improvement with respect to the preprocessor syntax.\nI've implemented the inverse error function using the Horner macro. The expanded code is:\nelemental function erfinv(x) result(res)\n    use, intrinsic:: ieee_arithmetic, only: ieee_value, &\n      ieee_positive_inf, ieee_negative_inf, ieee_quiet_nan\n    real(dp), intent(in) :: x\n    real(dp) :: a, t, res, p, q\n\n    a = abs(x)\n    if (a >= 1.0_dp) then\n      if (x == 1.0_dp) then\n        res = ieee_value(1._dp, ieee_positive_inf)\n      else if (x == -1.0_dp) then\n        res = ieee_value(1._dp, ieee_negative_inf)\n      else\n        ! domain error\n        res = ieee_value(1._dp,ieee_quiet_nan)\n      end if\n    else if (a <= 0.75_dp) then ! Table 17 in Blair et al.\n        t = x*x - 0.5625_dp\n  p = ((((((0.1760587821390590_dp*t + (-0.864213011587247794e1_dp))*t + (0.6545466284794487048e2_dp))*t +&\n      & (-0.16900142734642382420e3_dp))*t + (0.18644914861620987391e3_dp))*t + (-0.90784959262960326650e2_dp))*t +&\n      & (0.160304955844066229311e2_dp))\n  q = ((((((0.1e1_dp*t + (-0.206010730328265443e2_dp))*t + (0.10760453916055123830e3_dp))*t + (-0.22210254121855132366e3_dp))*t +&\n      & (0.21015790486205317714e3_dp))*t + (-0.91374167024260313936e2_dp))*t + (0.147806470715138316110e2_dp))\n        res = x * p / q\n    else if (a <= 0.9375) then ! Table 37 in Blair et al.\n        t = x*x - 0.87890625_dp\n  p = (((((((0.237516689024448_dp*t + (-0.5478927619598318769e1_dp))*t + (0.19121334396580330163e2_dp))*t +&\n      & (-0.22655292823101104193e2_dp))*t + (0.11763505705217827302e2_dp))*t + (-0.29344398672542478687e1_dp))*t +&\n      & (0.3444556924136125216_dp))*t + (-0.152389263440726128e-1_dp))\n  q = (((((((0.1e1_dp*t + (-0.10014376349783070835e2_dp))*t + (0.24640158943917284883e2_dp))*t + (-0.23716715521596581025e2_dp))*t&\n      & + (0.10695129973387014469e2_dp))*t + (-0.24068318104393757995e1_dp))*t + (0.2610628885843078511_dp))*t +&\n      & (-0.108465169602059954e-1_dp))\n        res = x * p/q\n    else ! Table 58 in Blair et al.\n      t = 1.0_dp / sqrt(-log(1.0_dp - a))\n  p = ((((((((((0.22419563223346345828e-2_dp*t + (-0.177910045751117599791e-1_dp))*t + (0.668168077118049895750e-1_dp))*t +&\n      & (0.72718806231556811306121_dp))*t + (0.207897426301749172289354e1_dp))*t + (0.262556728794480727266643e1_dp))*t +&\n      & (0.283026779017544899742694e1_dp))*t + (0.1042615854929826612283637e1_dp))*t + (0.129695500997273524030254_dp))*t +&\n      & (0.5350414748789301376564e-2_dp))*t + (0.56451977709864482298e-4_dp))\n  q = ((((((((0.1e1_dp*t + (0.203724318174121779298258e1_dp))*t + (0.387828582770420112635182e1_dp))*t +&\n      & (0.376311685364050289010232e1_dp))*t + (0.303793311735222062372456e1_dp))*t + (0.105429322326264911952443e1_dp))*t +&\n      & (0.129866154169116469345513_dp))*t + (0.5350558706793065395335e-2_dp))*t + (0.56451699862760651514e-4_dp))\n        res = p / (sign(t,x) * q)\n    end if\nend function\n\nEdit: there was an error in my erfinv version near the ends of the domain (-1,1), that I've now replaced.\nSwapping axes to compare with the error function in gnuplot I can see the code works correctly:"
                },
                {
                    "user": "vansnyder",
                    "date": "2020-06-22 18:26:23+00:00",
                    "text": "On Sun, 2020-06-21 at 13:33 -0700, Ivan wrote:\n Swapping axes to compare with the error function in gnuplot I can see\n the code works correctly:\n\n\nThis is reassuring, but wouldn't be adequate justification to publish\nin a professional journal.\n\nFor mathematical function testing, one method uses a higher-precision\nreference that is computed using a different algorithm, that can be\nimplemented in a transparently-correct way. Run the function, and the\nreference, using randomly-selected values in thousands or millions of\nlittle boxes, over the range of applicability (or several sub ranges).\nThen tabulate the fraction that are correct within 1/2 unit in the last\nposition (ULP), 1 ULP, 2 ULP, ....\n\nFor inverses, such as ERF and ERFINV, one can compute and tabulate\nERF(ERFINV(X)) - X, using a higher-precision and previously-verified\nversion of ERF.\n\nWhen implementing a published approximation, not verifying that the\napproximation computes the desired function, testing would verify that\nyou've correctly transcribed the constants. Errors other than the most\negregious ones wouldn't be visible on a plot."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-06-23 01:29:01+00:00",
                    "text": "Curious. Did you time your example against any intrinsics?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-23 10:38:50+00:00",
                    "text": "Thanks @vansnyder for the suggestions. After tabulating the error, I found the precision dropped slightly in one of the intervals. I replaced the code above now with some slightly more accuracte coefficients. After tabulating ERF(ERFINV(X)) - X (calculated in double precision) over the range (-0.995,0.995), the error does not exceed 2.e-16, but I will do more tests before making this a pull request.\n\nCurious. Did you time your example against any intrinsics?\n\nNot yet. I went down the rabbit-hole so to say, and started designing some benchmarking macros similar to those in BenchmarkTools.jl.\nFor comparison, the inverse error function is available in\n\nMATLAB - erfinv\nJulia - erfinv\nScipy - erfinv (through the Cephes library and the inverse of the normal distribution, see here)\nIntel MKL - v?ErfInv (vector version)\nNSWC Library - DERFI (this one also uses the rational approximations by Blair et al. (1976)  that appear in Julia and my code above; the polynomial coefficients however, are loaded from a table)"
                }
            ]
        },
        {
            "number": 178,
            "user": "p-costa",
            "date": "2020-05-03 21:57:38+00:00",
            "title": "fixed minor typo in comment",
            "text": "",
            "comments": []
        },
        {
            "number": 177,
            "user": "certik",
            "date": "2020-05-03 20:37:36+00:00",
            "title": "In-place naming convention",
            "text": "We need to figure out a consistent naming convention for routines that return the result in-place, as many routines will have two versions: in-place (e.g., eig_inplace) and out-of-place (e.g. eig). I think a good idea is to have the out-of-place version the default (eig), and have special naming convention for in-place (eig_inplace or some of the other option from the list below).\nThis was originally discussed at #10 (comment). List of options for syntax (#10 (comment)):\n\neig_inplace\neig_i or eig_I\neigI\n\nI'll update this list if more candidates are proposed.\nA lot of people like eig_inplace. It's long, but presumably it won't be used as often as eig, and it is clear what it does.\nOther languages:\nI couldn't find any naming convention how NumPy and Matlab does it. Looks like only Julia has a naming convention for in-place?\nJulia\nout-of-place: svd\nin-place: svd!",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2020-05-04 12:35:17+00:00",
                    "text": "I couldn't find any naming convention how NumPy and Matlab does it. Looks like only Julia has a naming convention for in-place?\n\nCertain functions in SciPy (perhaps also NumPy, but I couldn't find any) accept some logical arguments if they should overwrite the inputs or not. Take solve for instance:\n scipy.linalg.solve(a, b, sym_pos=False, lower=False, overwrite_a=False, overwrite_b=False, debug=None, check_finite=True, assume_a='gen', transposed=False)\nFor MATLAB I found this old blog post (https://blogs.mathworks.com/loren/2007/03/22/in-place-operations-on-data/#8) which says that some of the built-in functions already obey in-place semantics (e.g. A=max(A,B) will not create an intermediate variable). Users can take advantage of this in their own functions (hoping the MATLAB JIT will do the right thing):\nfunction y = myfunc(x)\ny = sin(2*x.^2+3*x+4);\n\nfunction x = myfuncIP(x)\nx = sin(2*x.^2+3*x+4); \nCalling y = myfuncIP(x) would result in an error.\nIn the Eigen C++ library for linear algebra, they provide both options via template mechanisms and overloaded constructors (see https://eigen.tuxfamily.org/dox/group__InplaceDecomposition.html for details) :\nPartialPivLU<Ref<MatrixXd> > lu(A); // in-place\nPartialPivLU<MatrixXd> lu(A); // preserve A"
                }
            ]
        },
        {
            "number": 176,
            "user": "ivan-pi",
            "date": "2020-05-03 18:36:46+00:00",
            "title": "Upper or lower triangular part of an array",
            "text": "triu and tril\ntril - lower triangular part of an array\ntriu - upper triangular part of an array\nReturn a copy of the lower/upper triangular part of a rank-2 array. The elements below/above the k-th diagonal are replaced with zeroes (default k=0)\nUseful to recover the lower or upper part of a matrix factorization.\nInterface\ninterface tril\n    module function tril_rsp(A) result(L)\n        real(sp), intent(in) :: A(:,:)\n        real(sp) :: L(size(A,1),size(A,2))\n    end function\n    module function tril_k_rsp(A,k) result(L)\n        real(sp), intent(in) :: A(:,:)\n        integer, intent(in) :: k\n        real(sp) :: L(size(A,1),size(A,2))\n    end function\n    ! .. repeat for all real and integer kinds ..\nend interface\nAnalogous interface for triu. The interfaces would go to the file stdlib_experimental_linalg.f90. Implementations would go to the submodule stdlib_experimental_linalg_trilu.f90.\nPoint for discussion: two separate functions (without or with diagonal) as shown above or only a single interface using the present intrinsic?\nOther languages\nJulia\n\ntril: https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.tril\ntriu: https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.triu\n\nMATLAB\n\ntril: https://de.mathworks.com/help/matlab/ref/tril.html\ntriu: https://de.mathworks.com/help/matlab/ref/triu.html\n\nPython (NumPy)\n\ntril: https://numpy.org/doc/stable/reference/generated/numpy.tril.html\ntriu: https://numpy.org/doc/stable/reference/generated/numpy.triu.html\n\nC++\n\n(Eigen) Triangular view: https://eigen.tuxfamily.org/dox/group__QuickRefPage.html#title14 (since matrices are classes, this gives a triangular view of a dense matrix with specialized operations)\n(Armadillo) trimatu/trimatl: http://arma.sourceforge.net/docs.html#trimat\n\nOther\n\nWould we like a subroutine version which works in-place? In Julia they use the tril!(M) and triu!(M) syntax for this purpose.",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2020-05-03 18:38:49+00:00",
                    "text": "I was working on some Kalman filter stuff today, and I realized this would be useful to check I am calling the right sequence of BLAS and LAPACK routines."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-03 19:15:22+00:00",
                    "text": "Nice proposition. It is something I often use in Octave.\n\nPoint for discussion: two separate functions (without or with diagonal) as shown above or only a single interface using the present intrinsic?\n\nWhy would you like 2 separate functions? I would suggest to implement only one function and use the optval function for the optional integer.\n\n\nWould we like a subroutine version which works in-place? In Julia they use the tril!(M) and triu!(M) syntax for this purpose.\n\n\nYes, I would. However, I don't really like the sign \"!\" used in Julia."
                },
                {
                    "user": "certik",
                    "date": "2020-05-03 20:38:23+00:00",
                    "text": "Great idea, thanks.\nRegarding in-place, see #177 for a discussion about the syntax. We can't use ! in Fortran (plus I don't really like it anyway)."
                }
            ]
        },
        {
            "number": 175,
            "user": "milancurcic",
            "date": "2020-04-19 19:31:00+00:00",
            "title": "Consolidate specification docs into a master specification doc",
            "text": "Somewhat related to #4.\nCurrently we have individual specification markdown documents for each module and we place them in the src/ directory.\nPersonally, I find that it'd be much easier to read the spec if we consolidated all the spec docs into a a single markdown file. Then we could have heading 2 for each module and heading 3 for each procedure. More importantly, if you wanted to show stdlib to somebody and have them see what's currently implemented, you could point them to a single document where they could see everything.\nSecond, spec docs shouldn't be in src/--this directory is for source files. Specification would be more accessible in the top-level directory. (I personally only read the spec docs on GitHub where they're rendered nicely).\nI'd be happy to take a stab at this if the community agrees it's a step forward.\n@certik @jvdp1 @ivan-pi What do you think?",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-04-20 15:03:46+00:00",
                    "text": "I agree with both points: all specs could be merged into one single document, and they should not be in src (intuitively I will not check src to find some docs).\nIt was convenient to keep it as now as a starting point.  I guess it will also depend how #4 will be implemented."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-26 20:47:47+00:00",
                    "text": "I agree the current set up is not optimal. Also the src/ directory is starting to get crowded.\nI don't think having one single markdown file is a good idea on the long term, it will quickly become too big, and people might mistakenly edit the wrong section, or delete something by accident, etc.. Maybe having separate markdown files for each module and merging them using pandoc upon pull requests would be a way to go (sort of like suggested here?\nI'm torn between including the documentation directly in the source files or our current approach. On one hand, including the documentation in the source files halves the number of files necessary to maintain and the documentation can be easily edited along with the code. On the other hand, it is easier to write markdown in a separate file (without having to write comment symbols, and using editor snippets), also the source code is more streamlined."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-29 18:53:28+00:00",
                    "text": "I'm torn between including the documentation directly in the source files or our current approach.\n\nShouldn't it be based on how the documentation #4 is developed?"
                },
                {
                    "user": "certik",
                    "date": "2020-04-29 20:08:05+00:00",
                    "text": "I don't feel strongly either way. The goal is to have an implementation independent specification so that one can implement a different implementation (perhaps commercial and/or faster) using it --- and this might later go into the Standard itself. If there is a better way to organize this specification, then let's do it."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-29 22:04:38+00:00",
                    "text": "I'm torn between including the documentation directly in the source files or our current approach.\n\nShouldn't it be based on how the documentation #4 is developed?\n\nYes. Perhaps my comment would be more suitable in that issue.\n\nThe goal is to have an implementation independent specification so that one can implement a different implementation (perhaps commercial and/or faster) using it --- and this might later go into the Standard itself.\n\nIf this is part of our plan, I think we should have an independent specification document. It would be annoying to have to look for the specs in the code source itself (or on some auto-generated website)."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-18 21:33:07+00:00",
                    "text": "This issue might be closeable thanks to #183. It's at least a step in the right direction.\nAlso, now the specs can use the FORD linking syntax to link directly to the API documentation."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-19 05:51:16+00:00",
                    "text": "Also, now the specs can use the FORD linking syntax to link directly to the API documentation.\n\nThis linking syntax sounds what I was looking for. How should I use it? It is not clear from the doc. Could you point to an example, please?"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-19 19:19:56+00:00",
                    "text": "This linking syntax sounds what I was looking for. How should I use it? It is not clear from the doc. Could you point to an example, please?\n\nFor future reference, I added some and a comment with explanation in PR #198."
                }
            ]
        },
        {
            "number": 174,
            "user": "jvdp1",
            "date": "2020-04-19 15:01:55+00:00",
            "title": "Proposal for covariance between 2 vectors or matrices",
            "text": "The PR #172 introduces a function to compute covariances of elements for a vector of an array.\nHere Iw ould like to discuss the API for a function cov that computes the covariance between 2 vectors or matrices x and y.\nThe API could be:\nres = cov(x, y, dim[, maskx, masky][, corrected])\n\nx, y: Shall be vectors or matrices of the same type, with the condition that size(x, dim) == size(y, dim)\nmaskx, masky (optional): Shall be scalars, vectors, or matrices of type logical. Vectors and matrices maskx and masky must be of the same shape as the corresponding vectors and matrices  x and y, respectively.\nIf one of the masks is a scalar, then both masks are scalar (mainly to avoid a large number of functions with scalar masks).\nIf one of the masks is a vector or a matrix, then none or both masks must be provided.\ncorrected (optional): Shall be a scalar of type logical.",
            "comments": []
        },
        {
            "number": 173,
            "user": "jvdp1",
            "date": "2020-04-17 19:32:15+00:00",
            "title": "Replace mean in ERROR message by var in var functions",
            "text": "Replace \"mean\" in ERROR message by \"var\" in var functions",
            "comments": []
        },
        {
            "number": 172,
            "user": "jvdp1",
            "date": "2020-04-12 10:05:34+00:00",
            "title": "Covariance of array elements",
            "text": "Draft proposal for covariance of array elements opened for discussion\nRelated to #113\nTo be discussed:\n\nName: the currently proposed name is cov. But what about covariance,....?\nAPI: similar to the API of variance\nImplementation: only for arrays of rank 1 and rank 2.\nImplementation: the API accepts only 1 array.\nAn implementation to compute the covariance among 2 arrays still needs to be done.\n\nOthers:\nOctave cov\nMatlab cov\nJulia cov\nR cov\nNumpy cov\ncov - covariance of array elements\nDescription\nReturns the covariance of the elements of array along dimension dim if the corresponding e\nlement in mask is true.\nPer default, the covariance is defined as:\n cov(array) = 1/(n-1) sum_i (array(i) - mean(array) * (array(i) - mean(array)))\n\nwhere n is the number of elements.\nThe scaling can be changed with the logical argument corrected. If corrected is .false.,\nthen the sum is scaled with n, otherwise with n-1.\nSyntax\nresult = cov(array, dim [, mask [, corrected]])",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2020-04-13 14:13:22+00:00",
                    "text": "I am fine with both cov or covariance. In case we decide to go for the long version, I would suggest renaming var to variance. They can always be renamed at import if desired, using use stdlib_stats, only: cov => covariance.\nOverall a nice proposal, so I am fine with merging."
                },
                {
                    "user": "certik",
                    "date": "2020-04-13 17:38:11+00:00",
                    "text": "Looks good. Yes cov seems fine, consistent with other languages."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-17 19:35:51+00:00",
                    "text": "It seems that all of you agreed with cov as name for this function.\nIf there are no other comments about the implementation and API, it could be merged.\nNote: An implementation to compute the covariance between 2 arrays still needs to be done, but it will be for another PR."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-22 14:58:22+00:00",
                    "text": "I will merge this PR. Thank you for your reviews and approvals."
                }
            ]
        },
        {
            "number": 171,
            "user": "jvdp1",
            "date": "2020-04-11 22:04:49+00:00",
            "title": "variance_correction: small issue with debug mode of gfortran 7",
            "text": "Gfortran 7 with debug options (but not Gfortran 9) failed on, e.g.,\ni32 = d\nSo, I replaced the line by:\nallocate(i32, source = int(d)",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2020-04-13 15:12:13+00:00",
                    "text": "In #169 (comment) @milancurcic reckoned we should avoid workarounds for what is supposed to be valid code.\nAt the same time, it would be a nuisance to bring in preprocessor macros to differentiate between compiler versions and avoid spurious warnings. Then again, your change is valid Fortran code, just a bit more explicit, so I suppose this is the easier solution in the short-term."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-04-13 15:50:38+00:00",
                    "text": "@jvdp1 What exactly fails here for gfortran 7?\nIf gfortran 7 didn't support reallocation on assignment (I thought it did), I don't see a good reason to babysit the compiler here--the feature is reasonably mature (F2003). I'd rather recommend upgrading the compiler to a later release.\nHowever, if the feature is supported but has a bug, we should file a bug report rather than inserting a workaround into stdlib.\nWe don't need to support all earlier releases of compilers. We just need to make a pragmatic decision what we want and don't want to support. It's fine for various things to be unsupported or broken until somebody complains.\nOf course, this is all just my opinion. I'm curious to hear what others think, @certik @nncarlson @nshaffer"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-13 16:52:15+00:00",
                    "text": "@jvdp1 What exactly fails here for gfortran 7?\n\nHere are more details:\n$ gfortran --version\nGNU Fortran (GCC) 7.2.0\nCopyright \u00a9 2017 Free Software Foundation, Inc.\n\nAdditional options used for compilation:\n-fimplicit-none -Wall -fcheck=all -fbacktrace\n\nIssue with test_far (and similarly for test_varn):\nAt line 60 of file /home/WUR/vande018/stdlib/src/tests/stats/test_var.f90\nFortran runtime error: Array bound mismatch for dimension 1 of array 's' (1/4)\n\nError termination. Backtrace:\n#0  0x402096 in ???\n#1  0x43ad54 in ???\n#2  0x2aaaab81b544 in ???\n#3  0x401538 in ???\n#4  0xffffffffffffffff in ???\n<end of output>\n\nCorrespinding line 60 in test_var.f90:\ns = d\nNote: there is no problem with gfortran 7 and without debug options."
                },
                {
                    "user": "certik",
                    "date": "2020-04-13 17:31:51+00:00",
                    "text": "It's this automatic reallocation of LHS, which used to be buggy in gfortran in various scenarios. We either require GFortran > 7, or we fix it by providing a workaround (one way or another) that works with GFortran 7.\nYes, in general valid code should work, but in reality many valid Fortran codes do not work with every compiler, and so providing workarounds for our supported compilers is necessary.\nSo it's just about deciding whether we want to support GFortran 7 or not."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-04-13 17:48:05+00:00",
                    "text": "I agree with @certik.  It's unfortunate but necessary.\nI'd also add that the set of supported compilers will evolve in time, with some older compilers being dropped while new ones are added. In this regard it will be important to somehow tie individual workarounds to specific compiler versions and not just to the compiler (e.g., gfortran).  That will allow workarounds for unsupported compilers to be easily removed from the code base. Otherwise the code base will become more and more littered with workarounds as time goes on."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-04-13 18:02:52+00:00",
                    "text": "However, if the feature is supported but has a bug, we should file a bug report rather than inserting a workaround into stdlib.\n\nUnless one is dealing with the NAG compiler where they almost always fix bugs within a couple of weeks, this is not an either-or proposition.  Definitely always file a bug report.  But then one will also need to implement a workaround if one wants to go ahead using the buggy feature. Every other compiler I've dealt with takes many months, sometimes years, to fix reported bugs."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-13 18:38:27+00:00",
                    "text": "Thank you for your feedbacks.\nThe same issue seems to be also present in gfortran 8!\nI will report the bug.\nFor this PR, I let you decide what is best for the current and future situations."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-14 07:10:36+00:00",
                    "text": "Bug reported here:\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=94585"
                },
                {
                    "user": "certik",
                    "date": "2020-04-14 08:46:58+00:00",
                    "text": "Thanks!\n\nThey already responded as wontfix.\n\nI would be ok to drop GFortran 7 support. By the time stdlib is useful, hopefully most people will be able to use GFortran 8.\n\u2026\nOn Tue, Apr 14, 2020, at 1:10 AM, Jeremie Vandenplas wrote:\n\n\n Bug reported here:\n https://gcc.gnu.org/bugzilla/show_bug.cgi?id=94585\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#171 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWENP3XOTD2552E7HGTRMQD7VANCNFSM4MGFGH2A>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-17 19:17:42+00:00",
                    "text": "Because the GFortran 7-branch is closed, I am also ok to drop GFortran 7 support. If more people think that too, this PR can be closed without being merged."
                },
                {
                    "user": "certik",
                    "date": "2020-04-17 19:22:45+00:00",
                    "text": "@milancurcic any comments?\nBtw I think you have some unrelated change in this PR that can go in (you should post it as a separate PR)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-04-17 19:24:39+00:00",
                    "text": "I agree with not supporting GFortran 7 with this workaround."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-17 19:26:51+00:00",
                    "text": "Btw I think you have some unrelated change in this PR that can go in (you should post it as a separate PR).\n\nI will open another PR for these!"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-30 20:59:04+00:00",
                    "text": "Btw I think you have some unrelated change in this PR that can go in (you should post it as a separate PR).\n\nI will open another PR for these!\n\nDone with PR #173"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-30 21:00:21+00:00",
                    "text": "I close this PR because it seems there is an agreement to not support GFortran 7 with this workaround,"
                }
            ]
        },
        {
            "number": 170,
            "user": "ivan-pi",
            "date": "2020-04-10 11:52:23+00:00",
            "title": "Addition of diag, eye, and trace",
            "text": "See proposal in #169 . This is a draft pull request.\nThis is my first time using the fypp preprocessor, so I decided to only focus on rank-2 arrays to keep things simple and submit a pull request before my focus shifts away from stdlib. Hopefully the API will not need to change if we decide to generalize these to higher rank-matrices, otherwise the generalizations could be placed into a stdlib_tensor module in the future.\nI am still missing the tests, but thought it would be beneficial to get some feedback on the functions and documentation first.\n@jvdp1 Did you use fypp to generate the tests for the statistical routines and then committed only the generated .f90 files?",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2020-04-10 18:20:30+00:00",
                    "text": "It would maybe good to move the functions in submodules. It avoids the compilation of alll functions when modifying only some of them.\n\n\nI agree. I expect that in the future we will likely have several linear algebra submodules (array creation routines, solvers, matrix properties...).\n\n\nI think it could be easily extended to ranks >2 with the same API quite easily using fypp. However, I am the target user for such functions.\n\n\nI don't think a tensor version of eye is trivial, at least not under a common interface like eye(n [,rank]). We could have multiple versions for different ranks, e.g. eye (equal to eye2),  eye3, eye4, eye5, etc.?\nI can try to make trace rank-generic for the main diagonal, and also have a version similar to numpy\nnumpy.trace(a, offset=0, axis1=0, axis2=1, dtype=None, out=None)\nwhich calculates the trace of each two-dimensional slice returning an array. But since the name trace is typically linked with linear algebra, for the tensor \"trace\" it might be a better idea to have a general tensor_contraction function (https://en.wikipedia.org/wiki/Tensor_contraction).\nWith diag comes again the question, how to specify the rank of the output? Also the diagonal specifier is not immediately clear. Is the aim to operate on the individual 2d slices, or somehow set/extract a diagonal/slice in >=3 dimensions?\n (image taken from here)\n\n\nI wrote the tests by hand.\n\n\nI applaud your effort. \ud83d\udc4f"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-10 18:32:22+00:00",
                    "text": "Is the aim to operate on the individual 2d slices, or somehow set/extract a diagonal/slice in >=3 dimensions?\n\nGood point. I didn't think so far.\nAnyway, this is a nice proposal that could help many people as is."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-10 22:20:56+00:00",
                    "text": "In the routine to extract the k-th diagonal from a matrix, I have the following interface:\n     function diag_${t1[0]}$${k1}$_mat_k(A,k) result(res)\n        ${t1}$, intent(in) :: A(:,:)\n        integer, intent(in) :: k\n        ${t1}$ :: res(minval(shape(A))-abs(k))\n    end function\n\nInterestingly, if abs(k) > minval(shape(A)), the size of res is negative, however this gets correctly translated into a zero-size array. I've double checked this with the following program:\nimplicit none\nreal :: res(-5)\nprint *, size(res)\nend\nwhich prints \"0\" for both the ifort and gfortan compilers  without any warnings. So it looks like Fortran had my back covered \ud83d\ude0e .\nEdit: a related issue appeared in the Intel Fortran Forum: https://software.intel.com/en-us/forums/intel-fortran-compiler/topic/297666. Here is a quote from the Fortran standard pertaining to this issue in the context of allocatable arrays:\n\nIf the lower bound is omitted, the default value is 1. If the upper bound is less than the lower bound, the extent in that dimension is zero and the array has zero size.\n\nExplicit-shape arrays also follow the same behavior. (e.g. https://groups.google.com/forum/#!topic/comp.lang.fortran/xGwU2diHm60)"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-11 00:57:33+00:00",
                    "text": "Is there any interest to extend diag also to logical arrays?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-11 20:23:41+00:00",
                    "text": "Is there any interest to extend diag also to logical arrays?\n\nNot from my side. For what would you use such a matrix?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-13 14:21:12+00:00",
                    "text": "It could be used as a mask to unpack values into a certain diagonal or more generally as a mask in other functions. The numpy diag also allows it, in MATLAB I think logical masks are binary arrays, so it probably also just works."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-13 17:12:14+00:00",
                    "text": "It could be used as a mask to unpack values into a certain diagonal or more generally as a mask in other functions. The numpy diag also allows it, in MATLAB I think logical masks are binary arrays, so it probably also just works.\n\nIf other languages support it, it is probably good to support it too. Up to you to decide. I don't think I would need such a logical function."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-05-03 20:05:02+00:00",
                    "text": "I was planning to have a go at the logical kind version, but would like to clarify first if it would suffice to support only the default logical kind or all those supported by the compiler (for some odd reason?):\nipribec@ipribec-T530:~/fortran$ cat test_logical_kinds.f90 \nuse iso_fortran_env\nprint *, logical_kinds\nend\nipribec@ipribec-T530:~/fortran$ gfortran test_logical_kinds.f90 && ./a.out\n           1           2           4           8          16\nipribec@ipribec-T530:~/fortran$ ifort test_logical_kinds.f90 && ./a.out\n           1           2           4           8\nipribec@ipribec-T530:~/fortran$ \n\nAny thoughts?\nIf not, pending a review of the tests, I would merge this."
                },
                {
                    "user": "certik",
                    "date": "2020-05-03 20:12:41+00:00",
                    "text": "I think we can merge this now. We are in experimental, so any such changes / modifications can always be done later."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-05-05 21:00:53+00:00",
                    "text": "Thanks @jvdp1, @milancurcic, and @certik for the review and approvals. I've squashed the commits and will merge after the tests are completed."
                }
            ]
        },
        {
            "number": 169,
            "user": "ivan-pi",
            "date": "2020-04-07 23:26:22+00:00",
            "title": "diag, eye, and trace",
            "text": "Related to #10\nConvenience functions for use in linear algebra. The functions would go into stdlib_experimental_linalg.f90. Simple implementation by looping over the diagonal. Type-generic (integer, real, complex) implementation using the fypp preprocessor.\nA draft is available here: https://github.com/ivan-pi/stdlib/blob/ivan-pi/src/stdlib_experimental_linalg.fypp (based on the version from fortran-utils #103 )\neye\nReturns the identity matrix\nfunction eye(n) result(res)\ninteger, intent(in) :: n\nreal(dp), allocatable :: res(:  ,:)\nend function\n\nDo we need an optional kind dummy variable for the return type (eye(n [, kind]))? Or just default to double precision?\nOther names: identity, ... ?\nGeneralize also to higher rank arrays (tensors)?\nFixed-size or allocatable output?\n\ntrace\nReturns the sum of diagonal elements\npure function trace(A) result(res)\nreal(dp), intent(in) :: A(:,:)\nreal(dp) :: res\nend function\n\nHow to deal with non-square matrices? Take the sum over the shorter dimension? Run-time shape assertion?\nOptional axis argument?\nDiagonal offset?\nGeneralize to higher rank arrays (tensors)?\n\ndiag\nCreate a diagonal matrix from a vector or extract a diagonal from a matrix\n! vector to matrix\nfunction diag(v, k) result(res)\nreal(dp), intent(in) :: v(:)\ninteger, intent(in), optional :: k ! place elements of v on the k-th diagonal\nreal(dp), allocatable :: res(:,:)\nend function\n! matrix to vector\nfunction diag(A, k) result(res)\nreal(dp), intent(in) :: A(:,:)\ninteger, intent(in), optional :: k ! extract elements from the k-th diagonal of A\nreal(dp), allocatable :: res(:)\nend function\n\nOther names: diagonal, ...\nSpecify which diagonal to use?\nHow to deal with non-square matrices? Extract the diagonal along the shorter dimension? Run-time shape assertion?\nGeneralize to higher rank arrays?\nFixed-size or allocatable output?\n\nOther languages\nThe API's differ slightly between languages, some are more flexible than others.\n\ndiag:\n\nJulia: https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.Diagonal\nMATLAB: https://de.mathworks.com/help/matlab/ref/diag.html\nPython: https://docs.scipy.org/doc/numpy/reference/generated/numpy.diag.html\n\n\ntrace\n\nJulia: https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.tr\nMATLAB: https://de.mathworks.com/help/matlab/ref/double.trace.html\nPython: https://docs.scipy.org/doc/numpy/reference/generated/numpy.trace.html?highlight=trace#numpy.trace\n\n\neye:\n\nJulia: eye has been deprecated (https://discourse.julialang.org/t/why-eye-has-been-deprecated/12824/7)\nMATLAB: https://de.mathworks.com/help/matlab/ref/eye.html\nPython: https://docs.scipy.org/doc/numpy/reference/generated/numpy.eye.html#numpy.eye",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-04-07 23:30:34+00:00",
                    "text": "Thank you!\nI like this.\nI have one comment: I think the function should not return an allocatable --- I think it could be faster to simply return the array and expect the caller to provide a correctly pre-allocated array as a result."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-07 23:43:50+00:00",
                    "text": "Yes, your comment is related to the discussion in #114. If the LHS is also allocatable (and unallocated), then I think the compilers will do the right thing and not create a temporary array.\nWould there be any interest in having two versions, say diag and diag_ (or diagA), one expecting preallocated arrays of correct size, and the other one returning allocatable ones? This way it would be possible to select for speed or flexibility."
                },
                {
                    "user": "certik",
                    "date": "2020-04-08 01:51:11+00:00",
                    "text": "Thanks for finding the prior discussion. What is the advantage of having it allocatable result? With auto allocate LHS, wouldn't the compiler properly allocate the LHS anyway?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-08 06:16:40+00:00",
                    "text": "With auto allocate LHS, wouldn't the compiler properly allocate the LHS anyway?\n\nYes, it does.\nAnd if the compiler doesn't do it (because it is not supported yet), I usually do something like:\n...\nreal, allocatable :: x(:, :)\nallocate(x, source = diag(x))"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-08 06:37:59+00:00",
                    "text": "Thank you for this.\n\neye\n\nDo we need an optional kind dummy variable for the return type (eye(n [, kind]))? Or just default to double precision?\n\n\nI would suggest to support all types, as for the other functions. Would a subroutine not easier to implement and to use for this scenario? E.g.,\ncall eye(x)\n\n\nOther names: identity, ... ?\n\n\neye is good for me.\n\n\nGeneralize also to higher rank arrays (tensors)?\n\n\nI would say yes, while I will probably never use it myself.\n\ndiag\n\nOther names: diagonal, ...\n\n\ndiag sounds good to me.\n\n\nSpecify which diagonal to use?\n\n\nYes, as you proposed should be fine. I guess that a negative number could be provided to extract elements below the diagonal?\n\n\nHow to deal with non-square matrices? Extract the diagonal along the shorter dimension? Run-time shape assertion?\n\n\nI am not sure to understand the question. I think you could loop until min(size(x, 1), size(x,2)).\n\n\nGeneralize to higher rank arrays?\n\n\nI would answer yes, while I would never use it myself."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-08 16:29:16+00:00",
                    "text": "eye\n\nDo we need an optional kind dummy variable for the return type (eye(n [, kind]))? Or just default to double precision?\n\n\nI would suggest to support all types, as for the other functions. Would a subroutine not easier to implement and to use for this scenario? E.g.,\ncall eye(x)\n\nThe downside of a subroutine is then you cannot chain the identity matrix into expressions, e.g.\nreal :: M(9,9), J(9,9)\nM = eye(9) + 1./(tau + 0.5)*(eye(9) - J))\nOn the other hand as a subroutine it would encourage reuse\nreal :: M(9,9), J(9,9), identity(9,9)\ncall eye(identity)\nM = identity + 1./(tau + 0.5)*(identity - J))\nThen again, I see this only as a convenience function, and not to be used inside some expensive kernel, as it is clear there are more efficient ways to add values to the diagonal of a matrix.\n@jvdp1 Do you have any suggestion how to control the return type of eye? I don't think I can add an integer kind variable as the return type needs to be resolved at compile time. As a subroutine however it would work fine.\n\n\n\n\nSpecify which diagonal to use?\n\n\nYes, as you proposed should be fine. I guess that a negative number could be provided to extract elements below the diagonal?\n\nFrom the numpy API for diag:\nDiagonal in question. The default is 0. Use k>0 for diagonals above the main diagonal, and k<0 for diagonals below the main diagonal.\nI noted now the Julia \u02d9Diagonal` is a bit different. Given a matrix A, it returns a matrix keeping only the elements on the diagonal (and setting the other values to zero)\n\n\n\n\nHow to deal with non-square matrices? Extract the diagonal along the shorter dimension? Run-time shape assertion?\n\n\nI am not sure to understand the question. I think you could loop until min(size(x, 1), size(x,2)).\n\nYour suggestion is equivalent to what I have now:\n      function diag_rsp_mat(A) result(res)\n        real(sp), intent(in) :: A(:,:)\n        real(sp) :: res(minval(shape(A)))\n\n        integer :: i\n        do i = 1, minval(shape(A))\n          res(i) = A(i,i)\n        end do\n      end function diag_rsp_mat\nUntil some form of assertion mechanism is available, I think this is the easiest solution. For the k dummy variable to select a  specific diagonal it will be necessary to flag an error if abs(k) > minval(shape(A)) - 1."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-08 16:56:09+00:00",
                    "text": "@jvdp1 Do you have any suggestion how to control the return type of eye? I don't think I can add an integer kind variable as the return type needs to be resolved at compile time. As a subroutine however it would work fine.\n\nWould a stragegy like the one used for ieee_value be an option for eye?\nE.g.,\nreal(sp) :: a\nreal(sp), allocatable :: b(:,:)\n\nb= eye(a,5)\n\nb= eye(1._sp, 5)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-04-08 16:58:23+00:00",
                    "text": "Thanks for this proposal. I like it. Some comments:\n\nAPI and function names look reasonable to me.\nRegarding whether the result should be allocatable, only if it must, i.e. if it can't be determined from shape/size of input parameters. I don't see why the function results here need to be allocatable. However, it may need to be if we are to generalize to arbitrary ranks.\nOn functions vs. subroutines: My personal rule is always use functions unless a you need to return more than one result, or you need to make side effects.\nI am also not the target user of these functions.\n\nSpecifically regarding eye:\n\n\neye\n\nDo we need an optional kind dummy variable for the return type (eye(n [, kind]))? Or just default to > double precision?\n\nWhy different return types? It's just a bunch of ones and zeros of some desired shape. In the same vain, why even double precision result? Why not just integer? You can then use it directly in expressions and let the compiler promote it to the higher types or kinds if needed.\nInteger-only result for eye() only becomes an issue if you want to pass it as an argument to a procedure that expects some other type or kind. Then you promote it explicitly."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-08 18:43:16+00:00",
                    "text": "Thank you both for your comments.\n@jvdp1 Yes, that would be the option giving full control to the caller.\n@milancurcic I like your solution with implicit type promotion as it simplifies the code.\nIf most of you agree with the implicit type promotion solution, then eye will simply be:\n    integer function eye(n) result(res)\n        integer, intent(in) :: n\n        integer :: res(n,n)\n        integer :: i\n        res = 0\n        do i = 1, n\n            res(i,i) = 1\n        end do\n    end function\nand can be used as to fill both fixed-size or allocatable arrays, and also appear in expressions:\n    real(sp) :: a(0:5,0:5)\n    real(dp), allocatable :: b(:,:)\n    integer(int32), allocatable :: t(:,:)\n\n    a = eye(6)\n    b = eye(9)\n    t = 3*eye(12)\n\n    call random_number(a)\n    a = a + eye(6)\nThis works fine with the ifort compiler and -warn all. With gfortran-9 and -Wall I get a bunch of warnings of the type test_eye.f90:30:0: Warning: \u2018b.dim[0].lbound\u2019 is used uninitialized in this function [-Wuninitialized] (it still works correctly). To prevent them it is necessary to follow Jeremie's approach above and with explicit type promotion:\n    allocate(b,source=real(eye(9)))"
                },
                {
                    "user": "certik",
                    "date": "2020-04-08 18:46:52+00:00",
                    "text": "What do you mean by \"implicit type promotion\"? I didn't get that part. I agree it should look like this:\n    function eye(n) result(res)\n        integer, intent(in) :: n\n        integer :: res(n,n)\n        integer :: i\n        res = 0\n        do i = 1, n\n            res(i,i) = 1\n        end do\n    end function\n(You had an extra integer before function, which is superfluous.)"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-08 18:50:24+00:00",
                    "text": "Oops, thanks.\nWhat I meant was we have only one copy of eye that returns an integer result, and allow the compiler to promote it to double, complex, int64, whatever, when used in an expression or upon assignment."
                },
                {
                    "user": "certik",
                    "date": "2020-04-08 18:51:18+00:00",
                    "text": "I see. I think that's fine."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-08 18:51:59+00:00",
                    "text": "@ivan-pi I am ok with the implicit type promotion, as proposed.\nNote: if we go for this solution, why not using 1-byte integer for the result res. This would limit the amount of memory needed by this function eye."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-04-08 18:55:10+00:00",
                    "text": "With gfortran-9 and -Wall I get a bunch of warnings of the type test_eye.f90:30:0: Warning: \u2018b.dim[0].lbound\u2019 is used uninitialized in this function [-Wuninitialized] (it still works correctly).\n\nI think this is a spurious warning. b is here used only on the LHS of the assignnment. It's fine.\nI strongly recommend against putting workarounds in code only to suppress warnings. In this specific case, I don't think that the compiler is warning about anything reasonable, as far as I can tell.\n\nwhy not using 1-byte integer for the result res. This would limit the amount of memory needed by this function eye.\n\nIs int8 portable at this time? I don't know. If yes, I think we should do it. I can't think of any other potential downsides."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-10 11:56:58+00:00",
                    "text": "I've gone forward and made a draft pull request (#170), implementing most of your suggestions. \ud83d\udc4d"
                },
                {
                    "user": "certik",
                    "date": "2020-04-10 16:30:02+00:00",
                    "text": "@ivan-pi thank you for doing this! Looks very nice."
                },
                {
                    "user": "certik",
                    "date": "2020-04-10 16:34:47+00:00",
                    "text": "We can now use diag to construct a new matrix from the diagonal.\nWould it make sense to also be able to assign to a diagonal of an existing matrix?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-10 17:16:11+00:00",
                    "text": "Would it make sense to also be able to assign to a diagonal of an existing matrix?\n\nI guess so. In Octave, I usually do that as:\nD=diag(diag(A))"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-10 17:26:26+00:00",
                    "text": "Would it make sense to also be able to assign to a diagonal of an existing matrix?\n\nWouldn't a subroutine be more suitable for this? Something along the lines of\nsubroutine set_diag(A,v,k)\nreal, intent(inout) :: A(:,:)\nreal, intent(in) :: v(minval(shape(A)) - abs(k))\ninteger, intent(in) :: k\nend subroutine"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-10 17:31:56+00:00",
                    "text": "I remembered there was a discussion on the topic of setting the diagonal over at j3-fortran/fortran_proposals#14\nThere was also a discussion for the identity matrix j3-fortran/fortran_proposals#103 with this interesting Fortran one-liner:\ninteger, parameter :: n = 4  ! dimension of the identity matrix\nreal(wp), parameter :: I(n,n) = RESHAPE([ (MERGE(1._wp, 0._wp, i/n==MOD(i,n)), i=0, n**2-1) ], [n,n])"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-10 20:25:24+00:00",
                    "text": "We can now use diag to construct a new matrix from the diagonal.\nWould it make sense to also be able to assign to a diagonal of an existing matrix?\n\nAnother way would be to have a function which returns the diagonal indices, like in numpy:\n>>> di = np.diag_indices(4)\n>>> di\n(array([0, 1, 2, 3]), array([0, 1, 2, 3]))\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15]])\n>>> a[di] = 100\n>>> a\narray([[100,   1,   2,   3],\n       [  4, 100,   6,   7],\n       [  8,   9, 100,  11],\n       [ 12,  13,  14, 100]])\n\nThis could work nicely, if it was possible to slice into a rank-2 array as a rank-1 array.\n\nOr perhaps a solution using the intrinsic unpack?\nreal :: A(3,3)\nA = 0\nA = unpack([1.,2.,3.],eye(3) == 1, A)\nHopefully a smart compiler would access only the values of A where eye(3) == 1 equals .true."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-05-05 21:35:15+00:00",
                    "text": "Hooray! With pull request #170 we have a new module for linear algebra. I've edited the labels to reflect the new status."
                }
            ]
        },
        {
            "number": 168,
            "user": "JHenneberg",
            "date": "2020-03-31 08:33:54+00:00",
            "title": "specified order of attributes #167",
            "text": "Lets discuss if this is need or giving to much overhead. For now there is positive (@jvdp1 ) and negative (@certik ) feedback.\nIn my opinion a standard library should not only provide functionalty, it also should give example how to use a programming language in an elegant way. We decided already in the STYLE_GUIDE.md to include indentation and whitespaces conventions which have of course bigger impact but specifiying that at an end of a scope there should be a closing statment is quite a minor thing so why to draw a line when specifiying the order of attritbutes?",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-04-07 14:37:31+00:00",
                    "text": "Merging into master, thank you!"
                }
            ]
        },
        {
            "number": 167,
            "user": "JHenneberg",
            "date": "2020-03-30 05:51:06+00:00",
            "title": "set order of attributes",
            "text": "While reading the style guide STYLE_GUIDE.md I noticed that the order of the attributes is not specified.\nGoing through the source files the order seems:\n\nallocatable\ndimension\nintent(intent-spec)\noptional\n\nAlthough it is not clear if allocatable should be after oder before dimension\nMissing attributes I can think of right now are:\n\ntarget, pointer\nparameter\npublic, private, protected\nasynchronous\nsave\nexternal\ncontiguous\nvolatile\n\nSo lets come up with a convention for the order of attributes.\nSuggestion so far for STYLE_GUIDE.md\n# Order of attributes\n\nSimiliar to the guidlines for indentation and whitespace, specifiying the order of appearance of attributes can  help reviewing code and git-diffs.\n\n1. ```allocatable```\n2. ```dimension```\n3. ```intent(<>)```\n4. ...",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-03-30 17:59:38+00:00",
                    "text": "Good point.\nI usually write things in this order:\n\ndimension\nallocatable\nintent(intent-spec)\noptional\n\nSome combinations of attributes are not possible.\nCould you maybe submit a PR with suggested modifications for further discussions?"
                },
                {
                    "user": "certik",
                    "date": "2020-03-30 21:18:06+00:00",
                    "text": "I do not follow a strict order, although typically intent() is at the end, the allocatable and dimension I use in any order, and optional is typically around intent() in either order.\nIs it important to always follow a certain order? It seems maybe we do not need to standardize this?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-31 12:01:45+00:00",
                    "text": "I tend to write these attributes in the same order as @jvdp1. More lately, I prefer to omit dimension, so:\nreal, dimension(:), allocatable :: a\nreal, dimension(:,:), allocatable :: b\nbecomes just:\nreal, allocatable :: a(:), b(:,:)\nNot only is the code less verbose by not including dimension, but also arrays of different size, shape, or rank can be declared on the same line.\nLike @certik, I don't think the order is as important. Rather than enforcing the order, I'd prefer seeing these two clauses:\n\nDon't use dimension attribute to declare arrays\nAlways specify intent for dummy arguments\n\nIf we did indeed specify order of attributes in the style guide, I'd personally like to see:\n\nintent attribute should be specified last in the declaration statement\nIf optional attribute is used to declare a dummy argument, it should follow the intent attribute\n\nor similar."
                },
                {
                    "user": "certik",
                    "date": "2020-03-31 14:08:32+00:00",
                    "text": "I agree with @milancurcic. I also prefer not to use dimension, the only exception is if I have a lot of arrays of the same dimension (of high rank), such as here:\nhttps://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/ofdft_fe.f90#L249\nthen it saves lots of typing."
                }
            ]
        },
        {
            "number": 166,
            "user": "jvdp1",
            "date": "2020-03-27 15:23:21+00:00",
            "title": "Spec for error_stop and check",
            "text": "@milancurcic Here is a first draft for the specs about error_stop and check.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-03-27 19:04:35+00:00",
                    "text": "Thank you @milancurcic and @everythingfunctional for your comments. They are now integrated."
                },
                {
                    "user": "certik",
                    "date": "2020-03-27 22:20:46+00:00",
                    "text": "Looks great. +1 to merge as is."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-30 18:00:17+00:00",
                    "text": "Thank you for your comments. I will merge it as is."
                }
            ]
        },
        {
            "number": 165,
            "user": "jvdp1",
            "date": "2020-03-27 08:26:07+00:00",
            "title": "Example in specs for stats",
            "text": "Small PR to clarify the examples in the specs for stats (the reshape calls made the examples complex IMO).",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-03-27 19:05:40+00:00",
                    "text": "This PR was quite straigthfoward, and mainly formatting. I will merge it."
                }
            ]
        },
        {
            "number": 164,
            "user": "jvdp1",
            "date": "2020-03-26 19:36:36+00:00",
            "title": "adapt_CI: correction to avoid RANK>4 in Github actions",
            "text": "I think I found the issue in #161 for which the Github action failed due to too long times needed for the manual Makefiles.\nThe issue is that the tests for in-tree builds generate the .f90 from fypp with RANK = 15. Because these are generated before running the manual Makefiles (and that there is no cleaning), the manual Makefiles do not generate them anymore, and try to compile all the .f90 files generated with RANK=15 (instead of RANK=4 as for CMake).\nThis proposition fixes this issue (and will fix the issue in #161 once merged there).\nTimes needed for the checks are also now more manageable.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-03-26 19:58:08+00:00",
                    "text": "Straightforward and approved. Merging into master."
                }
            ]
        },
        {
            "number": 163,
            "user": "milancurcic",
            "date": "2020-03-24 22:18:00+00:00",
            "title": "121 replace assert with check",
            "text": "This PR implements the check subroutine, proposed to replace assert for internal testing. Specifically:\n\nImplements check as proposed here\nReplaces existing calls to assert with calls to check\nRemoves the definition of assert from stdlib_experimental_error\n\nThis PR doesn't cover making all check calls to print meaningful messages on failure, and to execute them with warn=.true., to allow multiple test failures in a single run. These will be covered in a future PR.\nThis internal testing is meant as temporary until we can do it with fpm test as proposed in #162. For now, we consider this as a \"good enough\" solution that will help us move forward with development while fpm is in the works.\nFinally, there is also Brad's proposed implementation here which we shouldn't ignore. If there is some support from the community for it, let's discuss and consider it.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-03-25 02:11:54+00:00",
                    "text": "@ivan-pi You're right. The latest commit fixes that."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-25 15:53:01+00:00",
                    "text": "Thanks, all. @everythingfunctional, let's do a separate issue and PR for your proposal when you're ready. Merging."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-27 08:47:43+00:00",
                    "text": "@milancurcic Do we want that users use both check and error_stop outside stdlib? OR are these only aimed for stdlib?\nIf users can use them outside stdlib, then I think it would be good to have some specs (like for other functions)  (I can give a start based on the comments in the code). Personally, I could use both outside stdlib ;)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-27 12:08:35+00:00",
                    "text": "@jvdp1 I think so. Sorry, I totally forgot about the spec. That should've been part of the original PR. Please go ahead with a draft spec if you don't mind. Thank you!"
                }
            ]
        },
        {
            "number": 162,
            "user": "everythingfunctional",
            "date": "2020-03-23 20:38:51+00:00",
            "title": "Proposal to use Testing Framework",
            "text": "Rather than do ad-hoc testing of the standard library, we should adopt and use a dedicated testing framework. We'll use this issue to discuss possible candidates, their pros and cons, and what requirement we might have for choosing one.",
            "comments": [
                {
                    "user": "everythingfunctional",
                    "date": "2020-03-23 20:41:35+00:00",
                    "text": "I'm going to firstly suggest my library, vegetables.\nCons:\n\nIt comes with some additional dependencies\n\nPros:\n\nAs I'm also working on fpm, and the long term goal is for us to start using it, I will likely port it to fpm, alleviating the above con\n\nI'm open to suggestions about others though."
                },
                {
                    "user": "certik",
                    "date": "2020-03-23 21:19:44+00:00",
                    "text": "I think we need a testing framework. We should integrate it with fpm, so that things just work. Dependencies will then not be a problem.\nIn fact, I think Cargo allows you to use any testing framework you want. One simply specifies it in [dev-dependencies]. So we should design fpm in the same way. That way people can use any testing framework they like friction free.\nSo we can use vegetables. The issue I have is with the API. See:\n#121 (comment)\nI don't like assertEquals. I think Fortran's conventions are to use something like assert_equal or assert_eq, see STYLE_GUIDE.md#variable-and-procedure-naming.\n@everythingfunctional would you be willing to consider using such names, assuming most people would agree?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-23 21:43:37+00:00",
                    "text": "Of all the testing frameworks I looked at, I like vegetables the best, minus the camelCase but that's a nit pick :).\nWhat I'm still confused about is where do you write actual tests. Brad wrote here that testing should be done from the outside. Concretely, what does that mean for stdlib?\n\nTests are written in a dedicated project stdlib-tests which has vegetables as a dependency?\nTests are written in fpm which has vegetables as a dependency?\nTests are written in vegetables?\n\nOf the three, only the 1st makes some sense to me. Of course, the most sensible solution to me is to write tests in stdlib, and then the framework is a dependency there (if pure Fortran or C, not a biggie). But I got the impression that that's not what you're trying to do."
                },
                {
                    "user": "certik",
                    "date": "2020-03-23 21:46:31+00:00",
                    "text": "I propose to do what Rust / Cargo does (as well as Haskell / Stack). Have a tests directory, and each file there gets compiled to a binary. That file internally can import many other modules and use a test framework to execute tests.\nRegarding dependencies, fpm build will only build stdlib without tests, so no dependency on vegetables. fpm test builds both stdlib and the tests, and this command will pull in vegetables as a [dev-dependencies] item."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-03-23 21:57:15+00:00",
                    "text": "Like @certik said. The tests and library are in the same project, just kept in separate folders. The convention fpm is leaning towards is library code goes in src and test code goes in tests."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-03-23 22:00:22+00:00",
                    "text": "@certik , I could be convinced to switch styles. Do you know if there is any kind of consensus from the community on that? Is camel case really frowned on in Fortran?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-23 22:12:06+00:00",
                    "text": "The tests and library are in the same project, just kept in separate folders. The convention fpm is leaning towards is library code goes in src and test code goes in tests.\n\nOkay, I was confused with what you wrote before. So, to confirm, stdlib (and likewise, any other project) would have:\nstdlib/\n  src/\n  tests/\n\nand tests are not built within stdlib itself, only by fpm test. But each project carries its test sources. Correct?"
                },
                {
                    "user": "certik",
                    "date": "2020-03-23 22:22:35+00:00",
                    "text": "@milancurcic correct. This would be the standard layout as expected by fpm that works by default. Non-standard layout can still be used (by explicitly telling fpm in fpm.toml), but generally discouraged.\n@everythingfunctional\n\nDo you know if there is any kind of consensus from the community on that? Is camel case really frowned on in Fortran?\n\nLet's discuss at j3-fortran/fortran_proposals#168, so that we keep discussions focused and at one place."
                },
                {
                    "user": "aradi",
                    "date": "2020-03-24 06:42:21+00:00",
                    "text": "I just wanted to let you know, that I once also wrote a simple unit testing framework, which is based on the Fypp preprocessor. FyTest is in spirit similar to the Google-test framwork, leveraging the power of Fypp. It is a header-only library (it is a single Fypp-include file), so it does not add any external dependencies. It offers unit tests, test suites, fixtures and parameterized tests. Unfortunately, it is not that well documented yet, and has not been used by many projects yet, so it far less tested as Fypp. For a first impression, see those examples.\nPlease note, that I am the author of FyTest, but I am not pushing in any sense for its use. FyTest was just a toy project of mine, and Vegetables is for sure much-much more mature. But FyTest represents a slightly different testing approach, and I wanted to offer the opportunity to discuss about the approach first."
                }
            ]
        },
        {
            "number": 161,
            "user": "jvdp1",
            "date": "2020-03-22 19:15:51+00:00",
            "title": "Addition of optional center in API of moment()",
            "text": "As discussed in #153\nRelated to #113\nChanged the API of moment() from\nresult = moment(array, order [, mask])\nresult = moment(array, order, dim [, mask])\n\nto\nresult = moment(array, order [, center [, mask]])\nresult = moment(array, order, dim [, center[, mask]])\n\nThe default returned value before changes was central moments. Now it is raw moments, and central moments if center is provided.\nNote: if dim is provided, center must be an array. Otherwise, it must be a scalar.\nComments are welcome, @fiolj @ivan-pi @certik @milancurcic",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2020-03-23 21:09:19+00:00",
                    "text": "I appreciate that the current iteration also supports other centers. Is there any particular reason to prefer raw vs central moments as the default option? In Julia StatsBase.jl the default are central moments. The MATLAB moment is also central.\n! raw is default (currently)\nraw = moment(array, order)\ncentral = moment(array, order,center=mean(array))\n\n! vs\n\n! if central were default\ncentral = moment(array, order)\nraw = moment(array, order,center=0.0)\n\nI am not sure which is more convenient. If central was default, then, for the moment along a specific dimension  of a multidimensional array it would be convenient to have a zeros function:\n! raw is default (currently)\nraw = moment(array, order,dim=2)\ncentral = moment(array, order,dim=2,center=mean(array,dim=2))\n\n! if central is default\ncentral = moment(array, order,dim=2)\nraw = moment(array, order,center=zeros(size(array,1),...)) !  center is a rank >= 1 array\n\nFor the moment of a multi-dimensional array along a specific dimension the currently proposed version seems easier to use, it is however opposite from MATLAB and Julia. With central as default on the other hand, inferring the correct size of the zeros array for raw moments is error-prone.\nThoughts?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-23 21:47:15+00:00",
                    "text": "Thanks @ivan-pi for the comments. I though about this issue (default: raw or central moment) and wanted to have some discussion about that. I am glad you started it.\nI choose 'raw moment' as default such that center can be optional. However, I agree that other languages (Julia, Matlab, but also Scipy, Octave,R) have 'central momen' as default. Julia does not provide raw moments explicitely. So it would make sense that stdlib provides a central moment as default.\nPossible solution:\nA way to implement easily raw moments would be to allow a scalar center when dim is provided, in addition to the current implementation (i.e., an array for center when dim is mentioned). (Or should we also allow array center when dim is not provided? With which rank?)\nWith such an implemenation, a zero() function is not needed.\nSo, center would be still optional. But the default returned value is 'central moment'.\nIf center is provided, then the return value is  a moment about center. A raw moment could be computed by providing center = 0. This behaviour is similar to the one of Julia.\nThe API would remain the same. Only the default returned value would change."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-03-25 00:35:57+00:00",
                    "text": "For consistency with other programming languages used in scientific computing I would prefer to see central moments as default. That way it is easier for users to move between programming languages.\nIf I understand correctly, for the solution you are suggesting, the interface would be the following\n! existing API\nresult = moment(array, order [, center [, mask]])  ! center is a scalar, default is `mean(array)`\nresult = moment(array, order, dim [, center[, mask]]) ! center is an array, default is `mean(array,dim)`\n\n! possible solution\nresult = moment(array, order, dim, center [, mask]) \n    ! center is a scalar, raw moments with `center = 0`\n\nWould the type of center match the input array? I think it makes sense to allow integer arrays to have a real center. For real arrays presumably, it will be necessary to specify the precision as center = 0.0_sp, otherwise the compiler will complain.\nThe remaining option\nresult = moment(array, order, center [, mask]) ! center is an array, dim is not provided\n\ndoes not make sense to me in the context of statistical moments. It is in contradiction with the first version above, where the rank of the array and the location of values in the array carry no significance in the moment calculation. It would however make sense for things such as image moments, in which case the center would probably be a vector of size equal to the rank of the array. Currently, I don't think these different use cases are compatible."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-25 12:27:14+00:00",
                    "text": "Following the discussion with @ivan-pi\n\nCurrent default result is now central moment (instead of raw moment)\nthe  optional center must be a scalar if dim is not provided, OR can be a scalar or an array if dim is provided.\ncenter must be of the same type as res (so for integer arrays, center must be of type real(dp)).\n\nSo, this can be done to compute 2-th raw moment:\nres = moment( x, 2, center = 0.)\nres = moment( x, 2, dim = 1, center = 0.)\nres = moment( x, 2, dim = 1, center = zero)   !where zero is an array of the same size as res\nTests have been implemented for both options."
                },
                {
                    "user": "certik",
                    "date": "2020-03-25 16:17:16+00:00",
                    "text": "I restarted the builds, they are failing. Probably due to the conflicts."
                },
                {
                    "user": "certik",
                    "date": "2020-03-25 16:20:17+00:00",
                    "text": "@jvdp1 I got an email where you were asking about some CI failures due to floating point exceptions, but I can't find the comment here. If there is still an issue, let me know, I can have a look at that."
                },
                {
                    "user": "fiolj",
                    "date": "2020-03-25 16:28:40+00:00",
                    "text": "Sorry for the delay. It looks very good now. I also would prefer center for compatibility with other languages/environment. Thanks for all the work!"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-25 16:31:07+00:00",
                    "text": "With #163 now in master, I think this needs to be rebased to latest master, and replace calls to assert with calls to check. I used sed for this, for example:\nsed -i 's/assert/check/gi' test_moment.f90\nsed -i 's/assert/check/gi' test_rawmoment.f90"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-25 16:51:02+00:00",
                    "text": "@jvdp1 I got an email where you were asking about some CI failures due to floating point exceptions, but I can't find the comment here. If there is still an issue, let me know, I can have a look at that.\n\n@certik thank you for proposing help. I solved this issue and deleted the comment (sorry, I should have update it now).\nI will rebase the branche. It should be fine then."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-25 18:22:32+00:00",
                    "text": "@certik The tests for the manual Makefiles failed, probably because they take too much time. Removing all the flags for the debug options leads to pass the tests here.\nWhat could we do for this issue?"
                },
                {
                    "user": "fiolj",
                    "date": "2020-03-26 13:33:07+00:00",
                    "text": "@certik The tests for the manual Makefiles failed, probably because they take too much time. Removing all the flags for the debug options leads to pass the tests here.\nWhat could we do for this issue?\n\nI think you are right, the problem is the same that has been insinuating for a time now. Compilation times are getting too long due to rank-aware routines. It also happens with cmake system but my guess is that with Makefiles are slightly longer (at least for this case) and is crossing some time threshold in the CI system.\nI've done a simple test of building times in my machine, obtaining:\nreal\t4m15.740s\nuser\t4m2.226s\nsys\t0m7.115s\n\nand then, setting MAXRANK manually to 7:\n#! Ranks to be generated when templates are created\n#:set MAXRANK = 7\n#:if not defined('MAXRANK')\n  #:if VERSION90\n    #:set MAXRANK = 7\n  #:else\n    #:set MAXRANK = 15\n  #:endif\n#:endif\n\nI've got for a new complete build:\nreal\t0m42.008s\nuser\t0m38.078s\nsys\t0m3.121s\n\nNote: I've had to manually disable (comment out) some lines of test_mean_f03.f90 for it to compile.\nProbably we should discuss the compiling times in a new issue, because it will get worse quickly when we add new routines that are made to work with all different ranks."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-26 14:08:03+00:00",
                    "text": "I think you are right, the problem is the same that has been insinuating for a time now. Compilation times are getting too long due to rank-aware routines. It also happens with cmake system but my guess is that with Makefiles are slightly longer (at least for this case) and is crossing some time threshold in the CI system.\n\nIndeed, the problem also appeared with CMake, and it is why we limited the number of ranks to 4 for the CI.\nWe should probably do the same for the manual Makefiles. I will have a look at this option."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-26 16:57:57+00:00",
                    "text": "Seeing the report for the CI, it seems that the flag FYPPFLAGS (to limit the number of ranks to 4 for the CI) is not applied when using the Makefile.manual.  I have no idea how to check it.\n@certik @milancurcic Any ideas?\nEDIT: The PR #164 should fix this issue."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-26 20:01:18+00:00",
                    "text": "I merged #164 into master and restarted the builds here. But I forgot that we need to rebase to master here. @jvdp1 Can you do that?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-26 20:13:54+00:00",
                    "text": "I rebased this PR to master and all checks have passed,"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-26 20:47:47+00:00",
                    "text": "Thank you, great work! Merging into master."
                }
            ]
        },
        {
            "number": 160,
            "user": "sakamoti",
            "date": "2020-03-19 03:22:33+00:00",
            "title": "fix build failure with nagfor because of \"isnan\" (issue #159)",
            "text": "ieee_arithmetic module is added  and isnan is replaced to ieee_is_nan.\nThis fixes the issue #159.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-03-21 00:16:07+00:00",
                    "text": "Thank you for the PR!\n\u2026\nOn Fri, Mar 20, 2020, at 5:19 PM, Milan Curcic wrote:\n\n\n Merged #160 <#160> into master.\n\n \u2014\n You are receiving this because your review was requested.\n Reply to this email directly, view it on GitHub\n <#160 (comment)>, or\n unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAAFAWAOEUZ6DBP7QHP52ELRIP2ZHANCNFSM4LO7PTTQ>."
                }
            ]
        },
        {
            "number": 159,
            "user": "sakamoti",
            "date": "2020-03-18 14:58:58+00:00",
            "title": "Build with nagfor(7.0) is fail because of \"isnan\"",
            "text": "There are many isnan functions are used in test_mean.f90, test_moment.f90,  test_var.f90 and  test_varn.f90 files. But isnan is not a fortran standard. So, NAG fortran compiler (nagfor) fail to build these files. What about using ieee_is_nan instead of isnan?",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-03-18 17:39:43+00:00",
                    "text": "Thank you for testing stdlib.\nieee_is_nan could be used indeed. ieee_arithmetic is already used to generate NaN in mean(), moment(), and var() functions.\nIf you have time, could you modify the tests and submit a PR, please?\nThere has been several discussions around NaN and its implementation (e.g., #147). A more general solution is needed. Meanwhile, using ieee_is_nan should be fine, and a better solution than using compiler-dependent is_nan."
                },
                {
                    "user": "sakamoti",
                    "date": "2020-03-21 00:18:41+00:00",
                    "text": "Thank you for merging pull request #160 . Close this issue."
                }
            ]
        },
        {
            "number": 158,
            "user": "jvdp1",
            "date": "2020-03-14 20:15:28+00:00",
            "title": "Addition of TOCs in Markdown files",
            "text": "Some specs already contain multiple functions. So I thought it could be good to add TOCs for clarity.\nOf course, it can be discussed/modified/removed, as usual.",
            "comments": [
                {
                    "user": "nshaffer",
                    "date": "2020-03-15 02:02:46+00:00",
                    "text": "Nothing obviously amiss, except the vim plugin magic comment thing.\nLinks for each routine are obviously useful and good to have. Subsection links (Description, etc.) don't seem useful, though."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-18 08:27:37+00:00",
                    "text": "Nothing obviously amiss, except the vim plugin magic comment thing.\nLinks for each routine are obviously useful and good to have. Subsection links (Description, etc.) don't seem useful, though.\n\nThanks @nshaffer for the review. I will remove Vim comments and subsection links (Their are indeed all the same)."
                },
                {
                    "user": "certik",
                    "date": "2020-03-21 00:14:17+00:00",
                    "text": "Looks good to me.\n\u2026\nOn Fri, Mar 20, 2020, at 5:24 PM, Milan Curcic wrote:\n\n\n ***@***.**** approved this pull request.\n\n Looks great! My only suggestion is to remove the \"Implemented\" heading\n from the top of each spec file--it serves no purpose, and in some files\n it's incorrect (for example, in quadrature it lists some functions that\n aren't implemented).\n\n \u2014\n You are receiving this because your review was requested.\n Reply to this email directly, view it on GitHub\n <#158 (review)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWBSHU6KY7IUAFNJYD3RIP3JZANCNFSM4LJWBG2A>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-21 08:39:12+00:00",
                    "text": "Looks great! My only suggestion is to remove the \"Implemented\" heading from the top of each spec file--it serves no purpose, and in some files it's incorrect (for example, in quadrature it lists some functions that aren't implemented).\n\nThank you @milancurcic. Suggestion applied."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-21 19:15:06+00:00",
                    "text": "Ok. I will merge. Thank you for your comments."
                }
            ]
        },
        {
            "number": 157,
            "user": "leonfoks",
            "date": "2020-03-13 16:38:56+00:00",
            "title": "Update CMAKE files",
            "text": "I've updated the CMAKE build procedure to a similar setup that I have in Coretran.\nParsed out compiler flag options into different files for easier reading\nAdded DEBUG and RELEASE mode with DEBUG default.\nMoved test dir to /bin\nMoved .mod files to /include\nMoved built libraries (.o .a .dylib etc) to /lib\nAdded OpenMP finder (we might not need this thought)\nAdded new directories to gitignore.\nCMake is a pain for people who are not used to it.\nSo I print extra information to the screen explaining the options chosen,\nthe flags being used etc. and how to change these options.\nAdded more information when using CMAKE to help users when compiling.\nTODO: Add a compile flags file for PGI\nTODO: Add a compile flags file for CRAY? I can do this.\nTODO: Add information about how to change CMAKE_MAXIMUM_RANK - Easy",
            "comments": [
                {
                    "user": "leonfoks",
                    "date": "2020-03-13 16:39:50+00:00",
                    "text": "Obviously, this is all subject to change. We can discuss paths for mod files etc.\nI've added extra flags for a DEBUG build which might be causing a build failure.  But it's the best way to develop the lib from the start with harsh warnings IMHO"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-14 20:59:12+00:00",
                    "text": "CMake is a pain for people who are not used to it.\nSo I print extra information to the screen explaining the options chosen,\nthe flags being used etc. and how to change these options.\nAdded more information when using CMAKE to help users when compiling.\n\nI can't jugde the changes, but this one is useful. Thanks!"
                },
                {
                    "user": "certik",
                    "date": "2020-05-24 23:40:40+00:00",
                    "text": "The CI fails on Windows, so that has to be fixed.\nIt adds a lot more complexity to the CMake, hundreds of new lines to maintain. I feel we should just let cmake do its thing, and keep the number of lines that we have to write and maintain to a minimum.\nAnd ultimately, we are hoping to switch to the Fortran Package Manager for stdlib once it is ready, and fpm will be able to automatically generate the CMake files.\nfortran-lang/fpm#69"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-06-23 16:15:14+00:00",
                    "text": "@leonfoks How would you like to proceed with this PR? Can you make it work on Windows? There are still quite a few unresolved suggestions.\nAlso, can you reduce the added code to a minimum, as per @certik's suggestion?\nI wish I could provide more feedback here, but CMake is really not in my wheelhouse."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-07-06 20:07:38+00:00",
                    "text": "@milancurcic yes i can get this working on windows i think.  sorry for the delay, Paternity leave!"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-07-06 20:13:03+00:00",
                    "text": "@leonfoks Great to hear and congrats (I have a 4-month old next to me as I type this)! No rush."
                }
            ]
        },
        {
            "number": 156,
            "user": "JHenneberg",
            "date": "2020-03-10 08:44:10+00:00",
            "title": "fixes #154",
            "text": "as suggest by @MatthAlex",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-03-13 01:00:05+00:00",
                    "text": "Thank you @JHenneberg @MatthAlex. Merging."
                }
            ]
        },
        {
            "number": 155,
            "user": "jvdp1",
            "date": "2020-03-09 15:55:04+00:00",
            "title": "small_corrections: small issues detected when compiled with ifort17.0.4",
            "text": "Some small issues detected when compiled with ifort 17.0.4",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-03-09 18:10:43+00:00",
                    "text": "Good. I will merge it."
                }
            ]
        },
        {
            "number": 154,
            "user": "MatthAlex",
            "date": "2020-03-01 22:26:39+00:00",
            "title": "Missing \"fypp\" reference",
            "text": "Building and compiling the project should retain the mention of what the preprocessor is, when should be installed (as a dependency) and where someone can find it.\nAt this state of the README and Wiki page, the build is failing (with just cmake -B build) as fypp might not be pre-installed.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-03-02 15:16:59+00:00",
                    "text": "@MatthAlex thanks! I agree, we need to fix this. If you have a minute, you can submit a PR against README fixing it."
                },
                {
                    "user": "MatthAlex",
                    "date": "2020-03-03 09:36:28+00:00",
                    "text": "I can certainly try!"
                },
                {
                    "user": "MatthAlex",
                    "date": "2020-03-12 22:40:44+00:00",
                    "text": "Thanks @JHenneberg!\nClosing.."
                }
            ]
        },
        {
            "number": 153,
            "user": "jvdp1",
            "date": "2020-03-01 19:42:51+00:00",
            "title": "Addition of a function to compute the k-th order central moment of an array",
            "text": "Related to #113\nIn this draft pull request I propose the implementation of a function for the k-th  order central moment of an array.\nOther languages\nMatlab moment\nSciPy moment\nJulia moment\nR moment\nOctave moment\nNote: The functions of R and Octave can also return absolute central moment, raw moment, and absolute raw moment.\nProposed API and implementation\nmoment - central moment of array elements\nDescription\nReturns the k-th order central moment of all the elements of array, or of the elements of array along dimension dim if provided, and if the corresponding element in mask is true.\nThe k-th order central moment is defined as :\n moment(array) = 1/n sum_i (array(i) - mean(array))^k\n\nwhere n is the number of elements.\nSyntax\nresult = moment(array, order [, mask])\nresult = moment(array, order, dim [, mask])\nArguments\narray: Shall be an array of type integer, real, or complex.\norder: Shall be an scalar of type integer.\ndim: Shall be a scalar of type integer with a value in the range from 1 to n, where n is the rank of array.\nmask (optional): Shall be of type logical and either by a scalar or an array of the same shape as array.\nReturn value\nIf array is of type real or complex, the result is of the same type as array.\nIf array is of type integer, the result is of type real(dp).\nIf dim is absent, a scalar with the k-th central moment of all elements in array is returned. Otherwise, an array of rank n-1, where n equals the rank of array, and a shape similar t\no that of array with dimension dim dropped is returned.\nIf mask is specified, the result is the k-th central moment of all elements of array corresponding to true elements of mask. If every element of mask is false, the result is IE\nEE NaN.\nExample\nprogram demo_moment\n    use stdlib_experimental_stats, only: moment\n    implicit none\n    real :: x(1:6) = [ 1., 2., 3., 4., 5., 6. ]\n    print *, moment(x, 2)                            !returns 2.9167\n    print *, moment( reshape(x, [ 2, 3 ] ), 2)       !returns 2.9167\n    print *, moment( reshape(x, [ 2, 3 ] ), 2, 1)    !returns [0.25, 0.25, 0.25]\n    print *, moment( reshape(x, [ 2, 3 ] ), 2, 1,&\n                     reshape(x, [ 2, 3 ] ) > 3.)     !returns [NaN, 0., 0.25]\nend program demo_moment\nQuestions for discussion\n\nAgreement on API?\nAgreement on implementation (e.g. for complex numbers)?\nShould we support (absolute)(raw/central) moments in this function? E.g. through optional logicals absolute and raw? (see example in this branch )",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-03-09 20:18:41+00:00",
                    "text": "I just implemented (absolute) central/raw moments in this branch. Personally I only use central moments, which is the default returned value for most packages I checked (that sometimes supports only the central moment).\nAny thoughts @ivan-pi @aradi @fiolj @leonfoks?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-03-10 09:14:09+00:00",
                    "text": "I noticed the Scipy version uses exponentiation by squares for efficiency. Do you think in Fortran we can simply trust the compiler to do the right thing?\nSecond thing I am wondering is what is the sensitivity of this function to underflow/overflow? The reason I am asking is because I recall reading a paper by Hanson and Hopkin concerning some subtleties of the intrinsic Fortran norm2.\nConcerning the API, the SciPy version allows to pass a list of moments orders, e.g.\nreal :: x(1:5) = [ 1., 2., 3., 4., 5. ]\nprint *, moment(x, [1, 2]) ! prints 0 2\n\nSince I have not used this function before, I don't know whether this is particularly useful or not? It sure would complicate the allocation of a LHS variable..."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-03-10 09:22:53+00:00",
                    "text": "Should we support (absolute)(raw/central) moments in this function? E.g. through optional logicals absolute and raw? (see example in this branch )\n\n\nConcerning this point, I find the Octave solution of passing a character (\"c\", \"a\", \"ac\", \"r\", \"ar\") to an optional type dummy variable easier than two logicals:\nreal :: x(1:5) = [ 1., 2., 3., 4., 5. ]\nprint *, moment(x, 2, type='ar')\nprint *, moment(x, 2, absolute=.true.,raw=.true.)"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-10 10:46:47+00:00",
                    "text": "Thank you @ivan-pi for the comments.\n\nI noticed the Scipy version uses exponentiation by squares for efficiency. Do you think in Fortran we can simply trust the compiler to do the right thing?\n\nI hope so. At least I always trust it, while never check it. If it is not the case, it could a nice procedure for stdlib, e.g., power(x, order) that would perform something similar to Scipy.\n\nSecond thing I am wondering is what is the sensitivity of this function to underflow/overflow? The reason I am asking is because I recall reading a paper by Hanson and Hopkin concerning some subtleties of the intrinsic Fortran norm2.\n\nGood point. The function mainly relies on intrinsic functions (e.g., sum).\nI think that this point is applicable to all procedures in stdlib (e.g., mean, var, trapz,....). A possible solution (already proposed in another post; I don't remember which one) would be to have a standard implementation of the function (e.g., moment), and followed by other optimized/specific implementations of the same function (e.g., moment_largearray????)\n\nConcerning the API, the SciPy version allows to pass a list of moments orders, e.g.\nreal :: x(1:5) = [ 1., 2., 3., 4., 5. ]\nprint *, moment(x, [1, 2]) ! prints 0 2\n\nSince I have not used this function before, I don't know whether this is particularly useful or not? It sure would complicate the allocation of a LHS variable...\n\nI am not in favor of such a behavior (the user can call several times the same function, with different order). The main issue would be the dimension of the result (what would happen if only one value is given? Is the result a scalar (res) or a vector (res(1))? However, I may miss something."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-10 11:07:35+00:00",
                    "text": "Should we support (absolute)(raw/central) moments in this function? E.g. through optional logicals absolute and raw? (see example in this branch )\n\n\nConcerning this point, I find the Octave solution of passing a character (\"c\", \"a\", \"ac\", \"r\", \"ar\") to an optional type dummy variable easier than two logicals:\nreal :: x(1:5) = [ 1., 2., 3., 4., 5. ]\nprint *, moment(x, 2, type='ar')\nprint *, moment(x, 2, absolute=.true.,raw=.true.)\n\n\nNice suggestion. I agree that using characters may simplify the API.\nHere is my reasoning to propose logicals and not characters:\n\n\nwith logicals (absolute and raw), only 4 combinations are possible. With characters (e.g., a, c, and r as in Octave), many combinations are possible (there are even 5 combinations in Octave for 4 combinations allowed). This implies that the function will have 1) to check if the provided combination is allowed (e.g., ar and ra would be allowed and are the same, while cr or arc are not allowed) (so, 5 cases with characters, instead of 4 with logicals), and 2) to report an error message that the combination is incorrect. The latter may limit the implementation of pure functions. Using characters and its additional checks may also impact performance.\n\n\nit follows the API of variance that uses a logical to allow the Bessel 's correction of not.\n\n\nAgain, I also find that the API with characters is nicer, but have some (unfounded?) concerns about performance."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-03-10 12:59:07+00:00",
                    "text": "Thank you for explaining these points. As long as the API does not change, we can always modify for performance/accuracy later, or as you suggest add specialized versions.\nI agree with your concern about the dimension of the result. MATLAB does not have it either, so I suppose there is no need really. The current behavior is also fairly easy to remember, for the case of computing the moment along a single axis, the user simply needs to remember, the target array is one rank smaller than the original array:\nreal :: array(:,:,:,:)\nreal, allocatable :: mom2(:,:,:)\nmom2 = moment(array,order=2,dim=1)\n\nFor array slices, or chained calls to moments it  becomes more tricky (I don't know whether there are such use cases).\nThe purpose of this function is primarily statistics, right? I have used central moments before for image analysis purposes (e.g. to locate the centroid or area of an object), but I think a different function would be necessary for this."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-03-10 13:23:42+00:00",
                    "text": "Nice suggestion. I agree that using characters may simplify the API.\nHere is my reasoning to propose logicals and not characters:\n\n\nwith logicals (absolute and raw), only 4 combinations are possible. With characters (e.g., a, c, and r as in Octave), many combinations are possible (there are even 5 combinations in Octave for 4 combinations allowed). This implies that the function will have 1) to check if the provided combination is allowed (e.g., ar and ra would be allowed and are the same, while cr or arc are not allowed) (so, 5 cases with characters, instead of 4 with logicals), and 2) to report an error message that the combination is incorrect. The latter may limit the implementation of pure functions. Using characters and its additional checks may also impact performance.\n\n\nit follows the API of variance that uses a logical to allow the Bessel 's correction of not.\n\n\nAgain, I also find that the API with characters is nicer, but have some (unfounded?) concerns about performance.\n\nI think your concerns about performance are unjustified. If you check the routines in other languages they performs checks for NaN, dimensions, etc., but they are still more popular than Fortran (simply because they provide these functions). LAPACK also uses characters in the API to specify the form of the system of equations (transpose, no transpose...), but they return the info argument to inform about incorrect usage.  Plus, the routines already stop if the dimension exceeds the rank of the array, meaning they can not be pure (at least until Fortran introduces some assert facility that could be used in pure routines).\nI do agree with your concern about the multiple character combinations. I suppose renaming the absolute dummy variable to the shorter abs is not possible, because it would clash with the intrinsic function? (Is it possible to rename intrinsic functions?) Introducing two new functions for rawmoment and absmoment is less appealing than the current proposition."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-11 20:13:46+00:00",
                    "text": "The purpose of this function is primarily statistics, right? I have used central moments before for image analysis purposes (e.g. to locate the centroid or area of an object), but I think a different function would be necessary for this.\n\nIndeed, it is primarily statistics. I think the function you mentioned is an extension to 2D.\n\nI think your concerns about performance are unjustified. If you check the routines in other languages they performs checks for NaN, dimensions, etc., but they are still more popular than Fortran (simply because they provide these functions).\n\nYou convinced me. I will start an implementation with characters, instead of logicals. Then we can further discuss pros and cons based on the code.\nHowever, it could be easier to first merge this PR (if there is a consensus about it), and then submit another PR with the different moments.\n\nLAPACK also uses characters in the API to specify the form of the system of equations (transpose, no transpose...), but they return the info argument to inform about incorrect usage. Plus, the routines already stop if the dimension exceeds the rank of the array, meaning they can not be pure (at least until Fortran introduces some assert facility that could be used in pure routines).\n\n#95 could be usefull in these cases.\nOn the other hand, we could also implement an optional argument info in the different functions (mean, var,...). However, such an argument would be useless for some implementations, and the API of these functions would not be the smae/similar to the API of intrinsic functions (like sum).\n\nIntroducing two new functions for rawmoment and absmoment is less appealing than the current proposition.\n\nI agree."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-03-11 21:09:13+00:00",
                    "text": "After taking a closer look at the source code, the error message for \"wrong dimension\" currently refers to the mean function.\n\n\nHowever, it could be easier to first merge this PR (if there is a consensus about it), and then submit another PR with the different moments.\n\nAs the raw and absolute do not break backward compatibility of API I think this might be easier too. It would be nice to get an opinion from the remaining developers concerning their preference between logicals vs characters for option passing."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-12 11:33:34+00:00",
                    "text": "After taking a closer look at the source code, the error message for \"wrong dimension\" currently refers to the mean function.\n\nThank you for reviewing the code. It is now corrected as suggested.\n\nIt would be nice to get an opinion from the remaining developers concerning their preference between logicals vs characters for option passing.\n\nI agree! It needs more discussions."
                },
                {
                    "user": "fiolj",
                    "date": "2020-03-12 14:02:29+00:00",
                    "text": "Sorry to barging in late to the discussion. I do not have strong feelings about the function since I do not usually use it.\nI do not want to disrupt the implementation when it already has a lot of work in it but there are two points that are not clear.\nFirst, probably the simplest is that I do not understand what happens when a scalar mask is provided. I though that perhaps for functions as sum it is used to avoid an extra if statement.\nSecondly, when started to ponder about the interface with logical vs character flags I went to look to other implementations and started to think on the usefulness of the options.\nBecause is not my area of expertise, I only was able to think of\nSome Applications\n\nStatistics (centered)\nSystem of particles\n\nCenter of mass: need weights (mass)\nKinetic energy: need weights (sqrt(mass))\nInternal kinetic energy: need weigths (sqrt(mass)) and centered on v_cm (different from mean)\nMoments of inertia (also centered in places other than the mean)\n\n\n\nFor these reasons I would favor (slightly) an API more similar to Julia in that the center be given as a float point number (or rather a number of the same type than the array).\nresult = moment(array, order [, center] [, mask])\nresult = moment(array, order, dim [, center] [, mask])\nAdditionally, in the same spirit we could consider adding an array of weights\nThus, we only would have a remaining flag for absolute, which (because of my ignorance) I do not know how used/needed is.\nBecause of the advanced state of the current pull request, I'd be perfectly happy to leave it as it is now, and if there is any interest keep the discussion for a future next iteration."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-12 19:58:02+00:00",
                    "text": "Sorry to barging in late to the discussion. I do not have strong feelings about the function since I do not usually use it.\n\n\nI do not want to disrupt the implementation when it already has a lot of work in it but there are two points that are not clear.\n\nThank you for your comments @fiolj . There is no problem! I mainly implemented it to facilitate discussion.\n\nFirst, probably the simplest is that I do not understand what happens when a scalar mask is provided. I though that perhaps for functions as sum it is used to avoid an extra if statement.\n\nPersonally I do not understand the usefullness of a scalar logical, because it will always return NaN when it is .false.. I probably miss something there. So it was introduced in mean, var and moment to have the same API as the intrinsic function sum, which accept a scalar logical, and to be consistent with the standard.\nRegarding the implementation, it could be indeed passed to the intrinsic function sum, instead of having the additional condition. I implemented it that way to avoid unnecessary computations when mask = .false..\n\nSecondly, when started to ponder about the interface with logical vs character flags I went to look to other implementations and started to think on the usefulness of the options.\n...\nFor these reasons I would favor (slightly) an API more similar to Julia in that the center be given as a float point number (or rather a number of the same type than the array).\n\nThis is a nice idea. center should be a scalar when dim is not provided, and an array of rank-1 when dim is provided (Julia does not allow to specify a dim). Not providing center would lead to the raw moment, right? Using the function mean, something like that could be written:\nresult = moment(x, 2) ! raw moment\nresult = moment(x, 2, center = mean(x))  ! central moment\nresult = moment(x, 2, dim = 3, center = mean(x, 3, mask=(x >3)), mask = (x >3)) !central moment\nYour proposed API adds some flexibility to the function moment and might interest a broader audience, So I would be in favor of such an API.\nFor completness, I suggest to add a logical flag (with default being .false.) for absolute moments.\nSo the API could be:\nresult = moment(array, order [, center] [,absolute] [, mask])\nresult = moment(array, order, dim [, center] [,absolute] [, mask])\n\nWhat are your opinions about this API? @fiolj @ivan-pi @certik @milancurcic\nRe: weights, the aim was to implement a function for the moment in terms of mathematics/statistics. However, if the addition of an argument can extend its used in physics, I would agree."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-13 06:32:36+00:00",
                    "text": "Sorry for the late review. This is excellent, thank you. I especially appreciate the hyperlinked TOC in the spec file.\nI only had one question about the implementation. Otherwise, good to go.\n\nThank you @milancurcic for the review. Any thoughs about a different API:\nresult = moment(array, order [, center] [,absolute] [, mask])\nresult = moment(array, order, dim [, center] [,absolute] [, mask])\nwhere center would replace the computation of the mean, and absolute would be an optional logical for computing absolute moments?"
                },
                {
                    "user": "fiolj",
                    "date": "2020-03-13 13:14:51+00:00",
                    "text": "I've started some simple timing tests with gfortran on the overhead of using mean(), I do not have conclusive results yet, but noticed a few (minor) points in the code. Some of these will change with the new API implementation, but I mention them anyway.\nn is defined real, so we could do here the same that mean() does and convert explicitly the size to real:\n@@ -53,7 +53,7 @@ contains\n           return\n         end if\n \n-        n = size(x, kind = int64)\n+        n = real(size(x, kind = int64), dp)\n         mean = sum(real(x, dp)) / n\n\n         res = sum((real(x, dp) - mean)**order) / n\n\n\nAlso, we could put all calculations under the right case (although it perhaps may become quite irrelevant with the new API, unless we decide to use \"center moment\" as a default)\n@@ -82,11 +82,13 @@ contains\n           return\n         end if\n \n-        n = size(x, dim)\n-        mean = sum(x, dim) / n\n-\n-        res = 0\n         select case(dim)\n+\n+          n = real(size(x, kind = int64), ${k1}$)\n+          mean = sum(x, dim) / n\n+\n+          res = 0\n+\n           #:for fi in range(1, rank+1)\n           case(${fi}$)\n             do i = 1, size(x, dim)"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-13 15:21:17+00:00",
                    "text": "n = size(x, dim)\n -        mean = sum(x, dim) / n\n -\n -        res = 0\n          select case(dim)\n +\n +          n = real(size(x, kind = int64), ${k1}$)\n +          mean = sum(x, dim) / n\n +\n\n\nI've started some simple timing tests with gfortran on the overhead of using mean(), I do not have conclusive results yet, but noticed a few (minor) points in the code. Some of these will change with the new API implementation, but I mention them anyway.\nn is defined real, so we could do here the same that mean() does and convert explicitly the size to real:\n@@ -53,7 +53,7 @@ contains\n           return\n         end if\n \n-        n = size(x, kind = int64)\n+        n = real(size(x, kind = int64), dp)\n         mean = sum(real(x, dp)) / n\n\n         res = sum((real(x, dp) - mean)**order) / n\n\n\nFunny. I implemented it in the way you proposed for var (see comment ), but @milancurcic suggested to avoid explicit type casts, mainly to improve readability. The compiler should do the job.\nI aimed to review the code of mean() to remove such stuff, and harmonize it. But I will wait."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-14 16:04:54+00:00",
                    "text": "The API with optional absolute and center arguments seems reasonable to me. I am not the target audience for these though; I only ever calculate moments where center == mean(x). So I can't speak for the usefulness of it.\nI suggest to:\n\nMerge the basic implementation (this PR) into master;\nOpen a PR for optional center and absolute (perhaps even separate PRs if they're independent);\n\nSmall and specific PRs will allow for a focused discussion."
                },
                {
                    "user": "certik",
                    "date": "2020-03-14 16:14:59+00:00",
                    "text": "I agree with @milancurcic about how to move forward. I am not a target audience either for this, so I do not have a strong opinion either."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-14 19:51:55+00:00",
                    "text": "@milancurcic @certik Thank you for your advices. I will merge this PR.\nI will later submit other PRs for optional center and absolute as discussed in this PR with @fiolj and @ivan-pi .\n@fiolj I would be interested by your results regarding the overhead of calling mean() inside another function of stdlib, especially when the result is a large array (see #114 for a discussion on that topic). These results might help us on how to implement stat functions skewness() and kurtosis() because both need multiple computations of mean."
                },
                {
                    "user": "fiolj",
                    "date": "2020-03-19 00:31:19+00:00",
                    "text": "@fiolj I would be interested by your results regarding the overhead of calling mean() inside another function of stdlib, especially when the result is a large array (see #114 for a discussion on that topic). These results might help us on how to implement stat functions skewness() and kurtosis() because both need multiple computations of mean.\n\nA (naive) comparison of times for moment is in:\nhttps://gist.github.com/fiolj/7ebb1611e200d1fcd248b5866f851b76\nStrangely enough, I am not finding differences between using mean() and the intrinsic sum().\nI've just copied the implementation of mean and moment for a few (1D, 2D, 5D, real(dp)) cases and timed them with cpu_time().\nPlease, somebody check that these are valid tests of speed, I may be missing something."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-21 09:39:27+00:00",
                    "text": "Thank you @fiolj for these time comparisons.\nI added a loop to repeat 100 times the computations in the last part. No difference either.\nThere are maybe a bit naive and we should probably use some tools to get better numbers. But at least it seems to show that the overhead of calling the functionmean() is very small. Good to know.\nThank you for the tests."
                }
            ]
        },
        {
            "number": 152,
            "user": "leonfoks",
            "date": "2020-02-24 16:17:01+00:00",
            "title": "Optional argument impact on runtime",
            "text": "At the risk of discussing early over-optimization... I want to discuss the possible speed and optimization issues with having too many optional arguments.\nI can't remember which class I took, but I distinctly remember someone saying that optional arguments can be a serious slowdown in large scale applications. I'm not sure if this is true so i'm asking!\nCan anyone shed some light on how the compilers generally handle optional arguments? Are optional arguments determined at compile time? Or at runtime? If the latter, could there potentially be a substantial slowdown in large scale code?\nWhy am I bringing this up now? In the discussions of nan() and var() optional arguments are present, and i wanted to bring this up in case it is important before we move too far ahead with other modules.  If we can potentially prevent a base level of slowdown due to optional arguments, that might be advantageous at this point???\nAm I overthinking this?",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-02-24 16:58:21+00:00",
                    "text": "I think it's good and important topic to discuss, if for nothing else but for our understanding as we move forward.\nMy understanding here is quite limited, so I hope @certik @sblionel @klausler can shed some light.\nFrom all I can tell, presence of optional arguments at least can be resolved at compile time because there's no other way to pass an argument to a procedure other than by typing it out in the code (unlike e.g. Python). But whether compilers do that, I have no clue.\nThe slow-down can perhaps occur if the procedure is called from a tight, nested loop, and the procedure goes through many if-branches to find out whether the argument is present or not.\nThere's likely some overhead from just calling a procedure. Rule of thumb I was taught early on was to minimize calling procedures from tight nested loops."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-24 18:27:14+00:00",
                    "text": "Good point @leonfoks . I don't have the answer.\nRegarding mean and var functions, the scalar mask is optional in the implementation. It could be avoided by duplicating the functions (one with no mask as argument, and one with it as argument). The interface would do the job. However, it would add ~100(?) functions to the already high number of functions.\nSomewhat related to this topic, I am also wondering what is the penalty (if any) to have some many functions in an interface block. I would hope that the right function is choosen at the compile time."
                },
                {
                    "user": "sblionel",
                    "date": "2020-02-24 19:03:18+00:00",
                    "text": "@jvdp1 >  I am also wondering what is the penalty (if any) to have some many functions in an interface block. I would hope that the right function is choosen at the compile time.\nYes, it is.\n@milancurcic The compiler can see that a called procedure has an optional argument, as the standard requires an explicit interface be visible. For intrinsic procedures, of course, the compiler has even more information and might call different routines or expand things differently depending on presence optional arguments.\nThe canonical implementation is that an omitted argument is passed as a zero address. This is explicit in the C interoperability text but is how it works in most compilers. Testing for omission is just testing for a zero address."
                }
            ]
        },
        {
            "number": 151,
            "user": "jvdp1",
            "date": "2020-02-22 21:42:11+00:00",
            "title": "Addition of corrected in API of var (following #149)",
            "text": "This PR is following the discussion in #149 .\nNew syntax\nresult = var(array [, mask[, corrected]])\nresult = var(array, dim [,mask[, corrected]])\n\n\ncorrected is as last argument because mask is not always optional in the implementation (while corrected is always optional).\n\n\ncorrected is used as follows, e.g.:\n\n\nres = res / (n - merge(1._dp, 0._dp, optval(corrected, .true.)))\nWhen mask is an array, the additional condition .and. n > 0._dp is needed to ensure that the result is NaN when all elements are .false. and corrected == .true., as specified in the spec.\nIf corrected == .true. and n==0, then we got something like res = res / -1, which may lead to a result equal to 0, e.g., in the following case if the additional condition is not added:\n res = sum((x - mean)**2, mask) / (n -&\n                merge(1._${k1}$, 0._${k1}$, (optval(corrected, .true.)) .and. n > 0._${k1}$))\nTests have been adapted to consider this scenario.\nI also added some tests for corrected==.false.. However, it is now only for real(sp). I can add more tests later in this PR when we will agree on its implementation.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-02-23 18:58:11+00:00",
                    "text": "Thank you @milancurcic  for your comments. I modified the code following them; a bad habit to lose."
                }
            ]
        },
        {
            "number": 150,
            "user": "nshaffer",
            "date": "2020-02-21 14:35:06+00:00",
            "title": "Miscellaneous mathematical (non-special) functions",
            "text": "I propose that we provide a module with miscellaneous mathematical functions, those which feel like they could/should be intrinsics, but are not for whatever reason. From my own experience, here are functions which I have felt the need to implement myself several times:\n\nexpm1(x) and log1p(x) - I suspect that many compilers detect exp(x) - 1.0/log(1.0 + x) and call appropriate library routines, but I'd like to provide these explicitly.\nsignum(x) - The intrinsic sign function is awkward to use when you just want to know the sign of a number.\ncbrt(x) - Again, I suspect many compilers detect x**(1.0/3.0) and call into their math library's cbrt. However, real exponents are ugly and error-prone and would like a more semantic replacement for this common case.\nsinc(x) - I am tired of writing my own implementation of this, and I suspect others are as well, even if it is trivial.\nphase(z) - Equivalent to atan2(z%im, z%re)\n\nLet's brainstorm further functionality that you'd like to see.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-02-21 18:20:13+00:00",
                    "text": "I agree, these would be all useful. Compilers should detect exp(x) - 1 and log(1 + x)  and do the right thing, but it cannot hurt to have those functions explicitly.\nActually, sinc is not completely trivial. Here is the implementation that I use:\nreal(dp) elemental function sinc(x) result(r)\nreal(dp), intent(in) :: x\nif (abs(x) < 1e-8_dp) then\n    r = 1\nelse\n    r = sin(x)/x\nend if\nend function\nFor high accuracy once must fine tune the cutoff, I ended up with 1e-8, but we would need to test this and ensure we are getting ~1e-15 accuracy for all x."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-22 05:31:24+00:00",
                    "text": "Some more worth considering:\n\nFunctions to evaluate z*log(z) and log(z)/z which give the correct behavior near z=0. Not sure of good names.\n\nSome with a distinctly statistical flavor, which maybe belong in the stats module:\n\nlogit(x) for evaluating log(x)/log(1-x)\nlogistic(x) for evaluating exp(x)/[1 + exp(x)] (the function whose inverse is logit)\nlogsumexp(x) for evaluating log(sum(exp(x))) with x being an array."
                },
                {
                    "user": "epagone",
                    "date": "2020-02-25 16:58:27+00:00",
                    "text": "Would the factorial and the binomial coefficient belong to this too?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-01 20:02:51+00:00",
                    "text": "What about:\n\nCumulative product (cumprod)\nCumulative sum (cumsum)\n\nThey would be probably in another module since they would not be elemental."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-03-01 20:47:04+00:00",
                    "text": "If a \u201dmath\u201d module is reserved for the elemental functions, Perhaps cumsum cumprod etc. Could go in a \u201cnumerical\u201d module?\nSince we are talking about summation,  do we want to provide more robust implementations of sum and cumsum? The Kahan summation (and variants) spring to mind.  I can reserve this discussion for the actual cumsum proposal too if need be. Related to #134  about multiple implementations of a  concept."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-23 13:23:05+00:00",
                    "text": "Do we have a name for this module already? Would stdlib_<experimental>_math be too broad?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-23 13:39:43+00:00",
                    "text": "expm1(x) and log1p(x) - I suspect that many compilers detect exp(x) - 1.0/log(1.0 + x) and call appropriate library routines, but I'd like to provide these explicitly.\n\n\nThese functions are available in the NSWC Library under the following names:\n\nREXP/DREXP for computing exp(x) - 1\nREXP1/DREXP1 for computing (exp(x) - 1)/x\nALNREL/DLNREL for computing log(1 + a) for a > -1\nRLOG/DRLOG for computing x - 1 - log(x) for x > 0\nRLOG1/DRLOG1 for computing x - log(1 + x) for x > -1\n\nThe CBRT/DCBRT function is also available."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-06-23 14:52:31+00:00",
                    "text": "Yeah, NSWC has a lot of nice functionality, as long as you don't need complex numbers. But their implementations may still be useful reference material, especially for things like error tolerances for Taylor series approximations and the like.\nAs for the name, stdlib_experimental_math seems fine. Something more specific like mathutils also seems suitable. If we want to roll these in with special functions, that's fine too.\nA good next step would be to write the markdown API for some obviously useful functions and implement the interfaces for them in a module (to be implemented later in submodules). I would take this up myself, but I have a new baby at home."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-06-23 19:52:10+00:00",
                    "text": "A good next step would be to write the markdown API for some obviously useful functions and implement the interfaces for them in a module (to be implemented later in submodules). I would take this up myself, but I have a new baby at home.\n\nI've already started with the cube root function, see #214. Congrats! \ud83c\udf89"
                }
            ]
        },
        {
            "number": 149,
            "user": "milancurcic",
            "date": "2020-02-19 18:03:34+00:00",
            "title": "What kind of variance should `var()` return?",
            "text": "Playing with a toy example today, I was surprised to see the result (I guess I should have read the specification first, LOL).\nProgram:\nuse stdlib_experimental_stats, only: mean, var\nreal :: a(5) = [1, 2, 3, 4 ,5]\nprint *, var(a), mean((a - mean(a))**2)\nend\nI expected two identical numbers. Result:\n   2.50000000       2.00000000    \n\nThen I looked at the code for var() and saw that we're making an average by dividing the sum by (N - 1), rather than N.\nThen I looked at this issue and the spec, and it's all good: It says that the variance is defined in such way so that we're dividing by (N - 1). The code works as advertised.\nBut then I wondered why N - 1 and not N, and did some Google searching and found that there are all kinds of variances out there and that this particular flavor is called \"population variance\", or as described here the best unbiased estimator. Dividing by just N seems to be called just \"variance\".\nHow we define this not only affects the numerical result, but also in some cases the behavior of the program: variance of a scalar is 0, but population variance of a scalar is a NaN. Some discussion here.\nNumPy's np.var() for example defines it as a simple variance (divide by N), but you can optionally set a \"delta degrees of freedom\", so that np.var(x, ddof=1) corresponds to the population variance.\nI'm not a statistician but a wave physicist. I expect my variance to divide by N, and NumPy as served me well so far.\nQuestion: Should we consider adding optional \"delta degrees of freedom\" to make both statisticians and physicists happy?",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-02-19 18:12:42+00:00",
                    "text": "I would do what NumPy does, and divide by N. Then provide an option, just like NumPy, to allow the N-1 convention."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-19 18:54:14+00:00",
                    "text": "This Wikipedia page gives a nice explanation about the differences sample variance vs population variance.\nIn Octave, var uses N-1 as default (opt = 0), and N as an option (opt  = 1)., So it is divided by N - 1 + opt.\nIn NumPy var, it is divided by N - opt, with opt = 0 as default.\nBoth R and Julia use N-1 as default denominator.\nBoth approaches are fine for me, if it is clearly mentioned in the spec. N-1 seems to be more often use as default.\n\nQuestion: Should we consider adding optional \"delta degrees of freedom\" to make both statisticians and physicists happy?\n\nI think so too.\nRegarding the API, I would propose\nSyntax\nresult = var(array [, corrected [, mask]])\nresult = var(array, dim [, corrected[, mask]])\nArguments\ncorrected (optional): Shall be a logical scalar. If corrected is .true. (default value), the sum is scaled with n-1. If corrected is .false., then the sum is scaled with n.\nI prefer a logical in this case since only two values can be passed to var (0 and 1). So, allowing a number for this option would imply checking the passed value inside var (and possibly a return for erroneous values) to be sure it is 0 or 1."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-19 19:05:12+00:00",
                    "text": "@jvdp1 Are you saying that scaling with N and N - 1 are the only two possibilities? Meaning, is there any person or method that would perhaps want to scale with N - 2? We don't need to cover all possible bases, but a logical would indeed disable some flexibility if somebody wanted a different kind of variance.\nIf yes, then I think a logical argument works well. \"Corrected\" is confusing to me as a non-statistician. Any alternative names?\nI'm erring slightly toward what @certik suggested."
                },
                {
                    "user": "certik",
                    "date": "2020-02-19 19:48:43+00:00",
                    "text": "I didn't realize that NumPy was in the minority. Matlab's var also does N-1 by default (but it's configurable to use N as an option). As a physicist, using N seems more natural to me also, but given that NumPy is the only one that does this, and Matlab, Octave, R, Julia all use N-1, it seems we should do N-1 also for consistency."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-19 19:56:38+00:00",
                    "text": "@jvdp1 Are you saying that scaling with N and N - 1 are the only two possibilities? Meaning, is there any person or method that would perhaps want to scale with N - 2? We don't need to cover all possible bases, but a logical would indeed disable some flexibility if somebody wanted a different kind of variance.\n\nThe variance of a random variable X is defined as the expected value of the squared deviation from the mean, i.e., the variance of X is = to the mean of the square of X minus the square of the mean of X. Hence, the scaling with N.\nThe scaling with N-1 is called the Bessel's correction (hence the term corrected).\nI never read/learned about  values other than N and N-1 for variance (it doesn't mean it does not exist, but I don't see a justifictation for them).\n\nIf yes, then I think a logical argument works well. \"Corrected\" is confusing to me as a non-statistician. Any alternative names?\n\nI used corrected, similarly to Julia, but also because N-1 is called the Bessel 's correction.\n\nI'm erring slightly toward what @certik suggested.\n\nNumpy is the only one allowing values different than N or N-1. Among those I checked (Octave, Matlab, Julia, SAS), N-1 is the default, and N is optional.\nI have a preference for N-1 as default, and the only other option N, but I would be fine with the Numpy approach."
                },
                {
                    "user": "certik",
                    "date": "2020-02-19 20:21:08+00:00",
                    "text": "I am fine with either also, but leaning towards N-1 as well, for consistency with other packages."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-02-19 22:26:00+00:00",
                    "text": "The Bessel correction is necessary when the mean of the population is unknown and also needs to be estimated from the samples. Which just happens to be most practical cases.\nSince we are estimating the sample mean inside the function var, the denominator N-1 is the most appropriate for the variance."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-19 23:15:55+00:00",
                    "text": "There is prevalent preference for N - 1 as the default. I agree with it.\nAs for the API, @jvdp1 suggested optional logical argument which I think is a nice interface. The only downside to this I can think of is that it requires an extra if-branch relative to a ddof integer argument like numpy does, assuming no input validation (I don't think we need any).\nFor this reason I'm slightly in favor an integer argument -- less code and potentially less overhead."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-20 07:53:51+00:00",
                    "text": "The only downside to this I can think of is that it requires an extra if-branch relative to a ddof integer argument like numpy does, assuming no input validation (I don't think we need any).\n\nI don't agree with this statement. If we want a robust function, we need some checks, even with an integer argument (Otherwise, the denominator could become <0, that would lead to negative results for the variance). Numpy var checks the validity of the integer argument (e.g., you can't give an integer argument > N)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-20 13:43:27+00:00",
                    "text": "I think you disagree only with the second statement, that we don't need any input validation. You do need an extra if-branch if you pass a logical.\nThat is fine. If ensuring that the denominator must be 0 or 1 is important, then I'm in favor of a logical argument approach."
                },
                {
                    "user": "certik",
                    "date": "2020-02-21 18:30:38+00:00",
                    "text": "@jvdp1 are you ok with a logical argument also?\nIf so, then we are all in agreement. We already agree to make N-1 the default."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-21 22:21:12+00:00",
                    "text": "@jvdp1 are you ok with a logical argument also?\nIf so, then we are all in agreement. We already agree to make N-1 the default.\n\nI am ok with the logical argument.\nFor the API?\nSyntax\nresult = var(array [, corrected [, mask]])\nresult = var(array, dim [, corrected[, mask]])\nArguments\ncorrected (optional): Shall be a logical scalar. If corrected is .true. (default value), the sum is scaled with n-1. If corrected is .false., then the sum is scaled with n.\nI proposed corrected because n-1 is called Bessel 's correction.\nOther names than corrected?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-21 22:56:33+00:00",
                    "text": "Excellent. I think this API is the way to go. After your and Leon's explanations, corrected is clear and intuitive. Of course, we will explain its meaning in the spec."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-22 08:34:42+00:00",
                    "text": "I thought a bit about the implementation. What would be the best (efficiency/clarity):\n\n\n\n...\n    logical, intent(in), optional :: corrected\n    real(${k1}$) :: correction\n....\n    if ( optval( corrected, .true.)) then\n        correction = 1._${k1}$\n    else\n        correction = 0._${k1}$\n    endif\n...\n\n\n\n...\n    logical, intent(in), optional :: corrected\n    real(${k1}$) :: correction\n....\n    correction = 1._${k1}$\n    if ( .not. optval( corrected, .true.)) correction = 0._${k1}$\n...\n\n\n\n...\n    logical, intent(in), optional :: corrected\n    real(${k1}$) :: correction\n....\n    correction = 1._${k1}$\n    if ( present(corrected)) then\n       if (.not. corrected) correction = 0._${k1}$\n     end if\n...\nOther approaches?\n@milancurcic I can have a look at the implementation and submit a draft PR, if you want."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-22 16:57:24+00:00",
                    "text": "Both 1. and 2. look good to me, with a slight preference for 2 because fewer lines of code.\nI think 3. is unnecessary now that we have optval to do exactly that.\nWe could also do option 4:\ncorrection = merge(1, 0, optval(corrected, .true.))"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-22 18:35:07+00:00",
                    "text": "We could also do option 4:\ncorrection = merge(1, 0, optval(corrected, .true.))\n\nThat is even better, because correction is then not needed :)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-24 02:49:57+00:00",
                    "text": "Resolved by #151."
                }
            ]
        },
        {
            "number": 148,
            "user": "milancurcic",
            "date": "2020-02-18 23:59:16+00:00",
            "title": "Enable make for quadrature",
            "text": "This PR enables building the new quadrature module, as well as tests, with the manual Makefiles.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-02-19 00:19:39+00:00",
                    "text": "Tests pass, merging."
                },
                {
                    "user": "certik",
                    "date": "2020-02-19 00:29:22+00:00",
                    "text": "Thanks!"
                }
            ]
        },
        {
            "number": 147,
            "user": "jvdp1",
            "date": "2020-02-18 15:53:05+00:00",
            "title": "Function in `stdlib` to get  `NaN`",
            "text": "I would suggest we provide a function get_nan and internally implement it by any of the approaches that were discussed (ieee_value, sqrt or huge). That way we have just one simple place to modify, and the rest of stdlib uses get_nan and thus does not have to be modified. We should discuss a good name for such a function.\nOriginally posted by @certik in #128 (comment)\n\nThere was some discussion in #128 about NaN and how to generate it (not all compilers support ieee_arithmetic and its function ieee_value. Therefore, if could be nice to have such a function in stdlib that would work for all compilers.\nIn #128, the following solutions were proposed:\n\n\nieee_value (from ieee_arithmetic.f90)\n\n\nsqrt of a negative number (as implemented in gcc ieee_arithmetic.f90 )\n\n\nhuge (which does not return NaN??) @nshaffer\n\n\nInternal I/O to generate NaN (@urbanjost )\n\n\ntransfer method (@leonfolks  )\n\n\nPossible name for this function: get_nan\nHopefully I didn't miss a proposition.",
            "comments": [
                {
                    "user": "fiolj",
                    "date": "2020-02-20 12:13:44+00:00",
                    "text": "I agree with the proposition, and would like to make it available such a function rather soon, even if the implementation will change later.\nHaving a function like \"get_nan()\" and/or a comparison function \"is_nan(x)\" I think would suffice for most use-cases.\nI do not want to \"hack\" the discussion but I would suggest to have an unified discussion for the three quantities:\nNaN, plus_infinite, minus_infinite\nSince, they will be \"special\" values I would prefer an standard way to handling them rather than having each routine developer handling it individually."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-20 12:24:39+00:00",
                    "text": "I agree with the proposition, and would like to make it available such a function rather soon, even if the implementation will change later.\n\nI agree.\n\nHaving a function like \"get_nan()\" and/or a comparison function \"is_nan(x)\" I think would suffice for most use-cases.\n\nisnan is already supported by GFortran and Ifort, but I am not sure it is Standard Fortran, and it is only for IEEE values. So it would be indeed a nice addition.\n\nI do not want to \"hack\" the discussion but I would suggest to have an unified discussion for the three quantities:\nNaN, plus_infinite, minus_infinite\n\nGood point. There are already some comments about infinity in #118 ."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-21 13:34:36+00:00",
                    "text": "First, let me clarify that I suggested -huge(x) as a return value for a specific edge case for mean in order to avoid returning NaN. So we need not consider it here.\nI want to emphasize that the standard is written in a way that does not assume the existence of NaN and positive/negative infinity except for IEEE real kinds. That means the sqrt, transfer, and write approaches all involve undefined behavior for non-IEEE real kinds.\nSo there is a fundamental friction between practical concerns (we want to be able to produce and test for NaN) and a basic concept of the language (real semantics are independent of the underlying floating-point model).\nWith that in mind, I propose that we have a pre-processor test for whether the ieee_arithmetic module exists. If it does, for each real kind, test if it is an IEEE kind. If it is, define NaN and +/- infinity using the IEEE intrinsic procedures. If ieee_arithmetic does not exist or if a specific kind is not IEEE-conforming, then use a fallback approach.\nOf the fallback approaches discussed so far, I like the internal write best. It directly asks for a \"NaN\", and if the compiler knows what that means, you get something meaningful, even if it is not necessarily going to follow IEEE NaN semantics."
                },
                {
                    "user": "certik",
                    "date": "2020-02-21 18:28:00+00:00",
                    "text": "Let's brainstorm the name of this function. The internal implementation of it can be decided upon later, and also changed easily.\nHere are some possible names that come to my mind:\n\nget_nan()\ngetnan()\nnan()\nieee_nan()\n\nUsing the naming convention of \"two syllables do not need a _\", the getnan() seems the most natural. And also consistent with isnan().\nSo I vote for getnan().\nUpdate: based on the discussion below, I now think nan() is a better choice."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-22 04:59:15+00:00",
                    "text": "Assuming we want to be able to produce NaNs of various kinds, I suggest the following API\npure elemental function nan_<kind>(x)\n    real(<kind>), intent(in) :: x\n    real(<kind>) :: nan_<kind>\nend function nan_<kind>\nwhere the different <kind> implementations are lumped under a generic name nan.\nThis approach is modeled on the intrinsic new_line(c), where the kind of the argument is used to determine the result kind. This is necessary because generic interfaces can't disambiguate based on the result alone. I prefer the name nan to reflect that it's a glorified constant. Analagously, we have new_line, not get_new_line.\nI think there is no question about the API for isnan, but for completeness\npure elemental function isnan_<kind>(x)\n    real(<kind>), intent(in) :: x\n    logical :: isnan_<kind>\nend function isnan_<kind>\nThe only challenge is having to be careful about playing nicely with the pre-existing (non-standard) isnan functions provided by many compilers. Presumably, we will deal with this with preprocessor flags and logic, etc."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-22 08:17:54+00:00",
                    "text": "Assuming we want to be able to produce NaNs of various kinds, I suggest the following API\npure elemental function nan_<kind>(x)\n    real(<kind>), intent(in) :: x\n    real(<kind>) :: nan_<kind>\nend function nan_<kind>\nwhere the different <kind> implementations are lumped under a generic name nan.\n\nIt sounds good to me. It is a similar API to huge, tiny, epsilon,...\n\nI prefer the name nan to reflect that it's a glorified constant. Analagously, we have new_line, not get_new_line.\n\nBased on @nshaffer  reason, I vote for nan too (similarly, we have huge (not gethuge), tiny, epsilon, ...).\n\nThe only challenge is having to be careful about playing nicely with the pre-existing (non-standard) isnan functions provided by many compilers. Presumably, we will deal with this with preprocessor flags and logic, etc.\n\nAs fas as I know, when implemented, isnan supports only IEEE NaN. So it could be checked with CMake, as already done for error stop"
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-22 11:30:06+00:00",
                    "text": "Yes, nan(), with the proposed interface sounds good to me too.\nA very minor point on isnan() is that it probably should also work with complex number arguments, so the user does not have to make it manually every time."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-22 17:05:48+00:00",
                    "text": "I'm fine with either nan() or getnan() with slight preference for nan().\nIf we do choose to go with nan() on the basis of it being a glorified constant, I argue that we also add this specific implementation:\npure elemental function nan_default()\n    real(real32) :: nan_default\nend function nan_default\nwhich would be also overloaded by the generic nan(), and which returns a single-precision real NaN if argument is omitted. Now you could really use it like a constant because Fortran allows you to call functions without (), i.e. just nan. Maybe you shouldn't though, to be consistent with the style elsewhere in the code.\nNevertheless, for people like me who almost exclusively work with single precision, nan() is nicer to use than nan(1._real32)."
                },
                {
                    "user": "certik",
                    "date": "2020-02-23 04:17:49+00:00",
                    "text": "I am also fine with nan and the above design."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-24 15:59:15+00:00",
                    "text": "It sounds like we have a consensus on the name and API. Based on this thread:\nnan\nDescription\nnan(x) is an elemental function that returns a NaN value of the same type as x. If x is omitted, the default type is real(sp).\nSyntax\nresult = nan(x)\nArgument\nx (optional) : Shall be a scalar or an array of type integer, real or complex.\nReturn value\nIf IEEE is supported, the result is IEEE NaN and of the same type as x.\nIf IEEE is not supported, the result is NaN and of the same type as x.\n\nTo progress a bit on this function:\n\n\nNote: for huge, espilon,..., the argument is not otpional. This is not a problem for me, but it might be a problem for the standard.?.\n\n\nImplementation\n\n\n\nIEEE support: ieee_arithmetic.f90, ieee_value\nNo IEEE support: internal I/O or transfer approach or other approaches?\n\nThe choice could be made at the compilation through CMake (and for isnan too)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-24 17:01:56+00:00",
                    "text": "What module does nan() belong to? I think the discussion first started around the stdlib_experimental_constants, but I'm not sure if that's the best place."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-24 18:31:35+00:00",
                    "text": "I don't see an issue with allowing nan to be called without arguments. However, it should return a default real, not real(sp). Our API should not make reference to specific kind parameters where it can be avoided.\nI don't think the standard has any qualms with functions without arguments, see command_argument_count. It make sense for epsilon et al. to require an argument because those functions query the floating point model that a particular kind implements. The fact that new_line also requires an argument is a flaw in my opinion (though I'm curious what the standards lawyers on CLF have to say about that).\nAs for which module to put this in, I think stdlib_experimental_constants is OK, but I'd also support lumping NaN and infinities together in a new module stdlib_experimental_naninf."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-24 18:56:20+00:00",
                    "text": "I don't see an issue with allowing nan to be called without arguments. However, it should return a default real, not real(sp). Our API should not make reference to specific kind parameters where it can be avoided.\n\nI see your point and agree with you for this function.\n\nAs for which module to put this in, I think stdlib_experimental_constants is OK, but I'd also support lumping NaN and infinities together in a new module stdlib_experimental_naninf.\n\nBoth are fine for me, with a preference for stdlib_experimental_naninf. E.g., do we want functions as isnan in stdlib_experimental_constants?"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-24 20:04:37+00:00",
                    "text": "So this is an irrelevant detail, but I thought I'd share my findings: if nan were an intrinsic function it would not be allowed to have interfaces both with and without arguments. This is because it would be classified as an inquiry function, and inquiry functions have at least one argument. It would be an inquiry function because it depends only on properties of its argument, not the value.\nI think we are not holding stdlib functions and subroutines to the same level of rigor as intrinsic ones, so the point is moot, but that's the answer."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-28 18:51:06+00:00",
                    "text": "Question:\nWhich compilers do not support IEEE NaN? (to test a few things)\nhttp://fortranwiki.org/fortran/show/Fortran+2003+status"
                }
            ]
        },
        {
            "number": 146,
            "user": "nshaffer",
            "date": "2020-02-06 13:42:31+00:00",
            "title": "First steps toward quadrature",
            "text": "Here is a starting point for the proposed quadrature module (#112)\n\n\ntrapz, trapz_weights\n\nSimple API, implementation, and tests for 1-d real arrays only\nTODO: complex arrays (straightforward for 1-d)\nTODO: multi-dimensional arrays (still some API questions to resolve)\n\n\n\nsimps, simps_weights\n\nAPI for 1-d real arrays\nTODO: Implementation & tests\nTODO: complex arrays\nTODO: multi-dimensional arrays\n\n\n\nI did not get as far as I hoped in the past week, put I want to get some baseline code up for others to work off of.\nSome points I'm hoping for some specific feedback on:\n\nEdge cases. Do we like the proposed handling of small arrays?\nThe even argument of simps and simps_weights. Does this seem like a reasonable thing to do? Does the API make sense?",
            "comments": [
                {
                    "user": "nshaffer",
                    "date": "2020-02-07 13:48:22+00:00",
                    "text": "@certik Hm, I'm of two minds about that. Sometimes you're testing that a function return a specific value, and it is incorrect behavior if it differs even by one bit. That's the case in optval and for my edge-case tests for trapz. But I do like the ideal of warning-free compilation. I've gone ahead and changed all the real equality tests here to tolerance checks against epsilon."
                }
            ]
        },
        {
            "number": 145,
            "user": "masuday",
            "date": "2020-02-06 04:59:21+00:00",
            "title": "A function to compare two floating-point numbers",
            "text": "Inspied by Julia, I would like to have a function to compare two floating-point numbers with a tolerance, useful for testing.\nelemental function is_approximated_1(x) result(nearly_equal)\n    real(dp),intent(in) :: x\n    logical :: nearly_equal\n    nearly_equal = abs(x) < d_tol\nend function is_approximated_1\n\nelemental function is_approximated_2(x,y) result(nearly_equal)\n    real(dp),intent(in) :: x,y\n    logical :: nearly_equal\n    nearly_equal = abs(x-y) < d_tol\nend function is_approximated_2\n\nelemental function is_approximated_2_tol(x,y,tol) result(nearly_equal)\n    real(dp),intent(in) :: x,y,tol\n    logical :: nearly_equal\n    nearly_equal = abs(x-y) < tol\nend function is_approximated_2\nDefining a general name:\ninterface is_approximated\n   module procedure is_approximated_1, is_approximated_2, is_approximated_2_tol\nend interface is_approximated\nUsage:\nreal(real64) :: x(5),y(5)\n\nprint *,any(is_approximated(x,y))",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-02-06 10:24:20+00:00",
                    "text": "I would propose the following API:\nis_approximated( x [, tol])\nis_approximated( x, y, [, tol])\n\nwhere tol is optional for both functions. A default tol can be determined with optval.\nSo, something like:\nelemental function is_approximated_2_tol_dp(x,y,tol) result(nearly_equal)\n    real(dp),intent(in) :: x,y\n    real(dp), intent(in), optional :: tol\n    logical :: nearly_equal\n    nearly_equal = abs(x-y) < optval(tol, d_tol)\nend function is_approximated_2_tol_dp\nI would also think that we can drop is_approaximated(x [, tol]) because the user would do explicitely what the second API does implicitely.\nThis function could be used in the tests of stdlib. A bitwise check with (almost) the same API could also be implemented. See #142 for more discussion.\nFinally I may envisage some rebuttals from the community regarding this function because it is a one-line function."
                },
                {
                    "user": "masuday",
                    "date": "2020-02-06 16:04:31+00:00",
                    "text": "I agree with your suggestion. A simple API is good enough.\nI like this function because this comparison always occurs in any tests. A function with a clear purpose makes the code readable. For more precise comparisons, a bit-wise approach is preferred."
                },
                {
                    "user": "aradi",
                    "date": "2020-02-06 16:32:47+00:00",
                    "text": "I'd suggest to go with something more general, which allows also relative error. I like quite a lot Numpy's isclose() function which enables to specify both, absolute and relative error. So the interface could be like\nelemental function is_close(x, y, reltol, abstol) result(isclosel)\n    real(dp),intent(in) :: x, y\n    real(dp), intent(in), optional :: reltol, abstol\n    logical :: isclose\n    isclose = abs(x - y) < reltol * abs(y) + atol\nend function is_close\n\nAlso, the name is_close() is much shorter than is_approximated()."
                },
                {
                    "user": "masuday",
                    "date": "2020-02-06 16:48:45+00:00",
                    "text": "@aradi Julia also uses a similar function. Personally, for a quick comparison, I am using the following function (as suggested by Tamas_Papp).\nabs(x - y) < reltol * (1+abs(x)+abs(y))"
                },
                {
                    "user": "wclodius2",
                    "date": "2020-06-20 17:17:17+00:00",
                    "text": "I suggest is_within."
                }
            ]
        },
        {
            "number": 144,
            "user": "jvdp1",
            "date": "2020-02-06 00:03:03+00:00",
            "title": "Addition of variance function in stdlib_experimental_stats",
            "text": "Based on #137\nWith this PR, I propose to add a function for computing the variance of elements in arrays using the same API as stdlib::mean. The used algorithm is a two-pass algorithm (as discussed in #3).\nBased on #3 and #114, I avoided to use the function mean (and to create a new function center for doing x - mean), to avoid loss in performance.\n\nHow can we avoid select case statement:\n\n        select case(dim)\n          #:for fi in range(1, rank+1)\n          case(${fi}$)\n            n = real(size(x, dim), ${k1}$)\n            mean = sum(x, dim) / n\n            do i = 1, size(x, dim)\n              res = res + (x${rankindice(':', 'i', rank, fi )}$ - mean)**2\n            end do\n          #:endfor\n          case default\n            call error_stop(\"ERROR (mean): wrong dimension\")\n        end select\nand\n        select case(dim)\n          #:for fi in range(1, rank+1)\n          case(${fi}$)\n            n = real(count(mask, dim), ${k1}$)\n            mean = sum(x, dim, mask) / n\n            do i = 1, size(x, dim)\n              res = res + merge( (x${rankindice(':', 'i', rank, fi )}$ - mean)**2,&\n              #:if t1[0] == 'r'\n                                  0._${k1}$,&\n              #:else\n                                  cmplx(0._${k1}$, 0._${k1}$, ${k1}$),&\n              #:endif\n                                  mask${rankindice(':', 'i', rank, fi)}$)\n            end do\n          #:endfor\n          case default\n            call error_stop(\"ERROR (mean): wrong dimension\")\n        end select\nI probably miss something that should be obvious!\nAnother issue is the compilation time needed with the Makefiles in the CI!\nNote: Each new statistical function in stdlib_stats will potentially includes 600 additional functions. It really illustrates the issue of having no templates.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-02-06 09:47:53+00:00",
                    "text": "@fiolj Could you check the implementation for complex numbers? Currently there is no tests implemented, to limit the number of tests (but I can implement some tests in a latter commit/PR)."
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-06 16:34:13+00:00",
                    "text": "I\"ll do,  but I can't before this night or tomorrow morning\n\nEl jue., 6 de feb. de 2020 06:47, Jeremie Vandenplas <\nnotifications@github.com> escribi\u00f3:\n\u2026\n @fiolj <https://github.com/fiolj> Could you check the implementation for\n complex numbers? Currently there is no tests implemented, to limit the\n number of tests (but I can implement some tests in a latter commit/PR).\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#144?email_source=notifications&email_token=AAOTPJI45BEWWDFRHN76RZTRBPMEXA5CNFSM4KQUDHUKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEK6SHXY#issuecomment-582820831>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAOTPJMTE6L74EXCLGWIGXDRBPMEXANCNFSM4KQUDHUA>\n ."
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-07 06:22:07+00:00",
                    "text": "I found it really good overall, but I think the variance for complex arrays is always a real number\n(wikipedia link).\nThus, for instance in var_all, we should replace:\n@@ -16,7 +16,7 @@ contains\nmodule function ${RName}$(x, mask) result(res)\n${t1}$, intent(in) :: x${ranksuffix(rank)}$\nlogical, intent(in), optional :: mask\n\n\n   ${t1}$ :: res\n\n\n\n\n\n   real(${k1}$) :: res\n\n\n\nand\n@@ -28,7 +28,7 @@ contains\nn = real(size(x, kind = int64), ${k1}$)\nmean = sum(x) / n\n\n\n   res = sum((x - mean)**2) / (n - 1._${k1}$)\n\n\n\n\n\n   res = sum(abs(x - mean)**2) / (n - 1._${k1}$)\n\n\n\nand in rname(\"var\",rank, t1, k1):\n\n\n   ${t1}$ :: res${reduced_shape('x', rank, 'dim')}$\n\n\n\n\n\n   real(${k1}$) :: res${reduced_shape('x', rank, 'dim')}$\n\n\n\nand later:\n\n\n         res = res + (x${rankindice(':', 'i', rank, fi )}$ - mean)**2\n\n\n\n\n\n        res = res + abs(x${rankindice(':', 'i', rank, fi )}$ - mean)**2\n\n\n\nAlso, if res is real, we don't need the conversion to real to return ieee_nan\n\n\n     res = ieee_value(real(res, kind=${k1}$), ieee_quiet_nan)\n\n\n\n\n\n     res = ieee_value(1._${k1}$, ieee_quiet_nan)\n\n\n\nCoincidentally, I was thinking that my solution to the ieee for complex was unnecessarily complex.\nThe above line: res = ieee_value(1._${k1}$, ieee_quiet_nan) should work also when res is a complex variable.\nFinally, Tomorrow I can look into it in more detail, but I was thinking that may be, even for real numbers we don't have to match the kind of the input. Indeed if the input is a large quantity of real(sp) it may be desirable that the variance (and mean) be calculated in double precision. I don't know if I am missing something about availability of double precision for some machines but I would think that nowadays that should not be an issue"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-07 20:26:18+00:00",
                    "text": "Thanks @fiolj for your review.\nI will look tomorrow on your propositions for the variance of complex.\nBelow are some other comments.\n\nCoincidentally, I was thinking that my solution to the ieee for complex was unnecessarily complex.\nThe above line: res = ieee_value(1._${k1}$, ieee_quiet_nan) should work also when res is a complex variable.\n\nThis is indeed a good idea, much simpler than the previous implementation. I will implement it here and for mean too.\n\nFinally, Tomorrow I can look into it in more detail, but I was thinking that may be, even for real numbers we don't have to match the kind of the input.\n\nThe idea was to get the same API as sum. So the result is of the same type as the real array, as in sum. This API also avoids internal conversion from, e.g., sp to dp, before calling sum (since it would have little sense to do it after sum operations IMO).\nAlso, having all results in dp, will not reduce the number of generated functions.\n\nIndeed if the input is a large quantity of real(sp) it may be desirable that the variance (and mean) be calculated in double precision.\n\nI think it is the responsability of the user to check that (as it is already the case with sum)."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-07 23:03:58+00:00",
                    "text": "From @fiolj  comments, I push commits for:\n\nsimplifying the ieee_value call (as proposed by @fiolj)\nimplementing a corrected computation of variance of complex\nimplementing tests for complex (I tested them against Octave)\n\nRegarding the implementation, I did e.g.,\n      #:if t1[0] == 'r'\n          res = sum((x - mean)**2) / (n - 1._${k1}$)\n        #:else\n          res = sum(abs(x - mean)**2) / (n - 1._${k1}$)\n        #:endif\nto avoid the abs function in the real var function (it is there useless and give some penalties to efficiency)\n@fiolj  could you confirm it was what you suggested, please?"
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-08 14:11:10+00:00",
                    "text": "Thanks @jvdp1, that was exactly what I suggested.\nI think it looks good"
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-08 14:16:26+00:00",
                    "text": "This PR is fine. Thanks.\nIn the long term, I wonder if fypp can be improved so that there is not as much repetition. There are still 8 different blocks to declare the signature of the function (real/integer and (x, mask)/(x, dim, mask) and mask = scalar/array, all combinations 2x2x2=8). And even more long term, the Fortran language itself should be improved so that fypp is not needed.\n\nI agree with @certik here. I was thinking along the same lines. A possible solution for real/int interfaces does not seem to difficult. Something like (for instance for the function mean):\n\n    #:for k1, t1 in RCI_KINDS_TYPES\n      #:for rank in RANKS\n        #:set RName = rname(\"mean_all\",rank, t1, k1)\n        #:set ret_type = 'real(dp)' if t1[0] == 'i' else t1\n        module function ${RName}$ (x, mask) result(res)\n          ${t1}$, intent(in) :: x${ranksuffix(rank)}$\n          logical, intent(in), optional :: mask\n          ${ret_type}$ :: res\n        end function ${RName}$\n      #:endfor\n    #:endfor\n\n\nwhich is valid for all types (real, complex, int). For some simple functions we could write the implementation in some way that would be mostly the same also.\nFor functionvar, we could use something similar\n    #:for k1, t1 in RCI_KINDS_TYPES\n      #:for rank in RANKS\n        #:set RName = rname(\"var_all\",rank, t1, k1)\n        #:set ret_type = 'real(dp)' if t1[0] == 'i' else \"real({})\".format(k1)\n        module function ${RName}$(x, mask) result(res)\n          ${t1}$, intent(in) :: x${ranksuffix(rank)}$\n          logical, intent(in), optional :: mask\n          ${ret_type}$ :: res\n        end function ${RName}$\n      #:endfor\n    #:endfor\n\n\nThis would cut the code to a half, not solving the remaining four factor."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-09 13:47:40+00:00",
                    "text": "Thank you for your review.\n\nFor functionvar, we could use something similar\n    #:for k1, t1 in RCI_KINDS_TYPES\n      #:for rank in RANKS\n        #:set RName = rname(\"var_all\",rank, t1, k1)\n        #:set ret_type = 'real(dp)' if t1[0] == 'i' else \"real({})\".format(k1)\n        module function ${RName}$(x, mask) result(res)\n          ${t1}$, intent(in) :: x${ranksuffix(rank)}$\n          logical, intent(in), optional :: mask\n          ${ret_type}$ :: res\n        end function ${RName}$\n      #:endfor\n    #:endfor\n\nThis would cut the code to a half, not solving the remaining four factor.\n\nThat will reduce the number of blocks, but it might give a fypp file that is difficult to read and to follow due to too many conditional statements (if/set; especially for the implementation where fypp conditions (if) will be needed, as already used for complex). We could probably implement some functions in common.fypp, but I am still afraid for the complexity of the code.\nFor now, I would suggest that we merge this PR with the master. Then we can open a PR to (try to) reduce the number of blocks in var and mean (but unfortunately, it will not reduce the number of generated functions)."
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-10 11:05:01+00:00",
                    "text": "El 9/2/20 a las 10:47, Jeremie Vandenplas escribi\u00f3:\n For now, I would suggest that we merge this PR with the master. Then we\n can open a PR to (try to) reduce the number of blocks in |var| and\n |mean| (but unfortunately, it will not reduce the number of generated\n functions).\nYes, agree. It is not a completely satisfactory solution yet, and we\nshould try to come out with something better. I put it forward mainly to\nstart thinking about it."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-18 00:17:51+00:00",
                    "text": "I just revisited this PR. It looks like everybody approved it. We can revisit any outstanding minor issues in a later PR. Merging, thanks @jvdp1!."
                }
            ]
        },
        {
            "number": 143,
            "user": "masuday",
            "date": "2020-02-05 16:00:05+00:00",
            "title": "Naming rules for initializer & finalizer of procedural API",
            "text": "I have a concern about the naming rules of the initializer and finalizer of an object (or user-derived type). It is unclear for traditional APIs, while it is relatively clear for object-oriented APIs. I quickly checked MKL, NAG, and IMSL.\n\nMKL: new for initializer, and delete for finalizer (for random number generators)\nNAG: init for initializer, and no finalizer\nIMSL: no initializer/finalizer; having comprehensive subroutines initialized by arguments like IPARM(*)\n\nThe other question is whether it should be prefix or suffix. My suggestion is to have init for the initializer and final for the finalizer to be a suffix.",
            "comments": [
                {
                    "user": "nshaffer",
                    "date": "2020-02-11 22:21:11+00:00",
                    "text": "I prefer to use the default constructor where able. If the type requires a special constructor (e.g., it has allocatable or pointer components), I overload the default one. As an example:\nmodule foo_type\n  implicit none\n\n  type :: foo\n    integer :: n\n    real, allocatable :: x(:)\n  end type foo\n\n  interface foo\n    module procedure constructor\n  end interface foo\n\ncontains\n\n  pure function constructor(n, x) result(obj)\n    integer, intent(in) :: n\n    real, intent(in) :: x(n)\n    type(foo) :: obj\n\n    obj%n = n\n    obj%x = x\n  end function constructor\nend module foo_type\nIn cases where more complicated initialization logic is needed or if the derived type has a large memory footprint, I prefer a subroutine prefixed by init_. If explicit finalizers are needed, I prefer prefixing the subroutine with final_."
                }
            ]
        },
        {
            "number": 142,
            "user": "certik",
            "date": "2020-02-04 17:58:55+00:00",
            "title": "Use epsilon() for tolerances",
            "text": "The original tolerances look arbitrary:\nreal(sp), parameter :: sptol = 1.2e-06_sp\nreal(dp), parameter :: dptol = 2.2e-15_dp\n\nbut when written using epsilon() they are almost exactly 10x the machine\nepsilon for the particular precision kind:\nreal(sp), parameter :: sptol = 10.06633 * epsilon(1._sp)\nreal(dp), parameter :: dptol = 9.907919 * epsilon(1._dp)\n\nso I just rounded it to 10:\nreal(sp), parameter :: sptol = 10 * epsilon(1._sp)\nreal(dp), parameter :: dptol = 10 * epsilon(1._dp)\n\nwhich now shows the intent more clearly: the tolerance assumes we lose\none digit of accuracy.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-02-04 18:11:23+00:00",
                    "text": "Both options are fine with me, if we keep it consistent across the files.\nHere is an answer of @aradi when I proposed to use epsilon."
                },
                {
                    "user": "certik",
                    "date": "2020-02-04 18:50:03+00:00",
                    "text": "Thanks @jvdp1. @aradi in that comment you gave epsilon(1.0_dp)**(7.0_dp / 8.0_dp) as an example. Rather, as in this PR, one should use 10 * epsilon(1.0_dp), and as shown in the commit description, the result is in fact equivalent to your original hard wired tolerance. (In some other cases, one might need to use something like 1e3_dp * epsilon(1._dp) if more tolerance is needed.)"
                },
                {
                    "user": "nncarlson",
                    "date": "2020-02-05 00:09:37+00:00",
                    "text": "I feel like a drive-by sniper by commenting. But with a carefully chosen data set (e.g., integral values, power of 2 number of values) the calculations will be done without any round-off and tests can be for equality (bit-for-bit). One can dispense entirely with any notion of an appropriate epsilon, and the data easily hard-coded in the test itself without the extra complexity of reading from a file. The test would be far simpler.  What exactly is being gained by using data that uses all the significant digits?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-05 08:04:24+00:00",
                    "text": "I feel like a drive-by sniper by commenting. But with a carefully chosen data set (e.g., integral values, power of 2 number of values) the calculations will be done without any round-off and tests can be for equality (bit-for-bit). One can dispense entirely with any notion of an appropriate epsilon, and the data easily hard-coded in the test itself without the extra complexity of reading from a file. The test would be far simpler. What exactly is being gained by using data that uses all the significant digits?\n\nI like this idea. But do you think it is possible for functions more complicate than mean, and with all algorithms?"
                },
                {
                    "user": "aradi",
                    "date": "2020-02-05 08:41:12+00:00",
                    "text": "@nncarlson Your comments are more than welcome! We do the PRs in public in order to get critical comments from skilled developers and improve so the quality of stdlib.\nAs for the bit by bit comparison: I agree, one could maybe use special numbers and check by bitwise comparison. However, we should keep in mind that\n\nthis may not work for more complicated functions and\nthis is not the typical use case.\n\nEspecially latter is important IMO, as the test suite should definitely include tests for the typical use cases (using all significant bits). However, adding the specially designed input values with bitwise check for the results could make up for very nice additional tests."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-02-05 14:19:16+00:00",
                    "text": "I like this idea. But do you think it is possible for functions more complicate than mean, and with all algorithms?\n\nUnfortunately not. Only a subset of those things where something rational is being computed. But in cases where it is possible, it makes the tests much more straightforward, and I think that is preferable.\n\nEspecially latter [this is not the typical use case] is important IMO, as the test suite should definitely include tests for the typical use cases (using all significant bits).\n\nIt's certainly not the typical use case, but what exactly is being tested? I think it is that the correct elements from the input arrays are being summed and normalized by the correct value; i.e., the code of the mean function. For that, carefully chosen integral values (in this case) are sufficient to test that.  I think the only thing  that using general values (requiriing all significant bits) adds to the test is to test that the hardware does addition and division correctly. But I think that is something this and other  tests can assume."
                },
                {
                    "user": "certik",
                    "date": "2020-02-05 21:38:30+00:00",
                    "text": "We can further improve this to test things exactly, but I am also fine with just keeping this as is. This PR is effectively just a refactoring what is in master, so I merged it."
                }
            ]
        },
        {
            "number": 141,
            "user": "nshaffer",
            "date": "2020-02-04 17:07:00+00:00",
            "title": "Add spec for optval",
            "text": "I based this on the structure of the spec for mean. Things I'm not 100% sure of\n\nIs an \"implemented\" section necessary for this case?\nDo we want language-defined terms capitalized or formatted some other way, e.g., PRESENT vs present vs present?\nIs my mixed usage of \"default\" and \"fallback\" a problem?",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-02-04 17:59:38+00:00",
                    "text": "Thank you.\n\nI based this on the structure of the spec for mean. Things I'm not 100% sure of\n\nIs an \"implemented\" section necessary for this case?\n\n\nI suggest to keep it; to follow the same format as other specs.\n\n\nDo we want language-defined terms capitalized or formatted some other way, e.g., PRESENT vs present vs present?\n\n\nI think it is @milancurcic who mentioned that, for the mean spec, he preferred e.g., present over PRESENT. I tried to follow that rule for the other specs.\n\n\nIs my mixed usage of \"default\" and \"fallback\" a problem?\n\n\nI am ok with it."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-04 20:00:48+00:00",
                    "text": "Alternatively, to avoid confusion regarding what \"present\" means, we could write:\n\nReturns x if present(x) returns .true., otherwise default.\n\ninstead of\n\nReturns x if it is present, otherwise default."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-07 13:54:56+00:00",
                    "text": "Thanks for the feedback, all. I've changed styling to match Milan's suggestions, which seem reasonable to me. I've left in the Implemented section. I suspect if we write tools that parse the specs or something, it would be useful to have them all follow a consistent structure."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-13 15:40:39+00:00",
                    "text": "I will merge this PR since most of us approved it."
                },
                {
                    "user": "certik",
                    "date": "2020-02-13 19:18:56+00:00",
                    "text": "Thanks!\n\u2026\nOn Thu, Feb 13, 2020, at 9:40 AM, Jeremie Vandenplas wrote:\n I will merge this PR since most of us approved it.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#141?email_source=notifications&email_token=AAAFAWDMHSYVJZK67OABX7TRCVSXPA5CNFSM4KP2TG7KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOELVO3SQ#issuecomment-585821642>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWFTL5FE6PLSXC2IBFDRCVSXPANCNFSM4KP2TG7A>."
                }
            ]
        },
        {
            "number": 140,
            "user": "fiolj",
            "date": "2020-02-04 14:04:46+00:00",
            "title": "Added support and test for mean of complex arrays",
            "text": "Added support and tests for complex types.\nI changed the names of the specific functions, following the convention used in optval.",
            "comments": [
                {
                    "user": "fiolj",
                    "date": "2020-02-04 16:36:50+00:00",
                    "text": "Ok, @jvdp1  @aradi What do you think of using a macro for names like the following?\n#:def rname(gname, rank, type, kind, suffix='')\n  $:\"{0}_{1}_{2}{3}_{2}{3}\".format(gname, rank, type[0], kind) if suffix == '' else \"{0}_{1}_{2}{3}_{4}\".format(gname, rank, type[0], kind, suffix)\n#:enddef\n\nAssuming that t1='real', k1='sp', rank=1,\n${rname(\"mean_all\",rank, t1, k1)}$\nwill give:\nmean_all_1_rsp_rsp"
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-04 19:03:14+00:00",
                    "text": "I was getting an error for complex numbers. I am not sure but it seems\nthat it is not defined for complex numbers.\n\nEl 4/2/20 a las 14:53, Jeremie Vandenplas escribi\u00f3:\n\u2026\n ***@***.**** approved this pull request.\n\n Pending my minor comment, I think these changes are good. Having the\n macro in |common.fypp| clarifies the other |.fypp| files. Thank you.\n\n ------------------------------------------------------------------------\n\n In src/stdlib_experimental_stats_mean.fypp\n <#140 (comment)>:\n\n>          ${t1}$, intent(in) :: x${ranksuffix(rank)}$\n          logical, intent(in), optional :: mask\n          ${t1}$ :: res\n\n          if (.not.optval(mask, .true.)) then\n -          res = ieee_value(res, ieee_quiet_nan)\n +          res = ieee_value(real(res, kind=${k1}$), ieee_quiet_nan)\n\n |ieee_value| returns a NaN of the same type as |res|. So it should be OK\n without the conversion to a |real|, right? Or do I miss something?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#140?email_source=notifications&email_token=AAOTPJPPWL24AYGAWDKEC4LRBGTTDA5CNFSM4KPXP4QKYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCUGRCUQ#pullrequestreview-353177938>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAOTPJKF3PDVRP6JDB3SLNLRBGTTDANCNFSM4KPXP4QA>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-04 19:28:36+00:00",
                    "text": "I was getting an error for complex numbers. I am not sure but it seems that it is not defined for complex numbers.\n\nIt seems that you are right: it is not defined for complex (at least in gfortran)\nSo it can be merged from my side."
                },
                {
                    "user": "certik",
                    "date": "2020-02-05 21:41:56+00:00",
                    "text": "I resolved conflicts and tests seem to pass. We got two approvals, so I am going to merge it now."
                }
            ]
        },
        {
            "number": 139,
            "user": "fiolj",
            "date": "2020-02-02 15:27:41+00:00",
            "title": "Optval",
            "text": "Used template and added complex support and tests to optval\nNote: now it seems to work. It is built after changes on common.fypp added in pull request #138 (Added complex to io)",
            "comments": [
                {
                    "user": "fiolj",
                    "date": "2020-02-02 23:46:09+00:00",
                    "text": "Ok, I'll roll back formatting, correct along the lines commented by\n@certik and @nshaffer and send new PRs for both #138 and #139.\n\nEl 2/2/20 a las 8:12 PM, Ond\u0159ej \u010cert\u00edk escribi\u00f3:\n\u2026\n ***@***.**** requested changes on this pull request.\n\n Thanks for extracting the optval function into fypp! We definitely want\n that.\n\n Can you please not do any formatting changes in the same PR? If you want\n to propose formatting changes, please send a new PR with just those\n changes. If you could split the formatting changes from this PR, then we\n can merge it.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#139?email_source=notifications&email_token=AAOTPJJKUKOZJGQC545PBITRA5HOFA5CNFSM4KO2JI3KYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCT5LOJI#pullrequestreview-351975205>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAOTPJLFUJ67LBR3S6YK5ADRA5HOFANCNFSM4KO2JI3A>."
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-03 00:50:26+00:00",
                    "text": "I added it by mistake. I've not used cmake before. What did confuse me\nwas that stdlib_experimental_io.f90 was there even when it is generated\nby fypp (and  stdlib_experimental_io.fypp is also present a few lines\nabove).\n\n\nEl 2/2/20 a las 6:37 PM, nshaffer escribi\u00f3:\n\u2026\n ***@***.**** commented on this pull request.\n\n ------------------------------------------------------------------------\n\n In src/CMakeLists.txt\n <#139 (comment)>:\n\n> @@ -25,6 +26,7 @@ set(SRC\n      stdlib_experimental_error.f90\n      stdlib_experimental_kinds.f90\n      stdlib_experimental_optval.f90\n +    stdlib_experimental_stats.f90\n\n I don't believe this entry should be here, since\n |stdlib_experimental_stats.f90| is generated by |fypp|.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#139?email_source=notifications&email_token=AAOTPJKJOIEUQZ5P5U56LKLRA44KBA5CNFSM4KO2JI3KYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCT5J73A#pullrequestreview-351969260>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAOTPJKOXM2XAG46JWEFPVLRA44KBANCNFSM4KO2JI3A>."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-03 13:11:16+00:00",
                    "text": "I added it by mistake. I've not used cmake before. What did confuse me was that stdlib_experimental_io.f90 was there even when it is generated by fypp (and stdlib_experimental_io.fypp is also present a few lines above).\n\nNo worries, really this should be automatically handled by CMake, it's just not in place yet."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-03 14:13:08+00:00",
                    "text": "Note to anyone who would be happy to do it: a spec stdlib_experimental_optval.md must be added.\n\nI have written a spec locally and will submit a PR sometime soon."
                }
            ]
        },
        {
            "number": 138,
            "user": "fiolj",
            "date": "2020-02-02 14:06:50+00:00",
            "title": "Added complex to io",
            "text": "Implementation of support for complex number in io\nNote that I had to change the function number_of_rows_numeric()",
            "comments": [
                {
                    "user": "fiolj",
                    "date": "2020-02-03 00:06:03+00:00",
                    "text": "Support for complex. No reformatting."
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-03 17:22:24+00:00",
                    "text": "Changed files along the lines suggested by @jvdp1 ."
                }
            ]
        },
        {
            "number": 137,
            "user": "jvdp1",
            "date": "2020-02-02 09:37:47+00:00",
            "title": "Proposal for variance and centering functions",
            "text": "Based on discussions in #113, #3, #128, I would like to propose the following addition to stdlib_experimental_stats:\n\nvar - variance of array elements\nDescription\nReturns the variance of all the elements of array, or of the elements of array along dimension dim if provided, and if the corresponding element in mask is true.\nThe variance is defined as the best unbiased estimator and is computed as:\n var(x) = 1/(n-1) sum_i (array(i) - mean(array))^2\n\nSyntax\nresult = var(array [, mask])\nresult = var(array, dim [, mask])\nArguments\narray: Shall be an array of type integer, or real.\ndim: Shall be a scalar of type integer with a value in the range from 1 to n, where n is the rank of array.\nmask (optional): Shall be of type logical and either by a scalar or an array of the same shape as array.\nReturn value\nIf array is of type real, the result is of the same type as array.\nIf array is of type integer, the result is of type double precision.\nIf dim is absent, a scalar with the variance of all elements in array is returned. Otherwise, an array of rank n-1, where n equals the rank of array, and a shape similar to that of ar ray with dimension dim dropped is returned.\nIf mask is specified, the result is the variance of all elements of array corresponding to true elements of mask. If every element of mask is false, the result is IEEE NaN.\nExample\nprogram demo_mean\n    use stdlib_experimental_stats, only: var\n    implicit none\n    real :: x(1:6) = [ 1., 2., 3., 4., 5., 6. ]\n    print *, var(x)                            !returns __TOBECOMPLETED__\n    print *, var( reshape(x, [ 2, 3 ] ))       !returns __TOBECOMPLETED__ \n    print *, var( reshape(x, [ 2, 3 ] ), 1)    !returns [__TOBECOMPLETED__]\n    print *, var( reshape(x, [ 2, 3 ] ), 1,&\n                  reshape(x, [ 2, 3 ] ) > 3.)  !returns [__TOBECOMPLETED__]\nend program demo_mean\n\nTo be discussed (not exhaustive):\n\n\nBased on discussions in #3, I suggest to first implement a two-pass algorithm. Other algorithms can be implemented later,  as proposed in #134. Allowing dim and mask in the API will not lead to a function as simple as in #3 comment.\n\n\nThe centering of an array along a dimension (e.g., x(:, i) - mean(x, 2)) will most likely require a loop. To have a clean implementation of the function var, I propose to add a function center to perform the different centering of an array x, and var would call it for the centering. However, I am afraid about efficiency (especially memory usage since an additional temporary array could be needed for the function center) with this proposition.\n\n\nThe proposed name for the variance function is var. But what about variance (or other propositions)?\n\n\nOthers:\nOctave var\nR var\nJulia var\nNumpy var\nRequesting feedback from (at least) @certik @milancurcic @ivan-pi @aradi @leonfoks",
            "comments": []
        },
        {
            "number": 136,
            "user": "nshaffer",
            "date": "2020-02-02 07:17:14+00:00",
            "title": "Slow build and failing tests with `std_experimental_stats_mean`",
            "text": "Compiler: gfortran 9.2.0\nOS: Arch Linux 32-bit\nProcessor: Intel Atom (2 logical cores)\nWhen I build stdlib on my (admittedly low-spec) machine, preprocessing and compilation of the submodule std_experimental_stats_mean is strikingly slow, especially the compilation step. I speculate that this is due to the preprocessor generating dozens of routines for different kinds, types, and ranks which then take a long time for the compiler to churn through. This raises two questions:\n\nDo other users experience similar slowdowns?\nIf so, is it enough to raise concern about build times, considering that many stdlib functions will have similary heavy use of code generation to achieve genericity?\n\nIt is also worth noting that both tests related to mean fail for me. Below are the relevant (but not terribly helpful) sections from the test log. Each \"test\" consists of dozens of assertions, and I have not pinpointed which one borks it all -- gfortran's backtrace has not helped. Am I alone in this?\n11/14 Testing: mean\n11/14 Test: mean\nCommand: \"/home/nrs/Documents/stdlib/build/src/tests/stats/test_mean\" \"/home/nrs/Documents/stdlib/build/src/tests/stats\"\nDirectory: /home/nrs/Documents/stdlib/src/tests/stats\n\"mean\" start time: Feb 02 00:02 MST\nOutput:\n----------------------------------------------------------\nERROR STOP Assert failed.\n\nError termination. Backtrace:\n#0  0x7a4d86 in ???\n#1  0x4cc596 in ???\n#2  0x4ba290 in ???\n#3  0x4c7495 in ???\n#4  0xb79c1f28 in ???\n#5  0x4b9364 in ???\n#6  0xffffffff in ???\n<end of output>\nTest time =   0.17 sec\n----------------------------------------------------------\nTest Failed.\n\"mean\" end time: Feb 02 00:02 MST\n\"mean\" time elapsed: 00:00:00\n----------------------------------------------------------\n\n12/14 Testing: mean_f03\n12/14 Test: mean_f03\nCommand: \"/home/nrs/Documents/stdlib/build/src/tests/stats/test_mean_f03\" \"/home/nrs/Documents/stdlib/build/src/tests/stats\"\nDirectory: /home/nrs/Documents/stdlib/src/tests/stats\n\"mean_f03\" start time: Feb 02 00:02 MST\nOutput:\n----------------------------------------------------------\nERROR STOP Assert failed.\n\nError termination. Backtrace:\n#0  0x735f05 in ???\n#1  0x45d715 in ???\n#2  0x44a943 in ???\n#3  0x458614 in ???\n#4  0xb7970f28 in ???\n#5  0x44a364 in ???\n#6  0xffffffff in ???\n<end of output>\nTest time =   0.16 sec\n----------------------------------------------------------\nTest Failed.\n\"mean_f03\" end time: Feb 02 00:02 MST\n\"mean_f03\" time elapsed: 00:00:00\n----------------------------------------------------------",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-02-02 07:52:55+00:00",
                    "text": "@nshaffer The compilation time has been a concern for the Github CI (GFortran 8 and 9). Due to that we limited the number of ranks to 4 in the CMake files for the CI.\nThe number of ranks can be limited with the CMake CMAKE_MAXIMUM_RANK.\nThe tests were OK on the Github Actions.\nAlso, using CMake, I have no issues on my Desktop (Fedora 31 64bit - GFortran 9.2.1 - Intel Core I7 4 cores):\nbuild]$ time make -j\n[  2%] Generating stdlib_experimental_stats_mean.f90\n[  7%] Generating stdlib_experimental_stats.f90\n[  7%] Generating stdlib_experimental_io.f90\nScanning dependencies of target fortran_stdlib\n...\n[ 97%] Linking Fortran executable test_mean_f03\n[100%] Linking Fortran executable test_mean\n[100%] Built target test_mean_f03\n[100%] Built target test_mean\n\nreal\t0m16,172s\nuser\t0m20,246s\nsys\t0m2,074s\n[build]$ ctest\nTest project /home/jvandenp/stdlib/build\n  ....\n      Start 11: mean\n11/13 Test #11: mean .............................   Passed    0.00 sec\n      Start 12: mean_f03\n12/13 Test #12: mean_f03 .........................   Passed    0.04 sec\n      Start 13: Sleep\n13/13 Test #13: Sleep ............................   Passed    0.35 sec\n\n100% tests passed, 0 tests failed out of 13\n\nLabel Time Summary:\nquadruple_precision    =   0.01 sec*proc (2 tests)\n\nTotal Test time (real) =   0.44 sec\n\nThe following tests did not run:\n\t  1 - always_skip (Skipped)\n\nI agree with you that achieving genericity by creating so much code for only one function is a problem. I am a bit afraid when other functions similar to mean will be added to stdlib_experimental_stats. Any ideas how to avoid that?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-02-02 12:46:48+00:00",
                    "text": "I did a clean build on my desktop (Ubuntu 16.04 64 bit, gfortran 9.2.1, Intel Core i5 (4 cores):\n(base) 13:35:59 ipribec@ipribec-ThinkPad: ~/TUM/stdlib/build$ time make -j\n[  2%] Generating stdlib_experimental_io.f90\n[  5%] Generating stdlib_experimental_stats_mean.f90\n[  7%] Generating stdlib_experimental_stats.f90\nScanning dependencies of target fortran_stdlib\n...\n[ 97%] Linking Fortran executable test_mean_f03\n[100%] Linking Fortran executable test_mean\n[100%] Built target test_mean_f03\n[100%] Built target test_mean\n\nreal\t0m11.350s\nuser\t0m13.542s\nsys\t0m0.736s\n\nAll tests passed.\n\n\nEach \"test\" consists of dozens of assertions, and I have not pinpointed which one borks it all -- gfortran's backtrace has not helped. Am I alone in this?\n\nA good reason to move forward with the assert subroutines/macros discussed in #121 and #72.\nHave you tried doing a binary search?"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-02 19:59:59+00:00",
                    "text": "@jvdp1 @ivan-pi Ok, thanks for confirming that you don't get test failures. I'll keep hunting. Until we've formalized our unit testing practices, I think it's helpful to print out a message for each conceptually distinct test (one or more \"asserts\" that go together). That way, you get a bit more information in the log when trying to hunt down failures. Better yet is to have each conceptually distinct test be a separate program, which what CTest seems to expect, but I understand that's a little onerous.\n@jvdp1 I don't have a good solution in mind for getting around source code explosion. C++ uses the concept of template instantiation. It's possible to emulate that with pre-processing (see https://github.com/SCM-NV/ftl for a cpp-based example), but that has to happen user-side. As long as we're unwilling to inflict pre-processing on users (which I agree with), this solution seems not to work for stdlib.\nUsing submodules helps somewhat. We can restrict modules to containing type definitions and the generic API and use separate submodules to implement the procedures for each generic name. This look like the approach you're taking with stats and stats_mean and friends, and I think it's a good one. It's mainly a dev-side benefit, but it's much better than nothing."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-11 19:09:25+00:00",
                    "text": "I revisited this today. All the failing asserts were double-precison test cases (real and complex alike). I was able to get all tests passing on my machine by increasing dptol to 10000*epsilon(1._dp). Smaller powers of ten out front led to failures. This was true of both the mean and the mean_f03 tests.\nSince the tests just exercise the implementation, and nobody else reports a problem, I suspect this is a platform-specific issue. If someone has a 32-bit machine they can reproduce this on, that'd be the next thing to look into."
                },
                {
                    "user": "certik",
                    "date": "2020-02-11 22:52:38+00:00",
                    "text": "@nshaffer thanks for investigating this. It looks like this is a problem on 32bits and we need to fix it. setting dtol to 1e4_dp*epsilon(1._dp) is an acceptable solution to me."
                }
            ]
        },
        {
            "number": 135,
            "user": "masuday",
            "date": "2020-02-01 00:16:36+00:00",
            "title": "Pseudorandom number generator",
            "text": "EDIT: An updated proposal is available below.\nThere are a few suggestions to have pseudorandom number generators (PRNGs) in the library, e.g., #1 (comment) and #104 (comment). Focusing on the uniform floating-point PRNG [0.0, 1.0), we have already had the intrinsic subroutine, random_number. The first question is whether we should have custom PRNGs of the uniform distribution. Or, we should concentrate on derived PRNGs like non-uniform distributions or integer PRNGs. I think it is still worth developing custom PRNGs because of better flexibility and performance.\nWith the custom PRNGs, we have many more questions.\n\nShould we have various generators (e.g., integer numbers) in addition to a floating-point PRNG [0.0, 1.0)?\nShould it support different algorithms of PRNG, or can we provide a single algorithm?\n\nIf true: Should it optionally call the intrinsic subroutine?\nIf true: Should the seed (state) be global, private, or both?\n\nIf global, Should it be thread-safe?\n\n\n\n\n\nThe decision defines a design of API. A possible API is the same as the intrinsic subroutines. The subroutine name in the below example is just a placeholder.\n! just arbitrary precision here\ntype(random_number_generator) :: rng\nreal(dp) :: harvest\ninteger :: seed(2)\n\n! for local state as derived type\nseed = [1,2]\ncall pseudorandom_seed(rng,put=seed)\ncall pseudorandom_number(rng,harvest)\n\n! for global state as saved seed\ncall pseudorandom_seed(put=seed)\ncall pseudorandom_number(harvest)\nPlease tell me what you think about it.\n\nR: https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/Random\nPython: https://docs.python.org/3/library/random.html\nNumPy: https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html\nMatlab: https://www.mathworks.com/help/matlab/random-number-generation.html\nOctave: https://octave.org/doc/v4.0.3/Special-Utility-Matrices.html#Special-Utility-Matrices\nJulia: https://docs.julialang.org/en/v1/stdlib/Random/\nC++: https://en.cppreference.com/w/cpp/numeric/random\nRust: https://rust-num.github.io/num/rand/index.html#thread-local-rng\nGo: https://golang.org/pkg/math/rand/\nNAG: https://www.nag.co.uk/numeric/fl/nagdoc_fl24/html/g05/g05conts.html\nMKL: https://software.intel.com/en-us/mkl-developer-reference-fortran-random-number-generators\nIMSL: https://docs.roguewave.com/imsl/fortran/6.0/stat/default.htm?turl=rnun.htm\nGSL: https://www.gnu.org/software/gsl/doc/html/rng.html",
            "comments": [
                {
                    "user": "peteroupc",
                    "date": "2020-02-01 00:36:35+00:00",
                    "text": "I have a section \"Guidelines for New RNG APIs\" that gives my thoughts on how new APIs should support RNGs.  (It seems that the focus is not on security, so ignore the information on cryptographic RNGs there if that is true.)\nAlso, any new PRNGs provided by the API should not use global state; see also the recent NumPy RNG policy."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-02-01 22:45:40+00:00",
                    "text": "I would support having both custom uniform and also non-uniform and integer distributions. Importantly, for Fortran the RNG should work also when run in parallel (both coarray or OpenMP, OpenMPI environments). Quoting from a blog post  by Jason Blevins:\n\nTo fix this problem, each thread needs to have its own independent RNG. There is no simple way to accomplish this with Fortran\u2019s random_number intrinsic. Instead, we need a more sophisticated RNG that can have multiple \u201cinstances.\u201d Fortran\u2019s user-defined types provide a nice solution. If we create a type that will store the state of each stream of random numbers, we can then build an array of RNGs\u2013one for each thread or experiment\u2013each started at a different seed.\n\nThe C++ standard library also provides several non-uniform distributions and different generators in a high-level object API.\nThe NAG libary also provides both different generators and also non-uniform distributions.\nRust also provides thread-local RNGs."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-02-02 01:31:29+00:00",
                    "text": "@peteroupc That link is fantastic, ill check it out!\nI have a PRNG that is thread safe, and non global state, in coretran. See #104 and this link\nIt is thread safe under OpenMP and OpenMPI, I have not tried it with coarrays but I don't see why it wouldn't work.\nThe base generator can be changed depending on what the user wants. So far i've implemented the xorshift128+ and xorshift1024* but I would like to add xoroshiro variants too since I read they are a little more robust when it comes to the big crush tests.  The seed of the generators can be specified. I also have the capability of randomly generating seeds using the splitmix64 algorithm. The PRNG class can generate past just uniform.  Most of the functions were written by Alan Miller and were released into public domain.\nThe default generators in Matlab and Python are Mersenne Twister generators which have a huge period, but they can't be \"jumped\" for parallel codes, although after reading the link above, maybe they can?  My PRNG class has a \"jump\" type bound procedure.  IMHO The best way to use a PRNG in parallel is to instantiate and seed every PRNG on every thread with the same seed, and jump each \"rank's\" PRNG by an integer amount of cycles, (usually the rank (or thread) number)\nI believe the speed is comparable to numpy's generator, but its been a while since I ran them.\nI would love to use this as a starting point, and modify/add to what I already have! Feedback would be greatly appreciated!\nCaveat I've tested with gfortran, and I think Intel. Would need testing with other compilers.\nHere's the example from my docs on how to use the PRNG in coretran.\nprogram PrngTest\nuse Prng_Class, only: Prng\nimplicit none\n\ntype(Prng) :: rng\ninteger(i64) :: seed(16)\ninteger(i32) :: i, id\n\nreal(r64) :: a\n\n! Use a constructor to initialize the Prng with a random seed\n! Using display = .true. will print the randomly generated seed to the screen\n! So you can reproduce any results later if you wish.\nrng = Prng(big = .true., display = .true.)\n\n! Or you could have set the seed using this\n! seed = [Some numbers, size 16 if big == .true., size 2 if big == .false.]\n! and you can use rng = Prng(seed, .true., .true.)\n\n! Draw from a uniform distribution\ncall rng%rngUniform(a) ! Can take min, max\n\n! Draw an integer between 1 and 100 inclusive\ncall rng%rngInteger(id, 1, 100)\n\n! Other distributions\ncall rng%rngNormal(a) ! can take mean, std\ncall rng%rngExponential(a, lambda=1.d0)\ncall rng%rngWeibull(a, lambda=1.d0, k=1.d0)\nstop\nend program\nAnd here is an example in parallel using OpenMPI\nprogram PrngTest_mpi\ninclude 'mpif.h'\nuse Prng_Class, only: Prng\nimplicit none\n\ntype(Prng) :: rng\ninteger(i64) :: seed(16)\ninteger(i32) :: i, id, ierror, size, rank\n\nreal(r64) :: a\n\ncall MPI_INIT(ierror)\ncall MPI_COMM_SIZE(MPI_COMM_WORLD, size, ierror)\ncall MPI_COMM_RANK(MPI_COMM_WORLD, rank, ierror)\n\n! Generate a seed that is the same on all ranks.!\n! seed = [16 numbers]\n! This could be generated randomly and broadcast, or set by a user.\n\n! Initialize the PRNG on each rank\nrng = Prng(seed, big=.true., display=.true.)\n\n! To avoid PRNG aliasing, jump each PRNG class by the rank number\nrng%jump(rank)\n\n! Do cool things.\n\ncall MPI_FINALIZE(ierror)\nend program"
                },
                {
                    "user": "masuday",
                    "date": "2020-02-02 04:31:00+00:00",
                    "text": "@peteroupc Thank you for your thoughts. The new PRNG should be non-cryptographic, and a possible option includes xoshiro, xoroshiro, and/or Mersenne Twister (MT). For API, IMHO, we are going to the basic uniform PRNG [0,1) because of the compatibility with random_number as the first step, then likely integer PRNGs. The PRNG (0,1) or (0,1] is useful for statistical distributions.\n@ivan-pi Thank you for the useful resource. It seems that, in parallel, each thread should have a thread-specific PRNG, and I agree with this design.\n@leonfoks Thank you for sharing your code. I agree that xoshiro/xoroshiro can be the default PRNG. A code for Jump Ahead for MT is available. It is useful for us to have PRNGs of probability distribution functions, and we will probably discuss it after we fix the APIs for the basic PRNGs. We can take advantage of your code to implement the algorithms!\nAs @ivan-pi and @leonfoks suggested, it seems to be better that each thread has a private state explicitly. Steve Lionel also suggested it. The support for thread-safety is inconsistent across compilers:\n\nIntel Fortran: thread-safe only for coarrays.\nGFortran: thread-safe for OpenMP.\n\nBy the way, I have one more question: how much flexibility can we have in PRNGs?\n\n\nAssuming we are going to have several algorithms (e.g., xoshiro and MT), if the kind of internal state (int64) is the same across the algorithms, the implementation can be simple. Supporting both int32 and int64, we need a careful design in APIs. The kind of random bits (outputs) has the same issue. The issue is in \"jump\", too. Some algorithms may not support it (as in a table by @peteroupc), and the function can be optional.\n\n\nShould it be flexible enough for the users to be able to use their custom PRNGs? Or, we simply provide a couple of built-in algorithms? If we take the latter, the internal state and the output can be fixed to int64."
                },
                {
                    "user": "peteroupc",
                    "date": "2020-02-02 05:00:41+00:00",
                    "text": "I should note that generating random floating-point numbers in computers depends on generating random integers \u2014 not the other way around.  See also this answer. Notably, since there are infinitely many real numbers between two others, it is impossible for any computer to choose from among all of them.  Thus, floating-point random generation methods should be derived from integer PRNGs, not the other way around.  The API can include a method that generates a number in [0, 1), but that should not be the only random generation method available.\nI should also note that many high-quality PRNGs have an internal state of much more than 64 bits (usually either 128 or 256 bits). (In this sense, MT19937's state is huge compared to other modern PRNGs.)  Rather, it's more useful to speak of the number of seeds the PRNG admits (which should be at least 2^63 for high-quality PRNGs), and less importantly, of the output size in bits.\nHaving named PRNGs (as is the case in C++ and NumPy 1.17) is useful, since their implementation is more likely to be stable across time.  Allowing the use of custom PRNGs is also useful, but is less important at this point."
                },
                {
                    "user": "certik",
                    "date": "2020-02-02 05:15:27+00:00",
                    "text": "@masuday thank you for starting the discussion. I think this is a nice fit into stdlib.\nHere is my implementation of some of the random number generators (gamma and normal distribution):\nhttps://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/random.f90\nalso initializing the seed using system time is a very useful function that we should have in some form in stdlib:\nhttps://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/utils.f90#L402"
                },
                {
                    "user": "masuday",
                    "date": "2020-02-02 17:13:24+00:00",
                    "text": "@peteroupc Thank you for your comment! I realized my comment was somewhat ambiguous.\nI am aware that random FP numbers are from uniform random-bit generators (URBGs) like xoshiro256++. My previous comment meant that the standard FP PRNG [0,1) is a good starting point to discuss API and some specifications because the reference implementation is already available in Fortran (random_number). We can expand the discussion to uniform integer PRNGs.\nI think there is no problem in the size of the internal state, i.e., random_seed(size=). A possible issue could be its \"kind\" (int32 or int64). If we support the maximum flexibility in URBGs, we should support any \"kinds\" for the internal state. We can fix it to a single \"kind\", and we can transfer (type-cast) it to the other \"kinds\". But IMHO, casting is awkward in Fortran (although it is debatable). Perhaps I am afraid of it too much, and we can just use a fixed kind, int64.\nC++ and NumPy is a useful reference for APIs, as @peteroupc mentioned. I tend to like a procedural style (similar to the intrinsic random_number and random_seed as in the original post) so that the users easily guess how to use the new PRNGs.\n@certik makes a good point (thank you for sharing your code!). random_number is a generic name to return a scalar or an array. IMHO, the new PRNGs should have the same feature. Also, I would like to a procedure to initialize the seed by timestamp."
                },
                {
                    "user": "masuday",
                    "date": "2020-02-03 01:05:14+00:00",
                    "text": "This post is pretty long. I made it because more concrete suggestions can stimulate the discussion.\nHere is a draft proposal with some description of the issue. A formal proposal will come in a separate thread. I use some terminology taken from the C++ implementation. In the draft, random numbers mean pseudorandom numbers.\nOverview\nThe scope of PRNGs in stdlib is limited to non-cryptographic random numbers. Here is a hierarchy of PRNGs.\n\nUniform random bit generators (URBGs)\n\nUniform random number generators (uniform PRNGs)\n\nShuffling and random sampling\nUnivariate random number distributions\n\nMultivariate random number distributions\n\n\n\n\n\n\n\nA random-number engine is a main body of URBG, and a typical engine is a family of the linear feedback shift register (LFSLs) and its variants (Mersenne Twister and xoshiro256, etc.). Uniform generators convert the random bits to a uniform random number in integer or real type. Shuffling and random-sampling algorithms depend on the integer random numbers. The uniform random numbers are used to generate statistically-distributed random numbers.\nIn this draft, I focus only on URBGs and uniform PRNGs. stdlib should provide particular engines (URBGs) as built-in. The users may use a custom engine, but it should be compliant with the interface of the built-in engines.\nWe can have both a (procedural) low-level API and an object-oriented API. This proposal is biased to the low-level API, but one can wrap the subroutines to define the OO API.\nLow-level API for URBG engines\nEngine subroutine\nThe engine should be a subroutine with a common interface. My suggestion for the interface is that the engine receives an array of int64 state, and returns random bits as a single int64 variable. The procedure changes the state, and we should not use a function.\ninterface\n   subroutine random_number_engine(state,harvest)\n      integer(int64),intent(inout) :: state(:)     ! may need \"allocatable\"\n      integer(int64),intent(out) :: harvest\n   end subroutine random_number_engine\nend interface\nThe default engine is undefined. I put a dummy subroutine for the engine.\nsubroutine random_number_engine_undef(state,harvest)\n   integer(int64),intent(inout) :: state(:)    ! may need \"allocatable\"\n   integer(int64),intent(out) :: harvest\n   stop \"undefined engine\"\nend subroutine random_number_engine_undef\nWhenever we use this dummy engine, we need allocatable for the state.\nUser-derived type\nA derived type holds an engine and its state.\ntype random_number_generator\n   integer :: state_size = 0\n   integer(int64),allocatable :: state(:)\n   procedure(random_number_engine),nopass,pointer :: engine => random_number_engine_undef\nend type random_number_generator\nSeeding\nWe should have a subroutine to seed the engine (i.e., constructor). My suggestion is to have a similar subroutine to the reference, random_seed. It specifies the engine and the seed at the same time.\n! The name should be changed.\nsubroutine random_number_seed(rng, engine, size, put, get, auto)\n   type(random_number_generator),intent(inout) :: rng   ! state structure\n   character(len=*),intent(in),optional :: engine       ! engine name\n   integer,intent(out),optional :: size                 ! same as the reference\n   integer(int64),intent(in),optional :: put(:)         ! same as the reference\n   integer(int64),intent(out),optional :: get(:)        ! same as the reference\n   logical,intent(in),optional :: auto                  ! automatic seeding\n   ...\nend subroutine random_number_seed\nIf the engine has a \"jump\" feature as pointed by @leonfoks, we can have an extra subroutine to do it. We may have an additional member variable to the derived type: logical :: has_jump and a procedure procedure(random_number_jump),nopass,pointer :: jump.\nSupporting a user-defined engine, we need one more subroutine.\nExample\ntype(random_number_generator) :: rng\ninteger :: state_size\ninteger(int64),allocatable :: seed(:)\n\n! traditional method\ncall random_number_seed(rng, \"xoshiro256**\", size=state_size)\nallocate(seed(state_size))\nseed = 1234567890\ncall random_number_seed(rng, \"xoshiro256**\", put=seed)\ndeallocate(seed)\n\n! automatic method based on timestamp etc\ncall random_number_seed(rng, \"xoshiro256**\", auto=.true.)\nSummary\nSuggestion:\n\nA derived type has a state and a procedure pointer to the random-bit engine.\nThe engine is a subroutine with the state for input and the random-bit integer for output.\nThe seed subroutine (constructor) has a similar form as random_seed with automatic seeding, engine specification, and more.\nA separate subroutine can perform \"jumping\" for some engines.\nAn additional subroutine may support user-defined engines.\n\nLow-level API for uniform PRNGs\nReal numbers\nFirst, I suggest a uniform PRNG for a real number in [0,1) as in random_number. The following is only for real64, but we can have a real32 version. Also, we should support the various output, a scalar, and an array with different ranks.\nsubroutine random_real_uniform(rng,harvest)\n   type(random_number_generator),intent(inout) :: rng\n   real(real64),intent(out) :: harvest\n   ...\nend subroutine random_real_uniform\nWe can extend it to the general uniform distribution.\nsubroutine random_real_uniform(rng,harvest,lower,upper)\n   type(random_number_generator),intent(inout) :: rng\n   real(real64),intent(out) :: harvest\n   real(real64),intent(in),optional :: lower\n   real(real64),intent(in),optional :: upper\n   ...\nend subroutine random_real_uniform\n@peteroupc suggests implementing the different ranges: [0,1), (0,1], (0,1), and [0,1]. I find (0,1) or (0,1] useful for generating random numbers under statistical distributions with log(x). Assuming we implement all the four options, we have several options for the API.\n\nUse additional arguments like random_real_uniform(rng,harvest,lopen=0.0,uclose=1.0).\nUse separate subroutines like random_real_uniform_open_close(rng,harvest,0.0,1.0).\n\nWe can choose either of them so that the usage is not too complicated.\nInteger numbers\nAlthough we can get random bits directly from the engine, we should have a separate subroutine to obtain the bits because of the consistency of APIs.\nsubroutine random_raw_stream(rng,harvest)\n   type(random_number_generator),intent(inout) :: rng\n   integer(int64),intent(out) :: harvest\n   ...\nend subroutine random_raw_stream\nFor the uniform integer PRNG, we can use the following subroutine.\nsubroutine random_integer_uniform(rng,harvest,lower,upper)\n   type(random_number_generator),intent(inout) :: rng\n   integer(int64),intent(out) :: harvest\n   integer(int64),intent(in) :: lower\n   integer(int64),intent(in) :: upper\n   ...\nend subroutine random_integer_uniform\nSummary\nSuggestion:\n\nThe uniform PRNGs have a similar interface as random_number.\nThe output can be a scalar or an array with various Fortran \"kinds\".\nFor real numbers, the default generator supports the range, [0,1). Optionally, we can support various ranges like (0,1].\nFor integer numbers, we can have two subroutines for a raw number and a uniform integer.\n\nTo be discussed\n\nRestriction on engines (supporting int64 only)\nDesign of the user-derived type (object)\nBoundary of uniform random numbers\nAPI for each subroutine\nJumping subroutine\nNaming rules\n\nIMO, it is useful to support a scalar seed like put_scalar= in the seeding subroutine.\n\nAPI in other programming languages\nI reached the above proposal for APIs because of the comparison with the other programming languages.\nLocal state\nRegarding thread safety, each thread should have a separate state. The suggested API always takes the local state as an argument, and it is simple to remember. This design is typical in non-object-oriented languages.\nJulia can have the state as a local variable. Most numerical libraries supporting Fortran give the local state (e.g., MKL, NAG, GSL). In object-oriented languages, a PRNG is an instance of a generator class, and each thread has a local PRNG (e.g., C++ and NumPy).\nUser-derived type specialized to a particular engine\nThe \"type\" (say, object) that I have shown in the proposal is flexible to have any engine if it is compliant with the interface. The engine is assigned in the seed subroutine. Because we can use the common object, the users easily remember this rule.\nThis API is similar to MKL, although it seems not to use a procedure pointer. In C++, the programmer specifies a particular class of the engine. It is efficient in computations, but we have to prepare a derived-type for each of the engines."
                },
                {
                    "user": "masuday",
                    "date": "2020-02-06 01:20:25+00:00",
                    "text": "I have investigated the APIs of PRNGs in major programming languages and libraries. See my Gist for details. Based on the research, I would like to suggest a revised API.\nI would suggest 3 subroutines for a random-bit generator (the engine): initializer, re-seeder, and uniform PRNG. The user must call the initializer for the first time (optionally with a seed). A separate subroutine puts/gets the internal state. A new API looks like:\n   type(random_number_generator) :: rng\n   integer :: state_size\n   integer(int64),allocatable :: state(:)\n   real(dp) :: harvest\n\n   ! initialize\n   call random_number_init(rng, \"default\", seed=[3245,8730,1211])\n\n   ! uniform real numbers\n   call random_real_uniform(rng, harvest)\n\n   ! reseed by date_and_time\n   call random_number_seed(rng, auto=.true.)\n\n   ! get state\n   call random_number_state(rng,size=state_size)\n   allocate(state(state_size))\n   call random_number_state(rng,get=state)\n\n   ! put state\n   call random_number_state(rng,put=state)\nI support the \"default\" PRNG for a real number ranged between 0 and 1. Looking at the other languages/libraries, the range differs.\n\nInclusive of 0: [0,1) i.e. 0<=r<1; Fortran, C++, and major compiled and scripting languages.\nExclusive of 0: (0,1] or (0,0); MATLAB, R, and many numerical/statistical libraries and software.\n\nI believe that [0,1) is a straightforward implementation and that (0,1] or (0,0) is useful for applications such as sampling from statistical distribution functions because zero is problematic in logarithm and division (although the probability of getting zero is negligible). I tend to support (0,1] or (0,0) as the default.\nAny thoughts?"
                },
                {
                    "user": "leonfoks",
                    "date": "2020-02-06 04:33:25+00:00",
                    "text": "I think the 3 basic methods you suggest are a great starting point for us to get going on this.\nI might have missed this somewhere, but are these functions meant to be type bound procedures of the random_number_generator derived type? They might as well be since the user needs to import the random_number_generator class anyway.\nThe constructor needs to return the derived type random_number_generator from a function to take advantage of the more modern derived type constructor capabilities. This would let the user instantiate the class with the name of the class. @certik @milancurcic Is there any reason we might want to stay away from the constructor interface on DTs based on the discussion about functions returning anything other than a scalar?\nHere are the key points\n\nMake call random_number_init(rng, \"default\", seed=[3245,8730,1211]) an actual constructor for the random_number_generator class\nRename random_real_uniform() to rand() since that is the most common across the languages.\nMake the subroutine random_number_state into a type bound procedure, either as two separate subroutines, %get_state and %set_state, or as %state with optional arguments. Personally I prefer two separate TBPs.\nWe don't need the attribute state_size, we can inquire that from the state once it's set.\n\nFrom a user perspective, using the module below would look like this\ntype(random_number_generator) :: rng\nreal(dp) :: a, b(10), c(10, 10)\ninteger(i64), allocatable :: state(:)\n\nrng = random_number_generator(seed=[3245, 8730, 1211])\n\ncall rng%get_state(state)\n\ncall rng%rand(a)\ncall rng%rand(b)\ncall rng%rand(c)\nThe module\nmodule m_random_number_generator\n\ntype random_number_generator\n    integer(int64), allocatable :: state(:)\n\ncontains\n\n    procedure, public :: get_state => get_state_rng\n\n    generic, public :: rand => rand_d1_Prng_, rand_d1D_Prng_, rand_d2D_Prng_\n        !! random_number_generator%rand() - Draw from a uniform distribution\n        !! Draws uniform random numbers on [0, 1)\n    procedure, private :: rand_d1_Prng_ => rand_d1_Prng\n    procedure, private :: rand_d1D_Prng_ => rand_d1D_Prng\n    procedure, private :: rand_d2D_Prng_ => rand_d2D_Prng\n\n    procedure, public :: set_state => set_state_rng\n\nend type random_number_generator\n\ninterface random_number_generator\n    !!Overloaded Initializer for a Prng - Pseudo random number generator.\n\n    module procedure :: init_with_seed_rng, init_random_seed_rng\n\nend interface random_number_generator\n\n!====================================================================!\nfunction init_with_seed_rng(seed) result(this)\n    type(random_number_generator) :: this\n        !! Prng Class\n    integer(i64), intent(in) :: seed(:)\n        !! Seed of the Prng\n\n    ! Set the explicit seed\nend function init_with_seed_rng\n\nfunction init_random_seed_rng() result(this)\n    type(random_number_generator) :: this\n        !! Prng Class\n\n    ! Use date and time to obtain a random seed\n    ! Set the seed.\nend function init_random_seed_rng\n!====================================================================!\n\nsubroutine get_state_rng(this, state)\n    class(random_number_generator), intent(in) :: this\n        !! Prng Class\n    integer(i64), allocatable, intent(inout) :: state(:)\n        !! State of the Prng\nend subroutine get_state_rng\n\nsubroutine set_state_rng(this, state)\n    class(random_number_generator), intent(inout) :: this\n        !! Prng Class\n    integer(i64), intent(in) :: state(:)\n        !! Set this as the state of the Prng\nend subroutine set_state_rng\n\n! Use FYPP to process the different functions and ranks.\nsubroutine rand_d1_Prng(this, res)\n    class(random_number_generator), intent(inout) :: this\n        !! Prng Class\n    real(dp), intent(out) :: res\nend subroutine\n\nsubroutine rand_d1D_Prng(this, res)\n    class(random_number_generator), intent(inout) :: this\n        !! Prng Class\n    real(dp), intent(out) :: res(:)\nend subroutine\n\nsubroutine rand_d2D_Prng(this, res)\n    class(random_number_generator), intent(inout) :: this\n        !! Prng Class\n    real(dp), intent(out) :: res(:, :)\nend subroutine\n\nend module m_random_number_generator"
                },
                {
                    "user": "masuday",
                    "date": "2020-02-06 17:16:36+00:00",
                    "text": "@leonfoks, I agree with you. I started from a traditional style, and my suggestion converged to an object-oriented style. We can implement PRNGs in the OO style while we have traditional (non-OO) APIs that I prefer to use as @certik. We can wrap the OO APIs with some subroutines (it is a reason why my suggestion has subroutines).\nI prefer short names: rand, set_seed, set_state, get_state, It makes sense to separate set_state and get_state for the OO APIs. For traditional APIs, it can be unified. I also agree not to have state_size.\nCurrently, we do not have OO APIs in src/, so it should be a model-case for such APIs."
                },
                {
                    "user": "masuday",
                    "date": "2020-02-07 04:22:13+00:00",
                    "text": "EDIT: I rewrote the code because my post was wrong. Everything in a class is private (protected is not allowed).\nI have some suggestions on @leonfoks's class proposal. IMO, the internal state should not be open. Also, we may have 2 constants for convenience.\ninteger,parameter :: random_seed_kind = int64   ! would be int32\ninteger,parameter :: random_state_kind = int64\n\ntype random_number_generator\nprivate\n    integer(random_state_kind),allocatable :: state(:)\n\ncontains\n...\nend type random_number_generator\nFollowing @certik's comment, I would modify get_state to have non-allocatable state.\nsubroutine get_state(this,state)\n    class(random_number_generator) :: this\n    integer(random_state_kind),intent(inout) :: state(:)\nend subroutine get_state"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-03-10 13:38:15+00:00",
                    "text": "@leonfoks, I agree with you. I started from a traditional style, and my suggestion converged to an object-oriented style. We can implement PRNGs in the OO style while we have traditional (non-OO) APIs that I prefer to use as @certik. We can wrap the OO APIs with some subroutines (it is a reason why my suggestion has subroutines).\n\nWrapping the OO API in a subroutine would effectively mean the code is only valid from Fortran 90 upward when derived types were introduced. While I suppose most people today are using sufficiently modern compilers and would not be affected (unless enforcing specific compiler flags), should we aim to have subroutine versions for users who might want to import the new RNG routines into their decades old F77 codebases? @certik @milancurcic"
                },
                {
                    "user": "certik",
                    "date": "2020-03-10 15:10:30+00:00",
                    "text": "@ivan-pi I think there is general agreement that we will do a low level API that is just subroutines, no derived types (unless there is no clean way to do that), and then an optional high level API that uses OO."
                },
                {
                    "user": "dev-zero",
                    "date": "2020-05-04 15:36:09+00:00",
                    "text": "As for the OO-API: I've ported CP2K's parallel stream PRNG to OO. As  PRNGs go it is probably a very specific case and unimportant for most other applications, but already before I ported it there was a possibility to dump & load the state."
                },
                {
                    "user": "certik",
                    "date": "2020-06-09 15:39:45+00:00",
                    "text": "@masuday do you want to open a PR with initial implementation of this?\nI think there is a broad agreement that we want this, and it's just about agreeing on an API that would work for everybody."
                },
                {
                    "user": "masuday",
                    "date": "2020-06-09 17:41:23+00:00",
                    "text": "@certik Thank you for chiming. I agree with you, and I am making a PR in a couple of days."
                }
            ]
        },
        {
            "number": 134,
            "user": "jvdp1",
            "date": "2020-01-31 08:27:48+00:00",
            "title": "Trade-off between efficiency and robustness/accuracy",
            "text": "From #3 where the discussion deviated on efficiency and robusteness of algorithms implemented in stdlib, and the potential associated trade-off .\nSee this comment and the following ones for more details.\nThis trade-off should probably be discussed case by case (when submitting PRs), with the main aim that it should benefit the vast majority of the Fortran community??",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-01-31 20:54:31+00:00",
                    "text": "I see three fundamental pillars here:\n\nAPI design (ease of use)\nAccuracy (correctness)\nEfficiency (computational performance)\n\nAll three are important and should be discuss in one or more steps of the workflow.\nYes, I think accuracy vs. efficiency trade-offs should be considered on a case by case basis. Some cases may even justify having multiple implementations of a function to serve different requirements.\nThere's no silver bullet here. Some industries require higher accuracy (I dunno -- astronomy? applied math?). For some others (e.g. weather and ocean prediction, or other chaotic systems) accuracy is completely irrelevant as soon as you start working with real-world data. We need to take it case by case and involve as much community as we can in the design and implementation process.\nMy position is that API design (ease of use) should be the highest priority by far, at least in the initial stages of design and implementation. Computers are cheap. Programmers are expensive. My experience so far is that ease of use wins in most scenarios. I think our number 1 job with stdlib is to make Fortran easier and more fun to use."
                },
                {
                    "user": "certik",
                    "date": "2020-01-31 21:12:22+00:00",
                    "text": "I agree with @milancurcic. We should discuss on a case by case basis. In general, we want a nice API to make Fortran easy and fun to use.\nMy own preferences are that we obviously want the correct answers, and we want excellent performance (I wouldn't like us to make design decisions that would hinder performance in any way). As an example here: #3 (comment), I would need to study the behavior of both of the algorithms, i.e. their performance and accuracy. If the answer is that one is faster but less accurate, the other one is slower but more accurate, then we can have both and the user can choose. That's one way we can handle it."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-31 21:35:49+00:00",
                    "text": "I agree with both @milancurcic and @certik comments: the API should have the highest priority, such that the Fortran community (in its  broad sense) can benefit from stdlib.\nI like the idea to have different implementations of a function (variance could be a nice example). Hopefully such a strategy would allow to avoid some (not really positive) discussions. I think the spec should also specify the pros and cons of the different implementations. That may help the users in their choice for an adequate implementation."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-02-02 01:59:45+00:00",
                    "text": "Agree on all fronts. Adding multiple methods for each function is a good idea.  Perhaps have a 'primary' function with the standard name, variance, plus extras available like variance_method.  That way, it's still easy to use the most generally applicable version, but allows users to dig deeper if they wish.\nI think discussions per algorithm is key, since different personal experiences will dictate which are implemented and which might not, and it will allow a consensus on the method that is deemed 'primary'."
                }
            ]
        },
        {
            "number": 133,
            "user": "aradi",
            "date": "2020-01-30 15:47:39+00:00",
            "title": "Adding the preprocessor to the repository?",
            "text": "Any views on adding the pre-processor to stdlib? Fypp consists of a single file. If we had it in the repository, the build requirement would reduce to:\n\nFortran compiler\nCMake\nPython\n\nAll those are quite common, while having Fypp installed on your machine rather not.",
            "comments": [
                {
                    "user": "leonfoks",
                    "date": "2020-01-30 16:05:36+00:00",
                    "text": "If the decision is made to omit the expanded code from the repo, this would be ideal!  It would certainly make it easier on the user."
                },
                {
                    "user": "certik",
                    "date": "2020-01-30 17:03:40+00:00",
                    "text": "It's this file: https://github.com/aradi/fypp/blob/7895a7efb7d2f07dc284cece6cc9474297b8dc55/bin/fypp.\nI think that might be fine, to make it easier for people to build.\n\nIf the decision is made to omit the expanded code from the repo\n\nYes, we should not include generated code in the git repository, but rather the release tarball should have the generated code (and thus no Python dependency)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-30 23:14:22+00:00",
                    "text": "I agree this would ease development. How do you suggest to include it? Commit the script to the repo directly or as a git submodule? The latter would make keeping up to date with upstream easier."
                },
                {
                    "user": "certik",
                    "date": "2020-01-30 23:27:09+00:00",
                    "text": "I would suggest to commit into the repo directly. The submodules seem to cause more trouble than benefits from my experience."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-20 12:27:13+00:00",
                    "text": "I would suggest to commit into the repo directly. The submodules seem to cause more trouble than benefits from my experience.\n\nWhat kind of troubles did you get with submodules?"
                },
                {
                    "user": "certik",
                    "date": "2020-02-21 18:33:04+00:00",
                    "text": "What kind of troubles did you get with submodules?\n\nYou have to remember to clone with --recursive, you have to remember how to update, new users have to learn what to do when \"git diff\" says \"dirty\", and git clean -dfx does not clean submodules, etc. If possible, I try to avoid them."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-21 22:15:30+00:00",
                    "text": "You have to remember to clone with --recursive, you have to remember how to update, new users have to learn what to do when \"git diff\" says \"dirty\", and git clean -dfx does not clean submodules, etc. If possible, I try to avoid them.\n\nThank you for your explanations @certik . Then it sounds better to commit it into the repo directly."
                }
            ]
        },
        {
            "number": 132,
            "user": "jvdp1",
            "date": "2020-01-29 20:09:16+00:00",
            "title": "mask_mean_dev: addition of a mask in mean API",
            "text": "Addition of mask in the API of mean, as discussed in #128. NaN returns are based on ieee_arithmetic;\nUpdate of the spec;\nCorrection of a small typo/error introduced in a previous PR (an integer array was not converted to real(dp) before doing the sum (were our tests not severe enough for these scenarions?).\n\n@aradi : I can't request you as reviewer (the system doesn't find you). Could you have also a look, please?",
            "comments": [
                {
                    "user": "aradi",
                    "date": "2020-01-30 08:22:11+00:00",
                    "text": "@jvdp1 Sure. Actually, now it seems to be possible to select me as reviewer. I'll try to have a detailed look at it tomorrow."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-01 16:31:29+00:00",
                    "text": "Thank you @aradi for the review.\n@milancurcic could  you have a last look and merge it if you are happy with the proposed changes?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-01 19:27:00+00:00",
                    "text": "Great work, thanks @jvdp1"
                }
            ]
        },
        {
            "number": 131,
            "user": "certik",
            "date": "2020-01-29 17:06:05+00:00",
            "title": "Fix a typo (\"four\" instead of \"two\")",
            "text": "This is an omission that was supposed to be part of #60, but we missed\nit. This PR fixes it.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-02-02 23:15:00+00:00",
                    "text": "I am going to merge it, as it was an obvious typo that we forgot to do in the previous PR."
                }
            ]
        },
        {
            "number": 130,
            "user": "aradi",
            "date": "2020-01-29 08:43:55+00:00",
            "title": "Mean 1d",
            "text": "Substantially reduced code & number of fypp-constructs in mean().\nExtended mean() to handle reduction from 1D-array to scalar (similar to sum())\nIntroduced tolerances when testing floating point results (note checking with == 0.0 is highly unreliable and may give false positives)\nReformatted test file according to style guide.\n\nCommits in order of relevance, feel free to cherry pick if you don't like all of them.",
            "comments": [
                {
                    "user": "aradi",
                    "date": "2020-01-29 16:44:14+00:00",
                    "text": "Well, the styleguide says the body of every Fortran construct should be indented by two (4) spaces, so I have chosen the one I prefer more \ud83d\ude06 .\nAnyway, I have taken out the reformatting commit, it really does not belong to here, I agree. I'll wait with reformatting changes until the style guide becomes non-ambigous. \ud83d\ude09"
                },
                {
                    "user": "certik",
                    "date": "2020-01-29 17:06:55+00:00",
                    "text": "@aradi ha, that was a mistake, thanks for spotting it. I fixed it in #131."
                },
                {
                    "user": "certik",
                    "date": "2020-01-29 17:09:05+00:00",
                    "text": "@aradi the PR looks great, thank you!"
                }
            ]
        },
        {
            "number": 129,
            "user": "aradi",
            "date": "2020-01-28 13:11:00+00:00",
            "title": "Fypp cleanup",
            "text": "I refactored and reformatted the fypp-templates in order to enhance readability (in CMake as well in source code). I'd suggest to keep fypps impact on code readability as small as possible. See the suggested changes. Feel free to cherry-pick parts, if you don't like the overall style. Commits are in order of relevance.",
            "comments": []
        },
        {
            "number": 128,
            "user": "jvdp1",
            "date": "2020-01-27 18:21:26+00:00",
            "title": "Addition of a mask to stdlib_experimental_stats function `mean`",
            "text": "Current\n(Related to #113)\nThe current spec for stdlib mean is:\nmean - mean of array elements\nDescription\nReturns the mean of all the elements of array, or of the elements of array along dimension dim if provided.\nSyntax\nresult = mean(array)\nresult = mean(array, dim)\nArguments\narray: Shall be an array of type integer, or real.\ndim: Shall be a scalar of type integer with a value in the range from 1 to n, where n is the rank of array.\nReturn value\nIf array is of type real, the result is of the same type as array.\nIf array is of type integer, the result is of type double precision.\nIf dim is absent, a scalar with the mean of all elements in array is returned. Otherwise, an array of rank n-1, where n equals the rank of array, and a shape similar to that of array with dimension dim dropped is returned.\n\nProposal\nI would like to propose to add mask into the API of mean as follows (similar to the intrinsic sum):\nmean - mean of array elements\nDescription\nReturns the mean of all the elements of array, or of the elements of array along dimension dim if provided, and if the corresponding element in mask is true.\nSyntax\nresult = mean(array [, mask])\nresult = mean(array, dim [, mask])\nArguments\narray: Shall be an array of type integer, or real.\ndim: Shall be a scalar of type integer with a value in the range from 1 to n, where n is the rank of array.\nmask (optional): Shall be of type logical and either be a scalar or an array of the same shape as array.\nReturn value\nIf array is of type real, the result is of the same type as array.\nIf array is of type integer, the result is of type double precision.\nIf dim is absent, a scalar with the mean of all elements in array is returned. Otherwise, an array of rank n-1, where n equals the rank of array, and a shape similar to that of array with dimension dim dropped is returned.\nIf mask is specified, the result is the mean of all elements of array corresponding to true elements of mask. If every element of mask is false , the result is zero.\n\nThis definition of mask for mean agrees with the definition of mask of the intrinsic sum in the Fortran Standard draft:\np. 429:\n\nMASK (optional) shall be of type logical and shall be conformable with ARRAY.\n\nand\np. 9:\n\n3.36\nconformable\n\u27e8of two data entities\u27e9 having the same shape, or one being an array and the other being scalar\n\nImplementation\nEach function for mean, e.g.,\nmodule function mean_1_sp_sp(x) result(res)\n    real(sp), intent(in) :: x(:)\n    real(sp) :: res\n    res = sum(x) / real(size(x, kind = int64), dp)\nend function mean_1_sp_sp\nshould then become:\nmodule function mean_1_sp_sp(x, mask) result(res)\n    real(sp), intent(in) :: x(:)\n    real(sp) :: res\n    logical, intent(in), optional :: mask\n\n    if(.not.optval(mask, .true.))then\n        res = 0._dp\n\treturn\n    end if\n\n    res = sum(x) / real(size(x, kind = int64), dp)\n\nend function mean_1_sp_sp\n\nmodule function mean_1_mask_sp_sp(x, mask) result(res)\n    real(sp), intent(in) :: x(:)\n    real(sp) :: res\n    logical, intent(in) :: mask(:)\n    res = sum(x, mask) / real(count(mask, kind = int64), dp)\nend function mean_1_mask_sp_sp\nI kown there was some discussions about dim and if it should be considered as optional or not in the spec. I guess the same discussion could appear here since mask is not optional in one of the 2 functions. However, it will behave like optional for the users through the interface mean.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-27 18:41:47+00:00",
                    "text": "That looks good to me. It would appear as \"optional\" due to the interface to the users, so I think that's what matters, and the above is just an implementation detail how to actually implement it."
                },
                {
                    "user": "certik",
                    "date": "2020-01-27 18:42:51+00:00",
                    "text": "A larger philosophical question is whether we have to implement mask for every array function that operates on arrays, or only on some?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-27 19:00:20+00:00",
                    "text": "A larger philosophical question is whether we have to implement mask for every array function that operates on arrays, or only on some?\n\nWhy would you not implement it on everey function? Also, from rank 3 to rank 7 or 15, it would auto-generated."
                },
                {
                    "user": "certik",
                    "date": "2020-01-27 19:13:05+00:00",
                    "text": "The only downside that I can see is that it will be a lot of functions. But I think we want to support the \"mask\" argument. The other approach would be that somehow the user would run the mask on the array before passing it to sum or mean (NumPy implements masked arrays). But I don't know how to do that efficiently in Fortran, so the mask argument seems appropriate."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-27 19:26:40+00:00",
                    "text": "I think it would be good to have the same API as sum and other intrinsic functions.\nThe users will not see all the functions behind the interface, and I think it can be manageable with auto-generation. It could be only (maybe) tricky for the CI, but we can limit the number of dimensions (currently 4). Also, I don't think the CI should stop us to implement a correct/desired code/API."
                },
                {
                    "user": "certik",
                    "date": "2020-01-27 19:29:39+00:00",
                    "text": "I agree."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-27 22:16:58+00:00",
                    "text": "Excellent proposal. I only have a problem with the following statement:\n\nIf every element of mask is false , the result is zero.\n\nIs this not dangerous? The user might think that zero is a legitimate mean value. Can't we return (a IEEE?) NaN or something along these lines so the user can catch the exception? All this hopefully without hurting performance."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-27 22:57:27+00:00",
                    "text": "Is this not dangerous? The user might think that zero is a legitimate mean value. Can't we return (an IEEE?) NAN or something along these lines so the user can catch the exception? All this hopefully without hurting performance.\n\nGood point. The intrinsic sum returns 0, following the Standard:\n\nCase (ii): The result of SUM (ARRAY, MASK = MASK) has a value equal to a processor-dependent approximation to the sum of the elements of ARRAY corresponding to the true elements of MASK or has the value zero if there are no true elements.\n\nSo, for the mean, if mask = .false., it ends up with a division of 0. by 0.. So mean should most likely return NaN. A simple way to return NaN could be:\nreal(dp)::res\nif (.not.optval(mask, .true.) then\n    res = res /0._dp\n    return\nend if\nNote that GFortran does not allow expressions like res = 0._dp / 0._dp or res = 1._dp / 0._dp."
                },
                {
                    "user": "certik",
                    "date": "2020-01-27 23:48:01+00:00",
                    "text": "I would be careful with the nans. I usually turn them off in my production codes. Is there any current intrinsic function in Fortran that can return nan? I think returning zero would work. Stopping the program with an error would also work, but the issue is that then mean could not be a pure function..."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-28 00:12:27+00:00",
                    "text": "I would be careful with the nans. I usually turn them off in my production codes.\n\nI think this resonates in some way with the discussion had about assert. I.e. in debug mode you catch the cases that return NaN and in release mode you can ignore them (at your own risk, trading \"safety\" with performance).\nStill, I think mathematically stands that although the sum of no values is zero, the mean of no values is undefined."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-28 02:25:05+00:00",
                    "text": "Having had to deal with Nan in a lot of programming environments, the most reliable way  I found may seem surprising, but is\nfunction nan64(value)\nuse,intrinsic :: iso_fortran_env, only: real64\nimplicit none\ncharacter(len=*),parameter::ident=\"@(#)M_units:: nan64(3fp): Returns a NAN (Not a number) of type real64\"\ncharacter(len=3),save :: STRING='NaN'\nreal(kind=real64) :: nan64,value\n   read(STRING,*)nan64\nend function nan64\nwhich is one part of a generic nan(value) where the returned value is the type of value  that could be auto-generated. Note the string cannot be a parameter, which seems non-intuitive; but internal reads cannot read from a constant. The rest of the generic definition is quite repetitive but (I think) obvious.\nIt's a long story, but a lot of \"standard\" ways of defining a NaN are subject to whether the compiler supports the IEEE standard, whether optimizations change the definition or test (I have an is_nan function too), and so on. So far, reading the string \"NaN\" has proved  portable and is supported by the Fortran standard as far back as I could find (if anyone knows when the earliest support by the standard was, feel free to add it here)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-28 05:19:11+00:00",
                    "text": "@urbanjost interesting. A few questions: what's the purpose of the ident parameter in your nan64 function? Also, why does it accept value as an argument? It does not seem to be used."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-28 07:37:56+00:00",
                    "text": "Still, I think mathematically stands that although the sum of no values is zero, the mean of no values is undefined.\n\nI totally agree with @epagone statement, and I should have thought about it sooner: the mean of no values is undefined, not 0.\nRegarding our implementation of mean along a dimension and with a mask being of the same shape as the input x, we have:\nmodule function mean_2_mask_sp_sp(x, dim, mask) result(res)\n    real(sp), intent(in) :: x(:,:)\n    logical, intent(in) :: mask(:,:)\n    integer, intent(in) :: dim\n    real(sp) :: res(merge(size(x, 1), size(x, 2), mask = 1 < dim ))\n\n    select case(dim)\n     case(1)\n       res = sum(x, 1, mask) / real(count(mask, 1), sp)\n     case(2)\n       res = sum(x, 2, mask) / real(count(mask, 2), sp)\n     case default\n       call error_stop(\"ERROR (mean): wrong dimension\")\n    end select\n\nend function mean_2_mask_sp_sp\nThis implementation may return an array res with numbers and NaN as means.\nIf we aim to return 0.0 (or any other value different thanNaN (even for the NaN proposed by @urbanjost) for the following case:\nmodule function mean_2_all_sp_sp(x, mask) result(res)\n    real(sp), intent(in) :: x(:,:)\n    logical, intent(in), optional :: mask\n    real(sp) :: res\n\n    if (.not.optval(mask, .true.)) then\n        res = ??? 0._sp / value / @urbanjost NaN????\n        return\n    end if\n\n    res = sum(x) / real(size(x, kind = int64), sp)\n\nend function mean_2_all_sp_sp\nthen, for consistency across all mean functions, we will have to catch the possible compiler NaN in mean_2_mask_sp_sp(x, dim, mask) and replace them by  ??? value / @urbanjost NaN????, leading to complicate and less efficient code.\nProbably, IMHO, the best way to be consistent with mean_2_mask_sp_sp(x, dim, mask) (and to keep this latter function simple and efficient) would be something like:\nmodule function mean_2_all_sp_sp(x, mask) result(res)\n    real(sp), intent(in) :: x(:,:)\n    logical, intent(in), optional :: mask\n    real(sp) :: res\n\n    if (.not.optval(mask, .true.)) then\n        res = sum(x, .false.) / count(.false.)\n        return\n    end if\n\n    res = sum(x) / real(size(x, kind = int64), sp)\n\nend function mean_2_all_sp_sp\nWith such an implementation, NaN could be still ignore in release mode (while not the case with @urbanjost approach, right?)."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-28 07:51:48+00:00",
                    "text": "I would be careful with the nans. I usually turn them off in my production codes. Is there any current intrinsic function in Fortran that can return nan?\n\nThe intrinsic function fraction(x) may return NaN if x is an IEEE NaN or Infinity. So it is quite a special case.\n\nI think returning zero would work. Stopping the program with an error would also work, but the issue is that then mean could not be a pure function...\n\nI suggest to avoid to return 0 (or any other value, or @urbanjost NaN), at least for consistenty with other functions of mean; see previous comment).\nI would argue the same thing about stopping the program with an error, because it would mean that when mask is an array and the mean is computed along a dimension, we would need to check that there is no NaN in the array result of the function mean, or that there is no true element in the mask along a dimension. Such checks would penalize the efficiency of the function (in addition to not be able to be pure)."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-28 14:33:55+00:00",
                    "text": "FYI: Regarding questions on nan64(3f) function: I extracted the function to generate a NaN from a generic function, where VALUE was used merely to select the kind of the NaN. The bit pattern of NaN is dependent on the KIND, the unused value was just used to determine kind.\nThe IDENT variable is a whole other discussion, not really pertinent to the Nan function per-se,\nbut really a whole other topic.\nThe IDENT is used like a C #ident directive. I (still) use metadata like that to automatically build indexes of .code. This particular syntax is often optimized away as an unused variable but is still useful in the source.  I use a preprocessor that handles some of the issues with such data to keep it in the binaries.\nDidn't mean to cause confusion; the basic idea is the most reliable way to generate a NaN that I have found is to do an internal read of the string 'NaN'.\nThe IDENT stuff is very useful for QA and configuration control and automated documentation but is not well supported by Fortran. Many systems even include a place for metadata in executables but it does not seem to be used a lot anymore; but I need it for a variety of reasons.  I would ask for support of metadata strings as an extension to Fortran but (surprisingly to me) even #ident is not well supported in C.\nLets me automatically build an index like\nsource index and\nget information from executable files like\n   what slice.exe\n   slice.exe:\n\n    PRODUCT:        GPF library utilities and examples\n    PROGRAM:        slice(1)\n    DESCRIPTION:    display a set of curves as slices with a 3D view\n    VERSION:        1.1, 20190326\n    AUTHOR:         John S. Urban\n    HOME PAGE:      http://www.urbanjost.altervista.org/index.html\n    COMPILED:       Fri, Jan 24th, 2020 3:57:19 PM\n\nI have my own what(1) command. It used to be nearly ubiquitous on Unix systems but came with SCCS, which has largely been superseded by mg, git, ...\nAnyway, ignore the IDENT string, with the exception that maybe there should be some kind of discussion of metadata and Fortran.\nThe nan(3f) and is_nan(3f) functions are in M_units.f90 in my GPF github collection"
                },
                {
                    "user": "certik",
                    "date": "2020-01-28 16:18:52+00:00",
                    "text": "@urbanjost I see, thanks for the background.\n@jvdp1 I think it's probably fine to return NaN, as I make them raise a runtime exception if a NaN is used in my production codes."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-28 16:22:12+00:00",
                    "text": "Is there any current intrinsic function in Fortran that can return nan?\n\nsqrt and log of a negative number both return a nan.\nIn my view, the only reasonable value to return in this case is a nan. It's also behavior consistent with numpy.\nIf intrinsic modules like ieee_arithmetic or ieee_features don't provide a named nan and Inf constants, stdlib should. This is a perfect use case for stdlib_experimental_constants."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-28 18:13:23+00:00",
                    "text": "@milancurcic With ieee_arithmetic, we could get IEEE NaN as follows (ieee_nan in ieee_features is private:\nuse ieee_arithmetic, only: ieee_value, ieee_quiet_nan\nimplicit none\nreal::res\n\nres = ieee_value(res, ieee_quiet_nan)\nThis implementation is also not kind-dependent.\nThe only issue with IEEE is that it may not supported by all compilers since it is Fortran 2003. However, this is not a problem with preprocessing (there is already a flag for Fortran 90 in the fypp files).\nSo, would be a solution like the following one acceptable for stdlib::mean, while thinking how to implement  constants like NaN, Inf,...:\n#:if VERSION90\nres = 0._sp\nres = res / res\n#:else\nres = ieee_value(res, ieee_quiet_nan)\n#:endif\nThe IEEE NaN would be returned if the compiler support ieee_arithmetic; otherwise it would return a NaN compatible with what other functions with an array mask would return when all elements are false."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-28 20:13:16+00:00",
                    "text": "I've used the transfer method for defining NaN for while now. Is there any reason why this is a bad idea?\nI'm not sure how portable this approach is.\nBoth gfortran 9 and ifort 19 print \"NaN'. I'm not sure what happens with older version of the compilers.\n    real(sp) :: NaN = transfer(Z'7FF80000', 1.0)\n    real(dp) :: NaN64 = transfer(Z'7FF0000000000001', 1._dp)"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-28 20:27:44+00:00",
                    "text": "I've used the transfer method for defining NaN for while now.\n\nIt is probably a way to implement that in a module constant #99 . We will probably need to differentiate quiet and signaling NaN.\nFrom Intel ieee_arithmetic.f90:\n      REAL(4), PARAMETER :: FOR_S_SNAN         = TRANSFER((/ Z'7FA00000' /),1.0_4)\n      REAL(4), PARAMETER :: FOR_S_QNAN         = TRANSFER((/ Z'7FC00000' /),1.0_4)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-28 21:10:50+00:00",
                    "text": "I see nothing wrong with using transfer. You can also assign binary literals, for example for 32-bit values:\nreal, parameter :: nan = b'11111111110000000000000000000000'\nreal, parameter :: neginf = b'11111111100000000000000000000000'\nreal, parameter :: posinf = b'01111111100000000000000000000000'\nHowever, if ieee_arithmetic is implemented on most compilers, we should just do that for simplicity, as it should work for any kind and provides quiet/signaling NaN for us, as Jeremie pointed out."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-28 23:58:17+00:00",
                    "text": "So, it seems that everybody agrees that NaN should be returned when mean is equal to 0./0..\nCurrently, and until (if) NaN is implemented inside stdlib, I proposed to implement NaN as:\nres = ieee_value(res, ieee_quiet_nan)\nBoth ieee_value and ieee_quiet_nan are provided by ieee_arithmetic. ieee_arithmetic is supported by GFortran 5 and higher and Intel 14 and higer. Do we aim to support older compilers? Do other compilers support IEEE modules (I believe so, at least for the most recent versions)?\nIf it is needed, preprocessing can be implemented to avoid IEEE (see comment), but I think it would be beter to avoid that solution for this NaN case."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-29 00:09:59+00:00",
                    "text": "I think it's reasonable to expect F2003 features to work. IEEE arithmetic features seem to be supported by most compilers, their recent versions that is, see table on page 12: https://www.fortranplus.co.uk/app/download/30202489/fortran_2003_2008_2018_compiler_support.pdf"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-30 00:15:06+00:00",
                    "text": "So are we just going to assume all real kinds on all target compilers and platforms are IEEE compliant? Or at least have a concept of \"nan\" that resembles IEEE's?\nThis is relevant to #118 as well."
                },
                {
                    "user": "certik",
                    "date": "2020-01-30 01:11:11+00:00",
                    "text": "I would simply test it out (see #15). And if it works everywhere, then use it. Note that \"inf\" are disabled if \"-ffast-math\" is used, which is the default in my production codes. But otherwise stdlib can use them I think, just like sqrt(-1.) returns a NaN. I tested this simple code:\nreal :: a\na = -3\nprint *, sqrt(a)\nend\nwith:\ngfortran -O3 -march=native -ffast-math a.f90 \n\nand it prints:\n              NaN\n\nSo I think the NaN might work even with -ffast-math. Note that in Debug mode, I use the following options:\ngfortran -Wall -Wextra -Wimplicit-interface -g -fcheck=all -fbacktrace -ffpe-trap=invalid,zero,overflow -finit-real=snan -finit-integer=-99999999 a.f90\n\nand then the code above gives an exception:\n$ ./a.out \n\nProgram received signal SIGFPE: Floating-point exception - erroneous arithmetic operation.\n\nBacktrace for this error:\n#0  0x7f8837f5f2da in ???\n#1  0x7f8837f5e503 in ???\n#2  0x7f8837b91f1f in ???\n#3  0x55e126135939 in MAIN__\n\tat /tmp/a.f90:3\n#4  0x55e1261359b8 in main\n\tat /tmp/a.f90:4\nFloating point exception (core dumped)\n\nThat way any such invalid operation such as sqrt of negative numbers is caught right when it happens with a nice stacktrace. So I suggest we use NaN in the same way as a way to trigger an exception, assuming it could be done."
                },
                {
                    "user": "certik",
                    "date": "2020-01-30 01:15:34+00:00",
                    "text": "So this code:\nprogram test_none\nuse ieee_arithmetic, only: ieee_quiet_nan, ieee_value\nimplicit none\nreal :: nan\nreal :: a\nnan = ieee_value(nan, ieee_quiet_nan)\na = -3\nprint *, a, nan\na = nan\nprint *, a, nan\nend\ntriggers the exception at the nan = ieee_value(nan, ieee_quiet_nan) line:\n$ ./a.out \n\nProgram received signal SIGFPE: Floating-point exception - erroneous arithmetic operation.\n\nBacktrace for this error:\n#0  0x7f4b625ca2da in ???\n#1  0x7f4b625c9503 in ???\n#2  0x7f4b621fcf1f in ???\n#3  0x7f4b6275ced8 in ???\n#4  0x5558914f6a44 in test_none\n\tat /tmp/a.f90:6\n#5  0x5558914f6bba in main\n\tat /tmp/a.f90:2\nFloating point exception (core dumped)\n\nSo we would not be able to actually assign it to a nan, but if we use it as ieee_value(x, ieee_quiet_nan), then we can assign it when an invalid input is presented to mean and then gfortran should give a nice exception above."
                },
                {
                    "user": "certik",
                    "date": "2020-01-30 01:20:05+00:00",
                    "text": "I then tried the following code:\nprogram test_none\nimplicit none\nreal, parameter :: NaN = transfer(Z'7FF80000', 1.0)\nreal :: a\na = -3\nprint *, a, NaN\na = NaN\nprint *, a, NaN\na = a + 5\nprint *, a, NaN\nend\nand that unfortunately will not trigger any exception:\n$ gfortran -Wall -Wextra -Wimplicit-interface -g -fcheck=all -fbacktrace -ffpe-trap=invalid,zero,overflow -finit-real=snan -finit-integer=-99999999 a.f90 && ./a.out \n  -3.00000000                  NaN\n              NaN              NaN\n              NaN              NaN\n\nI don't know how that works, but somehow transfer(Z'7FF80000', 1.0) is different to ieee_value(1.0, ieee_quiet_nan)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-30 01:23:11+00:00",
                    "text": "Conclusion: from the above analysis, I would recommend the ieee_value(1.0, ieee_quiet_nan) approach. We can perhaps wrap it into a function like get_nan(1.0), or even just nan(1.0). We can provide an alternative implementation of nan(1.0) on compilers that would not support ieee_value(1.0, ieee_quiet_nan)."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-30 09:21:47+00:00",
                    "text": "I had a look in GCC ieee_arithmetic.F90 ieee_value function. Interestingly, they generate the NaN result as:\nres = -1\nres = srqt(res)\nSo I guess it could be also a way to generate NaN for compilers that do not support ieee_arithmetic. However, It would be pretty old compilers (e.g., older than GFortran 5, ifort 14, ...)\nieee_arithmetic.F90:\n....\n elemental real(kind=4) function IEEE_VALUE_4(X, CLASS) result(res)\n\n    real(kind=4), intent(in) :: X\n    type(IEEE_CLASS_TYPE), intent(in) :: CLASS\n    logical flag\n\n    select case (CLASS%hidden)\n      case (1)     ! IEEE_SIGNALING_NAN\n        if (ieee_support_halting(ieee_invalid)) then\n           call ieee_get_halting_mode(ieee_invalid, flag)\n           call ieee_set_halting_mode(ieee_invalid, .false.)\n        end if\n        res = -1\n        res = sqrt(res)\n        if (ieee_support_halting(ieee_invalid)) then\n           call ieee_set_halting_mode(ieee_invalid, flag)\n        end if\n      case (2)     ! IEEE_QUIET_NAN\n        if (ieee_support_halting(ieee_invalid)) then\n           call ieee_get_halting_mode(ieee_invalid, flag)\n           call ieee_set_halting_mode(ieee_invalid, .false.)\n        end if\n        res = -1\n        res = sqrt(res)\n        if (ieee_support_halting(ieee_invalid)) then\n           call ieee_set_halting_mode(ieee_invalid, flag)\n        end if\n..."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-07 14:34:55+00:00",
                    "text": "Regarding the discussion on the return value for zero-size arrays or masked arrays with no true entries: the behavior for maxval and minval is to return -huge(x). I think this is preferable to NaN because it can be tested for with non-IEEE floating point types. For instance, I know IBM's real(16) is non-IEEE."
                },
                {
                    "user": "epagone",
                    "date": "2020-02-07 17:17:01+00:00",
                    "text": "Regarding the discussion on the return value for zero-size arrays or masked arrays with no true entries: the behavior for maxval and minval is to return -huge(x). I think this is preferable to NaN because it can be tested for with non-IEEE floating point types. For instance, I know IBM's real(16) is non-IEEE.\n\nWhen I decide to go down this route, in my codes I usually introduce a parameter (e.g. r_undef = -huge(x)) in a module with all similar control parameters, used across the program. Just to keep the code more clean and avoid \"magic numbers\"."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-07 20:13:39+00:00",
                    "text": "Regarding the discussion on the return value for zero-size arrays or masked arrays with no true entries: the behavior for maxval and minval is to return -huge(x). I think this is preferable to NaN because it can be tested for with non-IEEE floating point types. For instance, I know IBM's real(16) is non-IEEE.\n\nI don't agree it is preferable to return -huge(x) (or something different than NaN) for zero-size arrays or masked arrrays with no true entries, because these cases are equal to 0./0., which is NaN.\nNaN are also returned (by the division of 0./0.)  when mask is an array, but for these cases they are dependent on the compiler.\nTo avoid the dependency on IEEE NaN, would you agree to replace:\nres = ieee_value(res, ieee_quiet_nan)\nby\nres = -1\nres = sqrt(res)\n(as implemented in ieee_aritmethic.f90 of gcc)\nor\nres = 0._dp\nres = sum(x, .false.) / res\n?\nUsing sqrt could allow the compilation of the code for non-IEEE types."
                },
                {
                    "user": "certik",
                    "date": "2020-02-07 22:18:00+00:00",
                    "text": "I would suggest we provide a function get_nan and internally implement it by any of the approaches that were discussed (ieee_value, sqrt or huge). That way we have just one simple place to modify, and the rest of stdlib uses get_nan and thus does not have to be modified. We should discuss a good name for such a function."
                }
            ]
        },
        {
            "number": 127,
            "user": "jvdp1",
            "date": "2020-01-27 17:58:36+00:00",
            "title": "Removed stdlib_experimental.f90 (replaced by .fypp) and corrected Markdown file",
            "text": "I removed stdlib_experimental_io.f90 from the directory, and added stdlib_experimental_io.fypp into CMake and Make files.\n\ncorrection of the example in one of the Markdown files (see #3 comment )",
            "comments": []
        },
        {
            "number": 126,
            "user": "certik",
            "date": "2020-01-27 17:07:05+00:00",
            "title": "Functions to open a temporary file (temporary directory)",
            "text": "Other languages:\n\nPython: tempfile module with mkstemp, mkdtemp and TemporaryDirectory\nRust: tempfile package with tempfile, tempdir and TempDir\nJulia: mktemp, mktempdir",
            "comments": [
                {
                    "user": "epagone",
                    "date": "2020-01-27 22:26:34+00:00",
                    "text": "I might be missing something obvious, but why can't we just use open(status='SCRATCH',...)?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-27 23:49:36+00:00",
                    "text": "We could. I haven't thought of that as an option."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-28 02:51:58+00:00",
                    "text": "There are some similiar routines described in\nM_io and M_io.f90 and M_path.f90 in GPF. There are seperate routines for a true status='scratch' file and a unique scratchfile name; and a discussion of the pros and cons of how status='scratch' is implemented (there is a big variation in implementations) at wiki that brings up a few relevant points about how depending on status='scratch'  has pitfalls because of bad implementations.   I really like the idea of making a scratch directory, especially if it was cleaned up automatically like a scratch file should be;  I do not have anything like that. The python implementation does not clean up at termination automatically."
                },
                {
                    "user": "certik",
                    "date": "2020-01-28 05:15:29+00:00",
                    "text": "Python's mkdtemp does not clean up, but TemporaryDirectory does."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-28 08:53:15+00:00",
                    "text": "I really like the idea of making a scratch directory, especially if it was cleaned up automatically like a scratch file should be; I do not have anything like that.\n\n@urbanjost: I like this idea too. Would it be possible with derived types and a final procedure?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-28 16:30:33+00:00",
                    "text": "Yes, we should use a derived type with a finalizer for this. I updated the issue description with links to temporary files and directories implementation in Python, Rust and Julia."
                }
            ]
        },
        {
            "number": 125,
            "user": "urbanjost",
            "date": "2020-01-26 03:33:59+00:00",
            "title": "suggestions for experimental_io  open()",
            "text": "Two possible changes for consideration:\nAs IOSTAT returns numbers that are programming-environment specific the OPEN statement should\nreturn IOMSG and print it when the user has asked to have the IOSTAT value returned.  The message provided by the compiler is often a lot easier to understand than the implementation-specific numbers.\nPerhaps it has settled down, but at one time there was a lot of variation in what happened when a blank filename was used on an OPEN.  Some systems opened a file with a default name like 'file.10'. I think that particular error should be trapped by the code, or perhaps open a SCRATCH file  (I wrote a similar routine in the past where that is what happened, so I have a bias there)\nThe M_io.f90 module was something I mostly used for prototyping quick utilities except for READ_LINE and SWALLOW. Used to use NOTOPEN a lot before NEWUNIT= was added to OPEN.\nBut I find it interesting that several discussions in stdlib are about similar routines; just proving we\nall are reinventing the wheel all the time -- hopefully stdlib will ultimately eliminate most of that.t\nMy routine most equivalent to your open() experiment is fileopen(). I played with it a few too many times so it does cute things like allowing '>', '<', '>>' as substitutes for 'r','w','a' for a shell-like feel\nthat I mostly did as an experiment that several people liked; but in retrospect it should have been kept clean and simple and as much like other common languages as possible; so I like open() so far; but surprised no one felt unconfortable with calling it open instead of fopen since there is already a Fortran directive called OPEN.\nThe contents of M_io.f90 (definitely not the most evolved module, but it was good for Q&D work):\n950  fileclose (3m_io)    - [M_io] A simple close of a sequential file(LICENSE:PD)\n951  filedelete (3m_io)   - [M_io] A simple close of an open file with STATUS='DELETE'(LICENSE:PD)\n952  fileopen (3m_io)     - [M_io] A simple open of a sequential file(LICENSE:PD)\n953  uniq (3m_io)         - [M_io] append a number to the end of filename to make a unique name if name exists(LICENSE:PD)\n954  rd (3m_io)           - [M_io] ask for string from standard input with user-definable prompt(LICENSE:PD)\n955  print_inquire (3m_io) - [M_io] Do INQUIRE on file by name/number and print results(LICENSE:PD)\n956  notopen (3m_io)      - [M_io] Find a FUN/LUN (Fortran-unit-number) that is not in use(LICENSE:PD)\n957  M_io (3m_io)         - [M_io] Fortran I/O module (LICENSE:PD)\n958  read_all (3m_io)     - [M_io] read a line from specified LUN into allocatable string up to line length limit(LICENSE:PD)\n959  read_line (3m_io)    - [M_io] read a line from specified LUN into allocatable string up to line length limit cleaning up input line(LICENSE:PD)\n960  read_table (3m_io)   - [M_io] read file containing a table of numeric values(LICENSE:PD)\n961  slurp (3m_io)        - [M_io] read a file into a character array(LICENSE:PD)\n962  swallow (3m_io)      - [M_io] read a file into a character array line by line(LICENSE:PD)\n963  get_tmp (3m_io)      - [M_io] Return the name of the scratch directory(LICENSE:PD)\n964  scratch (3m_io)      - [M_io] Return the name of a scratch file(LICENSE:PD)\n965  splitpath (3m_io)    - [M_io] split a Unix pathname into components(LICENSE:PD)\n966  dirname (3m_io)      - [M_io] strip last component from filename(LICENSE:PD)",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-01-26 09:25:20+00:00",
                    "text": "Thank you @urbanjost for this post. I have some comments below.\n\nTwo possible changes for consideration:\nAs IOSTAT returns numbers that are programming-environment specific the OPEN statement should\nreturn IOMSG and print it when the user has asked to have the IOSTAT value returned. The message provided by the compiler is often a lot easier to understand than the implementation-specific numbers.\n\nI think it is a good idea to use iomsg to help the users. However, I would suggest to not print iomsg per default when iostat is asked. For some applications, I just need to know if iostat is equl to 0 or not.\n\nPerhaps it has settled down, but at one time there was a lot of variation in what happened when a blank filename was used on an OPEN. Some systems opened a file with a default name like 'file.10'. I think that particular error should be trapped by the code, or perhaps open a SCRATCH file (I wrote a similar routine in the past where that is what happened, so I have a bias there)\n\nI don't think such a behavior is possible with the stdlib open (at least I could not reproduce it). For example,\nu=open('  ','wt',iostat=io)\nwill return a io status = 2 because the open statement does not accept blank filenames.\n\nbut surprised no one felt unconfortable with calling it open instead of fopen since there is already a Fortran directive called OPEN.\n\nThere has been some discussions about the name in #71.\n\n951 filedelete (3m_io) - [M_io] A simple close of an open file with STATUS='DELETE'(LICENSE:PD)\n\nSee #14 (this comment and others) for some discussions on this topic.\n\n960 read_table (3m_io) - [M_io] read file containing a table of numeric values(LICENSE:PD)\n\nIs it similar to stdlib loadtxt?\n\n961 slurp (3m_io) - [M_io] read a file into a character array(LICENSE:PD)\n\nIt might be a nice extension to stdlib loadtxt."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-26 17:15:42+00:00",
                    "text": "http://www.urbanjost.altervista.org/LIBRARY/libGPF/download/tmp/html/BOOK_M_io.html\ndescribes the M_io.f90 module.  The routines have similar functionality to the IO routines being created in io_experimental.  The loading of tables keeps reparsing in mine;  I think parsing the top line and counting the number of variables and then using standard I/O as done in io_experimental is probably far more efficient.\nI literally meant in  open() to detect a blank filename and then do a standard Fortran OPEN on  a scratch file as an alternative to generating an error.  The compilers I tried where I tried a blank filename do not act like the filename parameter was not present which was a problem I saw in the past that made me think you should trap for a blank filename yourself instead of depending on the compiler to flag it as an error, but maybe no compiler does that anymore. It was a confusing difference in the past between compilers.\nI was trying to move the GPF (General Purpose Fortran) collection from my own site to github but was having a lot of problems with getting the automatically generated documents to work in github and then stdlib started so I have not done much with it lately, but it is a lot easier to read the online\ndocuments from GPF download"
                },
                {
                    "user": "certik",
                    "date": "2020-01-27 17:07:42+00:00",
                    "text": "Regarding the blank filename, I would not silently open a temporary file, but rather give an error. As in Python:\nIn [1]: a = open()                                                              \n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-1-7d12777c4d26> in <module>\n----> 1 a = open()\n\nTypeError: open() missing required argument 'file' (pos 1)\n\nIn [2]: a = open(\"\")                                                            \n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\n<ipython-input-2-1b5b4ce920cc> in <module>\n----> 1 a = open(\"\")\n\nFileNotFoundError: [Errno 2] No such file or directory: ''\n\nFor temporary files, we should create a different function, e.g., Python has mkstemp. I just opened #126 for that."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-27 17:34:22+00:00",
                    "text": "Regarding the blank filename, I would not silently open a temporary file, but rather give an error.\n\nI agree with @certik. And it is already what should happen with the stdlib open."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-28 03:05:02+00:00",
                    "text": "I have a similar routine to stdlib::open called fileopen, and it uses a null filename to open a scratch file and looking thru my usage of the routine the first and second most common usage where \"fileopen('filename')  and fileopen('','rwb') so thought I would mention it; no strong feelings on what a blank name should do; especially since what testing I could do does not show any modern compilers that opened an explicit blank filename as a \"default\" system-dependent name; although a lot do open a named file called something like \"file.NNN\" where NNN is the LUN; even some open the file as \"file.-NNN\" when newunit= is used. The negative sign seems a bit ugly. Maybe it is obvious but part of the style guide could be to always either use a named file or status='scratch' but to not use this \"feature\" of most programs to open default filenames."
                }
            ]
        },
        {
            "number": 124,
            "user": "jvdp1",
            "date": "2020-01-23 23:24:33+00:00",
            "title": "addition of stdlib_experimental_stats mean",
            "text": "follow-up of #119 and after merging #123  (See @certik comments).\nIn addition to #119, CMakefiles and Makefiles.manual were modified to support fypp. Therefore, the auto-generated .f90 files are not present in this PR.\nIssue: I could not modify the CI for Windows properly. I would need help there.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-23 23:48:00+00:00",
                    "text": "This makes it pass on Windows: jvdp1#5"
                },
                {
                    "user": "certik",
                    "date": "2020-01-23 23:51:18+00:00",
                    "text": "Now there is another problem. The CI suggests the file stdlib_experimental_stats_mean.f90 takes over 4.5 minutes to compile (https://github.com/jvdp1/stdlib/pull/5/checks?check_run_id=406216313):\nThu, 23 Jan 2020 23:43:13 GMT [ 28%] Building Fortran object src/CMakeFiles/fortran_stdlib.dir/stdlib_experimental_stats_mean.f90.o\nThu, 23 Jan 2020 23:47:30 GMT [ 31%] Linking Fortran static library libfortran_stdlib.a\n\nWhich in my opinion is a big problem. Although perhaps this is only in Release mode.\nI tested on my desktop in Debug mode, and things take under 2s to compile:\n$ time make -j\n[  2%] Generating stdlib_experimental_stats_mean.f90\n[  5%] Generating stdlib_experimental_stats.f90\nScanning dependencies of target fortran_stdlib\n[  8%] Building Fortran object src/CMakeFiles/fortran_stdlib.dir/stdlib_experimental_error.f90.o\n[ 11%] Building Fortran object src/CMakeFiles/fortran_stdlib.dir/stdlib_experimental_ascii.f90.o\n...\n[100%] Built target test_optval\n[100%] Built target test_ascii\n[100%] Built target test_mean\n\nreal\t0m1.862s\nuser\t0m3.014s\nsys\t0m0.644s\n\nIn Release mode it took 5.6s. So I think that's fine.\nUpdate: I use GFortran 7.4.0. At the CI, this GFortran 7 on Linux takes 10s to compile. GFortran 8 takes 1m 26s and GFortran 9 takes 4m 25s. The timing for GFortran 7 is ok, but versions 8 and 9 are not acceptable in my opinion. But I don't know if this is a problem with GFortran, or with our code.\n@zbeekman what do you think of these timings? Something is wrong, every new major version of GFortran got much slower than the previous one."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-24 07:20:17+00:00",
                    "text": "@certik : Here are the times on my desktop:\nWhen the files includes arrays with up to 15 dimensions:\n$ gfortran --version\nGNU Fortran (GCC) 9.2.1 20190827 (Red Hat 9.2.1-1)\n...\n$ time make -j\n[  5%] Generating stdlib_experimental_stats_mean.f90\n[  5%] Generating stdlib_experimental_stats.f90\n.....\n[ 97%] Linking Fortran executable test_mean\n[100%] Linking Fortran executable test_mean_f03\n[100%] Built target test_mean\n[100%] Built target test_mean_f03\n\nreal\t0m21,621s\nuser\t0m23,165s\nsys\t0m1,692s\n\nWhen all loops for real arrays are replaced by sum(x) and sum(x, dim):\n$ time make -j\n[  5%] Generating stdlib_experimental_stats.f90\n...\n[100%] Built target test_mean_f03\n\nreal\t0m16,390s\nuser\t0m18,122s\nsys\t0m1,502s\n\nSee Actions of branch _stat_mean_dev_2 for details with this branch. The tests with GFortran 9 took still >3 minutes.\nWhen the files includes arrays with up to 7 dimensions (with the same compiler):\n$ time make -j\n[  5%] Generating stdlib_experimental_stats_mean.f90\n[  5%] Generating stdlib_experimental_stats.f90\n....\n[ 97%] Linking Fortran executable test_ascii\n[100%] Linking Fortran executable test_mean\n[100%] Built target test_ascii\n[100%] Built target test_mean\n\nreal\t0m3,312s\nuser\t0m4,973s\nsys\t0m1,250s\n\nSo,\n\nWith CMake, I am far from the times we saw on Github. (Note: when using the Makefile.manual, GFortran 9 took over 2 minutes to compile the version with up to 15 dimensions)\nReplacing all loops for real arrays does not help much.\nThe difference between GFortran 7 and Gfortran (8 or 9) can partially be explained by the fact that GFortran supports only arrays up to 7 dimensions, while GFortran 8 and 9 support arrays with dimentions up to 15.\nIt is strange that GFortran 9 requires >2 times the time of GFortran 8 since they are based on the same code."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-24 10:46:17+00:00",
                    "text": "@certik @zbeekman\nIn the branch stat_mean_dev_3, I replaced all loops by using sum(x), or sum(real(x,dp)). Suprisingly to me, sum(real(x,dp)) does not create a double-precision temporary array of the same dimensions as x. It was the main reason I used loops instead of sum.\nSince this reason is not valid (at least with GFortran 9; please explain me why ;)), I propose to merge this branch \"stat_mean_dev_3\" into this PR.\nRegarding compile times of stat_mean_dev_3 on my desktop (GFortran 9):\n$ time make -j\n[  5%] Generating stdlib_experimental_stats_mean.f90\n[  5%] Generating stdlib_experimental_stats.f90\n...\n[100%] Built target test_mean_f03\n\nreal\t0m10,240s\nuser\t0m11,773s\nsys\t0m1,729s\n\nSo there is a speedup of 2 (on my desktop) in comparison to this PR that includes all loops for real and integer arrays.\nFrom Github Actions, Build and compile times are 6s for GFortran7, 1m 15s for GFortran 8, and 1m 51s for GFortran 9. These times are better than the initial 4 minutes, but I can't still understand why GFortran 8 and 9 need more time on CI than on my own desktop."
                },
                {
                    "user": "certik",
                    "date": "2020-01-24 21:21:53+00:00",
                    "text": "The other concerning thing is if a single function such as mean adds 4min to our build, then once we have say 50 such functions, we are talking of a build time over 3h. That does not scale well.\nAs a practical work around, we can have a CMake option for development, which would restrict dimensions to 3. That would allow us to develop with a reasonable compile time.\n@milancurcic what do you think we should do here?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-24 21:29:28+00:00",
                    "text": "More generally, can we have a build parameter to set the maximum rank to build? This would have a low default values for debug and release modes, and user could override it manually if they needed higher ranks? Something along the lines of:\ncmake .. -DCMAKE_MAXIMUM_RANK=8 # overrides default maximum rank"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-24 21:31:40+00:00",
                    "text": "As a practical work around, we can have a CMake option for development, which would restrict dimensions to 3.\n\nFor GFortran 7, the number of dimensions restricticted to 7, and the compile time is 6-7 seconds on Github Actions. Would 7 dimensions be an option for you @certik?\nOr is it possible that CMake recognizes that the tests are running on Github Actions, and that it limits the number of dimensions to 4? (Since it is a preprocessed loop starting at 3, going to 4 would be good).\nWhen a user would compile the library, CMake would see that it is not a Github Action, and will compile stdlib accordingly to its environment (i.e., up to 7 or 15 dimensions; which is quite quick on my desktop)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-24 21:33:41+00:00",
                    "text": "Yes, I am fine with any number of dimensions (including 7) as long as it is fast. If 7 can be made fast, then let's do it. Otherwise let's do less."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-24 23:26:40+00:00",
                    "text": "@certik @milancurcic : I implemented the proposed idea. So, for the CI, the maximum dimension for auto-generation of the .f90 files is limited to 5 (by using cmake -DCMAKE_MAXIMUM_RANK=5). If the flag CMAKE_MAXIMUM_RANK is not defined, then CMake will test if the compiler supports 7 or 15 dimensions.\nIssue: Something seems broken for CI on Linux when installing GFortran:\n\nE: Failed to fetch https://packages.microsoft.com/repos/microsoft-ubuntu-bionic-prod/dists/bionic/main/binary-amd64/Packages.bz2  File has unexpected size (89974 != 89668). Mirror sync in progress? [IP: 40.76.35.62 443]\nHashes of expected file:\n- Filesize:89668 [weak]\n- SHA512:239b3775157309c1f1ff14624d2d0044c5a0c57f6bf9a431f628de1c9f19c91e107c4bc78e1d12bce44121e5866fdf67328e6482151b6edd3456f8c541dc5739\n- SHA256:d737bf9c5418556ef337f43f0124a3db6e79c9f7209deb140ea87644169168b1\n- SHA1:de9e09d12abdb967a62954611af31655b3a8b5d9 [weak]\n- MD5Sum:9e9321f39e46dccc97d928ec9bffc87a [weak]\nRelease file created at: Thu, 23 Jan 2020 17:58:24 +0000\nE: Some index files failed to download. They have been ignored, or old ones used instead.\n##[error]Process completed with exit code 100.\n\nAny idea how to solve this?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-24 23:43:01+00:00",
                    "text": "Thanks for implementing it. Yes, the Linux image sometimes has this problem and last time I think it took about a day to resolve. I am hoping it will be faster this time."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-24 23:55:36+00:00",
                    "text": "Thanks for implementing it. Yes, the Linux image sometimes has this problem and last time I think it took about a day to resolve. I am hoping it will be faster this time.\n\nOK. We will see when it will resolve. At least for macos and GFortran 9 the compile time reduced from >3 minutes to 7s. I guess we can expect similar times for Linux."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-25 09:33:12+00:00",
                    "text": "I limited the number of dimensions to 4 (with cmake .. -DCMAKE_MAXIMUM_RANK=4). All cheks passed, and compile times are <10s.\nI think that all comments in #119 and in this PR were considered. Any other comments after an additional review?"
                }
            ]
        },
        {
            "number": 123,
            "user": "certik",
            "date": "2020-01-23 22:08:50+00:00",
            "title": "Do not use pip to install cmake",
            "text": "Fixes #122.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-23 22:56:55+00:00",
                    "text": "The CMake installation sped up from 11s to 3s on Linux. I am going to merge this, so that the other PRs start passing."
                },
                {
                    "user": "certik",
                    "date": "2020-01-23 22:59:58+00:00",
                    "text": "@zbeekman you might want to have a look at this. The Python way to install it failed, so I switched to a simple binary.\nP.S. It took me over 1h to figure out how to properly do that ---- the usual way of extracting the tarball and creating a symlink in /usr/local/bin completely failed (\"broken symlink\") but I don't have more time to investigate. The above way works for now."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-23 23:05:46+00:00",
                    "text": "Sure I\u2019ll take a look.\n\u2026\nOn Thu, Jan 23, 2020 at 5:59 PM Ond\u0159ej \u010cert\u00edk ***@***.***> wrote:\n @zbeekman <https://github.com/zbeekman> you might want to have a look at\n this. The Python way to install it failed, so I switched to a simple binary.\n\n P.S. It took me over 1h to figure out how to properly do that ---- the\n usual way of extracting the tarball and creating a symlink in\n /usr/local/bin completely failed (\"broken symlink\") but I don't have more\n time to investigate. The above way works for now.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#123?email_source=notifications&email_token=AACEIPG7W3D2MUVHZVOTWF3Q7IOO5A5CNFSM4KK5Z56KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEJZFETI#issuecomment-577917517>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AACEIPENBOQYHQ4ES7MICN3Q7IOO5ANCNFSM4KK5Z56A>\n ."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-24 17:28:13+00:00",
                    "text": "LGTM. I typically use the self-extracting script rather than a tarball, but this seems like a perfectly good approach, and, apparently, CMake is already the latest version on macOS I guess."
                }
            ]
        },
        {
            "number": 122,
            "user": "certik",
            "date": "2020-01-23 22:06:27+00:00",
            "title": "CI: CMake fails to install on macOS",
            "text": "An example error: https://github.com/fortran-lang/stdlib/pull/119/checks?check_run_id=406043264\n2020-01-23T21:35:25.6403130Z \ufffd[36;1mpip install --upgrade cmake\ufffd[0m\n2020-01-23T21:35:25.6548030Z shell: /bin/bash -e {0}\n2020-01-23T21:35:25.6548180Z env:\n2020-01-23T21:35:25.6548280Z   CI: ON\n2020-01-23T21:35:25.6548350Z   CMAKE_BUILD_PARALLEL_LEVEL: 2\n2020-01-23T21:35:25.6548470Z   CTEST_OUTPUT_ON_FAILURE: ON\n2020-01-23T21:35:25.6548570Z   CTEST_PARALLEL_LEVEL: 2\n2020-01-23T21:35:25.6548670Z   CTEST_TIME_TIMEOUT: 5\n2020-01-23T21:35:25.6548730Z   HOMEBREW_NO_ANALYTICS: ON\n2020-01-23T21:35:25.6548830Z   HOMEBREW_NO_AUTO_UPDATE: ON\n2020-01-23T21:35:25.6548920Z   HOMEBREW_NO_BOTTLE_SOURCE_FALLBACK: ON\n2020-01-23T21:35:25.6549010Z   HOMEBREW_NO_GITHUB_API: ON\n2020-01-23T21:35:25.6549080Z   HOMEBREW_NO_INSTALL_CLEANUP: ON\n2020-01-23T21:35:25.6549180Z   FC: gfortran-7\n2020-01-23T21:35:25.6549270Z   GCC_V: 7\n2020-01-23T21:35:25.6549370Z   pythonLocation: /Users/runner/hostedtoolcache/Python/3.8.1/x64\n2020-01-23T21:35:25.6549440Z ##[endgroup]\n2020-01-23T21:35:26.9423920Z Collecting cmake\n2020-01-23T21:35:26.9650240Z   Downloading cmake-3.13.2.post1.tar.gz (27 kB)\n2020-01-23T21:35:27.4408240Z     ERROR: Command errored out with exit status 1:\n2020-01-23T21:35:27.4409820Z      command: /Users/runner/hostedtoolcache/Python/3.8.1/x64/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pip-install-fbiqmw5w/cmake/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pip-install-fbiqmw5w/cmake/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pip-install-fbiqmw5w/cmake/pip-egg-info\n2020-01-23T21:35:27.4411610Z          cwd: /private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pip-install-fbiqmw5w/cmake/\n2020-01-23T21:35:27.4421200Z     Complete output (5 lines):\n2020-01-23T21:35:27.4422140Z     Traceback (most recent call last):\n2020-01-23T21:35:27.4424820Z       File \"<string>\", line 1, in <module>\n2020-01-23T21:35:27.4426060Z       File \"/private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pip-install-fbiqmw5w/cmake/setup.py\", line 7, in <module>\n2020-01-23T21:35:27.4426520Z         from skbuild import setup\n2020-01-23T21:35:27.4427270Z     ModuleNotFoundError: No module named 'skbuild'\n2020-01-23T21:35:27.4427760Z     ----------------------------------------\n2020-01-23T21:35:27.4450470Z ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2020-01-24 17:27:14+00:00",
                    "text": "Feel free to tag me with issues like this in the future. Your solution looks good to me, so I think there's nothing else to do.\nWork is super busy right now so I haven't been able to keep as close tabs on this repo as I would like."
                }
            ]
        },
        {
            "number": 121,
            "user": "milancurcic",
            "date": "2020-01-23 18:17:49+00:00",
            "title": "Proposal for test_condition",
            "text": "Evolved from discussion in #116.\nSummary\nThis is a proposal to add a subroutine test_condition to stdlib_experimental_error that will:\n\nTest the value of a logical condition like assert in stdlib_experimental_error does;\nAllow printing a custom error message to stderr;\nOptionally, allow passing an exit code like with assert;\nOptionally, only print the message without stopping the program, i.e. warn only;\n\nThis is useful for testing both programmer and user errors. It can be used regardless of how the program is built (debug or release mode).\nIt could also be used as a basic building block toward higher-level testing or exception handling proposed in #95.\nDescription\ntest_condition tests an input logical condition. If the condition evaluates to .false., the default behavior is to stop the program and print the error message. Optionally, the user can pass an exit code to stop the program with. Optionally, the user can choose to not stop the program, but only print the warning.\nAPI\nsubroutine test_condition(condition, msg, code, warn)\n  logical, intent(in) :: condition\n  character(*), intent(in), optional :: msg\n  integer, intent(in), optional :: code\n  logical, intent(in), optional :: warn\nArguments\n\ncondition: Logical condition to test\nmsg: (optional) Character string to print to stderr. Default\ncode: (optional) Integer exit code to set when stopping the program. (what should be the default value? Current implementation of assert doesn't set any default code as far as I can tell.)\nwarn: (optional) Logical. If .false. (default), test_condition will stop the program if condition is also false. If .true., it will print the error message to the screen and resume.\n\nExample\nuse stdlib_experimental_error, only: test_condition\n...\ncall test_condition(n > 0, 'n > 0 failed', warn=.true.)\nImplementation\nsubroutine test_condition(condition, msg, code, warn)\n  logical, intent(in) :: condition\n  character(*), intent(in), optional :: msg\n  integer, intent(in), optional :: code\n  logical, intent(in), optional :: warn\n  if (.not. condition) then\n    if (optval(warn, .false.)) then\n      write(srderr,*) optval(msg, \"Test failed.\")\n    else\n      call error_stop(optval(msg, \"Test failed.\"), code)\n    end if\n  end if\nend subroutine test_condition\nThis implementation depends on optval and error_stop.\nRequesting feedback from @certik @nncarlson @zbeekman @jvdp1 @ivan-pi.\nFor anybody reading, please explicitly thumbs up or down, and write a comment if thumbs down. This way we can get a clear idea on whether this is supported or not and how much.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-23 20:21:21+00:00",
                    "text": "I kind of like the name assert for writing tests. Obviously we need to distinguish it from the Debug assert macro. Rust has assert (always executed in both Debug and Release modes) and debug_assert (only in Debug mode): https://doc.rust-lang.org/std/macro.assert.html.\nAlso this is probably going to be part of a testing framework. So we should look at what other Fortran testing frameworks use:\n\nfunit: assert_true\npfunit: assertTrue\nFRUIT: assert_true\nflibs: assert\nzofu: test%assert\nObjexxFTK: CHECK\nvegetables: assertThat\n\nAnd for comparison, C++ testing frameworks:\n\ndoctest: CHECK\ncatch2: REQUIRE\nGoogle Test: ASSERT_TRUE\nBoost Test: BOOST_CHECK\ncppunit: CPPUT_CHECK\nCute: ASSERT\n\nI am thinking maybe it could be called assert_true, and later we can add others like assert_eq, etc."
                },
                {
                    "user": "pdebuyl",
                    "date": "2020-01-23 21:54:28+00:00",
                    "text": "fortran_tester my_tester%assert_equal, my_tester%assert_positive, my_tester%assert_close (arguably, those only cover numerical tests. I only realize this now :-) )."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-23 22:04:10+00:00",
                    "text": "Nice proposal. I would prefer the name assert_true (or maybe test_true) over test_condition. Anyway, it will be quite useful for debugging when multiple test are present."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-24 04:42:04+00:00",
                    "text": "It has been on my list to make a public version of testing and debugging\ncode including unit testing so I found this topic particularly intriguing.\nSince something related is starting here and I have reviewed most of the\nlisted utilities before I thought I would just list some functionality\nunique to what I use as food for thought ...\nSpecifically focusing on tests comprising a unit test (versus parameter\nchecking and other run-time testing functionality) a few differences between\nthe referenced unit testers and what I like in my version are:\nThere is a number of global parameters that are set external to the \nmain \"assert\" routine (I call mine UNIT_CHECK):\n\n* A \"level\" value which is just an integer that all the tests can\n  access that the user is free to use to determine what level of\n  testing to perform and/or how verbose to be.\n\n* As mentioned, an option to make a failure stop the test program\n  or to optionally continue (some of the references have this,\n  but as an option on \"assert\", not as a global mode).\n\n* An option to skip producing messages when successful to make the output\n  more succinct (some of the references have this, but as an option on\n  \"assert\", not as a global mode).\n\nIn tests that I call that I want part of the run-time production routines\nI want options like this to be parameters on the call to the \"assert\"\ntest routine, but in unit testing I want these to be run-time selectable\nglobal options for the entire set of tests.\nOther things I found different\n\n\nA name (almost always the procedure name being tested) is required as\nthe first parameter in my \"assert\" routine.\n\n\nOne I am pretty sure is totally unique is an optional command name\nto call when starting and stopping a test set.\nThis lets you arbitrarily enter test results into an SQLite\ndatabase file, a CSV log, send mail messages, or whatever arbitrary\naction you want, versus just printing a simple log or exiting with\na non-zero exit status -- you provide the command.\n\n\nthe \"message field\" is actually the \"message fields\" on mine, which is\nup to nine polymorphic variables so you can easily include numeric\nand logical values in the message, not just strings. Requires Modern\nFortran, of course -- but a major convenience.\n\n\nFOR MORE INFORMATION ON M_DEBUG\nSome unpolished parts of what I had in mind for what I was going to\nrelease have already been extracted and made available in the General\nPurpose Fortran\nrepository, primarily in the M_debug module, as I needed some basic\ntesting functionallity just to start GPF. So I agree based on experience\nthat the functionality of unit testing is needed pretty early on in\nstdlib.\nI usually mix the unit tests in M_debug  with generic routines similar\nto the dp_accdig() routine in M_math (to compare REAL values with a\ntolerance) and the ufpp(1) preprocessor $SYSTEM directive and the\nnumdiff(1) program... so M_debug is intentionally simple and not\ncomplete by itself, but is more a framework than a full utility. I\nthink that is a good model -- keep the unit test routines simple and\nuse generic routines for comparing reals. These routines can be called\nin the expression field of \"assert\" instead of being provided as a set\nof routines. Powerful testing intrinsics like ANY() and ALL() already\nexist and I do not think need re-invented.\nNote that if anyone builds the GPF repository it tries to run at least a\nfew thousand tests at the end so there might not be a lot of documenation\nbut there are a lot of examples, at least if you use gfortran on a\n*nix system (which is the default expected environment).\nSo lots of other things are possible, but normally you call very simple routines\nlike ...\nunit_check_start(...\nunit_check(name,expression,messages(s)...)\nunit_check(name,expression,messages(s)...)\nunit_check(name,expression,messages(s)...)\nunit_check_done(...\nGenerally for quick confidence tests to make sure things did not accidentally\nchange I find (in practice) that I just let it procedure basic messages,\nresulting in a simple log like:\nSTARTED test_suite_m_sort\nunit_check:       sort_shell           SUCCESS : sort string array, ascending\nunit_check:       sort_shell           SUCCESS : sort string array, descending\nunit_check:       sort_shell           SUCCESS : sort integer, ascending array\nunit_check:       sort_shell           SUCCESS : sort integer, descending array\nunit_check:       sort_shell           SUCCESS : sort real, ascending\nunit_check:       sort_shell           SUCCESS : sort real, descending\nunit_check:       sort_shell           SUCCESS : sort doubleprecision, ascending\nunit_check:       sort_shell           SUCCESS : sort doubleprecision, descending\nunit_check:       sort_shell           SUCCESS : sort complex by real component, ascending\nunit_check:       sort_shell           SUCCESS : sort complex by real component, descending\nunit_check:       sort_shell           SUCCESS : sort complex by imaginary component, ascending\nunit_check:       sort_shell           SUCCESS : sort complex by imaginary component, descending\nunit_check:       sort_shell           SUCCESS : sort complex array by magnitude, ascending\nunit_check:       sort_shell           SUCCESS : sort complex array by magnitude, descending\nunit_check:       sort_shell           SUCCESS : sort double complex by real component, ascending\nunit_check:       sort_shell           SUCCESS : sort double complex by real component, descending\nunit_check:       sort_shell           SUCCESS : sort double complex by imaginary component, ascending\nunit_check:       sort_shell           SUCCESS : sort double complex by imaginary component, descending\nunit_check:       sort_shell           SUCCESS : sort double complex by magnitude, ascending\nunit_check:       sort_shell           SUCCESS : sort double complex by magnitude, descending\nunit_check_done:  sort_shell           PASSED  : GOOD:20  BAD:0\n                      :\n                      :\nunit_check:       cosd                 SUCCESS : cosd 1.00000000 1.00000000 value= 0.00000000 accuracy= 1.35631564E-19 asked for 5 digits\nunit_check:       cosd                 SUCCESS : cosd 0.866025388 0.866025388 value= 30.0000000 accuracy= 1.35631564E-19 asked for 5 digits\nunit_check:       cosd                 SUCCESS : cosd 0.707106769 0.707106769 value= 45.0000000 accuracy= 1.35631564E-19 asked for 5 digits\nunit_check:       cosd                 SUCCESS : cosd 0.500000000 0.499999970 value= 60.0000000 accuracy= 1.35631564E-19 asked for 5 digits\nunit_check:       cosd                 SUCCESS : cosd -3.48994955E-02 -3.48994620E-02 value= 92.0000000 accuracy= 6.01741600 asked for 5 digits\n\nI have mine set up so a \"test_suite\" routine is searched for and\nautomatically called at the end of the build that uses a bash shell that\ncalls nm to find the test routine names and then builds a test program\nto call the tests, but that is a whole other discussion, I think."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-29 15:31:30+00:00",
                    "text": "Based on minimal feedback on this so far, there seems to be some support for this proposal, and no objections. I'd like to get more support here.\nRegarding the naming, now there seems to be more favor for assert_true. However @nncarlson has warned earlier not to associate the word \"assert\" with testing. I'm fine with staying away from the word assert for testing, however library review by @certik shows that this word is quite widely used for testing (and such is my experience with say, Python). It seems to me that Neil's interpretation of assert is thus more narrow than broadly used.\nUltimately, we should take the road that most of community seems to agree on. We need more feedback here, on the naming and the whole of the proposal alike.\n@zbeekman @jacobwilliams @ivan-pi @leonfoks @everythingfunctional @arjenmarkus @scivision mind chiming in (and please upvote or downvote the original post)?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-29 16:26:27+00:00",
                    "text": "In C++ I have been using doctest and catch2, which use CHECK and REQUIRE respectively. Here is an example: https://gitlab.com/lfortran/lfortran/blob/57d3b8077d884f0ff3945ad3a86b2da920e4b6b3/src/lfortran/tests/test_parse.cpp#L1014, I think CHECK is perfectly readable also. The only issue is that in C++ it is a macro, that somehow analyses the expression and can extract the left hands side and right hand side and print useful info. In Fortran, if this was to be just a subroutine, then it would probably be called check."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-29 17:30:17+00:00",
                    "text": "I think run time checking and unit testing functionality should be kept completely separate. And in fact I've found that run time checking that stops execution actually makes unit testing incredibly difficult.\nI'm not sure having what amounts to a fancy stop statement is a good idea. If I'm going to perform unit testing, I don't want any chance the program just stops. I want errors reported back to me. In fact I wrote a library to make this easier and more user friendly, so I could avoid having the data flow for errors be different from the normal data and control flow.\nI would not support the addition of a run time checking facility because I think it encourages poor software design."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-29 18:27:49+00:00",
                    "text": "Thank you for your feedback @everythingfunctional. I'm confused about some terminology so I need to ask.\n\nI think run time checking and unit testing functionality should be kept completely separate. And in fact I've found that run time checking that stops execution actually makes unit testing incredibly difficult.\n\nBy \"run time checking\", do you universally mean \"run time checking that stops the program\"? If yes, I agree. For my own testing (any kind really, unit, integration...), I use procedures very similar to test_condition proposed here, that don't stop the program, but only report on what succeeded or failed. In some cases I have an accumulator of successes or failures.\nWould you then suggest removing the option to stop the program here altogether (warn=.true. here would then be removed as an argument and used as default)? This would cleanly separate it from the existing assert from stdlib_experimental_error.\n\nI'm not sure having what amounts to a fancy stop statement is a good idea.\n\nIn case of a test_condition that stops, it's a convenience wrapper very much like optval is a wrapper for present.\n\nIf I'm going to perform unit testing, I don't want any chance the program just stops.\n\nMe too, but think beyond unit testing :). Some programs (yes, even in production) need to stop gracefully on some conditions. Sure, we can use an if-branch and a stop statement, and test_condition makes it easier to do so. Do you think this is a bad idea? If yes, why?\n\nI would not support the addition of a run time checking facility because I think it encourages poor software design.\n\nCan you explain why? I don't see it. So many languages and libraries do it successfully IMO."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-29 19:26:22+00:00",
                    "text": "By run time checking in that statement I meant, anything that causes the procedure to do something beyond it's normal operation and sends that result anywhere other than back through the argument list or function result. Whether it's stopping the program, printing to screen, writing to an output file or launching the missiles, that is something that my tests (or any calling procedure) no longer has control over or access to. I don't want my tests to stop, and I don't want them cluttered up with output from the production code (or to inadvertently launch the missiles).\nI don't think it's a good idea to add features to a language that enable a design/behavior we should be discouraging. Especially if it's something that could be accomplished with a library anyway. Maybe I'm being naive and idealistic though, because I could see a code base using a pattern like the following extensively, which would still enable deterministic testing.\nif (.not. some_condition) then\n    if (present(error)) then\n        error = code\n        return\n    else\n        print *, message\n        stop code\n    end if\nend if\n\nMaybe if you could get the feature to mimic that pattern and actually cause the procedure to return or stop depending on the presence of a variable and the value of a logical. I.e.\nassert(some_condition, message, code, error, fatal)\n\nSo, if error is not present or fatal is present and true, then it prints the given message to std_err and stops the program, otherwise error becomes defined with the value of code and the procedure returns without printing anything. It would really be cool if code and error only had to be of the same type, and not some intrinsic type. That would be a reasonable compromise I might support (or at least not speak against)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-29 22:48:06+00:00",
                    "text": "@everythingfunctional Okay, great, I understand better now.\n\nBy run time checking in that statement I meant, anything that causes the procedure to do something beyond it's normal operation and sends that result anywhere other than back through the argument list or function result. Whether it's stopping the program, printing to screen, writing to an output file or launching the missiles, that is something that my tests (or any calling procedure) no longer has control over or access to. I don't want my tests to stop, and I don't want them cluttered up with output from the production code (or to inadvertently launch the missiles).\n\nGreat, I agree, this indeed is not what test_condition (or however we name it) is for! :) I wouldn't put this in a function, which I tend to write as pure anyway. However, I would very much like to use this in top-level programs to check the results of functions and subroutines.\n\nI don't think it's a good idea to add features to a language that enable a design/behavior we should be discouraging. Especially if it's something that could be accomplished with a library anyway.\n\nThis is a proposal for stdlib, not the language (different repo). But otherwise, regarding discouraging certain style or behavior, it's not black and white. Any powerful feature can be used for good or harm.\n\nMaybe if you could get the feature to mimic that pattern and actually cause the procedure to return or stop depending on the presence of a variable and the value of a logical. I.e.\nassert(some_condition, message, code, error, fatal)\n\n\nI think we're moving in a good direction. Considering the naming feedback from @certik (I like it also), and your feedback here, let's consider this API:\nsubroutine check(condition, msg, fatal, code)\n  logical, intent(in) :: condition\n  character(*), intent(in) :: msg\n  logical, intent(in), optional :: fatal\n  integer, intent(in), optional :: code\nThis subroutine emits msg to stderr if condition is .false.. Optionally, if fatal is .true. (default .false.), it stops the program with the exit code if provided. I like this even better than the original.\nI changed the order of fatal and code (code is only meaningful if fatal is .true.). msg is also now required because warn-only is now the default behavior.\nWould you at least not object to this variant?"
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-29 23:25:19+00:00",
                    "text": "I have a tweak to make the usage alluded to a bit more convenient.\nfunction check(condition, msg, fatal, code, stat)\n    logical, intent(in) :: condition\n    character(len=*), intent(in) :: msg\n    logical, intent(in), optional :: fatal\n    integer, intent(in), optional :: code\n    integer, intent(out), optional :: stat\n    logical :: check\n\nso that one could write a line like\nif (check(condition, msg, fatal, code, stat)) return\n\nI would still lean towards not having the function emit msg at all if it doesn't stop the program. Where the conditions that cause the program to stop are:\n\nfatal is provided and is .true.\nstat is not provided\nstat is provided but code is not (this is essentially invalid usage)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-29 23:29:24+00:00",
                    "text": "One thing that I am still confused is what the intended audience of this check function is. Is it to write tests? If so, then how to you communicate to ctest that the test failed? Shouldn't fatal be .true. by default?\nAlso, a good testsuite framework (such as doctest in C++) collects the tests and shows all kinds of statistics. I think some of the Fortran test suites do the same. But this check function would be a very limited implementation of such a testsuite framework?\nWouldn't it make sense to simply leave such check functions to test frameworks?"
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-30 04:18:20+00:00",
                    "text": "The check function would not have anything to do with testing. As you recognized, it would have no way of communicating to a testing framework.\nAdditionally, I don't think test code should be mixed in with production code. Test code should call production code, not the other way around.\nYou may be right, that fatal should default to .true., which would make that bullet:\n\nfatal is not provided or is .true.\n\nThe basic use case for this is to be able to write code that, in production stops execution, but under test does not. You could have a procedure with optional arguments that could be used to return error conditions under test, but would not be utilized in production code. I.e.\nsubroutine foo(arg, stat)\n    integer, intent(in) :: arg\n    integer, intent(out), optional :: stat\n\n    ...\n    if (check(condition, \"Error occurred\", .false., SPECIFIC_ERR_CODE, stat)) return\n    ...\n\nso that in production code you would just\ncall foo(arg)\n\nbut in test code you could\ncall foo(CAUSE_FAILURE, stat)\n! Make some assertion about stat\n\nI think this provides a reasonable way to improve code that simply uses stop statements, and enables and encourages making that code testable. But it does not directly talk to any sort of testing framework."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-30 13:41:44+00:00",
                    "text": "@certik Here are some use cases:\n\nValidate user input: Print a warning if input is possibly problematic but the program can work, stop the program if it can't proceed with the given input. This is an ubiquitous pattern in programs with user interfaces.\nIn weather, ocean, and climate prediction (a virtually 100% Fortran industry), there are many properties of the model/program state that are potentially problematic for the user, but don't warrant stopping the program. For example, did humidity or rainfall go negative (yes, in models it happens)? The the velocity exceed the CFL stability limit? Warning without stopping is an ubiquitous pattern in fluid dynamics modeling.\nSay your program works with data that dynamically grows in size depending on the contents. Your program can also get its resident set size (memory used by the process). In production, you'd want to warn when this number go over some limit (say, 50% of total memory), and you'd want to stop it before it's critical, otherwise it would affect the system (write memory to swap or worse). This is also a common pattern in item 2.\n\nAs you can see from the use cases, two essential elements of this subroutine are:\n\nWarn the user on stderr;\nOptionally stop the program.\n\nSo rather than testing, perhaps think about this as a simple warn subroutine, that can optionally also stop. I agree with Brad that this is not meant to make a testing framework. I think I understand Brad's use case, but I personally wouldn't use it like that.\nI do object to this being a function and not a subroutine. The key part of this procedure is that it causes a side-effect (print to stderr and/or stop the program). That's pretty much all it does. One of the few things that I think Fortran got right over other languages is that it has a function and a subroutine. Functions can be used only in expressions. Subroutines can't be used in expressions. Expressions shouldn't cause side-effects. This is especially troublesome if the expression is a logical condition being tested (Brad's use case), or if its passed as an input argument to another procedure. If I understand correctly, integer, intent(out) :: stat was added exactly for causing an additional side-effect. I wouldn't object to this if we keep check a subroutine, although I don't personally care much for this functionality.\nRegarding Brad's wish that check shouldn't emit a message if it doesn't stop the program, we could do this if we made the msg argument optional.\nsubroutine check(condition, msg, fatal, code)\n  logical, intent(in) :: condition\n  character(*), intent(in), optional :: msg\n  logical, intent(in), optional :: fatal\n  integer, intent(in), optional :: code\nNow you can use it like this:\ncall check(x < 0, 'Warning: x is negative, solution may not converge') ! warn only \n\nor:\ncall check(fatal_condition, fatal=.true.) ! stops the program without printing to stderr\n\nWhat do you think?"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-01-30 15:04:42+00:00",
                    "text": "The discussion is already pretty lengthy - I will read it later today.\nBeing of an older generation and using an optical device to enhance my vision, I have to ask: is there any easy way to get this thread on paper? I really prefer to read from that ancient medium ;)."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-30 15:19:58+00:00",
                    "text": "If check is a subroutine, then my pattern becomes:\ncall check(condition, \"Error occurred\", .false., SPECIFIC_ERR_CODE, stat)\nif (present(stat)) then\n    if (stat /= 0) return\nend if\n\nI agree that in most cases side effects should be performed by subroutines, but in this case I think the general use case warrants it.\ni understand the use cases you have shown are prevalent in many code bases, but I don't think they are a good design. If the following is inside a procedure that needs to be inside a loop you'll see this warning tons of times, without necessarily any context as to what's causing it, and you may only really want to see it once. Not to mention if I hit this condition in a test it may clutter up the output from my tests, and makes it much more difficult to test that this condition does emit the message.\ncall check(x < 0, 'Warning: x is negative, solution may not converge') ! warn only\n\nIf the following is in a procedure, now I can't test that procedure to see that inputs causing fatal_condition do in fact result in the appropriate error.\ncall check(fatal_condition, fatal=.true.) ! stops the program without printing anything\n\nMy thought is that we could use this as a way to demonstrate that the use case I've shown is a relatively straightforward change from patterns that are in common use today, but that makes code more testable. Once that's been demonstrated we can request a check statement be added to the language to make it possible to remove the if (...) return portion from around those statements, but still retain the exact same behavior.\nI think this is a good use of an (experimental) standard library; demonstrate a use case for a feature that should be added to the language, with a clear upgrade path from existing code to the stdlib feature, and a clear upgrade path from the stdlib to the new langauge feature."
                },
                {
                    "user": "certik",
                    "date": "2020-01-30 17:11:14+00:00",
                    "text": "@arjenmarkus unfortunately I can't quickly figure out how to print a GitHub issue. However, if this is something that would allow you to participate here, we can use GitHub API to get the Markdown contents of the issue and all the comments, and then we can convert to pdf that can be printed. It's some work, so I can't do it right away. Let me know if this would be a high priority for you."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-01-30 18:15:41+00:00",
                    "text": "@certik Thanks for the offer - it is most a matter of convenience: I could read the thread from paper while commuting. Since there does not seem to be a convenient way to do it, I will just read it from screen instead."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-01-30 20:09:27+00:00",
                    "text": "Having read the discussion, I would like to add the following:\n\n\"check\" is a better name than \"test_xxx\" or \"assert\": it is more neutral. If we want to use it to check (oops, sorry) user-input and warn in a gentle way about possibly undesireable input or warn about states in the calculation that require attention, \"check\" conveys that intention, IMHO.\nThe idea of being able to control the behaviour at a central level is quite appealing, I think, and for that we could turn it into a method of some customisable object:\n\ncall checker%set_handler( stop_on_error )\n...\ncall checker%check(  x > 0, \"Variable x should be positive\" ) \nstop_on_error is then a routine that gets invoked if an error occurs (with some prescribed interface) - an idea I adopted from @urbanjost. And sundry other methods that control the behaviour globally. It is not even necessary to have only a single \"checker\" object, so that you can easily customise different parts of the program in different ways.\nUsing an object in this way, rather than a single routine or a set of routines, is customary in languages like C++ and Java where object-orientation is the preferred programming model.\nThe thing we should avoid is over-designing. It is easy to make a collection of routines (or methods) that allow us to change the behaviour in a myriad of ways, but let us stick to those aspects that are evidently useful at first. Extensions can be made in a later stage. Having said that, I know it is hard to answer the question \"what is evidently useful?\" ;)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-30 22:08:39+00:00",
                    "text": "To be honest I am also struggling to understand the motivation for this. I understand the motivation for Debug time assert, which is #72. I also understand the motivation for a testing framework, which I feel might be beyond the scope of stdlib (yes, we have to write tests in stdlib somehow, for now we simply call error_stop, later on we can switch to some more sophisticated testing framework), either way that's a separate issue also.\nThat leaves the use cases 1., 2., and 3. from #121 (comment). Of those I usually just write an if statement by hand, and if an error occurs, then I call error_stop(), which is already in stdlib.\nSo I personally do not see the motivation for this yet, but if others find this useful, I am not against."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-30 23:04:33+00:00",
                    "text": "That leaves the use cases 1., 2., and 3. from #121 (comment). Of those I usually just write an if statement by hand, and if an error occurs, then I call error_stop(), which is already in stdlib.\n\nExactly, this is the crux. It's a convenience wrapper over if / then / write(stderr, *) or if / then / error_stop(), nothing more.\n\nSo I personally do not see the motivation for this yet\n\nI can understand this. However, how do you motivate the need for the current implementation of assert in stdlib_experimental_error? It's literally this:\nif (.not. condition) call error_stop(\"Assert failed.\", code)\n\nI'd argue that check is more valuable than current assert because it abstracts away more boilerplate than assert does.\nWhat motivated me to propose this is the idea that stdlib would also provide convenience routines like this that simplify repetitive boilerplate. Do you think that stdlib should't provide utilities like this?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-30 23:29:35+00:00",
                    "text": "I see. Yes, the assert was added so that we can write tests today. Then we realized that it really should be split into #72 and into a test framework.\nIf you see it as a better \"assert\", then I am for it. Essentially something that we can use today to write tests. And if we want more, then we would switch to a full blown test framework. Is that your idea?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-31 15:51:21+00:00",
                    "text": "This started as a backward compatible improvement to assert in #116. The winds of community feedback brought me here. In #116, @nncarlson stressed (reasonably so) that assert should stay minimal in scope.\nIf current implementation of assert is indeed to eventually retire in favor of a preprocessor macro, then I don't think it hurts to \"upgrade\" the current implementation of assert to a more appropriately named check, with two benefits:\n\nPeople like @certik  who want to do ad-hoc testing with it can do so without a framework (or just in combination with ctest, like we do now);\nPeople like me who want to simply warn their users with a convenience subroutine can do so as well.\n\nI do think @everythingfunctional ideas brought up here are important and we should discuss them. They do seem outside of scope of this proposal and seem to be more akin to #95."
                },
                {
                    "user": "certik",
                    "date": "2020-01-31 17:04:16+00:00",
                    "text": "If the goal is to retire our current assert and replace it with check as discussed here, then I am for it. I think that's a good idea."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-17 17:48:43+00:00",
                    "text": "Let's pick this discussion up. It seems like there is satisfactory level of interest to retire assert in favor of check, from developers (myself @ivan-pi @certik @jvdp1). This would make stdlib development easier according to #136 and some earlier PRs that ran into the same issue (difficult to identify which assert failed).\nLet's look at the API again:\nsubroutine check(condition, msg, code, warn)\n  logical, intent(in) :: condition\n  character(*), intent(in), optional :: msg\n  integer, intent(in), optional :: code\n  logical, intent(in), optional :: warn\nThis API is compatible with current assert, meaning you could rename all assert calls to check and the code would build and run with the same behavior. In addition, people like me who want this to warn only in some scenarios could do it.\nImplemenation could be incremental:\n\nImplement check as described;\nReplace current assert calls with check;\nAdd informative messages to where check is used in current stdlib tests;\n(optional) remove assert from stdlib_experimental_error.\n\nAre there any objections to this API before I proceed with a PR?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-17 18:03:13+00:00",
                    "text": "It sounds good for me.\nTo avoid issues, it would maybe good to first merge the remaining PR, if there are ok.\nAlso, I would suggest to perform your steps 1, 2, and 4 in a same PR. I am not sure it is a good idea to have both assert and check in the same time in stdlib. This may allow people to still use assert while check is implemented, which I guess we would like to avoid that."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-02-21 08:13:15+00:00",
                    "text": "Just to be sure, the default behavior is warn = .false., so that a false condition will halt execution?\nI think it is sensible to not have assert and check in the library at the same time.\nAfter this PR I suppose the developers who wrote the modules should perform step 3, and add some informative messages to the current tests? Or should we wait until we have a more complete solution for testing?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-02-21 16:39:46+00:00",
                    "text": "Just to be sure, the default behavior is warn = .false., so that a false condition will halt execution?\n\nYes, I think so. It would preserve the behavior of assert, and make its intent a bit different from a testing framework where you want your program to fail tests and keep running.\n\nAfter this PR I suppose the developers who wrote the modules should perform step 3, and add some informative messages to the current tests?\n\nThis is quite easy and I don't mind doing it. We don't have that many modules and functions. All 4 steps above can be in a single PR.\n\nOr should we wait until we have a more complete solution for testing?\n\nNo. We're already hitting problems in development with current assert. I think we should do an easy fix now and carefully design anything more complete, if desired at all."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-22 19:29:33+00:00",
                    "text": "Is there any consensus/progress in this issue? Could I be of any help?\nSuch a subroutine could have been useful today ;)\n@milancurcic"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-22 19:42:08+00:00",
                    "text": "I'm glad you asked! I meant to tackle this next, sometime this coming week. I have a new baby and today is the last day of my 3-week parental leave, and thus lower activity on projects.\nIf you're eager to move it forward, please! Otherwise, I'd tackle it in the next few days.\nI think this is the implementation we're looking for:\nsubroutine check(condition, msg, code, warn)\n  logical, intent(in) :: condition\n  character(*), intent(in), optional :: msg\n  integer, intent(in), optional :: code\n  logical, intent(in), optional :: warn\n  character(*), parameter :: msg_default = 'Test failed.'\n  if (.not. condition) then\n    if (optval(warn, .false.)) then\n      write(srderr,*) optval(msg, msg_default)\n    else\n      call error_stop(optval(msg, msg_default), code)\n    end if\n  end if\nend subroutine check\nImportant points are:\n\nBackward compatible with assert, that is, you can replace current assert calls with check and the behavior won't change; which implies:\n\nStops the program by default, unless warn is .true.;\nPrints custom message only if msg is provided\n\n\n\nHow does that sound?"
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-03-23 14:33:01+00:00",
                    "text": "I still don't understand how this provides functionality different from the current assert. And, if it's backwards compatible with the current assert, then why call it something different?\nI would like to see the following implementation\nfunction check(condition, code, msg, fatal, stat)\n    logical, intent(in) :: condition\n    integer, intent(in) :: code\n    character(len=*), intent(in), optional :: msg\n    logical, intent(in), optional :: fatal\n    integer, intent(out), optional :: stat\n    logical :: check\n\n    character(len=*), parameter :: DEFAULT_MESSAGE = 'Check Failed.'\n\n    if (.not. condition) then\n        if (optval(fatal, .false.)) then\n            call error_stop(optval(msg, DEFAULT_MESSAGE), code)\n        else\n            if (present(stat)) then\n                stat = code\n                check = .true.\n            else\n                call error_stop(optval(msg, DEFAULT_MESSAGE), code)\n            end if\n        end if\n    else\n        check = .false.\n    end if\nend function check\nI think @milancurcic use case could be accomplished by simply adding an optional warn argument to assert. Then we can just leave both in the std_lib, as we appear to have sufficiently distinct use cases."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-23 14:43:47+00:00",
                    "text": "@everythingfunctional #116 shows how we got to here."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-23 14:55:11+00:00",
                    "text": "I like Brad's proposed implementation also, if either we:\n\nremove integer, intent(out), optional :: stat. Functions shouldn't do this -- it would be very difficult for a casual reader to notice that stat is being updated in an expression as a side effect;\nmake it a subroutine\n\nTo my eyes, Brad's check is closer to my check than my check is to assert. Plus, there have been (I think) convincing arguments to either leave assert alone or to drop it. I'm fine with either options.\nAs for why make check backward compatible with assert, I think the choice is pragmatic: 1) we can easily replace current calls to assert with check and be done with it; 2) people who still want existing assert functionality can have it.\nI am not opposed to having multiple functions and subroutines with somewhat overlapping but different capabilities."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-23 15:28:17+00:00",
                    "text": "@jvdp1 Let's keep this at the drawing board until we have a majority agreement."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-03-23 15:35:38+00:00",
                    "text": "@everythingfunctional #116 shows how we got to here.\n\nOk, I think I see what we've got now. Multiple uses cases/ideas trying to get in on one feature. Here's what I think the uses cases are:\n\nStatic/compile time asserts to check against programmer error\nRun time asserts to check against programmer error. Optimized away for anything but debug compilation\nRun time checking of user inputs\nRun time checking of intermediate results\nChecking in the context of testing\n\nI think checking in the context of testing should not be in the scope a the standard library. That is the responsibility of a testing library/framework. Besides, if I can tell which testing framework you're using by looking at your production code, then you're doing it wrong.\nI don't think static/compile time checking would fall under the purview of the standard library either. It would probably need to be implemented by some sort of macro/preprocessor anyway.\nIn order for something to be optimized away under different compiler options, it would need to be a language feature (or maybe make use of macros or preprocessors), which would again put it outside the purview of the standard library.\nThat leaves run time checking of user inputs and run time checking of intermediate results. I think the solution to these problems needs to be designed with respect to the kind of usage patterns we would like to see encouraged, and possibly discouraged, not simply the patterns currently in common usage.\nSometimes it's better to remove capabilities from a language than it is to add new ones. Fortran's history is littered with bad design decisions. Like computed goto and alternate entry points. With great power comes great spaghetti code."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-23 17:52:37+00:00",
                    "text": "Thanks for the summary of use cases. I agree that the problem is exactly \"Multiple uses cases/ideas trying to get in on one feature\".\n\nI think checking in the context of testing should not be in the scope a the standard library. That is the responsibility of a testing library/framework.\n\nI don't see it as black and white. Recent and popular languages like Python and Go do it successfully. I bet many others too. A small project will often roll its own testing functions rather than relying on a heavy testing framework.\nThough I tend to agree that a general and powerful testing framework may be out of scope for stdlib, you still need a way to test stdlib functions internally. Adding an external framework as a dependency is not feasible (not even vegetables, my favorite of the bunch), and current assert is not adequate. How would you do it?\nWe can safely ignore here the preprocessor macro and language developments.\nAs you say, let's focus on run time checking of user inputs and run time checking of intermediate results."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-23 18:14:15+00:00",
                    "text": "I have a new baby and today is the last day of my 3-week parental leave, and thus lower activity on projects.\n\nCongratulations @milancurcic !"
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-03-23 18:16:05+00:00",
                    "text": "My point is that stdlib functions shouldn't be tested internally. A testing framework should be used to test the stdlib from the outside. That way a user of the stdlib doesn't have to rely on the testing code.\nI understand that some languages make use of doctests and inline tests, but they make use of capabilities of those languages that Fortran doesn't have. Introspection and standardized docstrings in the case of Python, and fully AST aware macros and a builtin panic function in the case of Rust. I'm also still not convinced the way they do it is actually a good idea. I'm still of the opinion that the tests should not be mixed in with the production code, as then you require your users to also depend on your testing framework."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-23 18:32:38+00:00",
                    "text": "A couple of questions to try to understand pros/cons in this thread:\n@everythingfunctional what do you mean with:\n\nThat way a user of the stdlib doesn't have to rely on the testing code.\n\n@milancurcic\n\nAdding an external framework as a dependency is not feasible (not even vegetables, my favorite of the bunch),....\n\nWhy is it not feasible?\nMy main issue in this thread is that the use of multiple assert in a test file is painfull when a problem occurs (e.g., a too strict threshold when moving to another compiler).\nI would be happy with both approaches (internal or external testing), if they facilitate the development of stdlib, and do not rely on the current assert (that does not seem appropriate for the stdlib testing approach)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-23 18:43:43+00:00",
                    "text": "@everythingfunctional\n\nMy point is that stdlib functions shouldn't be tested internally. A testing framework should be used to test the stdlib from the outside.\n\nOkay, your point is now clear to me. However, I still don't understand why (they shouldn't be tested internally). Are there practical reasons or is it more of a dogma?\n\nThat way a user of the stdlib doesn't have to rely on the testing code.\n\nI don't think this is an answer to my question above because if you take care of testing internally, then this problem goes away.\nMoreover, I want as many users to run stdlib tests and as seamlessly as possible. This will help us discover bugs and cross-platform issues. As a user myself, I want to run tests for most libraries I use, and I don't want to have to install Perl, Ruby, or Haskell to do so."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-23 18:48:56+00:00",
                    "text": "@jvdp1\n\nWhy is it not feasible?\n\nI think it would add too much friction to development (it would for me), and it would discourage users from running tests.\n\nMy main issue in this thread is that the use of multiple assert in a test file is painfull when a problem occurs (e.g., a too strict threshold when moving to another compiler).\n\nSame. There's an easy solution that works, now.\n@everythingfunctional Recall also that we are now working only with experimental API, where we're supposed to try out and play with various approaches, and drop ones that don't work as we go. Nothing is set in stone here. This kind of analysis paralysis prevents work from getting done.\nPerfect is the killer of good enough."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-03-23 19:06:39+00:00",
                    "text": "I still don't understand why (they shouldn't be tested internally). Are there practical reasons or is it more of a dogma?\n\nWith Fortran, if your tests are inside your procedures, they'll be run every time a user calls that procedure. That adds overhead to your library.\n\nI don't think this is an answer to my question above because if you take care of testing internally, then this problem goes away.\n\nI don't think the problem goes away, I just think it's no longer apparent to the user.\n\nMoreover, I want as many users to run stdlib tests and as seamlessly as possible. This will help us discover bugs and cross-platform issues.\n\nI'm not sure I understand this statement. How does having more people run the same tests help to find bugs? To me, the best way to find bugs is to have more people use the code in various ways. Otherwise your tests would have already found the bug.\nI'm not saying the tests don't have value to outside users. In fact they are a great example of how your code is intended to be used, and done well describe the requirements the code is intended to fulfill. But your users should be able to see that your CI system is running the tests and trust that they pass. They shouldn't really need to run them themselves."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-23 19:07:24+00:00",
                    "text": "@milancurcic I understand your point of view.\nAn extension of the current assert() by combining @milancurcic and @everythingfunctional ideas proposed in this thread could be already useful for the experimental development.\nMeanwhile, a testing framework could be thought/set up for when we will move procedures from experimental part to the non-experimental part. Of course, this will not encourage the users to run tests."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-23 19:16:00+00:00",
                    "text": "With Fortran, if your tests are inside your procedures, they'll be run every time a user calls that procedure. That adds overhead to your library.\n\nI agree with that. However, I think we discussed different things.\nTesting are outside the procedures, but well inside the directory/project of stdlib. E.g., now we test the mean function in a test file that contains multiple calls to assert and mean like:\ncall assert( (mean(x) - 1) < sptol )\nAs implemented now, it is a bit as it is in BLAS/LAPACK: the project includes tests, that the the user may or may not run. There are no tests inside proedures of BLAS/LAPACK (except for validation of the values passed to procedures of course).\nDo I miss something?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-23 19:20:36+00:00",
                    "text": "With Fortran, if your tests are inside your procedures, they'll be run every time a user calls that procedure. That adds overhead to your library.\n\nOkay, I agree and I didn't have that in mind at all. I think of tests as separate programs that call library functions, and these programs may or may not ship alongside the library. What we're doing now with assert is a rudimentary version of that. The only things I would change about current stdlib testing is to allow showing a meaningful message (developer knows what failed), and failures don't stop the program (developer can see multiple failure by running the suite once). At this time I see no need to change or add anything else.\n\nI'm not sure I understand this statement. How does having more people run the same tests help to find bugs? To me, the best way to find bugs is to have more people use the code in various ways. Otherwise your tests would have already found the bug.\n\nYou're right, it doesn't really help if a user runs tests in the same environment as developers, and using the code in various ways is indeed more beneficial. However the output of tests will not always be the same across compilers, compiler versions, and operating systems."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-03-23 19:43:01+00:00",
                    "text": "What we're doing now with assert is a rudimentary version of that. The only things I would change about current stdlib testing is to allow showing a meaningful message (developer knows what failed), and failures don't stop the program (developer can see multiple failure by running the suite once).\n\nOk, so you're using assert as a rudimentary testing framework, but it wasn't really meant for that, and so it's not quite serving that purpose very effectively. A testing framework is intended to make writing those \"separate programs that call library functions\" easier and more useful for debugging."
                },
                {
                    "user": "certik",
                    "date": "2020-03-23 20:03:34+00:00",
                    "text": "I wrote the current assert in stdlib and in my codes I use it both as a testing framework and as Debug time testing (that unfortunately also gets executed in Release mode). In the short run it allows me (us) to get the work done and move on.\nIn the long run, I agree it's not a good solution for either use case.\nFor testing, we should use a testing framework that is integrated with fpm, so that fpm test will execute the tests, just like cargo test does, and if a test fails, report which one failed, and what the LHS and RHS values are etc.\nFor Debug time tests, probably the only way currently in Fortran is to use a macro (until j3-fortran/fortran_proposals#70 is accepted). However, I think this macro could be maintained in stdlib, as it would be very useful."
                },
                {
                    "user": "certik",
                    "date": "2020-03-23 20:09:22+00:00",
                    "text": "Per my previous comment, here is my proposal:\n\n\nget rid of the assert function, and introduce an ASSERT macro. Use that for Debug time checking of array bounds and other conditions that our code assumes, that we do not want to be checking in Release mode for performance reasons. See #72 for that.\n\n\nEither depend on a testing framework (see #162), or create our own \"mini testing framework\", and port our tests to use that\n\n\nThere is a third use case, where you want to be checking conditions in Release mode also. An example of that is this: https://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/src/linalg.f90#L110. I am currently undecided whether this use case is different from 1), i.e., whether this test should still be executed in Release mode. But if it should, then that's a third use case."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-03-23 20:18:55+00:00",
                    "text": "Thank you @certik. I like the long term plan and also support introducing ASSERT macro.\nIn the meantime, do you object extending existing assert subroutine to ease development so we can at least keep moving forward? What do we do for internal testing before we have ASSERT macro and fpm test?\nI will take some time to tally up current support/objections and elicit further support for this.\n@everythingfunctional Can you please open an issue to propose an external testing framework for stdlib testing?"
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-03-23 20:36:11+00:00",
                    "text": "sure thing"
                },
                {
                    "user": "certik",
                    "date": "2020-03-23 21:25:37+00:00",
                    "text": "@milancurcic I don't object at all. If it makes your life easier, go ahead and submit a PR. This is in experimental, so we should be free to experiment until we figure out what we want."
                }
            ]
        },
        {
            "number": 120,
            "user": "jvdp1",
            "date": "2020-01-22 17:10:19+00:00",
            "title": "stdlib_experimental_io: addition of a spec and extension of loadtxt and savetxt to support integers",
            "text": "Addition of a spec (stdlib_experimental_io.md) for the procedures in stdlib_experimental_io.f90 (loadtxt, savetxt, and open). This spec is different than previously because it also describes subroutines.\nExtension of loadtxt and savetxt to support integer.\nThe file stdlib_experimental_io.f90 was generated from the file stdlib_experimental_io.fypp using fypp.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-25 14:20:48+00:00",
                    "text": "It's a start. We can improve upon it with subsequent PRs. Thanks for the review and merging!\n\u2026\nOn Sat, Jan 25, 2020, at 6:00 AM, Ivan wrote:\n ***@***.**** commented on this pull request.\n\n In src/stdlib_experimental_io.md\n <#120 (comment)>:\n\n > +| `r` | open for reading (default) |\n +| `w` | open for writing, truncating the file first |\n +| `x` | open for exclusive creation, failing if the file already\n exists |\n +| `a` | open for writing, appending to the end of the file if it\n exists |\n +| `b` | binary mode |\n +| `t` | text mode (default) |\n +| `+` | open for updating (reading and writing) |\n Compared to the Python documentation (e.g. open\n <https://docs.python.org/3/library/functions.html#open>), the current\n explanation is relatively short and does not cover precisely what are\n the meanings of binary and text format and how they interact with the\n platform.\n\n But I do not want to hinder progress, so good to go from my side too. \ud83d\udc4d\n\n \u2014\n You are receiving this because your review was requested.\n Reply to this email directly, view it on GitHub\n <#120?email_source=notifications&email_token=AAAFAWAS7RYRS7JSXEMP64LQ7QZV5A5CNFSM4KKJLD4KYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCTBQJDI#discussion_r370932349>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWFRGDAUYAJIXZ2GSBLQ7QZV5ANCNFSM4KKJLD4A>."
                }
            ]
        },
        {
            "number": 119,
            "user": "jvdp1",
            "date": "2020-01-21 20:42:24+00:00",
            "title": "Addition of stdlib_experimental_stats function mean",
            "text": "Here is a proposal of a function mean in stdlib_experimental_stats (see #113 for discussions and comments on the API). The API of mean follows the one of Fortran functions such as sum, minval, maxval (except for mask that is not implemented (yet) in mean).\nThe function mean supports arrays with up to rank 15 for Fortran2003 and higher; otherwise, it supports up to rank 7 (for CI on Ubuntu 7).\nAll files were generated with fypp and the fypp files are still in the directory src (fypp comments could be probably cleaner). The .f90 files are probably easier to use for checking and commenting.\nNote: I modified the Makefile and CMake files but it need to be checked carefully.\nA Markdown spec file is in src.\nTo do in a following PR (if accepted): if this PR is accepted and merged: addition of mask as optional argument for mean, to fully follow Fortran conventions. It should be easy to implement when the current proposition is validated.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-01-21 22:17:07+00:00",
                    "text": "Couldn't the f03_stdlib_experimental_stats and f90__stdlib_experimental_stats be combined? Which compiler does not support the modern syntax?\n\n\nThe compiler in the CI Ubuntu 7 does not support arrays with rank >7.\n\n\nInside f03_stdlib_experimental_stats, couldn't the contents be generated using fypp also? It seems repetitive.\n\n\n@certik No sure to understand the question. Both files f90_stdlib_experimental_stats.f90 and f03_stdlib_experimental_stats.f90 are generated from stdlib_experimental_stats.fypp with fypp. Same thing for fxx_stdlib_experimental_stats_mean.f90. The flag VERSION90 is used to generate f90_ or f03_ files."
                },
                {
                    "user": "certik",
                    "date": "2020-01-21 22:22:42+00:00",
                    "text": "Ah ok, so all the repetitive files are generated from a simple template. That answers my question.\nWhat is Ubuntu 7? Do you mean GFortran 7?\nI am fine with the PR as is for now. Later on I think we should not check in generated files, as discussed in #35."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-21 22:36:38+00:00",
                    "text": "Ah ok, so all the repetitive files are generated from a simple template. That answers my question.\n\nYes, indeed.\n\nWhat is Ubuntu 7? Do you mean GFortran 7?\n\nGFortran from the Github actions under the name 'ubuntu-latest, 7) (see here for some details, before I modified the CMake files)\nHere is the reported message:\n\n/home/runner/work/stdlib/stdlib/src/stdlib_experimental_stat.f90:134:44:\n real(sp), intent(in) :: x(:,:,:,:,:,:,:,:)\n                                        1\n\nError: Array specification at (1) has more than 7 dimensions\n/home/runner/work/stdlib/stdlib/src/stdlib_experimental_stat.f90:138:44:\n real(sp), intent(in) :: x(:,:,:,:,:,:,:,:,:)\n                                        1\n\nError: Array specification at (1) has more than 7 dimensions\n/home/runner/work/stdlib/stdlib/src/stdlib_experimental_stat.f90:142:44:\n real(sp), intent(in) :: x(:,:,:,:,:,:,:,:,:,:)\n                                        1\n\nError: Array specification at (1) has more than 7 dimensions\n\n\nI am fine with the PR as is for now. Later on I think we should not check in generated files, as discussed in #35.\n\nI agree we should not check in generated files. However, no decision has been made in #35. So I prefered to keep both fypp files and the generated files. When a decision will be made in #35, generated files will be removed.\nI guess that later CMake should trigger the generation of the f90 files (but I don't know how to do that)."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-22 08:00:52+00:00",
                    "text": "Sorry to be so pedantic about this. Considering that this PR comes in before we have a spec template, we need to get the formatting right, otherwise it will only call for another PR. We can nail these things down here.\n\n@milancurcic  No problem. I will integrate them when the question about dim will be solved."
                },
                {
                    "user": "aradi",
                    "date": "2020-01-23 19:10:50+00:00",
                    "text": "As for the line length, yes fypp defaults to 132. You can override it with the -l option, but I am not sure, whether it is worth the effort. Most of the time, programmers will have to deal with the fypp-source file not with the generated one, so I think, one should impose the 80 character limit in on those.\nAs for the variable names: One shoud probably use number suffixes (e.g. i1, i2, etc.) instead of repeated underscores, as latter are very difficult to debug in my opinion. Something along the line:\n#:def varsuffix(rank)\n${str(rank)}$\n#:enddef\n\n#:def varlist(varname, listsize)\n${\",\".join([varname + varsuffix(i) for i in range(1, listsize + 1)])}$\n#:enddef\n\n[...]\n\ninteger :: ${varlist(\"i\", 10)}$\n\n[...]\n\n#:for fj in range(rank, 0, -1)\n  do i${varsuffix(fj}$ = 1, size(x, dim=${fj}$)\n#:endfor"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-23 19:18:30+00:00",
                    "text": "As for the variable names: One shoud probably use number suffixes (e.g. i1, i2, etc.) instead of repeated underscores, as latter are very difficult to debug in my opinion. Something along the line:\n\nThank you @aradi  for this suggestion. Using numbers instead of \"_\" should be easier to debug indeed. I will implement your suggestion in this fypp file."
                },
                {
                    "user": "aradi",
                    "date": "2020-01-23 19:19:16+00:00",
                    "text": "I guess I am overseeing something trivial, but are the nested do loops really necessary? For example  in mean_${rank}$_all_${k1}$_${k1}$(x) they seem to be just making a simple summation, where we could use simply sum() instead. We could then probably spare a few fypp-instructions. (According to my experience with pre-processing, each spared pre-processor instruction improves readability, even if it was a fypp-directive \ud83d\ude09 )"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-23 19:28:43+00:00",
                    "text": "I guess I am overseeing something trivial, but are the nested do loops really necessary? For example in mean_${rank}$_all_${k1}$_${k1}$(x) they seem to be just making a simple summation, where we could use simply sum() instead. We could then probably spare a few fypp-instructions. (According to my experience with pre-processing, each spared pre-processor instruction improves readability, even if it was a fypp-directive  )\n\nI agree. There are indeed simple sums. I implemented loops to be in agreement with the other scenarios, and also because I observed that such loops might outperform sum. In addition, when computing the sum of an integer array, it is first converted to a double-precision array. I think that doing something like sum(real(x, dp)) may request a huge temporary array in some cases, while only a temporary scalar is needed when loops are used. Am I wrong?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-23 21:47:49+00:00",
                    "text": "Thank you @aradi for the suggestion of using number suffixes (e.g. i1, i2, etc.) instead of repeated underscores. It is indeed easier to debug. This suggestion is now implemented in the last commit.\n@certik @milancurcic @ivan-pi @aradi\nI decided to keep all sums in loops in mean_${rank}$_all_${k1}$_${k1}$(x) (instead of replacing them by sum(x). My reasoning is that their structure remained similar to the one of mean_${rank}$_all_${k1}$_dp$(x) for which I want to avoid something like sum(real(x, dp)) (which may imply a temporary array). If I am wrong, please correct me.\nIf you agree with the PR in this state, please approve it explicitely. Then I guess it may be merged."
                },
                {
                    "user": "certik",
                    "date": "2020-01-23 21:59:04+00:00",
                    "text": "I have issues with committing autogenerated 30K lines long files into a git repository. The diff at some of your commits won't even show at GitHub because it's so long.\nWhy not to use this opportunity and do the right thing --- not commit autogenerated files, and rather build them as needed at the CI? I can help.\nThe other issue I have is that I think we should use sum instead of the long loops.\nMy last issue is that macOS builds fail. It's probably unrelated to this PR (#122), but we need to fix it."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-23 22:16:16+00:00",
                    "text": "I have issues with committing autogenerated 30K lines long files into a git repository. The diff at some of your commits won't even show at GitHub because it's so long.\nWhy not to use this opportunity and do the right thing --- not commit autogenerated files, and rather build them as needed at the CI? I can help.\n\nI started to implement that in another branch. I can merge it in this branch (or I open another PR).\n\nThe other issue I have is that I think we should use sum instead of the long loops.\n\nAs discussed earlier in this thread, I avoided to use sum to avoid temporary arrays, especially 1) when the mean of integer arrays  are computed (e.g., to avoid sum(real(x, dp))) and 2) when the mean along a dimension need to be computed (e.g., sum(x, 8)). There will be no issue for small arrays, but for large arrays, it might create memory problems. Also, my experience is that loops might be more (memory-)efficient for such scenarios. But I may be wrong on that and overlook some things."
                },
                {
                    "user": "certik",
                    "date": "2020-01-23 22:31:11+00:00",
                    "text": "If the generated file is not committed to the repository, then I am fine with loops, as we can easily change that later."
                },
                {
                    "user": "certik",
                    "date": "2020-01-23 23:00:59+00:00",
                    "text": "Can you merge with master to get #123 in? The tests should pass now."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-23 23:03:51+00:00",
                    "text": "Can you merge with master to get #123 in? The tests should pass now.\n\nI will do that. Or should I first merge the master in my branch stat_mean_dev_fypp (with modified CMake files and Makefile.manual). The 2 large .f90 are now removed and auto-generated by CMake. I also modify the CI (but not for Windows)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-23 23:04:41+00:00",
                    "text": "In that case I would suggest you create a fresh PR with clean commits on top of the master (no generated files are checked in)."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-23 23:05:35+00:00",
                    "text": "In that case I would suggest you create a fresh PR with clean commits on top of the master (no generated files are checked in).\n\nGood. I will do that."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-23 23:29:46+00:00",
                    "text": "I will close this PR in favor of #124, as suggested by @certik.\nIn additition to this PR, #124 supports the auto-generation of .f90 files by fypp."
                }
            ]
        },
        {
            "number": 118,
            "user": "nshaffer",
            "date": "2020-01-21 00:07:45+00:00",
            "title": "What to do about infinity?",
            "text": "Sometimes an algorithm needs a way to refer to positive or negative infinity (e.g., integration bounds) or test if a number is infinite. How are we going to do that? I see three directions we could take\n\nOnly implement such algorithms for IEEE-compliant real kinds. Use ieee_arithmetic to set and test for infinities.\nDefine special constants inf_{kind} which is IEEE positive infinity for supported kinds and is a special value (maybe huge(x) + 1.0) for non-IEEE kinds. Likewise, testing for infinities either uses ieee_arithmetic or tests for equality with the defined magic number.\nCreate a derived type that represents infinity and behaves as much like an IEEE infinity as possible when used alongside reals.\n\nOption 1 is simple but means that some stdlib functionality just can't be implemented for all a compiler's real kinds.\nOption 2 is simple for IEEE-compliant kinds but introduces a lot of undefined behavior for non-IEEE kinds. (e.g.: If k is a non-IEEE real kind, we can't guarantee that inf_k - 1.0_k does the \"right\" thing semantically.)\nOption 3 is complicated and might be a pain to use in practice. However, it's the only way I know of to get close to IEEE infinity semantics with non-IEEE reals.\nI'd like to hear opinions and alternatives, if people have them.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-27 18:10:20+00:00",
                    "text": "Can you give an example when this is needed?"
                },
                {
                    "user": "fiolj",
                    "date": "2020-01-28 20:21:08+00:00",
                    "text": "Looking at, for instance scipy source code, I found about a thousand references to np.inf, but I think most (if not all) are to signal the infinite value as stated by @nshaffer. I agree that is very convenient to signal quadrature limits, or step sizes, or similar. But in this case we only need start implementing the constant (for instance as in option 2) and a routine signaling if it is +inf, -inf, or a finite number.\nSomething like:\n  function is_inf(x) result(y)\n    implicit none\n    integer :: y     ! Returns 0 if x is finite, -1 if is minus-infinite and +1 if is plus-infinite\n    ....\n  end function is_inf\n\nOf course, we may just want a True/False result, or something different but with a minimal implementation we could keep advancing and later make additions/modifications as more use cases make it necessary."
                },
                {
                    "user": "certik",
                    "date": "2020-01-28 20:43:17+00:00",
                    "text": "Aren't the infinities disabled in -ffast-math mode? If so, then this might not work."
                },
                {
                    "user": "fiolj",
                    "date": "2020-01-29 13:40:11+00:00",
                    "text": "@certik  you are right, at least gfortran (silently) disables the ieee infinities, in the sense that it compiles and run but, for instance, ieee_is_finite(x) will give the wrong result.\nAdditionally, the question on when we need an infinite value could gives a good frame to decide if/what to implement.\nAs said before, scipy has about 1000 references to np.inf. From these only about 400 are in the code (not in tests, or documentation) and, as far as I can tell it is mainly used to initialize a value that will be tested or signal that a result is infinite (if (s == 0) logs = -inf)\nIn Scipy it is used in:\n\nIntegration routines\nOptimization routines\nstats (mainly continuum distributions)\nSome uses include definition of domains or regions, initialization of steps, or other values that will be updated\n\nIn GSL-2.5 there are about 50 references to GSL_POSINF and they are mostly used in continuum distributions. They use when they can C99X INFINITY, when not the equivalent of huge(x), and fallback to ieee by computing the value of 1.0/0.0.\nWith all that, I am not sure that we need to define an infinite. I've found it handy for integration domains, but my implementation was rather simple and based in huge(x)."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-29 15:37:19+00:00",
                    "text": "@certik Defining quadrature domains was my motivating use-case for this issue. Another use would be constraining curve fitting parameters, e.g., SciPy's scipy.optimize.curve_fit. For these cases, there are simple workarounds to not having a proper, reliable infinity. Sometimes huge(x) is a good enough replacement. Sometimes using character variables or logicals as flags is good enough. Sometimes you write separate routines with different parameter lists to handle cases when it makes sense for an argument to be infinite. From both the library author's point of view and the user's point of view, all these solutions look different and are maintained differently.\nFor now, maybe it makes sense to let individuals do whatever seems natural for the features they're implementing. Eventually, we will probably want to adopt a uniform approach, though."
                }
            ]
        },
        {
            "number": 117,
            "user": "ivan-pi",
            "date": "2020-01-20 22:34:35+00:00",
            "title": "User-defined callback routines",
            "text": "Before we dive into the implementation of root-solvers, optimization routines, and quadrature routines (see #87 and #112 ) I think it is worth discussing the \"standard\" way of defining callback routines (or in other words user-defined functions) which are potentially parametrized by some variables.\nSome of the possibilities are described at https://www.fortran90.org/src/best-practices.html#callbacks\nThe NAG library uses a very low level approach, where the user function carries along both integer and real user workspaces:\nFunction f(x, iuser, ruser)\nReal (Kind=nag_wp)\t:: \tf\nInteger, Intent (Inout)\t:: \tiuser(*)\nReal (Kind=nag_wp), Intent (In)\t:: \tx\nReal (Kind=nag_wp), Intent (Inout)\t:: \truser(*)\nDo we want to support a high level API were the users extend a base class (see related issue #27 ) that carries an evaluate method, as suggested already in the comment by @rweed #87 (comment)?\nIn the ideal case, the n-D root finding routines, the optimization routines, and quadrature routines could share the same callback interface.\nWhat should we do for routines that require both the function value and its derivative? Should we write multiple functions, as in\nreal function quad(x)\n  real, intent(in) :: x\n  quad = 2.0*x**2 + 3.0\nend function\nreal function dquad(x)\n  real, intent(in) :: x\n  dquad = 4.0*x\nend function\nor would a subroutine interface `like\nsubroutine quadd(f,df,x)\n  real, intent(in) :: x\n  real, intent(out) :: f\n  real, intent(out), optional :: df\n  f = 2.0*x**2 + 3.0\n  if (present(df)) df = 4.0*x\nend subroutine\nbe preferable?\nThe downside of such a subroutine interface is that it cannot be nested in other expressions.I know that personally, from performance reasons, I sometimes use the second approach, as typically the function and the derivative share some common sub-expressions that can be reused, potentially saving a few CPU operations.\nIt is of course possible to support several interfaces using \"adaptor\" routines, but this introduces extra calls, de-referencing issues, and just makes things more complicated.",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2020-01-20 22:59:48+00:00",
                    "text": "To provide a more concrete example of low vs high level callbacks I will borrow an example from the NLopt library (written in C) that defines a Fortran 77 interface. In the original low level interface the user needs to provide a function of the form:\n  subroutine square(val, n, x, grad, need_gradient, f_data)\n  double precision val, x(n), grad(n)\n  integer n, need_gradient\n  if (need_gradient .ne. 0) then ! gradient is only needed by certain optimization methods\n     grad(1) = 0.0\n     grad(2) = 0.5 / dsqrt(x(2))\n  endif\n  val = dsqrt(x(2)) ! value of f(x) \n  end \nThe f_data argument can be used to pass through a single variable containing any data and any type to your subroutine. (it is not even type-checked!!!)\nIn my refactored version of the NLopt Fortran interface (https://github.com/ivan-pi/nlopt) the user is required to extend an abstract base class nlopt_user_func carrying a deferred method eval:\nmodule functor_mod\n    use iso_c_binding, only: c_int, c_double\n    use nlopt, only: nlopt_user_func\n\n    implicit none\n\n    type, extends(nlopt_user_func) :: square\n    contains\n        procedure, public :: eval => eval_square\n    end type\n\ncontains\n\n    real(c_double) function eval_square(this,n,x,grad)\n        class(square), intent(in) :: this\n        integer(c_int), intent(in) :: n\n        real(c_double), intent(in) :: x(n)\n        real(c_double), intent(out), optional :: grad(n)\n        if (present(grad)) then\n            grad(1) = 0.0_c_double\n            grad(2) = 0.5_c_double/sqrt(x(2))\n        end if\n        eval_square = sqrt(x(2))\n    end function\nend module functor_mod\nA benefit of the \"functor\" approach is that it allows the user to encapsulate any parameters of the function in the extended derived type, instead of resorting to non-type-safe methods or array workspaces."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-20 23:21:45+00:00",
                    "text": "In my own codes, Fortran's contains mechanism usually makes this a non-issue. As a sketch, consider a 1-D Newton-like rootfinder with the interface\nfunction root(f, df, x0, ...)\n    interface\n        real function f(x)\n            real, intent(in) :: x\n        end function f\n        real function df(x)\n            real, intent(in) :: x\n        end function df\n    end interface\n    real, intent(in) :: x0\n    ...\nend function root\n\nIf I need to call this inside a subroutine foo, then I define f and df in the contains section of foo. That way, f and df can refer (dynamically!) to any variables accessible within foo. This is usually all the flexibility that I need. The library defines what interfaces it needs, the user provides functions or subroutines to match, and the correctness of the user code can be determined at run time. The main thing you lose in this approach is that the contained procedures are internal to the subprogram they're defined in. I have not found this to actually matter in my own codes, but my experience may not be everyone's."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-21 08:27:47+00:00",
                    "text": "Your example reminds me a bit of how one uses lambda functions to call the solve_ivp routine in Scipy which expects a function with the interface\ndef f(t,y):\n    dy = ...\n    return dy\nIf you have a function that requires some arguments, e.g. fun(t,y,args), you just wrap it in a lambda function:\nsol = solve_ivp(fun=lambda t, y: fun(t, y, *args), ...)\nBuilding upon your rootfinder example, you could use the functions externally from the calling subroutine by defining them first in a module\nmodule funcs\nimplicit none\ncontains\nreal function f(x,a,b,c)\n  real, intent(in) :: x, a, b, c\n  f = a*x**2 + b*x + c\nend function\nreal function df(x,a,b)\n  real, intent(in) :: x, a, b\n  df = 2*a*x + b\nend function\nend module\nAnd then internally in the routine calling the root function only define wrapper functions to conform to the interface:\nsubroutine call_root(x0,y,x,a,b,c)\n  use funcs\n  real, intent(in) :: x0\n  real, intent(out) :: x, y\n  real, intent(in) :: a, b, c\n  x = root(local_f, local_df, x0, ...)\n  y = f(x,a,b,c)\ncontains\n  real function local_f(x)\n    real, intent(in) :: x\n    local_f = f(x,a,b,c)\n  end function f\n  real function local_df(x)\n    real, intent(in) :: x\n    local_df = df(x,a,b)\n  end function df  \nend subroutine\nThis introduces some boilerplate code to make sure the interfaces conform. Since we are focusing on ease of use, I guess we can neglect the performance penalty incurred by having two function calls (I doubt we can make the callback routine interfaces pure).\nI suppose the question I am asking is should we support the different callback options (e.g. simple scalar callbacks, callbacks using array workspaces, extended derived types, reverse communication interfaces...) from the start or do we stick to a single interface and force the user to worry about it?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-21 15:11:14+00:00",
                    "text": "@nshaffer you described the \"nested functions\" approach: https://www.fortran90.org/src/best-practices.html#iv-nested-functions. It works well, and it is my method of choice also, but there is one caveat that we recently discovered and discussed at length with @pbrady, @nncarlson and @zjibben privately:\nhttps://nullprogram.com/blog/2019/11/15/\nThere are two approaches how the nested functions (that can access the parent function scope) are implemented in a compiler. GFortran uses the so called \"trampoline\" as described in the article, with the security implications and a possible performance penalty. The NAG compiler avoids the trampoline, but introduces intermediate wrapper functions which compute the local environment. Again, there is a performance penalty.  The question is how much of a performance penalty there is. We need to benchmark it.\n@milancurcic this is another candidate for our benchmarking repository.\nP.S. We also discussed that if the compiler has access to the source code, it could inline the integrator into user's code, which will eliminate the nested function (it gets inlined) and this whole performance issue disappears. However, I don't know if any compiler actually does that. That would be the optimal solution."
                }
            ]
        },
        {
            "number": 116,
            "user": "milancurcic",
            "date": "2020-01-20 17:42:18+00:00",
            "title": "Pass optional message to assert",
            "text": "Problem\nCurrent implementation of assert in stdlib_experimental_error always prints the same message on failure:\nsubroutine assert(condition, code)\n  logical, intent(in) :: condition\n  integer, intent(in), optional :: code\n  if (.not. condition) call error_stop(\"Assert failed.\", code)\nend subroutine\nAs is, if asserts fail, they tell you that they failed, but nothing more.\nIt's quite useful to be able to pass a custom message to assert. For example:\ncall assert(x < 3, \"Error: x must be < 3\")\nwould tell you why the assertion failed. This approach is especially useful during development, but could also be useful in production, for example to validate user inputs.\nThis is equivalent to Python's:\nassert x < 3, \"Error: x must be < 3\"\nSolution\nThis implementation would allow the user to optionally pass a custom message:\nuse stdlib_experimental_optval, only: optval\n\nsubroutine assert(condition, msg, code)\n  logical, intent(in) :: condition\n  character(*), intent(in), optional :: msg\n  integer, intent(in), optional :: code\n  if (.not. condition) call error_stop(optval(msg, \"Assert failed.\"), code)\nend subroutine\nThe solution is straightforward and backward compatible, assuming any existing code passed the optional code as a keyword argument.\nI'd like to get support here before writing up a spec and a PR (both will be quite straightforward).\n@certik @nncarlson @jvdp1 @ivan-pi @rweed What do you think? Anything I missed?\nThis issue is related to #72.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-01-20 20:44:56+00:00",
                    "text": "I think it is a good idea. I was developping a bit and got struggles to find which assert retunrs .false..\nMaybe msg should be trimmed in optval. How is it assumed that the user would take care of it?\n  if (.not. condition) call error_stop(optval(trim(msg), \"Assert failed.\"), code)\nCurrently, there is only test_always_skip.f90 that is using code through call assert(.false., 77)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-20 21:01:48+00:00",
                    "text": "Hmm, why would you want to trim it? msg is a character(*), so it will be always be of length of the input string. If the user (for whatever strange reason) passes a msg padded with spaces, I don't see why stdlib should trim that.\n\nCurrently, there is only test_always_skip.f90 that is using code through call assert(.false., 77).\n\nGood to know, thanks for scoping it out. If we implement this, we should fix this test to state code=77 as keyword argument. This may be a good item for #3: pass optional arguments as keyword arguments to prevent breakage when the API changes."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-20 21:14:59+00:00",
                    "text": "I looked through the functions and see no reason for trimming either, both optval and error_stop accept character(*), intent(in) dummy variables.\n\nThis may be a good item for #3: pass optional arguments as keyword arguments to prevent breakage when the API changes.\n\nWe should at least exempt optval from such a rule. But otherwise I agree it is a good practice to follow."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-20 21:16:45+00:00",
                    "text": "I'm unclear on the intended scope of this assertion code. Perhaps someone could orient me. Is this something meant for the testing framework only as @certik may have suggested or is meant for general use? Is there any relationship to a standards proposal for an ASSERT statement? Sorry, I haven't been following this thread as closely as I would have liked. I do use assertions in my own code, and have formed some very definite ideas about how they should work."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-20 21:17:55+00:00",
                    "text": "Hmm, why would you want to trim it? msg is a character(*), so it will be always be of length of the input string. If the user (for whatever strange reason) passes a msg padded with spaces, I don't see why stdlib should trim that.\n\nI was thinking to the scenario you described. But I agree with your point of view.\n\nThis may be a good item for #3: pass optional arguments as keyword arguments to prevent breakage when the API changes.\n\nIndeed, a good practice to follow (except for optval IMO)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-21 00:58:55+00:00",
                    "text": "@nncarlson I don't think there's a defined scope for stdlib's assert yet, or at least we haven't discussed it yet. I think we should. I also don't think we discussed any further the testing framework mentioned in #72.\nHere's my wishlist for assert:\n\n It's a subroutine that takes an input logical scalar argument and stops the program if its value is .false.;\n Like Python, it can optionally receive an input character string to emit a custom error message (this proposal);\n Optionally, the user can choose to emit an error message but not stop the program. This could be done with an optional logical warn argument;\n\nAnd that's it. I used asserts similar to this in both datetime-fortran and functional-fortran. I'd use them in other projects.\nOther optional capabilities that I don't desire but wouldn't oppose are:\n\n Optionally stop the program with an exit code\n Emit source file name and line number (a-la __FILE__ and __LINE__ cpp macros);\n\n\nI do use assertions in my own code, and have formed some very definite ideas about how they should work.\n\nGreat! Can you share them?"
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-21 19:25:11+00:00",
                    "text": "I think what is being imagined in the discussion here is more what I think of as a general \"error handling\" capability that is similar in spirit to Fortran namelists, which provide an input parsing capability that is good enough for a great many use cases. In the same vein, the error handling functions being discussed here provide value and are mostly good enough.  I do believe there is a place in stdlib for such a thing.\nI would not call these assertions, though.  What I'd like to see as part of standard Fortran is an assertion capability with a much more limited scope similar to what is in C. Assertions are for catching programmer errors -- things like mismatched dummy array sizes, pre-conditions, post-conditions, etc. -- and not for catching errors that are ultimately due to program input. Those require proper error handling like what might be provided by the above.  Assertions should be:\n\ntrivial to use, just ASSERT(scalar-logical-expression); no need to use a module.\nif tripped, print out file, line #, and ideally the condition (as a string), and abort execution.\nif not compiled in debug mode, completely disappear (absolutely no overhead). This probably means ASSERT would be a statement and not a procedure call.\n\nIn the meantime, one can come close to this using the preprocessor and an ASSERT macro, which is what I currently do.  This does require putting a #include statement at the top of files to include a header file that defines the macro (this is a nuisance). Something like\n#ifdef NDEBUG\n# define ASSERT(x) !assert( x )\n#else\n# define ASSERT(x) if(.not.(x)) call f90_assert(__FILE__,__LINE__)\n#endif\n\nf90_assert would necessarily be an external subroutine.\nI wouldn't object to this form of an assertion taking optional arguments like an error message, but I think that would require an explicit  interface (unless ASSERT were part of the language), and seems like scope creep toward a more general error handling system.\nMaybe we could split things into a low-level assertion similar to what I describe and a separate higher-level error handling capability?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-21 22:18:27+00:00",
                    "text": "@nncarlson I think what you are proposing is a solution that works today, until j3-fortran/fortran_proposals#70 gets implemented in the language itself."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-22 00:36:39+00:00",
                    "text": "I don't object to a minimal C-like assert like this. Should the current implementation of assert then be expanded to print file name and line?\n\nIn the same vein, the error handling functions being discussed here provide value and are mostly good enough. I do believe there is a place in stdlib for such a thing.\n\nYes, I'd personally find such subroutine more useful than a C-like assert. Basically what I'm looking for is the current implementation of assert in stdlib_experimental_error + emitting a custom message + optionally warn-only. How should this be called? test_condition?\n@certik where are you at on this?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-22 08:37:09+00:00",
                    "text": "I don't object to a minimal C-like assert like this. Should the current implementation of assert then be expanded to print file name and line?\n\nThat would be something nice to have at least file name and line in the output of assert. When implementing #119 , I added severeal assert in once in the test file, and tool me some times to find which one returns .false..\n\nYes, I'd personally find such subroutine more useful than a C-like assert. Basically what I'm looking for is the current implementation of assert in stdlib_experimental_error + emitting a custom message + optionally warn-only. How should this be called? test_condition?\n\nIs it (in some way) related to #95 ? Or could both idea be merged?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-22 12:36:52+00:00",
                    "text": "Is it (in some way) related to #95 ? Or could both idea be merged?\n\nI think the ideas are related and could have similar use cases. However I am personally not in favor of #95 (for me it's overkill). What I described in the previous message is exactly what I wish for.\n\nI added severeal assert in once in the test file, and tool me some times to find which one returns .false..\n\nThis problem could be easily fixed with this proposal :). It's also how I write tests, but I'm not married to the idea of it being called assert."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-22 14:35:17+00:00",
                    "text": "@nncarlson I think what you are proposing is a solution that works today, until j3-fortran/fortran_proposals#70 gets implemented in the language itself.\n\nExactly. In fact #72 started as just that, but quickly got diverted into a discussion about more elaborate error handling facilities. Again, I'm in no way opposed to such things, but they solve a different problem. Traditional assertions (and I'd rather the more elaborate error handling not co-opt that terminology) are strictly about catching unexpected programmer errors and should never be tripped (implemented by the compiler they can also declare conditions used by the optimizer). Other \"expected\" errors need a different solution.  Perhaps one way to help distinguish the two types is to ask whether it is appropriate for the error check to be omitted in a non-debug build."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-22 14:54:33+00:00",
                    "text": "Perhaps one way to help distinguish the two types is to ask whether it is appropriate for the error check to be omitted in a non-debug build.\n\nYes, I think this is the key distinction. I'd like to be able to test conditions with meaningful messages in both debug and release builds.\nOkay, it seems from this thread that there is now a more-or-less clearly defined scope for assert based on input from @nncarlson and @certik. This proposal shouldn't touch assert then.\nI will close this issue tomorrow and open a new proposal for test_condition to elicit feedback."
                },
                {
                    "user": "certik",
                    "date": "2020-01-22 15:56:36+00:00",
                    "text": "Yes, indeed, I currently use the assert function for both tests and inside code. Rather, it should be split, and there should be a version used for tests, which will be executed in Release mode also. And then there should be a version to be used inside code in Debug mode only (no overhead in Release mode), implemented using a macro."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-23 06:04:02+00:00",
                    "text": "I have my own preprocessor, which has a debug mode than only includes $ASSERT lines and blocks of lines starting with \"DEBUGVERSION: block\" to \"endblock DEBUGVERSION\" only if debug mode is enabled and activated (that is, they are either both in the code or excluded from the code).  Code that tests values is just part of the normal code (no way to turn if off or exclude it). So I use something similar to what you are describing a lot,. The discussion got be looking because the (very simplistic) macro $ASSERT allows up to nine values as a message. I found that over eighty percent of the $ASSERT lines\nadded a message (file name and line number gets added automatically) so I would give a thumbs up on a standard ASSERT directive, but vote for the optional message being available. But that seems like it should be a request for enhancement in the standard more than somthing in stdlib? As a footnote, the nine message values are class(*), which makes it really easy to build a useful message\n(like the tostring example on the Fortran WIki).\nI find that method extremely useful for building relatively arbitrary messages, albeit it requires unlimited polymorphic variables, which would probably exclude a lot of compilers from using a similar procedure. But if an ASSERT directive were to become part of the Fortran standard I would really like it to have a message that was similar, and think it would be useful if the message actually showed the logical test (which is something I keep meaning to add to my own $ASSERT directive and never seen to get around to :>)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-23 18:19:16+00:00",
                    "text": "Closing in favor of #121."
                }
            ]
        },
        {
            "number": 115,
            "user": "leonfoks",
            "date": "2020-01-19 20:03:48+00:00",
            "title": "Licensing information?",
            "text": "This is more for informational purposes and highlighting required care about licensed software. IANAL (just need to get that out the way, this is my opinion).\nI wanted to bring this up for those that may not be familiar with the licensing for Numerical Recipes algorithms. See this http://numerical.recipes/licenses/\nDo not use them for anything stdlib.  The license for all those algorithms is only for single use or institutional use basis, re-distributing them is not allowed.\nstdlib already has the MIT license so if in the future we are linking to more and more pre-existing software, be mindful of the license on that software.\nHere's one version of a one-way dependency graph\nFeel free to add to this with knowledge",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-19 20:09:20+00:00",
                    "text": "Indeed, we cannot use any code from Numerical Recipes.\n\nAll stdlib must be MIT/BSD style licensed. No GPL, no LGPL, no other more restrictive licenses.\n\nThe idea would be that vendors could provide commercial versions of stdlib with faster implementations.\n\u2026\nOn Sun, Jan 19, 2020, at 1:03 PM, Leon Foks wrote:\n I wanted to bring this up for those that may not be familiar with the\n licensing for Numerical Recipes algorithms. See this\n http://numerical.recipes/licenses/\n\n Do not use them for anything stdlib. The license for all those\n algorithms is only for single use or institutional use basis,\n re-distributing them is not allowed.\n\n I wonder how much money they make. They should just move to an open\n source license...\n  Perhaps this brings up the sticky subject of licensing? But I don't\n want to start it.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#115?email_source=notifications&email_token=AAAFAWBCOARY2ZIZL4RYLILQ6SW2LA5CNFSM4KI3HWE2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IHGPKBA>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWGE7X5C5G3KNPSB7T3Q6SW2LANCNFSM4KI3HWEQ>."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-19 20:13:20+00:00",
                    "text": "Using public domain code (or whatever public domain means, it's not consistent for different countries!)\nFrom what I gather, we can include \"PD\" code into the stdlib source.  But we cannot re-license that code since we are not the original authors.  I think we would have to maintain the public domain attribution to those pieces of code and state that in those files?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-19 20:23:50+00:00",
                    "text": "https://en.m.wikipedia.org/wiki/Public-domain_software\nI think this means we can do whatever we want with PD code, including relicensing."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-19 20:24:53+00:00",
                    "text": "okay great!"
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-20 00:20:13+00:00",
                    "text": "Back around 2015 I was involved in some contract talks with a major corporation, and their IP lawyer shared a couple slides (redacted) with me that described industry's view of open source software and its various licenses. You might find it interesting. Bottom line MIT and BSD are good, unsurprisingly.\n[Edit] But the deal with \"public domain\" is that it must be definitively declared to be so (\"confirmed\" in the language of the slides) otherwise it is a problem."
                },
                {
                    "user": "masuday",
                    "date": "2020-02-03 14:16:48+00:00",
                    "text": "How and where can I put the license information (the copyright and the original authors) when the code is taken from open source libraries? A separate question is whether I clarify the original author of a public-domain program.\nPerhaps we can have a file (SOURCE.md) to have the copyright notice instead of putting it to the source code. We can optionally put the source of public-domain software to the file just for reference."
                },
                {
                    "user": "dmey",
                    "date": "2020-02-03 14:25:17+00:00",
                    "text": "How and where can I put the license information (the copyright and the original authors) when the code is taken from open source libraries? A separate question is whether I clarify the original author of a public-domain program.\n\nIt depends -- this is normally the case only if you bundle external code.\n\nPerhaps we can have a file (SOURCE.md) to have the copyright notice instead of putting it to the source code. We can optionally put the source of public-domain software to the file just for reference.\n\nGeneral good practice is to have something like https://github.com/microsoft/vscode/blob/master/ThirdPartyNotices.txt."
                },
                {
                    "user": "masuday",
                    "date": "2020-02-03 14:51:03+00:00",
                    "text": "I agree it depends. I meant the BSD-like license. I believe that I should write the copyright notice somewhere in the package when I have (wholly or partially) taken or modified the original code released under the BSD license. I was looking for the good practice that you pointed."
                },
                {
                    "user": "certik",
                    "date": "2020-02-03 20:01:19+00:00",
                    "text": "I've been putting this into the LICENSE file directly: https://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/LICENSE, but I like the vscode's approach also: https://github.com/microsoft/vscode/blob/a14ad2f8b0a83bace3dae6c83c49224a3fb870aa/ThirdPartyNotices.txt as @dmey suggested."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-02-03 22:17:04+00:00",
                    "text": "I think it's also very important to maintain documentation of the author and license (though not necessarily the full text but simply a reference, as in \"BSD\") in the individual source files as well."
                }
            ]
        },
        {
            "number": 114,
            "user": "leonfoks",
            "date": "2020-01-19 19:07:57+00:00",
            "title": "Returning array from function",
            "text": "I was going to ask this in #113 but didn't want to derail that thread.\nThis is more of a personal question... since I've actually done very little with returning an allocatable array from a function.  I may have flawed logic, so please correct me if i'm wrong.\nI've had compile issues in the past returning allocatable from functions (cant remember all the details but perhaps others have had these too)  and I \"intuitively\" thought there might be a slow down if those functions need calling multiple times.\nIll use the snippet from #113\nfunction mean(mat, dim) result(res)\n    real(sp), intent(in) :: mat(:,:)\n    integer, intent(in), optional :: dim !dim = 1 or dim = 2 \n    real(sp), allocatable :: res(:)\nend function\nIf I have a large array, and I call this multiple times, does it reallocate memory for that variable every time? Or is there some cleverness that happens?\ne.g. 1D result is already allocated, function allocates its own result, on return those results are copied to pre-allocated array.\nreal(sp), allocatable :: x(:), A(:, :)\n\n! A = full of numbers\nallocate(x(shape(A)(2)))\n\nx(:) = mean(A, dim=1)\nIs it known what happens specifically, memory wise? Is it compiler dependent?\nI'm asking because it will be slower if allocations keep happening, we might want to be careful and always make subroutines available where preallocated memory can be accessed without any implicit allocations and then copies. Am I worrying about this too much haha.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-19 19:36:32+00:00",
                    "text": "This is really important.\n\nI don't think we should use allocatable at all in the lowest level API, unless the size of the output is truly not known ahead of time, like in loadtxt.\n\nAlso, in the past I have found that if a function returns an array (non allocatable), it can be slower than an equivalent subroutine with intent(out) array. Apparently there is an extra copy happening. This is something where it feels Fortran compilers must do better. I feel ideally there shouldn't be an overhead of using functions over subroutines, but unfortunately it seems there is.\n\u2026\nOn Sun, Jan 19, 2020, at 12:07 PM, Leon Foks wrote:\n I was going to ask this in #113\n <#113> but didn't want to\n derail that thread.\n  This is more of a personal question... since I've actually done very\n little with returning an allocatable array from a function. I may have\n flawed logic, so please correct me if i'm wrong.\n  I've had compile issues in the past returning allocatable from\n functions (cant remember all the details but perhaps others have had\n these too) and I \"intuitively\" thought there might be a slow down if\n those functions need calling multiple times.\n\n Ill use the snippet from #113\n <#113>\n\n function mean(mat, dim) result(res)\n     real(sp), intent(in) :: mat(:,:)\n     integer, intent(in), optional :: dim !dim = 1 or dim = 2\n     real(sp), allocatable :: res(:)\n end function\n If I have a large array, and I call this multiple times, does it\n reallocate memory for that variable every time? Or is there some\n cleverness that happens?\n\n e.g. 1D result is already allocated, function allocates its own result,\n on return those results are copied to pre-allocated array.\n\n real(sp), allocatable :: x(:), A(:, :)\n\n ! A = full of numbers\n allocate(x(shape(A)(2)))\n\n x(:) = mean(A, dim=1)\n Is it known what happens specifically, memory wise? Is it compiler dependent?\n\n I'm asking because it will be slower if allocations keep happening, we\n might want to be careful and always make subroutines available where\n preallocated memory can be accessed without any implicit allocations\n and then copies. Am I worrying about this too much haha.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#114?email_source=notifications&email_token=AAAFAWC6TNXY3SQSYYYBK3DQ6SQI7A5CNFSM4KI2655KYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IHGL63Q>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWBI63LLCUGKPWVAQNTQ6SQI7ANCNFSM4KI2655A>."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-19 19:42:39+00:00",
                    "text": "Phew, I was hoping I wasn't crazy haha"
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-19 23:14:05+00:00",
                    "text": "I don't believe there is any performance difference between an automatically-sized array valued function, for example\nfunction foo(array) result(res)\nreal, intent(in) :: array(:,:)\nreal :: res(size(array,dim=2))\nversus one whose result is allocatable. In either case the size of the result is determined at run time. So there is absolutely no reason to avoid allocatable results if one is determined to use a function.\n\nAlso, in the past I have found that if a function returns an array (non allocatable), it can be slower than an equivalent subroutine with intent(out) array. Apparently there is an extra copy happening.\n\nThis is the real problem with array-valued functions, allocatable or not, and has nothing to do with allocatable."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-20 16:58:59+00:00",
                    "text": "So there is absolutely no reason to avoid allocatable results if one is determined to use a function.\n\nHow about the allocation on stack vs. heap? Yes, this isn't defined in the language and is implementation specific, but I found that in practice there is a difference:\n\nNon-allocatable function result may be allocated on the stack, which is faster;\nAllocatable function result is always allocated on the heap, which is slower;\n\nI never measured this, but I have anecdotal personal experience of WRF being noticeably slower when compiled with -heap-arrays (ifort flag to make all arrays be allocated on heap).\nThis is also the caveat with non-allocatable function (or subroutine) results (output arguments): For large arrays, stack can overflow. This problem doesn't occur with allocatable arrays."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-20 17:12:25+00:00",
                    "text": "I can certainly believe there is a performance difference between stack and heap allocated. But in the case of an automatic array result that must be allocated at run time, do you think the compiler inserts code to decide where to allocate (stack or heap) based on the size it determines for a particular invocation of the function? (Note I'm not talking about a size known at compile time.) I suppose that could be the case; do you know?  But even if so, I think the far bigger cost is the one @certik pointed out with using a function at all."
                },
                {
                    "user": "certik",
                    "date": "2020-01-20 17:13:39+00:00",
                    "text": "We should setup a project to carefully benchmark all these options. Note that gfortran and Intel can put an allocatable on a stack as well.\n\u2026\nOn Mon, Jan 20, 2020, at 9:59 AM, Milan Curcic wrote:\n >\n > So there is absolutely no reason to avoid allocatable results if one is determined to use a function.\n\n How about the allocation on stack vs. heap? Yes, this isn't defined in\n the language and is implementation specific, but I found that in\n practice there is a difference:\n\n  * Non-allocatable function result may be allocated on the stack, which\n is faster;\n  * Allocatable function result is *always* allocated on the heap, which\n is slower;\n I never measured this, but I have anecdotal personal experience of WRF\n being noticeably slower when compiled with `-heap-arrays` (ifort flag\n to make all arrays be allocated on heap).\n\n This is also the caveat with non-allocatable function (or subroutine)\n results (output arguments): For large arrays, stack can overflow. This\n problem doesn't occur with allocatable arrays.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#114?email_source=notifications&email_token=AAAFAWCIENGWONBPWR32MH3Q6XJ5JA5CNFSM4KI2655KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEJNIWIY#issuecomment-576359203>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWAEIKYND6XWHNJ4S3TQ6XJ5JANCNFSM4KI2655A>."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-20 17:20:49+00:00",
                    "text": "We should setup a project to carefully benchmark all these options.\n\nThat would be very interesting to see. And there are many other specific performance questions like this.  Conclusions from such a project could feed into a \"Fortran best practices\" guide.\n\nNote that gfortran and Intel can put an allocatable on a stack as well.\n\nYep. My experience with intel is that I routinely have to unlimit the stack size to avoid hitting a segfault.  I have no such issues with NAG, for example."
                },
                {
                    "user": "certik",
                    "date": "2020-01-20 18:14:16+00:00",
                    "text": "Also I want to setup benchmarks for operations on arrays (y(:) = a(:) + b(:)) compared to an explicit loop. The loop seems to be faster some times and I have seen several codes moving away from arrays to explicit loops because of that.\nThose are things where I want Fortran compilers to do better. And a first step is to have reliable benchmarks, showing where the \"performance bug\" is."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-20 18:30:25+00:00",
                    "text": "In that benchmark,  a manually unrolled loop version would be cool to see.  The compilers should already do a good job of this. It would be nice to see in a benchmark though if it\u2019s worth it?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-20 18:36:43+00:00",
                    "text": "This looks like a good candidate for a fortran-lang/benchmarks repo. This could include both benchmarks of stdlib, and more fundamental basic operations discussed in this thread. It would be nice to have a pipeline there that automatically generates a report for all procedures/programs in the suite. Later on when we change implementations of some stdlib procedures that are used by other procedures, it would be useful to verify that there's no significant performance regression when changing the implementation of a building block.\nBesides these, I'm also curious about what's the overhead of calling a generic procedure that overloads some 50 or 100 specific procedures."
                },
                {
                    "user": "zerothi",
                    "date": "2020-04-06 11:51:32+00:00",
                    "text": "Additionally one should be careful with allocatable statements, the below is a perfectly reasonable code:\nreal, allocatable :: a(:)\n\na = [1, 2, 3]\na = [1, 2, 3, 4]\nHowever, the compiler have to add checks for sizes and do deallocation/allocation in case they aren't commensurate.\nTo force the compiler to not check one has to add this:\na(:) = [1, 2, 3]\nin which case it will segfault if the dimensions doesn't match.\nIf this library is low-level enough it should not rely on automatic allocation AND it should disallow array dimension checks (i.e. use a(:) = )"
                },
                {
                    "user": "certik",
                    "date": "2020-04-06 16:59:17+00:00",
                    "text": "@zerothi indeed, that seems to be what is needed now. It seems very unfortunate that the natural syntax a = [1, 2, 3] has a runtime overhead, and one must use a(:) = [1, 2, 3] instead.\nWhat's worse, say the code looks like this:\nreal :: a(3)\n...\na = [1, 2, 3]\nand then later you decide to change the declaration to allocatable:\nreal, allocatable :: a(:)\nallocate(a(3))\n...\na = [1, 2, 3]\nThen in the line a = [1, 2, 3] there is now performance overhead.\nI wonder if for this reason one should never use  a = [1, 2, 3] and instead always use  a(:) = [1, 2, 3], even in:\nreal :: a(3)\n...\na(:) = [1, 2, 3]\nSo that when the declaration is later changed to allocatable, there is no unexpected overhead."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-04-06 17:10:10+00:00",
                    "text": "The technique of using a(:) instead of a to avoid checks for reallocation when one knows they aren't needed is good.  However I'd be uncomfortable recommending using a(:) in the case a were not allocatable not knowing what object code compilers will generate. Superficially they are the same thing, but they are technically very different."
                },
                {
                    "user": "zerothi",
                    "date": "2020-04-06 18:09:32+00:00",
                    "text": "I don't think the compiler distinguishes between a and a(:) for non-allocatable arrays. I have never heard of performance degradation due to that. However, the other is very easy to check...\nGenerally I use it, simply because it is an easy documentation reminder of the array dimensions ;)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-04-06 18:20:34+00:00",
                    "text": "What's worse, say the code looks like this:\nreal :: a(3)\n...\na = [1, 2, 3]\n\nand then later you decide to change the declaration to allocatable:\nreal, allocatable :: a(:)\nallocate(a(3))\n...\na = [1, 2, 3]\n\nThen in the line a = [1, 2, 3] there is now performance overhead.\n\nIs the overhead due to a run-time check that the RHS has the same shape as the LHS, or due to the reallocation on assignment always happens, even if the shape is the same?\nIf the latter, that's compiler dependent, no? A compiler should be able to check at run-time if the array needs reallocating.\n\nI wonder if for this reason one should never use a = [1, 2, 3] and instead always use a(:) = [1, 2, 3]\n\nWhat happens if the re-allocation is desired, for example if size(a) == 3 and then you do a(:) = [1, 2, 3, 4]? In this case, I want re-allocation and not a run-time error."
                },
                {
                    "user": "zerothi",
                    "date": "2020-04-06 18:27:05+00:00",
                    "text": "What's worse, say the code looks like this:\nreal :: a(3)\n...\na = [1, 2, 3]\n\nand then later you decide to change the declaration to allocatable:\nreal, allocatable :: a(:)\nallocate(a(3))\n...\na = [1, 2, 3]\n\nThen in the line a = [1, 2, 3] there is now performance overhead.\n\nIs the overhead due to a run-time check that the RHS has the same shape as the LHS, or due to the reallocation on assignment always happens, even if the shape is the same?\n\nBasically\n..., allocatable :: a\na = [1, 2, 3]\ngets translated to this\nlogical :: dealloc\ndealloc = .false.\ndo i = lbound(a), ubound(a)\ndealloc = dealloc .or. size(a,dim=i) /= size(RHS, dim=i)\nend do\nif ( dealloc ) then\ndeallocate(a)\nallocate(a, mold=RHS)\nend if\na(...) = RHS(...)\n\nIf the latter, that's compiler dependent, no? A compiler should be able to check at run-time if the array needs reallocating.\n\nI have seen the same behaviour on both Intel and GCC, but yes, compilers could handle this differently.\n\n\nI wonder if for this reason one should never use a = [1, 2, 3] and instead always use a(:) = [1, 2, 3]\n\nWhat happens if the re-allocation is desired, for example if size(a) == 3 and then you do a(:) = [1, 2, 3, 4]? In this case, I want re-allocation and not a run-time error.\n\nWell you have nothing to do, then it won't allow reallocation. It isn't allowed by the specification (as far as I remember)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-04-06 18:36:51+00:00",
                    "text": "@zerothi Okay, got it, that's clear now. So this:\n\nI wonder if for this reason one should never use a = [1, 2, 3] and instead always use a(:) = [1, 2, 3]\n\napplies only when we know reallocation is not intended, which I didn't make the connection at first."
                },
                {
                    "user": "zerothi",
                    "date": "2020-04-06 18:39:17+00:00",
                    "text": "applies only when we know reallocation is not intended, which I didn't make the connection at first.\n\nexactly."
                },
                {
                    "user": "certik",
                    "date": "2020-04-06 19:25:31+00:00",
                    "text": "I have seen the same behaviour on both Intel and GCC, but yes, compilers could handle this differently.\n\n@zerothi how could compilers handle it differently?"
                },
                {
                    "user": "zerothi",
                    "date": "2020-04-06 19:27:36+00:00",
                    "text": "There could be flags that disable such checks and force array dimensions to be the same. This is just a guess and I don't know if it is there. Hence could ;)"
                },
                {
                    "user": "certik",
                    "date": "2020-04-06 19:29:42+00:00",
                    "text": "Both GFortran and Intel have such an option, see, e.g.: https://software.intel.com/en-us/fortran-compiler-developer-guide-and-reference-standard-realloc-lhs. I didn't know if that's what you were talking about, or something else."
                },
                {
                    "user": "zerothi",
                    "date": "2020-04-08 05:21:18+00:00",
                    "text": "Both GFortran and Intel have such an option, see, e.g.: https://software.intel.com/en-us/fortran-compiler-developer-guide-and-reference-standard-realloc-lhs. I didn't know if that's what you were talking about, or something else.\n\nYes."
                }
            ]
        },
        {
            "number": 113,
            "user": "jvdp1",
            "date": "2020-01-19 09:42:00+00:00",
            "title": "Proposal for descriptive statistics",
            "text": "Overview\nIt would be nice to have a module in stdlib that provides functions for computing means,variances, medians, ... of vectors, and of rows (columns) of 2D-arrays (at least).\nE.g.,\nreal :: res\nreal, allocatable :: res1(:)\nreal :: vector(5), mat(6,5)\n...\nres = mean(vector)\nres1 = mean(mat) !returns the mean of each row of mat\nres1 = mean(mat, dim = 2) !returns the mean of each column of mat\nThe same could be implemented for variance, median, ... So the API of all functions would be (almost) the same.\nAPI\nLet 's discuss the API of only mean for a vector first, and then for an array.\nFor a vector:\nfunction mean_sp_sp(vector) result(res)\n    real(sp), intent(in) :: vector(:)\n    real(sp) :: res\nend function\nFor a 2D array:\nfunction mean_sp_sp(mat, dim) result(res)\n    real(sp), intent(in) :: mat(:,:)\n    integer, intent(in), optional :: dim !dim = 1 or dim = 2 \n    real(sp), allocatable :: res(:)\nend function\nIf dim = 1, it returns the mean of each row (so res(1:size(mat,1))).\nIf dim = 2, it returns the mean of each column (so res(1:size(mat,2))).\nHere (generated manually with fypp) is an example for mean in stdlib.\nThe same API could be used for variance, median, cumulative sum, geometric mean, ...\nShould we support arrays of rank > 2? E.g., what would return mean(mat(:,:,:,:), dim =3)?\nShould we use functions or subroutine (and overload =)?:\nThe result of the procedure would be of the same kind as the input, and (implicit) conversion would be performed by the user. Functions could then be used.\nAlternatively:\nFor real arrays, procedures would return a result of the same kind, or of a lower kind, of the argument (e.g., a mean of a dp array would return the result in sp or dp). All computations inside the procedure would be performed in the same kind as the input array, and the result would be converted just before the function returns the result.\nFor integer arrays, procedures would return a result of a real kind (e.g., a mean of a int64 array would return the result in sp, dp, or qp). All computations inside the procedure would be performed in the same kind as  the result.\nImplementation\nProbably most of us have some implementations. @leonfoks has also an implementation for 1D array on Github.\nI would think about a module called stdlib_experimental_stat.f90 and multiple submodules (one per stat, e.g., stdlib_experimental_stat_mean.f90, that contains all functions related with that stat).\nThe first PR would contain only one stat, e.g. mean to facilitate the discussion.\nCurrently in stdlib\nmean (mean)\nvariance (var)\ncentral moment (moment)\nPossible additional functions\nstandard deviation (std)\nmedian (median)\nmode (mode)\nOthers\ncovariance (cov)\ncorrelation (corr)\nOther languages\nMatlab\nNumpy\nOctave\nR",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-19 17:52:17+00:00",
                    "text": "Let's talk about the API of mean, as you suggested. This looks good:\nfunction mean_sp_sp(vector) result(res)\n    real(sp), intent(in) :: vector(:)\n    real(sp) :: res\nend function\nI assume the user facing function will be just mean.\nRegarding the 2D version:\nfunction mean_sp_sp(mat, dim) result(res)\n    real(sp), intent(in) :: mat(:,:)\n    integer, intent(in), optional :: dim !dim = 1 or dim = 2 \n    real(sp), allocatable :: res(:)\nend function\nI would not use allocatable result. For speed reasons, the lowest level API should assume the user knows the length.\nRegarding the dim parameter name, we have to be careful of its meaning.\nLet's first talk about the intrinsic sum function that's already available and try to understand how that works:\n\nFortran sum: the dim is an integer that excludes that dimension from the sum\nNumPy sum: the axis is either or an array of integers, in both cases it includes those dimensions in the sum\nMatlab sum: the dim is an integer that includes the dimension in the sum.\n\nSo NumPy's axis as well as Matlab's dim seem to be equivalent. Fortran, on the other hand, chose the opposite convention of using the dim to exclude a dimension.\nYour mean above uses a Matlab's convention for mean. NumPy seems to be using a different convention. Not sure which one to choose here."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-19 18:17:08+00:00",
                    "text": "Fortran sum: the dim is an integer that excludes that dimension from the sum\nNumPy sum: the axis is either or an array of integers, in both cases it includes those dimensions in the sum\nMatlab sum: the dim is an integer that includes the dimension in the sum.\n\nSo NumPy's axis as well as Matlab's dim seem to be equivalent. Fortran, on the other hand, chose the opposite convention of using the dim to exclude a dimension.\nYour mean above uses a Matlab's convention for mean. NumPy seems to be using a different convention. Not sure which one to choose here.\n\nFor me, Matlab and Fortran dim  option for sum behave in the same way (e.g., sum(mat(1:4,1:2),dim=2) will return an array of dimention 4). However, the default behaviour is different between Fortran (returns the sum of the whole array) and Matlab (returns the sum for dim = 1). After checking, my proposition does not follow these rules of dim.\nSo I would propose to use the same behaviour as Fortran sum (with the same name dim).\nIt would be also in agreement with the function size and it behaviour with dim.\n\nI would not use allocatable result. For speed reasons, the lowest level API should assume the user knows the length.\n\nI agree for speed, while I think it would be very inconvenient. Should the API be something like that:\nfunction mean_sp_sp(mat, n, dim) result(res)\n    real(sp), intent(in) :: mat(:,:)\n    integer, intent(in) :: n\n    integer, intent(in), optional :: dim !dim = 1 or dim = 2 \n    real(sp), allocatable :: res(n)\nend function"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-19 19:07:46+00:00",
                    "text": "Regarding using allocatable as result, I think we can adopt a rule of thumb to not use allocatable unless necessary to make it work, but the priority should be ease of use. If assumed-size result requires more complex API, we should use an allocatable result.\n\nFortran sum: the dim is an integer that excludes that dimension from the sum\n\nI'm not sure what you mean by \"includes\" or \"excludes\", but in case of Fortran, the sum is performed along dim:\nreal :: a(2,3,4) = 1\nprint *, shape(sum(a, 2))\nend\noutputs:\n           2           4\n\nThis behavior is both Fortrannic and intuitive. It's consistent with numpy, I don't know about Matlab. It seems to me as the only reasonable behavior.\nA notable difference between Fortran's sum(x, dim) and Python's np.sum(x, axis) (I don't know about Matlab) is that Fortran always reduces the rank by 1 (dim must be a scalar). With numpy, axis can be a list or a tuple to perform reduction along multiple axes.\nstdlib's generic mean could accept both a scalar or a rank-1 array for dim:\n\nIf scalar, behaves the same way as for sum and others;\nIf array, it invokes the scalar version iteratively to reduce multiple dimensions in a single call; (however perhaps this precludes assumed-size result)\n\nA minor nit-pick about the API, I suggest that we don't insinuate a vector/matrix as input, as they're linear algebra-specific and imply rank in the name. Instead, I suggest use a more general name considering we should support any number of dimensions. For arrays I just like plain x:\nfunction mean_sp_sp(x) result(res)\n    real(sp), intent(in) :: x(:)\n    real(sp) :: res\nend function\nFor a 2-d array, passing the result size as an input is an unacceptable API in my opinion. Is there any other way we could do assumed-size result for reducing a 2-d (or multi-d) array?\nAnother important point of discussion: Should a mean of an integer array be an integer or a real?"
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-19 19:18:24+00:00",
                    "text": "I believe the mean of an integer array should be dp.  The result can be converted if needed.  Numpy returns a float from mean(int array)"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-19 19:26:32+00:00",
                    "text": "A notable difference between Fortran's sum(x, dim) and Python's np.sum(x, axis) (I don't know about Matlab) is that Fortran always reduces the rank by 1 (dim must be a scalar). With numpy, axis can be a list or a tuple to perform reduction along multiple axes.\nstdlib's generic mean could accept both a scalar or a rank-1 array for dim:\n\nIf scalar, behaves the same way as for sum and others;\nIf array, it invokes the scalar version iteratively to reduce multiple dimensions in a single call; (however perhaps this precludes assumed-size result)\n\n\nI would suggest to implement first the same behaviour as Fortran sum. We can see how to implement the Python behaviour later.\n\nA minor nit-pick about the API, I suggest that we don't insinuate a vector/matrix as input, as they're linear algebra-specific and imply rank in the name. Instead, I suggest use a more general name considering we should support any number of dimensions. For arrays I just like plain x:\nfunction mean_sp_sp(x) result(res)\n    real(sp), intent(in) :: x(:)\n    real(sp) :: res\nend function\n\nGood to know.\n\nFor a 2-d array, passing the result size as an input is an unacceptable API in my opinion. Is there any other way we could do assumed-size result for reducing a 2-d (or multi-d) array?\n\nI agree. Below is a possible workaround for 2D arrays (I just tried it; this implementation gives the same behaviour as Fortran sum):\ninterface mean\n    module function mean_1_sp_sp(x) result(res)\n        real(sp), intent(in) :: x(:)\n        real(sp) ::res\n    end function\n...\n    module function mean_2_all_sp_sp(x) result(res)\n        real(sp), intent(in) :: x(:,:)\n        real(sp) ::res\n    end function mean_2_all_sp_sp\n...\n    module function mean_2_sp_sp(x, dim) result(res)\n        real(sp), intent(in) :: x(:,:)\n        integer, intent(in) :: dim\n        real(sp) :: res(size(x)/size(x, dim))\n    end function mean_2_sp_sp\n...\nend interface\n\nAnother important point of discussion: Should a mean of an integer array be an integer or a real?\n\nIMHO, it should be always a real (for integer and real arrays)."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-19 19:57:17+00:00",
                    "text": "Minor comment, I think this last iteration is better than using the optional argument dim.  Let the interface handle the look up on function names.  I believe optional arguments hit runtime? Thus leading to slow down?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-19 20:03:24+00:00",
                    "text": "I don't think we can use optional because the result is a scalar if dim is provided and array otherwise, and we need to specify that at compile-time."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-19 20:08:05+00:00",
                    "text": "@milancurcic this interface don't use optional (and neither allocatable; the result is a scalar if dim is NOT provided, and an array otherwise; the interface handle that):\ninterface mean\n    module function mean_1_sp_sp(x) result(res)\n        real(sp), intent(in) :: x(:)\n        real(sp) ::res\n    end function\n...\n    module function mean_2_all_sp_sp(x) result(res)\n        real(sp), intent(in) :: x(:,:)\n        real(sp) ::res\n    end function mean_2_all_sp_sp\n...\n    module function mean_2_sp_sp(x, dim) result(res)\n        real(sp), intent(in) :: x(:,:)\n        integer, intent(in) :: dim\n        real(sp) :: res(size(x)/size(x, dim))\n    end function mean_2_sp_sp\n...\nend interface\nThis has the same behaviour as Fortran sum for 1D and 2D arrays"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-19 20:28:31+00:00",
                    "text": "@jvdp1 Yes, I was responding to @leonfoks regarding optional. I think your interface is the way to go.\nI couldn't find a viable solution for 3 or higher dimensional input arrays though."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-19 20:34:12+00:00",
                    "text": "@jvdp1 Yes, I was responding to @leonfoks regarding optional. I think your interface is the way to go.\n\nSorry @milancurcic for the misunderstanding\n\nI couldn't find a viable solution for 3 or higher dimensional input arrays though.\n\nMe neither. Any idea how it is implemented for Fortran sum?\nIf the community doesn't find a solution (I don't believe that :) ), should we first implement something for 1D and 2D arrays, and see later how to do it for >2D arrays (as for loadtxt and savetxt)?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-19 22:56:58+00:00",
                    "text": "For integer arrays, the API could look like:\n    module function mean_1_int8_dp(x) result(res)\n        integer(int8), intent(in) :: x(:)\n        real(dp) :: res\n    end function mean_1_int8_dp\nIf the array is integer, the result will be always dp."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-20 10:09:12+00:00",
                    "text": "@milancurcic @certik @leonfoks I found a workaround (using the Fortran merge; edit: simpler version than the initial one) for 3D arrays (without using a function with an allocatable array) when dim is always a scalar. I am not sure about the performance of this workaround, but it allows the function mean to have the same behaviour as the Fortran sum, and it could be easily extended to ranks >3.\nFunction: mean(x) or mean(x, dim) (for 1D, 2D, 3D arrays)\nAs it is now implemented here, it returns the mean of array elements of 1D, 2D, 3D arrays.\nIf dim is absent, a scalar with the mean of all elements in x is returned.\nif dim is present, an array of rank n-1, where n equal the rank of x, and a shape similar to that of x with dimension dim droppped is returned. The returned array contains the mean of the elements of x along dimension dim.\nThe result is of the same type as the array for real arrays, or is dp for integer arrays.\nIssue: I tried to use pure functions. While it compiled well with manual Makefile, CMake 3.16.1 does not like submodules + pure functions. Am I alone with this issue?\nAPI for dp\ninterface mean\n    module function mean_1_dp_dp(x) result(res)\n        real(dp), intent(in) :: x(:)\n        real(dp) :: res\n    end function mean_1_dp_dp\n\n    module function mean_1_int8_dp(x) result(res)\n        integer(int8), intent(in) :: x(:)\n        real(dp) :: res\n    end function mean_1_int8_dp\n\n\n    module function mean_2_all_dp_dp(x) result(res)\n        real(dp), intent(in) :: x(:,:)\n        real(dp) :: res\n    end function mean_2_all_dp_dp\n\n    module function mean_2_all_int8_dp(x) result(res)\n        integer(int8), intent(in) :: x(:,:)\n        real(dp) :: res\n    end function mean_2_all_int8_dp\n\n    module function mean_2_dp_dp(x, dim) result(res)\n        real(dp), intent(in) :: x(:,:)\n        integer, intent(in) :: dim\n        real(dp) :: res(size(x)/size(x, dim))\n    end function mean_2_dp_dp\n\n    module function mean_2_int8_dp(x, dim) result(res)\n        integer(int8), intent(in) :: x(:,:)\n        integer, intent(in) :: dim\n        real(dp) :: res(size(x)/size(x, dim))\n    end function mean_2_int8_dp\n\n\nmodule function mean_3_all_dp_dp(x) result(res)\n    real(dp), intent(in) :: x(:,:,:)\n    real(dp) :: res\nend function mean_3_all_dp_dp\n\nmodule function mean_3_all_int8_dp(x) result(res)\n    integer(int8), intent(in) :: x(:,:,:)\n    real(dp) :: res\nend function mean_3_all_int8_dp\n\nmodule function mean_3_dp_dp(x, dim) result(res)\n    real(dp), intent(in) :: x(:,:,:)\n    integer, intent(in) :: dim\n    real(dp) :: res( &\n                  merge(size(x,1),size(x,2),mask = 1 < dim, &\n                  merge(size(x,2),size(x,3),mask = 2 < dim )\nend function mean_3_dp_dp\n\nmodule function mean_3_int8_dp(x, dim) result(res)\n    integer(int8), intent(in) :: x(:,:,:)\n    integer, intent(in) :: dim\n    real(dp) :: res( &\n                  merge(size(x,1),size(x,2),mask = 1 < dim, &\n                  merge(size(x,2),size(x,3),mask = 2 < dim )\nend function mean_3_int8_dp\n\nend interface"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-20 17:12:05+00:00",
                    "text": "@jvdp1 Great! This is the exactly the solution I was trying to find yesterday but couldn't figure it out. Yes, it looks like it will expand nicely to as many dims as we need. We can do as many as 15, though I never worked with more than 5-d arrays. There's a typo in your interface (missing parentheses):\nmodule function mean_3_dp_dp(x, dim) result(res)\n    real(dp), intent(in) :: x(:,:,:)\n    integer, intent(in) :: dim\n    real(dp) :: res(merge(size(x, 1), size(x, 2), mask = 1 < dim), &\n                    merge(size(x, 2), size(x, 3), mask = 2 < dim))\nend function mean_3_dp_dp"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-20 17:15:31+00:00",
                    "text": "I am not too concerned about performance here. Arguments to merge are all scalar so this should reduce internally to if-branches at compile time.\nAlso, for stdlib I'd like to stress and re-iterate, easy of use and nice API should take priority over performance. Let's worry about making a great API first, then if needed work on performance within constraints of a great API design."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-20 17:23:32+00:00",
                    "text": "Yes, it looks like it will expand nicely to as many dims as we need. We can do as many as 15, though I never worked with more than 5-d arrays.\n\nI use fypp to generate the files. I will give a try to extend them to 15 dimensions.\n\nThere's a typo in your interface (missing parentheses):\n\nSorry. Too fast copy-paste..."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-20 17:27:22+00:00",
                    "text": "I am not too concerned about performance here. Arguments to merge are all scalar so this should reduce internally to if-branches at compile time.\n\nMe neither. For such functions, I prefer the functionality than efficiency. If I need efficiency, I would probably implement it myself anyway.\n\nAlso, for stdlib I'd like to stress and re-iterate, easy of use and nice API should take priority over performance. Let's worry about making a great API first, then if needed work on performance within constraints of a great API design.\n\nCurrently the proposed API for mean is the same as Fortran sum, maxval, minval (if we ignore the mask argument).\nWould it be possible to implement a mask in mean?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-20 17:54:30+00:00",
                    "text": "I agree to try to stick to Fortran conventions. Regarding performance, I would say great API and great performance are equal --- we can sacrifice a little bit of one to get a lot of the other, on a case by case basis. We should try not to sacrifice a lot of either."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-20 21:12:17+00:00",
                    "text": "I think everybody agrees on the following API of mean which follows Fortran conventions, and similar to Fortran sum, minval, maxval,...\nresult = mean(x)\nresult = mean(x, dim)\nwith x being an array of type 'integer' and 'real', and 'dim' a scalar with a value in the range from 1 to n (with n <=15), where n equals the rank of x.\nThe same Fortran conventions should be used for other similar functions (median, variance, standard deviation, geometric mean,...).\nFor performance, the current implementation might be good with merge. I tried to use pure functions, but it seems there is an issue with CMake and submodules. do concurrent could then be used.\n@certik @milancurcic @leonfoks @ivan-pi @scivision\nShould I write a spec and submit a PR? Or do we need another iterate on the API?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-20 21:41:58+00:00",
                    "text": "Great work on this interface!\nMy only concern is what will be the default behavior if the user passed dim is larger than the rank of the array? Should the code simply fail?\n\ndo concurrent could then be used.\n\nCould do concurrent modify the calculation sequence, meaning slightly different round-off errors upon each evaluation? (e.g. when compiled with the -qopenmp flag in Intel Fortran)."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-20 22:07:16+00:00",
                    "text": "My only concern is what will be the default behavior if the user passed dim is larger than the rank of the array? Should the code simply fail?\n\nI just added a\ncall error_stop(\"ERROR (mean): wrong dimension\")\nThe issue is that the functions cannot be pure anymore.\n\nCould do concurrent modify the calculation sequence, meaning slightly different round-off errors upon each evaluation? (e.g. when compiled with the -qopenmp flag in Intel Fortran).\n\nI think so (at least if auto-parallelisation or OpenMP is used)."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-21 13:45:01+00:00",
                    "text": "MEAN - mean of array elements\nDescription\nReturns the mean of all the elements of ARRAY, or of the elements of ARRAY along dimension DIM.\nSyntax\nRESULT = mean(ARRAY)\nRESULT = mean(ARRAY, DIM)\nArguments\nARRAY: Must be an array of type INTEGER, or REAL.\nDIM (optional): Must be a scalar of type INTEGER with a value in the range from 1 to n, where n equals the rank of ARRAY.\nReturn value\nIf ARRAY is of type REAL, the result is of the same type as ARRAY.\nIf ARRAY is of type INTEGER, the result is of type as double precision.\nIf DIM is absent, a scalar with the mean of all elements in ARRAY is returned. Otherwise, an array of rank n-1, where n equals the rank of ARRAY, and a shape similar to that of ARRAY with dimension DIM dropped is returned.\nExample\nprogram test\n    use stdlib_experimental_stat, only: mean\n    implicit none\n    real :: x(1:6) = (/ 1., 2., 3., 4., 5., 6. /)\n    print *, mean(x)                            !returns 21.\n    print *, mean( reshape(x, (/ 2, 3 /) ))     !returns 21.\n    print *, mean( reshape(x, (/ 2, 3 /) ), 1)  !returns (/ 3., 7., 11. /) \nend program\n\n@certik @milancurcic @nncarlson Is such a specification document (in Markdown) desired alongside the module?\nIf this API for mean is acceptable and also the document, I will create a PR for discussing its implementation (style, efficiency, ...). I implemented it up to 15 dimensions (with fypp).\nWhen the implementation will be ok, the implementation of a mask should be easy.\nThis mean function may also be used as a reference for other descriptive statistics (e.g., variance)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-21 16:07:55+00:00",
                    "text": "Thanks @jvdp1!\n\nIs such a specification document (in Markdown) desired alongside the module?\n\nI'd say yes.\nEditorial nit-picks:\n\nI recommend using monospace lowercase instead of uppercase, for example array and dim instead of ARRAY and DIM;\nUse modern array constructor syntax, for example [2, 3] instead of (/2, 3/). This should go into style guide as well;\nRegarding module name, I suggest stats instead of stat, which can be confused for \"status\"."
                },
                {
                    "user": "certik",
                    "date": "2020-01-21 17:50:17+00:00",
                    "text": "@jvdp1 thank you for starting this!\nI suggest we put it along side the module for now. Later on, I would like to have some automatic mechanism to parse these semantically (i.e., the tool would understand the sections as well as perhaps even the Fortran code) and produce nice online and pdf documentations."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-01 19:52:34+00:00",
                    "text": "See the draft PR #153 with a proposal for the k-th order central moment of an array.\nQuestion: should such a function only support central moment, or should it also support absolute central moment, raw moment, and absolute raw moment?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-22 19:35:24+00:00",
                    "text": "See the draft PR #153 with a proposal for the k-th order central moment of an array.\n\nA function moment() was implemented, and provided only the k-th central moment.\nBased on the discussion in #153, the PR #161  proposes a function moment that provides raw and central moments. The means must be provided by the user. Go to #161 for more discussion."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-28 11:44:05+00:00",
                    "text": "In the email lists of the ISO C++ Study Group 19 (Machine Learning) I found the following proposal for simple statistical functions: https://docs.google.com/document/d/1VAgcyvL1riMdGz7tQIT9eTtSSfV3CoCEMWKk8GvVuFY/edit\nThe  proposed functions include the mean, median, mode, population_stddev, sample_stddev, population_var and sample_var.\n@certik Do you know if the ISO Fortran committee also has such working groups for different application fields?"
                },
                {
                    "user": "certik",
                    "date": "2020-07-28 16:58:16+00:00",
                    "text": "The Fortran committee has a group for HPC. I think that is the only application field --- the committee does not have many people, but as the committee grows, it could have more working groups in the future. CCing @sblionel, he might have some thoughts on this."
                },
                {
                    "user": "sblionel",
                    "date": "2020-07-28 18:17:30+00:00",
                    "text": "I don't have an adequate background in statistics to know if people writing statistics applications in Fortran would find it useful to have these functions in the language rather than in a separate library, nor even if that is a sizeable body of users. Fortran's emphasis is on scientific and engineering programming, of which HPC is closely related. I could certainly see these in some sort of stdlib - what would be the advantage of making them intrinsics? Would programmers find that these simple interfaces are adequate for their needs, or are they likely to look for something with more options?\nThe committee members largely have engineering/science backgrounds, so we don't have a lot of experience with other application fields, and this complicates our ability to judge usefulness of features aimed at other fields. We're always looking for new members, especially if they add diversity to the committee background. Unfortunately, the structure of standards work, especially in the US (but also in some other countries) places financial burdens on those who wish to contribute. J3 (US) works around this by naming people as alternates, which costs nothing, but alternates can't vote if their principal is present.\nIt's certainly something worth thinking about, but my preference would be to have it be in stdlib first and see how well it is accepted."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-07-28 18:42:30+00:00",
                    "text": "I don't have an adequate background in statistics to know if people writing statistics applications in Fortran would find it useful to have these functions in the language rather than in a separate library, nor even if that is a sizeable body of users. Fortran's emphasis is on scientific and engineering programming, of which HPC is closely related. I could certainly see these in some sort of stdlib - what would be the advantage of making them intrinsics? Would programmers find that these simple interfaces are adequate for their needs, or are they likely to look for something with more options?\nThe committee members largely have engineering/science backgrounds, so we don't have a lot of experience with other application fields, and this complicates our ability to judge usefulness of features aimed at other fields. We're always looking for new members, especially if they add diversity to the committee background. Unfortunately, the structure of standards work, especially in the US (but also in some other countries) places financial burdens on those who wish to contribute. J3 (US) works around this by naming people as alternates, which costs nothing, but alternates can't vote if their principal is present.\nIt's certainly something worth thinking about, but my preference would be to have it be in stdlib first and see how well it is accepted.\n\nThese are functions we use often (or even daily) in my field (i.e. quantitative genetics), and therefore we re-implement these functions quite often (or we swicht to Octave/R/Julia to compute means, variances, regression coefficients, R2,...).\nHaving them as intrinsics could be useful, or at least in stdlib (e.g. as  here, with many options).\nFor me, the main advantage of having them as instrinsics would be to not link a simple program to a librabry out of which I just need var or moment functions."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-29 09:55:48+00:00",
                    "text": "Thanks @sblionel for your answer. I do not see a need to have these available as intrinsic procedures, but I do believe having them in a library such as this one can ease the experience for (new) Fortran users. An off-topic question: how does membership in national committees work? Browsing through the documents on the WG5 website, I had the feeling the national committee used to play an important role in driving Fortran development.\nIn Alan Miller's Fortran Software there are many statistical functions, indicating that Fortran was used in this field. I also have a copy of the book \"Programming for the social sciences: Algorithms and Fortran77 Coding\" (from 1986), which discusses simple statistical functions. The book \"Introduction to Computational Economics Using Fortran\" also rolls its own versions of these functions.\nToday, I am sure the majority of programmers prefer interpreted languages (Python, Julia, Matlab/Octave, R) for such work, or even spreadsheet programs (Excel, GraphPad, Origin, SPSS, etc.)."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-07-29 10:25:46+00:00",
                    "text": "Re interpreted languages: I guess that is true for interactive use where\nyou want to explore the data, but if you run into large amounts of\ninformation (say remote sensing images), a compiled language comes in quite\nhandy. I think a comprehensive set of statistical functions would be most\nwelcome. I have scanned Alan Millers' website for ideas myself :). And a\nlot of his software is rather more advanced than a mere mean value or other\ndescriptive statistics.\n\nAnother great source of algorithms is the work of Michel Olagnon. A bit of\ngoogling gave me this URL: http://www.fortran-2000.com/rank/ (and similar\nones). Michel used to be an active contributor to comp.lang.fortran.\n\nRegards,\n\nArjen\n\nOp wo 29 jul. 2020 om 11:56 schreef Ivan <notifications@github.com>:\n\u2026\n Thanks @sblionel <https://github.com/sblionel> for your answer. I do not\n see a need to have these available as intrinsic procedures, but I do\n believe having them in a library such as this one can ease the experience\n for users of Fortran. An off-topic question: how does membership in\n national committees work? Browsing through the documents on the WG5\n website, I had the feeling the national committee used to play an important\n role in driving Fortran development.\n\n In Alan Miller's Fortran Software <https://jblevins.org/mirror/amiller/>\n there are many statistical functions, indicating that Fortran was used in\n this field. I also have a copy of the book \"Programming for the social\n sciences: Algorithms and Fortran77 Coding\" (from 1986), which discusses\n simple statistical functions. The book \"Introduction to Computational\n Economics Using Fortran\" <https://www.ce-fortran.com/> also rolls its own\n versions of these functions.\n\n Today, I am sure the majority of programmers prefer interpreted languages\n (Python, Julia, Matlab/Octave, R) for such work, or even spreadsheet\n programs (Excel, GraphPad, Origin, SPSS, etc.).\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#113 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAN6YR5HQ5T7HD63B27YU6DR57W3LANCNFSM4KIYGOQQ>\n ."
                },
                {
                    "user": "sblionel",
                    "date": "2020-07-29 20:01:56+00:00",
                    "text": "An off-topic question: how does membership in national committees work? Browsing through the documents on the WG5 website, I had the feeling the national committee used to play an important role in driving Fortran development.\n\nBriefly, each National Body has its own rules for membership. Typically, you must live in that country or be employed by a company with offices in that country. Each country has its own rules for fees and intellectual property. For Fortran specifically, WG5 (ISO/IEC) delegates the development of the standard to the US NB (PL22.3 aka J3). WG5 sets the feature list and votes on drafts. Practically speaking, there are several non-J3 members who regularly participate in the development work. The only NBs that actively participate in WG5 are Canada, Germany, Japan, UK and US."
                },
                {
                    "user": "certik",
                    "date": "2020-07-29 20:07:34+00:00",
                    "text": "Re interpreted languages: with both stdlib and LFortran fully developed in a few years, I expect the experience with Fortran can be very similar as with Julia or Python in terms of interactive usage."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-27 20:50:21+00:00",
                    "text": "In testing my builds, I am having troubles compiling the statistical modules using Makefile.manual. On my machine the Makefile.manual is invoking gfortran, I suspect version 10.2. stdlib_stats_moment and stdlib_stats_var are taking forever to compile. I am not having this slowdown using Cmake, which I believe also invokes gfortran. Using Makefile.manual gfortran is also issuing a number of warnings that I suspect indicate problems for large arrays. Examples of the warnings are\nstdlib_stats_moment.f90:26261:12:\n     n = count(mask, kind = int64)\n        1\n\nWarning: Possible change of value in conversion from INTEGER(8) to REAL(4) at (1) [-Wconversion]\nand\nstdlib_stats_moment.f90:1312:12:\n     n = size(x, kind = int64)\n        1\n\nWarning: Possible change of value in conversion from INTEGER(8) to REAL(4) at (1) [-Wconversion]\nI don't think there is any advantage to invoking count and size with kind=int64 if the results are assigned to a variable of kind int32."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-27 21:02:29+00:00",
                    "text": "FWIW the command line for the Makefile.manual invocation of gfortran is\ngfortran -Wall -Wextra -Wimplicit-interface -fPIC -g -fcheck=all -c stdlib_stats_moment.f90"
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-09-27 21:20:09+00:00",
                    "text": "That looks to me like n is declared as a real, which is likely an error (although I haven't looked at the code)."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-27 21:23:34+00:00",
                    "text": "You\u2019re right I misread it.\n\u2026\n On Sep 27, 2020, at 3:20 PM, Brad Richardson ***@***.***> wrote:\n\n\n That looks to me like n is declared as a real, which is likely an error (although I haven't looked at the code).\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub <#113 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APTQDOUIQNP7KPO26MEF46LSH6UBLANCNFSM4KIYGOQQ>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-27 22:00:42+00:00",
                    "text": "That looks to me like n is declared as a real, which is likely an error (although I haven't looked at the code).\n\nn is the denominator of (possibly) multiple operations (divisions) between reals (sp,dp, or qp). Therefore, storing n as real requires only 1 conversion.\n\nIn testing my builds, I am having troubles compiling the statistical modules using >Makefile.manual. On my machine the Makefile.manual is invoking gfortran, I suspect >version 10.2. stdlib_stats_moment and stdlib_stats_var are taking forever to compile.\n\nThere are hundreds of functions to compile in both submodules. Limilting the RANK to 4 might reduce the compilation time."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-09-27 22:21:48+00:00",
                    "text": "n is the denominator of (possibly) multiple operations (divisions) between reals (sp,dp, or qp). Therefore, storing n as real requires only 1 conversion.\n\nThat makes sense. At some point, as low hanging fruit for somebody, I'd recommend putting in the explicit conversion just to declutter the warning messages at least."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-28 16:06:40+00:00",
                    "text": "At some point, as low hanging fruit for somebody, I'd recommend putting in the explicit conversion just to declutter the warning messages at least.\n\nAt the time of implementation, I recommended to let compiler use mixed-mode arithmetic and not do explicit conversion. I won't dig out the specific comment and thread, but I vaguely remember that this wasn't a universally preferred opinion and we just went with it.\nI personally don't appreciate some of gfortran's overly paranoid warnings about correct use of the language. In this specific example, it's okay--it could be useful to a user to know that there is implicit conversion happening. A more grave example is when gfortran warns you about trying to allocate a string on assignment (triggers -Wuninitialized). This is why I prefer carefully disabling some warnings rather than adding unnecessary explicit stuff to the code just to make the compiler happy.\nBut it's not only about the compiler. The code may be easier to understand with an explicit real() conversion. It's just that I am so used to mixed-mode arithmetic that redundant real() calls only add noise. But that's just me. If people prefer explicit, although unnecessary, type conversions in the code, I agree with the change."
                },
                {
                    "user": "certik",
                    "date": "2020-09-28 16:08:43+00:00",
                    "text": "I personally (I think) prefer explicit conversions between arithmetic, it helps to prevent unintended loss of accuracy."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-28 16:15:44+00:00",
                    "text": "@certik There's no loss of accuracy. Compiler will correctly promote the type as per language rules. This is purely about explicit and verbose vs. implicit and concise.\n$ cat mixed_mode1.f90 \ninteger :: a = 3\nreal :: b = 1.234, c\nc = a * b\nprint *, c\nend\n$ cat mixed_mode2.f90 \ninteger :: a = 3\nreal :: b = 1.234, c\nc = real(a) * b\nprint *, c\nend\n$ gfortran -S mixed_mode1.f90\n$ gfortran -S mixed_mode2.f90\n$ diff mixed_mode1.s mixed_mode2.s \n1c1\n< \t.file\t\"mixed_mode1.f90\"\n---\n> \t.file\t\"mixed_mode2.f90\"\n5c5\n< \t.string\t\"mixed_mode1.f90\"\n---\n> \t.string\t\"mixed_mode2.f90\""
                },
                {
                    "user": "certik",
                    "date": "2020-09-28 16:24:05+00:00",
                    "text": "@milancurcic I don't think there is any warning in the example you posted:\ninteger :: a = 3\nreal :: b = 1.234, c\nc = a * b\nprint *, c\nend\nSuch usage is fine and indeed there is no loss of accuracy. However in this example:\ninteger :: a = 3, c\nreal :: b = 1.234\nc = a * b\nprint *, c\nend\nYou get a warning and I personally like this warning, because you lose accuracy, and it might not have been intended by me:\n$ gfortran -Wall a.f90 \na.f90:3:4:\n\n c = a * b\n    1\nWarning: Possible change of value in conversion from REAL(4) to INTEGER(4) at (1) [-Wconversion]"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-28 16:29:20+00:00",
                    "text": "Okay, yours is a better example. But explicit cast still doesn't help you:\n$ cat mixed_mode3.f90 \ninteger :: a = 3, c\nreal :: b = 1.234\nc = real(a) * b\nprint *, c\nend\n$ gfortran -Wall mixed_mode3.f90 \nmixed_mode3.f90:3:4:\n\n c = real(a) * b\n    1\nWarning: Possible change of value in conversion from REAL(4) to INTEGER(4) at (1) [-Wconversion]\n\nHow would you in this example use explicit cast to get rid of the warning?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-28 16:32:51+00:00",
                    "text": "Sorry, I don't think this is a good example either.\nThe relevant example is one upthread:\n     n = size(x, kind = int64)\n        1\nWarning: Possible change of value in conversion from INTEGER(8) to REAL(4) at (1) [-Wconversion]\n\nwhere you can put that inside of a real() as Brad suggested.\nMy point is that adding a real() here won't do anything for precision, but only for readability."
                },
                {
                    "user": "certik",
                    "date": "2020-09-28 16:42:05+00:00",
                    "text": "The example I posted gets fixed by explicit cast to an int (saying as a user to the compiler that I am explicitly trimming the real to an integer):\ninteger :: a = 3, c\nreal :: b = 1.234\nc = int(a * b)\nprint *, c\nend\nIn the example you posted:\n     n = size(x, kind = int64)\n\nThe issue is that n must be real(4) (btw, shouldn't that be an integer)? The warnings comes from the fact that the 64bit integer can't always fit into 32 bit real, and thus you lose accuracy. I.e., this works (no warning, no loss of accuracy):\ninteger(4) :: a = 3\nreal(4) :: b = 1.234\nb = a\nprint *, b\nend\nbut this produces a warning (and there is a possible loss of accuracy if the integer was large enough):\ninteger(8) :: a = 3\nreal(4) :: b = 1.234\nb = a\nprint *, b\nend\nAs a user, I personally like that, as it almost always (for me) means I made a mistake and didn't realize there is a loss of accuracy in the conversion. If I want it, I can always type it explicitly, then it is clear to both the (human) reader as well as the compiler what is intended."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-28 16:47:10+00:00",
                    "text": "Good point, I didn't consider all the possibilities and especially the one of integer being too large. Jeremie explained here why n is real."
                },
                {
                    "user": "certik",
                    "date": "2020-09-28 16:49:19+00:00",
                    "text": "It looks like the warning worked as expected: you didn't realize that there is a possible loss of accuracy. :) And the fix is to put an explicit cast to real(4) in the code, then it is clear to everybody.\nUpdate: however the compiler warning should have been worded differently: it should say that there is a possible loss of accuracy because the integer(8) might not always fit into real(4)."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-28 16:54:24+00:00",
                    "text": "It looks like the warning worked as expected: you didn't realize that there is a possible loss of accuracy. :) And the fix is to put an explicit cast to real(4) in the code, then it is clear to everybody.\n\nThank you for the explanations. I will have a look and open a PR with explicit casts for these several warnings."
                },
                {
                    "user": "certik",
                    "date": "2020-09-28 17:00:09+00:00",
                    "text": "Now, to be completely precise, you lose accuracy (in principle) any time you assign integer to real even of the same size. Here is an example:\ninteger(4) :: a = 1234567890\nreal(4) :: b = 1.234\nb = a\nprint *, a\nprint *, b\nend\nWhich does not warn, but prints:\n  1234567890\n   1.23456794E+09\n\nSo the last digit is now 4 instead of 0. But I assume this is such a common operation (32bit integer to 32bit real) that the compiler does not warn by default (you only lose \"a little\" of accuracy), and only warns if you assign a 64bit integer to 32bit real, as you might lose a lot (half the digits of the integer number in some cases I think)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-09-28 17:00:20+00:00",
                    "text": "And the fix is to put an explicit cast to real(4) in the code, then it is clear to everybody.\n\nWell, this is only a fix for clarity of the code, right?\nIf we really wanted to fix the possible loss of precision, shouldn't we use a real64 for n to accommodate very large arrays?\n$ cat huge.f90 \nuse iso_fortran_env\nprint *, huge(1_int32), huge(1_int64)\nprint *, real(huge(1_int64), kind=real32)\nprint *, real(huge(1_int64), kind=real64)\nend\n$ gfortran -Wall huge.f90 && ./a.out \nhuge.f90:3:14:\n\n print *, real(huge(1_int64), kind=real32)\n              1\nWarning: Change of value in conversion from \u2018INTEGER(8)\u2019 to \u2018REAL(4)\u2019 at (1) [-Wconversion]\nhuge.f90:4:14:\n\n print *, real(huge(1_int64), kind=real64)\n              1\nWarning: Change of value in conversion from \u2018INTEGER(8)\u2019 to \u2018REAL(8)\u2019 at (1) [-Wconversion]\n  2147483647  9223372036854775807\n   9.22337204E+18\n   9.2233720368547758E+018"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-28 17:12:13+00:00",
                    "text": "If we really wanted to fix the possible loss of precision, shouldn't we use a real64 for n to accommodate very large arrays?\n\nThe loss of precision would appear at another stage, because the n is used as the denominator in the result of the function (that is real(int32) in this case), right?\nThe kind=int64 in the intrinsic size is used to avoid issues with arrays of size that does not fit in int32 (which can be easily reached, especially when multiple dimensions are used)."
                },
                {
                    "user": "certik",
                    "date": "2020-09-28 17:16:10+00:00",
                    "text": "Well, this is only a fix for clarity of the code, right?\n\nYes. That we have thought about the issue and we \"know what we are doing\". That it is not an oversight."
                },
                {
                    "user": "wclodius2",
                    "date": "2020-09-28 17:35:56+00:00",
                    "text": "The conversion to real32 has a precision of 2**-24, and so has a round off error of about 2**-25. It is rare to have a precision this high for statistical measurements, for a standard deviation of 0.1% it would require about 2**30 measurements, i.e.,  (1/(2**-25/2**-10)**2, but I suppose for some of the fundamental constants it would be important."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-09-29 18:14:27+00:00",
                    "text": "So the last digit is now 4 instead of 0. But I assume this is such a common operation (32bit integer to 32bit real) that the compiler does not warn by default (you only lose \"a little\" of accuracy),\n\nIndeed. Such operations are mentioned by gfortran with the flag -Wconversion-extra (and there are many of them in stdlib )"
                }
            ]
        },
        {
            "number": 112,
            "user": "nshaffer",
            "date": "2020-01-18 23:55:04+00:00",
            "title": "Proposal for quadrature",
            "text": "Overview\nLet's get numerical integration into stdlib. As a baseline, here's what I'd want in a general-purpose integration module.\n\nInterfaces to QUADPACK routines, both simple wrappers and a more modern interface a la SciPy's scipy.integrate.quad.\nRoutines to integrate arrays as if they are tabulated function values. At a minimum, we'd want trapezoid rule and Simpson's rule.\nSome niche or less well-known rules that are still useful. Examples might be endpoint-corrected discrete Fourier transforms (see Numerical Recipes Sec. 13.9) and double-exponential rules.\n\nThe idea would be to provide easy-to-use and reasonably general numerical integration routines that cover 95% of what people need. Some things which are out of scope in my opinion:\n\nODE integration\nMonte Carlo integration\nBasis representations of abstract integral operators\n\nI envision having two modules: one being a light f90 wrapper for QUADPACK which expert users can use, the other being the main module with a nicer interface to QUADPACK's functionality, as well as array-integrating routines.\nIntegrating functions\nI've already written wrappers and tests for \"non-expert\" QUADPACK routines (link). All these do is create explicit interfaces and give names to magic numbers, e.g., error codes and integrand weight selectors. It will need a little refactoring to port to stdlib, but I am pretty confident that my module quadpack_interface uses all the right types, kinds, and intents to agree with the F77 routines. No need to duplicate that effort here.\nFrom a modern programmer's perspective, QUADPACK has some unattractive qualities:\n\nExplicitly passed workspace arrays with sizes requirements that are documented but not enforced in code. These mattered in the days of tight memory constraints, but nowadays, we can relieve the caller of this burden.\nOut-parameters that are not usually useful should be made optional.\nTechnical-detail in-parameters should be made optional with sensible default values.\nThe integrand function must be a scalar function of one variable. This can make it clumsy to integrate functions with additional parameters, and doing multiple integrals by nested QUADPACK calls gets cumbersome.\nRoutines for weighted integrands can be greatly simplified and clarified. For instance, qaws implements weight functions that remove algebraic/logarithmic singularities at the integration endpoints. The type of singularity is controlled by an integer argument, whose value affects the meaning of other arguments.\n\nSolving these issues should be the motivating goal of a module that delivers high-level integration functions that call down to the appropriate QUADPACK subroutines, internally handling the magic numbers, workspace array allocation, and translating return codes to proper runtime errors if necessary. I have some design sketches that I'll talk about in a later post.\nIntegrating arrays\nIntegrating arrays is a simpler task. We just need to decide how featureful we want to be with this. For reference, NumPy/SciPy provide\n\nnumpy.trapz: trapezoidal rule with either equidistant or arbitrary abscissas.\nscipy.simps: Simpson's rule with either equidistant or arbitrary abscissas.\nscipy.romb: Romberg integration, which is restricted to equidistant abscissas whose length is 2**k + 1, e.g., 1, 3, 5, 9, 17...\nscipy.cumtrapz: cumulative trapezoidal rule with optional initial value\n\nWe should have all these, except maybe Romberg integration. I don't think I have ever used it \"for real\", but maybe other people can make a case for keeping it. To this basic set of routines, I'd also like to add companion functions to trapz and simps that return the weights for a particular array of abscissas. This is useful for integrating many different arrays that represent functions tabulated on a common grid. Once you have the weights from, e.g., w = trapz_weights(x), then computing the integral is as simple as integral = dot_product(y, w).\nDetails\n\nAre there any licensing show-stoppers with QUADPACK? You always wonder with these Netlib libraries.\nWe need to decide (elsewhere) what conventions to adopt for wrapping F77 codes. Relevant aspects here are\n\ntranslating real and double precision to appropriate real kinds\nexplicit interfaces for external procedure\nmanaging workspace arrays (Module-level or subprogram-level? With or without save?)",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-19 03:33:35+00:00",
                    "text": "I would suggest to concentrate on the API. We can use QUADPACK as an implementation, or we can use something else; either way I would consider that secondary. The API however, is essential.\nHere is an implementation of Gaussian quadrature that I have been using in all my codes: https://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/quadrature.f90, it returns the points x and weights w, and the user does the actual integration using sum(f(x)*w)."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-20 16:39:57+00:00",
                    "text": "Are there any licensing show-stoppers with QUADPACK? You always wonder with these Netlib libraries.\n\nScipy is using the QUADPACK routines and is itself under the BSD license, so it should be possible.\nhttps://github.com/scipy/scipy/tree/v1.4.1/scipy/integrate/quadpack\nThere is a great Python package with tons of references for different quadratures: https://github.com/nschloe/quadpy\nFor generating classic Gaussian quadratures there are a lot of legacy codes available, unfortunately none of them have permissive licenses:\n\nI have refactored versions of some old routines by Stroud and Secrest: https://github.com/ivan-pi/stroud_quad (not sure how licensing works with code taken from old books)\nDaniele Funaro wrote a bunch of quadrature routines useful for spectral methods:\nhttp://morespace.unimore.it/danielefunaro/routines/\nThere is IQPACK, which is however under the restrictive ACM license:\nhttps://dl.acm.org/doi/abs/10.1145/35078.214351\nThere is also ORTHPOL, which is under the same restrictive ACM license:\nhttps://dl.acm.org/doi/10.1145/174603.174605\nhttps://www.cs.purdue.edu/archives/2001/wxg/codes/ORTHPOL\nLarry Young recently wrote a whole set of new routines for generating Gaussian quadrature routines:\nhttps://www.tildentechnologies.com/Numerics/index.html (no license info)\n\nGiven the large palette of Gaussian quadratures perhaps they would fit better into a separate package, but simple rules like the trapezoidal and Simpson methods could be part of stdlib."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-20 17:13:14+00:00",
                    "text": "@ivan-pi Thanks for the research! I am in the process of writing up my \"vision\" for this module, but I want to respond to one specific point. I think the huge variety of existing implementations should not stop us from defining canonical interfaces. For instance, we should not provide routines that are explicitly Gauss-Kronrod integrators or Clenshaw-Curtis integrators, or Bill-and-Ted integrators. We should have routines for \"integrate f(x) from a to b, with both a and b finite\" and \"integrate w(x)*f(x) from a to infinity with w(x)=sin(c*x)\". Then specific implementations can decide how to map the different cases to actual quadrature rules. Obviously, we will have to provide reference implementations, but that's OK.\nOn the other hand, I agree that fancy quadrature routines are a good candidate for splitting off into a separate package once stdlib matures. At that point, we can open the doors to specializations like \"clenshaw_curtis_quadrature.f90\" and \"gauss_kronrod_quadrature.f90\"."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-26 16:53:21+00:00",
                    "text": "Here's a first cut at some interfaces.\nTrapezoidal rule for arrays\nIntegrate arrays with trapezoidal rule, either with implicit abscissas (assumed equally spaced) or explicit abscissas\ninterface trapz\n    module procedure trapz_dx\n    module procedure trapz_x\nend interface trapz\n\n...\n\ncontains\n\n...\n\nfunction trapz_dx(y, dx) result(integral)\n    real, dimension(:), intent(in) :: y\n    real, intent(in) :: dx\n    real :: integral\n    ...\nend function trapz_dx\n\nfunction trapz_x(y, x) result(integral)\n    real, dimension(:), intent(in) :: y\n    real, dimension(size(y)), intent(in) :: x\n    real :: integral\n    ...\nend function trapz_x\n\nTrapezoidal weights for given abscissas\nfunction trapz_weights(x) result(w)\n    real, dimension(:), intent(in) :: x\n    real, dimension(size(x)) :: w\n    ...\nend function trapz_weights\n\nSimpson's rule for arrays\nIntegrating arrays with Simpson's rule should look the same as the trapezoidal rule. The only catch is the need to do something for the case of even-length arrays. There are three approaches to choose from:\n\nDisallow even-length arrays (throw a runtime error).\nDo Simpson's rule for an odd-length section of the array and then patch on a different rule for the remainder (e.g, Simpson's 3/8 rule).\nUse an alternative O(h\u2074) rule on the whole array.\n\nOption 1 is the simplest but also most restrictive. Option 2 is the most flexible, but a good API probably requires that all the simps_* routines take a third optional argument that gives the user some control over how the patching occurs. Option 3 is simple but may not count as \"Simpson's rule\" from a purist's perspective.\nAdaptive integration of functions\nAdaptive integration of functions can be implemented in many, many ways. This is where it's most useful to specify a fairly general API and let specific implementations decide what algorithms to use. I think adaptive 1-D integration should let users request\n\ninfinite upper and/or lower integration bounds\nweight functions\ninterior breakpoints\nabsolute and/or relative error tolerance\nrecursion limit, or some equivalent way to let the integrator \"bail out\" of a badly behaved integral\nestimate of the error in computed integral\ndiagnostic information (e.g., a return code and and/or a message)\n\nAn actual implementation does not need to honor all requests literally. For instance, if an integrator detects that the integrand decays rapidly as x->infinity, it should be allowed to truncate at a \"big enough\" x that it thinks will satisfy the requested tolerance. Or, if the user specifies a weight function, it should not be required that the implementation actually use that information in deciding what specific quadrature rule to use.\nHere are some examples of what I think adaptive integration calls should look like (not being careful about real kinds for now)\n! Integrate f(x) from x=-1 to 1 with given absolute and relative error tolerance\nintegral = quad(f, -1.0, 1.0, abstol=1e-12, reltol=1e-6)\n\n! Integrate f(x) from x=5 to x=12, with breakpoints at x=6.0 and 9.2\nintegral = quad(f, 5.0, 12.0, points=[6.0, 9.2])\n\n! Integrate f(x) from x=0 to infinity with weight function sin(8x)\nintegral = quad(f, 0.0, +inf, weight=sin_weight(8.0))\n\n! Integrate f(x) from x=-infinity to infinity with weight function 1/(x-4),\n! putting an error bound in the variable \"delta\"\nintegral = quad(f, -inf, +inf, weight=pole_weight(4.0), errbnd=delta)\n\nIn all cases, f is a function with the interface\nfunction f(x)\n    real, intent(in) :: x\n    real :: f\nend function\n\nThis is the simplest thing to start with and can be changed depending on the findings in #117.\nThere are two further non-obvious things illustrated: weights and infinite integration limits.\nWeighted integrands\nI suggest that weights be specified as instances of class(weight_t), whose extensions allow for parameterization of the weight. For instance, the definition of sin_weight might be\ntype, extends(weight_t) :: sin_weight(k)\n    ! w(x) = sin(omega*x)\n    integer, kind :: k\n    real(k) :: omega\nend type sin_weight\n\nand the definition of pole_weight might be\ntype, extends(weight_t) :: pole_weight(k)\n    ! w(x) = 1/(x-c)\n    integer, kind :: k\n    real(k) :: c\nend type pole_weight\n\nThere are lots of other weight functions one could consider including, e.g., the weights corresponding to the classical orthogonal polynomials. Making each one a distinct type makes it easier to implement weight-specific quadrature rules.\nInfinite integration bounds\n\"Infinity\" is a non-standard concept outside the IEEE modules. I opened some discussion on different mechanisms for representing infinite values in #118. Some consensus needs to be reached there before we can decide what do to for (semi-)infinite integration domains here.\nNon-adaptive integration of functions\nThe approach @certik shared for non-adaptive quadrature looks good to me. The strategy of returning the abscissas and weights make a lot of sense. Not only does it avoid recalculation for the case of doing many similar integrals, but it also allows more flexibility in the integrand function. I think we should also offer corresponding all-in-one functions that generate the weights and abscissas internally, akin to having both trapz and trapz_weights.\nOne case that doesn't work well with the \"explicit summation\" approach is when the caller wants a rule for infinite or semi-infinite domains. This is because there is no standard way to refer to \"infinity\" (again, see #118)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-27 18:15:06+00:00",
                    "text": "I think generally this API looks good to me.\nRegarding your last point, I agree we should do both --- returning the points and weights as well as have a higher level API that hides it from the user and instead requests the user to provide a callback.\nRegarding returning points and weights for an infinite domain, I've used exactly the same API as for a finite domain. Here is how it works:\nhttps://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/quad_laguerre.f90#L11\nI only implemented a few orders. It returns the points on an infinite interval [0, oo)."
                },
                {
                    "user": "fiolj",
                    "date": "2020-01-27 18:49:51+00:00",
                    "text": "Hi, I've just come across this proposal. I've been working on trying to produce something similar with some of the methods I've been in contact. My idea is/was to make an interface similar to numpy/scipy in a modern fortran, with good documentation and examples. The idea is that the project is open and driven by a community, but at this point is just starting with my vision of it. So, If possible, I'd rather merge/contribute in this ongoing project with a shared vision.\nCurrently, for integration I implemented:\n\nA version of trapz, simps for functions and data-values, with a single interface.\nA version of integrators using quadpack routines.\nA version of tanh-sinh (double exponential) integration\nA version of simpson adaptive integrator\nAll integrators, work for real and complex functions, for functions f(x) and f(x,args) (a single interface)\n\nThe project is at https://github.com/numericfor/numfor with documentation at https://numericfor.github.io/numfor/\nOf course, working alone, I've made some decision about some of the topics that are being discussed here (API, treatment of infinite, etc).\nIf something of it is useful, I'd be glad to help to integrate it to stdlib and work with the community to adapt it to a consensus API.\nRegards,\nJuan"
                },
                {
                    "user": "certik",
                    "date": "2020-01-27 19:25:54+00:00",
                    "text": "Hi @fiolj, welcome! Yes, that would be awesome if you could contribute. Indeed, the main value of stdlib is that we agree on the API as a community. The actual implementation is straightforward, as we have all done that already or can relatively easily do.\nIf you want to help, go ahead and help us reach an agreement regarding APIs and feel free to propose everything that you already implemented. You can follow the WORKFLOW."
                },
                {
                    "user": "fiolj",
                    "date": "2020-01-28 14:58:13+00:00",
                    "text": "Thanks @certik, I agree with all points by @nshaffer, the above API seems sensible.\nI would also add that may be useful to integrate not only real but also complex functions\nfunction f(x)\n  real, intent(in) :: x\n  complex :: f\nend function\n\nOther decisions (infinite limits, f(x, *args)) depend on other issues.\nRegarding the implementation, besides wrapping, I've been doing some refactoring of the QUADPACK routines. Probably there are some things to modify but I could help to put them in the preferred way starting from the version already in\nhttps://github.com/numericfor/numfor/tree/master/src/integrate/quadpack"
                },
                {
                    "user": "certik",
                    "date": "2020-01-28 16:14:05+00:00",
                    "text": "@fiolj thank you. Looking forward!\n@nshaffer it looks like you will get an agreement on the API, so it seems the next step is to create an implementation and then we can discuss the details once you send a PR."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-29 17:13:21+00:00",
                    "text": "@fiolj That is an impressive effort! I don't have the time right now to look carefully through the repo, but it looks like there are good ideas in there I haven't considered yet. Is it the case that the real \"meat\" of your computational routines lives inside cpp include files? Do you think those include files will be easy to reuse with a different preprocessor, or are they written in a very cpp-reliant way?\n@certik I will get the ball rolling with a PR that includes the simplest things. For features we're still working out (e.g., adaptive quadrature), is it OK to have stub functions that just illustrate the proposed API?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-29 17:18:56+00:00",
                    "text": "For features we're still working out (e.g., adaptive quadrature), is it OK to have stub functions that just illustrate the proposed API?\n\nI think so. It's about getting the ball rolling."
                },
                {
                    "user": "fiolj",
                    "date": "2020-01-29 17:22:06+00:00",
                    "text": "@nshaffer I was thinking on starting a project just like this...\nI think that we can use my reformatted quadpack routines as a starting point if we agree to it. I didn't want to depend on a different program and just used cpp but using fypp will make the implementation really much easier, and I think it will be quite straightforward the change. Though I haven't tried to use it yet.\nIt would be good if you can start with the proposal for the API"
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-04 19:56:39+00:00",
                    "text": "Sorry about the noise, but rethinking the API for trapz (and may be simps) may be it would make sense to implement those functions for arrays of rank larger than one, like Numpy trapz.\nLooking to the implementation of stats_mean, I think we could do something similar.\n@nshaffer is working in an implementation, thoughts on this?\nI was thinking that may be we could use something like this for the interface:\n#:include \"common.fypp\"\n#:set RANKS = range(1, MAXRANK + 1)\n#:set RC_KINDS_TYPES = REAL_KINDS_TYPES + CMPLX_KINDS_TYPES\n\n    interface trapz\n    #:for k1, t1 in RC_KINDS_TYPES\n      #:for rank in RANKS\n        #:set RName = rname(\"trapz_dx\",rank, t1, k1)\n        pure module function ${RName}$(y, dx) result(res)\n            ${t1}$, intent(in) :: y${ranksuffix(rank)}$\n            real(${k1}$), intent(in) :: dx\n            ${t1}$ :: res${reduced_shape('x', rank, 'dim')}$\n        end function ${RName}$\n      #:endfor\n    #:endfor\n\n    end interface trapz\n\nend module stdlib_experimental_quadrature\n\n\nand, similarly for the implementation:\n#:set RANKS = range(1, MAXRANK + 1)\n#:set RC_KINDS_TYPES = REAL_KINDS_TYPES + CMPLX_KINDS_TYPES\n\n  #:for k1, t1 in RC_KINDS_TYPES\n    #:for rank in RANKS\n      #:set RName = rname(\"trapz_dx\",rank, t1, k1)\n      pure module function ${RName}$(y, dx, dim) result(res)\n          ${t1}$, dimension(:), intent(in) :: y\n          real(${k1}$), intent(in) :: dx\n          ${t1}$ :: res${reduced_shape('y', rank, 'dim')}$\n          integer :: L\n          L = size(y)\n          if (dim >= 1 .and. dim <= ${rank}$) then\n              res = dx*(sum(y(2:L-1), dim) + 0.5_${k1}$*(y(1) + y(L)))\n          else\n              call error_stop(\"ERROR (trapz): wrong dimension\")\n          end if       \n      end function ${RName}$\n    #:endfor\n  #:endfor\n\n  #:for k1, t1 in RC_KINDS_TYPES\n    #:for rank in RANKS\n      #:set RName = rname(\"trapz_all_dx\",rank, t1, k1)\n      pure module function ${RName}$(y, dx) result(res)\n          ${t1}$, dimension(:), intent(in) :: y\n          real(${k1}$), intent(in) :: dx\n          ${t1}$ :: res${reduced_shape('y', rank, 'dim')}$\n          integer :: L\n          L = size(y)\n          res = dx*(sum(y(2:L-1)) + 0.5_${k1}$*(y(1) + y(L)))\n      end function ${RName}$\n    #:endfor\n  #:endfor"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-04 20:35:16+00:00",
                    "text": "@fiolj I've been thinking about that too. I support trapz (and simps) being rank-generic. In turn, trapz_weights should also be rank-generic, I would think. The use case is obvious.\nIn general, though, I think we should be judicious about which routines we make rank-generic, at least for now. Implementing generic ranks makes the source very difficult to read. One also has a great many more tests to write (in principle).\nWe are still in early stages of developing, trying different APIs and such. I think it is not a good use of our time and effort to add generic ranks to all routines that could conceivably take in a multi-dimensional array (but which cannot be made elemental). Again, for trapz and friends, the use case is obvious.\nEven so, in my initial PR, I intend to only show the 1-d API. The code will be easy to read and review. With that in place, the subsequent PR (yours, if you like) to implement generic ranks will be easier to understand compared with doing it all in one shot."
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-05 09:22:47+00:00",
                    "text": "Even so, in my initial PR, I intend to only show the 1-d API. The code will be easy to read and review.\n\nI agree with that strategy. I just didn't think on doing trapz and simps rank-generic at the time we discussed the interface, and wanted to open it for discussion.\n\nWith that in place, the subsequent PR (yours, if you like) to implement generic ranks will be easier to understand compared with doing it all in one shot.\n\nI still am not sure what is the best strategy for collaboration on medium-sizes branches like this. I don't know if it is possilbe/desirable to update two forks in parallell and make intermediate PRs between those, or just make several PRs with small pieces of code to the main repository."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-07 06:05:29+00:00",
                    "text": "Thinking on it some more, there are some API questions we need to resolve before implementing generic kinds for trapz and such. Before getting into the details, I am thinking that the most general API for, say, trapz would be\nresult = trapz(y, dx, dim [, mask])\nresult = trapz(y, dx [, mask])\nresult = trapz(y, x, dim [, mask])\nresult = trapz(y, x [, mask])\n\nIf dim is present, the rank of the result is one less than the rank of y.\nThe argument dx is either a scalar or, if rank(y) >= 2, then dx may instead be a 1-d array with size(dx) == rank(y).\nThe argument x has the same shape as y.\n\nWith that established, here are two questions I'd like opinions on:\n\nWhen dim is absent what should be the result? Most intrisic reductions (sum, maxval, etc.) produce a scalar when no dim is specified. In the context of integration, that means performing a multi-dimensional integral. To me this is the natural thing to do, but I am open to other ideas.\nWhat should mask do? In the intrinsic reduction functions, it's obvious. Here, I can think of three reasonable approaches:\n\nTreat elements of y where the mask is .false. as if they were zero. This parallels how sum behaves, but I do not think it would be useful.\nUse the mask to indicate the integration domain. For instance, if mask = [.true., .true., .false., .true., .true. true.], then trapz(y, x, mask) would be equivalent to trapz(y(1:2), x(1:2)) + trapz(y(4:6), x(4:6)). This is more useful, I think, but it has the potential to get complicated in higher dimensions.\nDon't support masked integration."
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-20 13:23:38+00:00",
                    "text": "I like your API and implementation as it is. Regarding your two questions:\n\n\nWhen dim is absent, Numpy integrates along the last dimension. In this case I like your idea of multidimensional integration and returning a scalar better.\n\n\nOn the use of mask:\n\n\n\nWhat should mask do? In the intrinsic reduction functions, it's obvious. Here, I can think of three reasonable approaches:\n1. Treat elements of `y` where the mask is `.false.` as if they were zero. This parallels how `sum` behaves, but I do not think it would be useful.\n\n2. Use the mask to indicate the integration domain. For instance, if `mask = [.true., .true., .false., .true., .true. true.]`, then `trapz(y, x, mask)` would be equivalent to `trapz(y(1:2), x(1:2)) + trapz(y(4:6), x(4:6))`. This is more useful, I think, but it has the potential to get complicated in higher dimensions.\n\n3. Don't support masked integration.\n\n\nI think the combinations of option 2 are too many to make something universally useful and we, at least at this stage, keep it simple. I would not support masked integration now."
                }
            ]
        },
        {
            "number": 111,
            "user": "jvdp1",
            "date": "2020-01-18 16:06:55+00:00",
            "title": "Classification of the issues?",
            "text": "There are now several open issues related to many topics. Several of them are related to a same scope. Would it be worthwhile to create some labels to classify a bit the issues? For example, the labels utilities, algorithms and mathematics (as the scope of stdlib)?",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-18 16:23:45+00:00",
                    "text": "I think that's a great idea. Why don't you go ahead and create labels and start labeling the issues."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-18 17:10:26+00:00",
                    "text": "Thanks @jvdp1. While you're at it, can you also create the labels for the 5 steps of development from #5? That way we can also track progress for various modules/procedures."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-18 17:11:47+00:00",
                    "text": "Sorry I mean from the WORKFLOW.md."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-18 17:21:51+00:00",
                    "text": "@milancurcic I created the 5 labels idea, API, specification, implementation and release.\nI also created labels utilities, mathematics, algorithms, and compilers, and attributed them to some of the issues."
                }
            ]
        },
        {
            "number": 110,
            "user": "certik",
            "date": "2020-01-17 19:27:56+00:00",
            "title": "Create a Fortran webpage",
            "text": "We should have a dedicated repository just for the https://fortran-lang.org/ webpage. For now let's discuss here.\nHere are some sections that I think should be part of it. There can be other sections too of course.\nFortran Ecosystem Page\nA curated page about the Fortran ecosystem. Here is one idea how it can look like:\nhttps://maulingmonkey.com/guide/cpp-vs-rust/#crates-of-note\nIt would be automatically generated from a list of projects / metadata that we provide. A good start for a list of projects would be: https://github.com/fortran-lang/stdlib/wiki/List-of-popular-open-source-Fortran-projects (#28). We would list them by category, e.g.:\n\napplications (electronic structure, mechanics, ...)\nbasic libraries (like stdlib)\nfile io (hdf5, netcdf, ...)\n\nThe idea would be for people new to Fortran to help them discover packages and to see what the status of the Fortran ecosystem is (I really like the automatic stats like number of stars, number of commits per year, number of contributors, ...).\nWe can set some minimal barrier of entry to prevent spam / pet projects. In the above wiki we arbitrarily set it at 30 stars at GitHub. We can lower it to 20 or even just 10 stars or something like that.\nFortran tutorial and reference\nWe can adapt what is at https://www.fortran90.org/ and other such pages, and then improving it as a community. We should also prominently list stdlib there.\nCompilers\nIt would list all the Fortran compilers, with links to their webpages, etc. Both commercial and open source. We would maintain a testsuite that the compiler needs to pass in order to be listed. It can be as simple as the reference Lapack plus a simple test program in the Fortran 90 style. So it would be a low barrier, but high enough so that the compiler is usable.\nCommunity\nHere is an example how such a page could look like and what information to list: https://www.rust-lang.org/community\nWe should have some forum where anything can be discussed. Right now we are organizing the Fortran community around the two repositories:\nhttps://github.com/fortran-lang/stdlib\nhttps://github.com/j3-fortran/fortran_proposals\nBut what if somebody wants to create some meetup or a Fortran conference, or just organize some hackathon, or other things, then it would be nice to have some forum where such things can be organized. Also for announcing new Fortran projects and libraries.\nEssentially this would be a place to go if you want to see what is happening in Fortran.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-01-18 02:42:21+00:00",
                    "text": "Fantastic! I agree this is a must have for the future of Fortran. Currently Fortran doesn't have a home on the internet.\nWhat should be our first step? I suggest starting with a basic landing page, and take it from there.\nExamples for inspiration:\n\nhttps://clojure.org/\nhttps://common-lisp.net/\nhttps://crystal-lang.org/\nhttps://dlang.org/\nhttps://elixir-lang.org/\nhttps://elm-lang.org/\nhttps://www.erlang.org/\nhttps://fsharp.org/\nhttps://golang.org/\nhttps://www.haskell.org/\nhttps://julialang.org/\nhttps://nim-lang.org/\nhttps://www.python.org/\nhttps://racket-lang.org/\nhttps://www.ruby-lang.org/\nhttps://www.rust-lang.org/\nhttps://ziglang.org/\n\nOf the bunch, I like Nim's website the best. I think the Fortran language page should say what Fortran is, describe the features of the language in brief notes (statically-typed, parallel, high performance etc.), and show an example code snippet upfront.\nThe landing page can lead to other pages that @certik described, and others."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-20 16:06:27+00:00",
                    "text": "This is a great idea! It would also be helpful to have a website like https://en.cppreference.com/w/cpp. The closest thing currently as far as a simple language reference goes are the gfortran and Intel Fortran compiler pages. An online webpage with content similar to Modern Fortran Explained by Metcalf and Cohen would go a long way.\n\nBut what if somebody wants to create some meetup or a Fortran conference, or just organize some hackathon, or other things, then it would be nice to have some forum where such things can be organized. Also for announcing new Fortran projects and libraries.\n\nI see a lot of potential in engaging with existing Fortran users. Last year I created a Fortran group over the meetup app: https://www.meetup.com/Fortran-User-Group-Munchen/\nIt attracted 20 users in under a week. I have yet to organize a meetup in real life.\n(For perspective, the C++ meetup group in Munich has just under 3000 members and c. 150 users come to a typical meetup.)"
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-27 01:08:54+00:00",
                    "text": "As a first step would using this site and GitHub Pages suffice?  There are limits on the amount of data that Github allows to be exported as HTML and traffic limits but everything could be at one site and a skeleton could be up in a few minutes.  Seems like there is a significant advantage to starting that way as github is already set up as a collaborative site. Then you could mirror it to a \"real\" webpage. The Fortran Wiki is also somewhere everyone could build the content collaboratively that already exists."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-20 20:37:59+00:00",
                    "text": "This is resolved. Direct any further issues to https://github.com/fortran-lang/fortran-lang.org."
                },
                {
                    "user": "certik",
                    "date": "2020-05-20 22:06:23+00:00",
                    "text": "Well, I think we have implemented all of my ideas, so we can close this issue and improve things as we go. Thanks @milancurcic, @LKedward and others to make it happen."
                }
            ]
        },
        {
            "number": 109,
            "user": "nncarlson",
            "date": "2020-01-13 23:51:24+00:00",
            "title": "Update CMakeLists handling of .mod files",
            "text": "This resolves the issue @certik noted in #108 with the NAG compiler not finding the .mod files. It's unclear to me why things worked with other compilers, as this change is not NAG-specific at all.\nThis also handles installation of the .mod files (or whatever the compiler creates) which was missing before. One question is where the .mod files should be installed. This installs them into include, but it is arguably better to install them alongside the library file in the lib directory.\nI've tested this with Intel and NAG (temporarily using the workarounds from #108).",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-14 06:16:25+00:00",
                    "text": "@scivision can you please also review this? You were the one who implemented CMAKE_Fortran_MODULE_DIRECTORY as part of #51."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-14 16:57:11+00:00",
                    "text": "This is a nice programmatic way to do this, using the CMake generators."
                },
                {
                    "user": "certik",
                    "date": "2020-01-14 18:11:35+00:00",
                    "text": "Thanks for the review @scivision and thanks for the fix @nncarlson."
                }
            ]
        },
        {
            "number": 108,
            "user": "certik",
            "date": "2020-01-13 17:12:18+00:00",
            "title": "Workarounds for NAG",
            "text": "For NAG 6.2 and the latest master (f300f4a):\n\nDoes not seem to support submodules.\n\ndiff --git a/src/CMakeLists.txt b/src/CMakeLists.txt\nindex 72b3d25..6a11a43 100644\n--- a/src/CMakeLists.txt\n+++ b/src/CMakeLists.txt\n@@ -9,12 +9,6 @@ set(SRC\n \n add_library(fortran_stdlib ${SRC})\n \n-if(f18errorstop)\n-  target_sources(fortran_stdlib PRIVATE f18estop.f90)\n-else()\n-  target_sources(fortran_stdlib PRIVATE f08estop.f90)\n-endif()\n-\n add_subdirectory(tests)\n \n install(TARGETS fortran_stdlib\ndiff --git a/src/stdlib_experimental_error.f90 b/src/stdlib_experimental_error.f90\nindex 3d932d6..b35083b 100644\n--- a/src/stdlib_experimental_error.f90\n+++ b/src/stdlib_experimental_error.f90\n@@ -3,16 +3,46 @@ use, intrinsic :: iso_fortran_env, only: stderr=>error_unit\n implicit none\n private\n \n-interface ! f{08,18}estop.f90\n-module subroutine error_stop(msg, code)\n+public :: assert, error_stop\n+\n+contains\n+\n+subroutine error_stop(msg, code)\n character(*), intent(in) :: msg\n integer, intent(in), optional :: code\n-end subroutine error_stop\n-end interface\n \n-public :: assert, error_stop\n+! Aborts the program with nonzero exit code\n+! this is a fallback for Fortran 2008 error stop (e.g. Intel 19.1/2020 compiler)\n+!\n+! The \"stop <character>\" statement generally has return code 0.\n+! To allow non-zero return code termination with character message,\n+! error_stop() uses the statement \"error stop\", which by default\n+! has exit code 1 and prints the message to stderr.\n+! An optional integer return code \"code\" may be specified.\n+!\n+! Example\n+! -------\n+!\n+! call error_stop(\"Invalid argument\")\n \n-contains\n+write(stderr,*) msg\n+\n+if(present(code)) then\n+  select case (code)\n+  case (1)\n+    error stop 1\n+  case (2)\n+    error stop 2\n+  case (77)\n+    error stop 77\n+  case default\n+    write(stderr,*) 'ERROR: code ',code,' was specified.'\n+    error stop\n+  end select\n+else\n+  error stop\n+endif\n+end subroutine\n \n subroutine assert(condition, code)\n ! If condition == .false., it aborts the program.\n\nCan't find modules compiled before (fixed by #109). Workaround is to specify -I manually:\n\ncmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_Fortran_FLAGS_DEBUG=\"-I$HOME/repos/stdlib\" .\n\nEverything then builds and tests pass (including quadruple precision).",
            "comments": [
                {
                    "user": "nncarlson",
                    "date": "2020-01-13 20:09:49+00:00",
                    "text": "NAG 7.0 just released does support submodules. I'll get it installed on our machines tonight or tomorrow.\nRegarding the need for an explicit include, something is not right in the CMakeLists.txt file; this works if done right. I'll look into it tonight."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-14 00:12:03+00:00",
                    "text": "I've put in PR #109 that fixes the issue of not finding compiled .mod files"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-14 16:49:10+00:00",
                    "text": "Yes NAG 7.0 was the first to support submodule"
                },
                {
                    "user": "certik",
                    "date": "2020-01-15 14:48:10+00:00",
                    "text": "With the latest master (dc7e49b) and NAG 7.0, there are three warnings:\n[  3%] Building Fortran object src/CMakeFiles/fortran_stdlib.dir/stdlib_experimental_error.f90.o\nNAG Fortran Compiler Release 7.0(Yurakucho) Build 7006\nWarning: /home/certik/repos/stdlib/src/stdlib_experimental_error.f90, line 34: ERROR_UNIT explicitly imported into STDLIB_EXPERIMENTAL_ERROR (as STDERR) but not used\n[NAG Fortran Compiler normal termination, 1 warning]\n[  6%] Building Fortran object src/CMakeFiles/fortran_stdlib.dir/f18estop.f90.o\nNAG Fortran Compiler Release 7.0(Yurakucho) Build 7006\nExtension: /home/certik/repos/stdlib/src/f18estop.f90, line 23: Stop-code is not constant\nExtension: /home/certik/repos/stdlib/src/f18estop.f90, line 25: Stop-code is not constant\n[NAG Fortran Compiler normal termination, 2 warnings]\n\nFor now we can ignore those.\nThen there is an error:\nError copying Fortran module \"src/mod_files//stdlib_experimental_errorestop\".  Tried \"src/mod_files/STDLIB_EXPERIMENTAL_ERRORESTOP.mod\" and \"src/mod_files/stdlib_experimental_errorestop.mod\".\nmake[2]: *** [src/CMakeFiles/fortran_stdlib.dir/depend.make:9: src/CMakeFiles/fortran_stdlib.dir/stdlib_experimental_errorestop.stamp] Error 1\nmake[1]: *** [CMakeFiles/Makefile2:93: src/CMakeFiles/fortran_stdlib.dir/all] Error 2\nmake: *** [Makefile:141: all] Error 2\n\nI think this has to do with how NAG names submodules and how cmake finds them (or not in this case)."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-15 14:53:43+00:00",
                    "text": "That NAG 7.0 error may be a bug in cmake. Similar errors happenes with other compilers until CMake fixed the bugs.\nThe NAG 7.0 warnings are due to NAG not being in Fortran 2018 syntax mode. I didn't look if nag 7.0 has a command line option to enable Fortran 2018 syntax."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-15 14:56:34+00:00",
                    "text": "-f2018 is the option we need"
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-15 15:07:37+00:00",
                    "text": "The \"copying\" thing that cmake is complaining about had me confused. But it looks like it copies the .mod files (that are created where we want them) into the CMakeFiles tree to serve as a .stamp file.\nIntel, for example, calls their compiled submodule file stdlib_experimental_error@estop.smod, whereas NAG calls it stdlib_experimental_error.estop.sub.\nI think CMake just needs to be taught how NAG behaves; 7.0 is the first version with support for submodules."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-15 15:11:11+00:00",
                    "text": "Yes that NAG file naming scheme for submodules is completely different than any other compiler so I would say there's a very high chance that CMake needs to update itself."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-15 15:14:25+00:00",
                    "text": "I'm checking the latest CMake now to be sure it's no different than 3.14.  If it doesn't work I'll submit an issue to the cmake project."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-15 15:40:08+00:00",
                    "text": "I submitted the cmake issue. If they don't act on it quickly, I'd bet it is easy to fix and submit a PR ourselves. But I'll leave it at that for now."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-15 19:16:04+00:00",
                    "text": "Well the kitware folks were very quick and helpful to point out where changes needed to be made, but labeled the issue \"not a priority for us, but you're welcome to submit a PR\". So I've gone ahead and done that.\nUpdate: Looks like it will be in 3.16.3 due out around 1/23."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-22 21:37:44+00:00",
                    "text": "https://blog.kitware.com/cmake-3-16-3-available-for-download/\nshows that Neil's support for NAG submodule was incorporated into CMake 3.16.3. Thanks!"
                },
                {
                    "user": "certik",
                    "date": "2020-01-22 21:47:03+00:00",
                    "text": "@zbeekman will be pleased that I am happy to recommend CMake 3.16.3 for stdlib. ;)"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-23 17:16:18+00:00",
                    "text": "haha, well if we need it we need it. But, for the record I wasn't advocating for the latest cmake (unnecessarily...) just for a version I knew to be reliable."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-27 19:40:54+00:00",
                    "text": "NAG could require CMake 3.16.3 like:\nif(CMAKE_Fortran_COMPILER_ID STREQUAL NAG)\n  cmake_policy(VERSION 3.16.3)\nendif()\nwhile allowing other compilers to use older CMake"
                }
            ]
        },
        {
            "number": 107,
            "user": "certik",
            "date": "2020-01-13 16:54:04+00:00",
            "title": "Workarounds for the PGI compiler",
            "text": "I am using PGI 18.10 and the latest master (f300f4a):\n\nIt does not support error stop and stderr:\n\n--- a/src/f08estop.f90\n+++ b/src/f08estop.f90\n@@ -19,22 +19,22 @@ module procedure error_stop\n !\n ! call error_stop(\"Invalid argument\")\n \n-write(stderr,*) msg\n+write(*,*) msg\n \n if(present(code)) then\n   select case (code)\n   case (1)\n-    error stop 1\n+    stop 1\n   case (2)\n-    error stop 2\n+    stop 2\n   case (77)\n-    error stop 77\n+    stop 77\n   case default\n-    write(stderr,*) 'ERROR: code ',code,' was specified.'\n-    error stop\n+    write(*,*) 'ERROR: code ',code,' was specified.'\n+    stop\n   end select\n else\n-  error stop\n+  stop\n endif\n end procedure\n\n\nIt does not support qp and it can't even declare real(qp) (it says \"kind must be positive\", but it is negative because qp is not supported). So one has to remove all qp code. #35 will fix this.\n\n\nThen there is an internal compiler error that I haven't figured out yet what causes it:\n\n\n[ 73%] Building Fortran object src/tests/io/CMakeFiles/test_open.dir/test_open.f90.o\nPGF90-F-0000-Internal compiler error. interf:new_symbol, symbol not found     629  (/users/certik/repos/stdlib/src/tests/io/test_open.f90: 4)\nPGF90/x86-64 Linux 18.10-0: compilation aborted",
            "comments": [
                {
                    "user": "scivision",
                    "date": "2020-01-14 16:48:13+00:00",
                    "text": "Until PGI 19.4, PGI struggled with Fortran 2003 and 2008 is really buggy if there at all. 19.10 was the first PGI that was usable with Fortran 2008 syntax in my opinion."
                }
            ]
        },
        {
            "number": 106,
            "user": "urbanjost",
            "date": "2020-01-10 01:52:40+00:00",
            "title": "Proleptic Gregorian Calendar and ISO-8601 support ",
            "text": "I am wondering what the interest is in Civilian Calendar functions (Starting with Proleptic Gregorian Calendar and ISO-8601 support but open to other calendar systems) ?  I think that a basic implementation should be relatively quick to produce and close-ended.\nAn example of the scope of functionality I am initially envisioning  as being part of a standard interface is encompassed in several sources\nCurrent technology:\n\nThe C/C++ date and time interfaces ( Should the interface be essentially a binding to the C interface leveraging the ISO_C_BINDING?) (C)\nThe Fortran Wiki has links to several popular interfaces\nM_time(FORTRAN:PD)\ndatetime-fortran (FORTRAN)\nlibdate from the FLIBS repository (FORTRAN)\nHigh-precision Fortran libraries such as the NASA SPICElib library is a good example if you care about Leap Seconds, Orbital Mechanics, Astronomy and GPS/Satellite communications, for example. But I personally consider this level of precision above this initiative (at this point, at least). There are some very interesting ways to flexibly handle the precision up to\nfourteen places after the decimal point. See routines like the following that talk about leap second engines and so on (unfortunately the page is alphabetical, not sorted by category):\n\n\nGR2JUL - Gregorian to Julian Calendar\nUTC2ET - UTC to Ephemeris Time\nTPARSE - Parse a UTC time string\nTPICTR - Create a Time Format Picture\nTIMOUT - Time Output\nTCHCKD - Time components are checked\nTCHECK - Time Check\nTEXPYR - Time --- Expand year\nTIMDEF - Time Software Defaults\nUNITIM - Uniform time scale transformation\nTTRANS - Time transformation\nTPARCH - Parse check---check format of strings\nTPARTV - Time string ---parse to a time vector\nTSETYR - Time --- set year expansion boundaries\nETCAL - Convert ET to Calendar format\nSPKLEF - S/P Kernel, Load ephemeris file\nSPKUEF - S/P Kernel, Unload ephemeris file\n(FORTRAN)\n\n\ntime_module.f90 a few routines (FORTRAN)\nPlease add others here",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-01-12 22:37:32+00:00",
                    "text": "Thanks for starting this issue. I believe we should have date and time handling in stdlib. Similar to #103 and #104, when we have most of date and time functionality in stdlib (no matter what API), I will happily sunset the datetime-fortran project and direct users to stdlib. Until then...\nFrom the cursory inspection of M_time, flibs/libdate, and my knowledge of datetime-fortran, my impression is:\n\nAll three provide a datetime (or similarly named) class, with integer components for year, month, and so on, and arithmetic comparison operators;\nflibs/libdate seems most basic of the three in terms of functionality, but nevertheless useful reference;\nM_time allows adding and subtracting seconds from a datetime to return a new datetime;\nM_time also provides some interesting astrological functions related to phases of the moon and similar that I didn't see in other two;\ndatetime-fortran provides a timedelta class which allows adding or subtracting arbitrary periods of time: You can do datetime +/- timedelta (returns a datetime), timedelta +/- timedelta (returns a timedelta), or datetime - datetime (returns a timedelta); datetime and timedelta are closely modeled after Python's counterparts;\ndatetime-fortran also provides interfaces to C tm struct and strftime and strptime functions, which I didn't see in other libraries.\n\nBeing the central piece, it seems to me like the first natural step for us to discuss is the datetime derived type. From datetime-fortran:\ntype :: datetime\n  integer :: year = 1\n  integer :: month = 1\n  integer :: day = 1\n  integer :: hour = 0\n  integer :: minute = 0\n  integer :: second = 0\n  integer :: millisecond = 0\nend type datetime\nUsing initializers for components allows one to instantiate with just datetime(). Perhaps that's not so useful for year, month, and day, but for hour, minute, second, and millisecond it is because it allows you to easily work with just dates: datetime(2020, 1, 12) will represent midnight of today. This is similar to Python's datetime.datetime.\n@certik @marshallward @zbeekman @jvdp1 @ivan-pi what do you think?"
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-12 23:13:39+00:00",
                    "text": "FYI: there are applications that require time computations to be more accurate than 1 millisecond."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-12 23:30:51+00:00",
                    "text": "Of course. For getting current time, pure Fortran will get us down to a millisecond. For microseconds we may need to interface C (Python dateteme gets microseconds).\nFor arithmetic, we can go as fine as we want. Will microseconds suffice? Can you list applications that you know of that would need this or more precise timekeeping?\nPerhaps we can treat this more generally by declaring datetime % second as a real of a high precision."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-13 02:11:54+00:00",
                    "text": "Actually have some of my own that need to go way below a millisecond. in the one example module (M_TIME) most of the computations are done with double precision but if you go thru the DAT array you do round to milliseconds, primarily because the DATE_AND_TIME routine only returns milliseconds.  A large amount of standard calendar use often does not go below a second for formatted output.  There were a couple of reasons to basically extend the DATE_AND_TIME function in M_TIME, including the limitations it had; some were probably similiar to why DATE_and_TIME has no unit smaller than a millisecond.\n\nA good point. What precision do we want a datetime structure to be able to hold?\n\u2026\n On January 12, 2020 at 6:13 PM Jacob Williams ***@***.***> wrote:\n\n\n     FYI: there are applications that require time computations to be more accurate than 1 millisecond.\n\n     \u2014\n     You are receiving this because you modified the open/close state.\n     Reply to this email directly, view it on GitHub #106?email_source=notifications&email_token=AHDWN3MTJ6E7BEBDYFZBNN3Q5OP2JA5CNFSM4KFBDTJ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIXG64I#issuecomment-573468529 , or unsubscribe https://github.com/notifications/unsubscribe-auth/AHDWN3IADNRGRFGDXHDG4PLQ5OP2JANCNFSM4KFBDTJQ ."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-13 03:47:40+00:00",
                    "text": "For a lot of orbit computations we will use ephemeris time (a count of seconds since 1/1/2000). As a double precision number, that gives around 1 microsecond precision for the present day. I am aware of precise orbit determination and deep space navigation applications that require more accuracy than that. I think some people use femtoseconds (1e-15 sec).\nI'm thinking more for calculations. The precision of getting the system time doesn't really matter too much to me personally."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-13 08:00:16+00:00",
                    "text": "A added a link to the SPICElib library to an alphabetical index, because it has routines with a settable precision down to 14 digits after the decimal,  allows for correcting for the accursed leap-seconds with a\n\"leap-second kernel\", uses a # character in the output formats to let the user specify how many digits to display.  Looking for a link to SPICElib documentation on just the time functions, which I thought existed but have not found.  If we look at going higher precision there are lessons to be learned there."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-13 17:42:53+00:00",
                    "text": "Combining the questions about precision that have come up and looking at the high-precision SPICElib documentation I think the type should have an element that is the precision of the \"millisecond\" element in the sense that it is the number of digits that are useful after the decimal place in a floating point representation of the \"milliseconds\" .\n\nAssuming int32 values that would let the new precision element be anything from 0 to 9. To allow the precision value to be up to 18 everything would probably be\ntype INT64.  Note that the JULIA language uses INT64 values, but has three fields for partial fractions\nnamed millisecond, microsecond, and nanosecond.\n\nSince DATE_AND_TIME is the standard routine for getting the system clock time and is mute about whether the milliseconds returned are valid or not I think it would be useful to ask for an enhancement to DATE_AND_TIME with a ninth field designating precision in the VALUE array returned or to return a new optional parameter called PRECISION.  I see where a number of implementations like PYTHON have warnings about milliseconds being potentially inaccurate, stating some system clocks return values only to the second without any way to detect this condition in DATE_AND_TIME itself.\n\nSo assuming milliseconds are being returned correctly the precision element would be 3 for DATE_AND_TIME, for example; but if not other precision values would at least let you know.\n\nMaybe even a value of -1 would mean to not even trust the seconds field and so on but I do not think that is required without a use case but it might be useful. If you converted a\ndate like \"Jan. 1st 2020\"  then you really did not know the hour, minute, second, for example\n\nAre we assuming values have to be \"valid\" times and\nso negative values are not allowed?  Actually in some stuff I wrote if you had a date representing \"Jan 11th 2020 at noon\"  and  then subtracted 100 from the hour field and then queried it as a civil calendar string it would return 100 hours earlier, so I did not \"check for valid values\" like making sure hours were positive between 0 and 24 for example.\n\nSo, a PRECISION element or not?  Or leave it at milliseconds, add other fields like JULIA, or go with a\nfloating point value?\n\nAre values allowed to be \"illegal\", like negative numbers?\n\nIf they cannot be \"illegal\" should there be a way to flag the value as \"unknown\"; maybe a logical value for a KNOWN attribute for each field?\n\n If PRECISION is allowed what should the required allowed range of the value be? If it is to be > the number of digits in \"huge(1_int32)\" can hold then it has to be a bigger than usual integer like kind=int64\n\nAnd are timezones and daylight savings and leapseconds not included in the type?  For scientific computation that is usually ignored, Civil Calendars sometimes ignore leapseconds in computations,\n... it can get complicated but I think it is important to select a model or the type described is ambigious. I would assume the type described so far is a ZULU time because there is no time zone, but I am not sure."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-13 20:22:57+00:00",
                    "text": "I wonder if this might be a use case for parameterized derived types (I confess I've never found a use case before)?:\ntype :: datetime(sec_precision)\n  integer,len :: sec_precision = 3  ! defaults to milliseconds\n  integer :: year = 1\n  integer :: month = 1\n  integer :: day = 1\n  integer :: hour = 0\n  integer :: minute = 0\n  integer :: second = 0\n  integer,dimension(sec_precision) :: fractions_of_sec = 0\nend type datetime"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-14 17:43:06+00:00",
                    "text": "My use case\ngeospace plasma physics simulations / data assimilation / remote sensing, I feel the minimum necessary precision is that integer microseconds are necessary in a datetime type. I.e. more precise is fine too.\nA typical case is a simulation evolving on microsecond timescales, assimilating data from satellites, radars, GNSS, etc. with sensor cadences from 100 microseconds to 1 second.\nSuggestion\n\nint64 microseconds\nall timekeeping parameters int64\nconvenience methods input/output real64 time e.g. for seconds and fractional second\nsome internal calculation would use real64\n\nQuestion\n\nwhat is the compromise smallest datetime \"tick\" to settle on? Windows uses int64 100 nanosecond tick.\nIs the epoch window with int64 nanoseconds too small for our Fortran audience?"
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-20 21:02:59+00:00",
                    "text": "Another FYI: the IAU SOFA library has some routines for time computations. http://www.iausofa.org"
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-23 06:35:35+00:00",
                    "text": "After looking through a good number of other languages it seems that int64 is commonly used in most recent implementations. Precision is handled in a variety of ways. Python includes additional fields called millseconds, microseconds, and nanoseconds instead of a precision value. I find that confusing and a bit vague and prefer the idea of a single integer for fractional seconds with a precision field saying how many digits of accuracy are in that. In several cases precision is lost going from single high-precision values that are in a variety of forms from Julian to Unix Epoch time to a variety of others to Civilian times. Scientific calculations seem to almost always use UTC/GMT/ZULU time and avoid the issues with timezones and Daylight Savings times; but often include corrections for leap seconds. I'm torn between whether we should seperate the two main classes (high precision computations and high-precision timing versus general Civilian calendar dates and times which seem in practice to rarely even use fractional seconds).  But especially if we try to have one type that covers it all, I agree integer values should be int64 and floats should be at least real64. I find it unlikely any relevant system would not have real64 so that seems reasonable. But most scientific calculations I found just used intrinsic types for precise computations, so I am still wondering whether it is reasonable to make a single type for all time-related functions.  And I have not seen much dialog on whether the type should include timezone information. It seems in business applications in particular that it is important to know the data was generated in a particular time zone; where it appears to be rare that scientific calculations care much about timezones when doing computations; and the timezones appear to just be a potential cause of errors. Still, I would say we go with the proposed type but specify it to be int64, and add a numeric-only timezone field similar to the Fortran intrinsic DATE_AND_TIME(3), and add another field called PRECISION that indicates the number of significant digits in the \"millisecond\" field and rename it to something like \"fractional seconds\".  Promising that much precision basically implies we consider leap seconds, which I was hoping to at least initially ignore.."
                }
            ]
        },
        {
            "number": 105,
            "user": "leonfoks",
            "date": "2020-01-09 04:58:03+00:00",
            "title": "stdlib group with separate but related repositories?",
            "text": "There is quite a wide variety of proposals.\nDoes it make sense ahead of time to split the stdlib into defined parts like numpy and scipy have done?\nI can see maths, sorting, random numbers, linalg etc. going into NumFortran?\nKdTrees, interpolation, splines, etc. going into SciFortran?  (Theres already a SciFortran but you get what I mean)\nMeshing? Python has a package called Discretize, but something similar could be handled in Fortran.\nThey could all be under the umbrella of the stdlib.\nIf i'm missing the point of anything stdlib related, please let me know!",
            "comments": [
                {
                    "user": "scivision",
                    "date": "2020-01-09 16:12:09+00:00",
                    "text": "That structure does seem to work well for a lot of projects in other languages. It could help ensure each part is kept to high quality while keeping agility of development. It could also facilitate the continuum of such efforts as many projects will probably be affiliated and API compatible, like the Numpy stack, h5py, xarray, pandas, etc.\nFor example w.r.t. file I/O, some libraries will simply have an iso_c_binding interface, some will be shims to polymorphic Fortran interfaces, some will be pure Fortran modules, etc.\nThis Fortran stdlib doesn't map exactly to the C++ concept of stdlib or other languages. It considers the math/analysis nature of Fortran."
                },
                {
                    "user": "certik",
                    "date": "2020-01-09 16:45:58+00:00",
                    "text": "So having a rich ecosystem of Fortran packages is something we need. But we need #44 to make that approach work well. Languages like Julia first started with richer standard library, but lately it seems their approach is to use separate packages for functionality and a smaller standard library. This part of a blog post argues this point also:\nhttp://cliffle.com/blog/m4vga-in-rust/#rust-has-a-package-manager\nBut: even if we succeed and in few years we have a rich ecosystem of packages and a large community and easy to create your own package, I think there is large value in having stdlib with the scope as defined in the README (https://github.com/fortran-lang/stdlib#scope), and the reason is that it will make Fortran very much with batteries included just like Matlab or Python+SciPy. The reason NumPy is a separate package is that Python itself is not numerically oriented, unlike Fortran, which already has a large subset of NumPy already built-in. Then stdlib is roughly in the range of SciPy (plus utilities). SciPy could be split into 10 packages, but there is high value in having just one package, as the \"base\", that gets you started to prototype your code and has everything you need to do numerical computing. Then, as you need more specialized packages, you will install such packages using fpm (Fortran Package Manager), as discussed in #44.\nAs an example of this how it can work, see the issue #101. I think h5fortran should stay as a separate package. But we can think if it makes sense to provide some simple high level functionality in stdlib itself."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-09 16:59:05+00:00",
                    "text": "I would personally prefer a leaner standard library focused on generic \"computer science\" operations such as sorting and I/O, and rely on custom libraries for numerical work, perhaps provided by a robust distribution (if not packaging) system.  There's only a few variations in output when sorting a list (stable and unstable, for example) but many ways to do an interpolation."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-09 17:05:53+00:00",
                    "text": "Good points.  I never really thought about the importance of the package manager and its influence on project development.\nThis probably goes without saying but I might suggest that repo organization follows an approach where we are splitting the code base into well defined sections such that. If in the future a package manager makes it feasible, the code base could be split at a later date if it makes sense."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-09 17:23:03+00:00",
                    "text": "I think the target audience is a factor. Python started out as a general-purpose language and its stdlib reflects that.\nThis exercise is interesting to do with any language that has a stdlib. Try Python, C, C++, Haskell, Go, Rust, Nim. The result: Every stdlib has different scope.\nIf we look at Fortran's target audience (read: who uses Fortran?), then the functionality covered by numpy and scipy is largely in the center, not on the outskirts. Based on this, I'd argue that numpy+scipy stuff is more in scope of Fortran's stdlib than collections and sorting (though I think they are very much in scope too)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-09 17:29:48+00:00",
                    "text": "Sorry, I didn't answer the question.\nI think yes (for more specialized stuff), but only eventually down the road. Splitting by functionality would be counterproductive this early. We're still learning who uses Fortran, how they use it, and what do they want."
                },
                {
                    "user": "certik",
                    "date": "2020-01-09 17:33:48+00:00",
                    "text": "To add to @milancurcic's answer --- everything in stdlib currently is in the \"experimental\" namespace. That means we are reserving the freedom for ourselves to change things, to move things around, or to (down the road) split them into separate packages. Logistically, because we are just starting, and our community is still small, let's collaborate around just one repository. As our community becomes big and stdlib becomes big and hopefully we have a working fpm at that point, let's revisit this discussion.\nUpdate: to be even more specific, let's do steps 1. - 4. from https://github.com/fortran-lang/stdlib/blob/master/WORKFLOW.md in this stdlib repository. Once we get to the point that we are ready for step 5. for some features, then it's time to think hard if they should go into stdlib, or perhaps if it makes sense to create more libraries. Until then, let's work together to build a community, and to work on standardizing the API for the features that we all want, and put them into \"experimental\" into stdlib."
                },
                {
                    "user": "certik",
                    "date": "2020-01-09 23:43:45+00:00",
                    "text": "Here is a nice blog post from somebody learning Rust:\nhttps://hackernoon.com/programming-in-rust-the-good-the-bad-the-ugly-d06f8d8b7738\nand he has an excellent point near the end:\n\nWhile not as bad as the Node.js ecosystem, the list of dependencies for every library has become quite long. I wrote a small GitHub bot called LabHub, and I\u2019m still surprised by how many dependencies get pulled in (181 crates, if you\u2019re wondering). To me, this suggests fragmentation and duplication, which could perhaps be improved by slowly graduating some widely needed features into the standard library (something that C++ has done very slowly).\n\nSo I suggest we keep trying to agree on common functionality that we all want, and agree an an API and put into experimental.  At the same time, let's work on fpm (#44) and try to create a healthy Fortran package ecosystem like in Rust. But even if we are successful, as Rust shows, there is still a need for a high quality stdlib. And for the scope of stdlib, we already have about 10 Fortran packages that people use, see the list at #1. So we are at the point when it's time to consolidate all these libraries into just one library and all of us to collaborate on that."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-10 02:37:50+00:00",
                    "text": "Cool yeah these are all great reasons and ideas to get moving!"
                }
            ]
        },
        {
            "number": 104,
            "user": "leonfoks",
            "date": "2020-01-09 04:24:44+00:00",
            "title": "Porting everything from Coretran to stdlib",
            "text": "Based of @certik rundown of his fortran-utils!\nI think Coretran has some useful stuff that could go into stdlib.\nHere is what's in Coretran at the moment. I will list from more to less important.\nImportant, None of my routines handle arbitrary defined types. I.e. I can't sort an array of Joe's custom made classes.\nRandom\nI have implemented the Xorshift128+ algorithm that lets you jump the state of the PRNG.  I need to switch to Xoroshiro128+/* because I read that it's more robust.  Most languages provide a Mersenne Twister generator, but its not good for parallel applications. My PRNG is OO and thread safe since a local state is used on each thread.\n\n Random number generator.\n Distributions to generate random numbers from. Normal, Gamma, Weibull etc.  This is not a complete section.\n\nDynamic Arrays\nI think these are akin to C++ vectors?  OO.\nMemory starts low, as entries are added, memory is reallocated only when its full and increases by a set factor.  Similarly, if entries are removed the memory is only reallocated once it is 25% full.\nOverloaded for r32, r64, i32, i64.\n\n dynamic_array\n arg_dynamic_array\n\nSearching\nThese will be fundamental when it comes to developing other functions within the stdlib if we want fast algorithms.\n\n Brute force search, this is needed for small arrays and is faster than Binary for less than like 16 values.\n Binary Search\n Interval Search\n\nSorting (#98)\n\n I have an introspection sort that primarily uses a Quicksort with a Median of 3 pivot.  Quicksort goes N^2 for already sorted listed (or nearly sorted) so I swing off into a heap sort at the point at which the quicksort would be slower. These two are unstable sorts.  I have a merge sort as well with an extra O(N) memory is stability is required. On average this is O(nlogn). Handles tail recursion by switching to an insertion sort when we are less than 16 values.\nI think a TimSort is better than a quicksort from what I gather but I could never implement it.  And from #38 a quicksort wont be great for sparse things.\n\nSpatial\n\n K-Dimensional KdTree. OO with both a KdTree class, and KdTreeSearch to make searches thread safe.  At each iteration the tree is split at the median along the dimension with the highest variance which keeps it balanced. (Hence why I needed a quick median algorithm.)\n\nGeometry\nI implemented Shewchuk's algorithms for exactly computing whether a point is inside the a) circumcircle of a triangle or b) the circumsphere of a tetrahedron.  I was going to use this to write a Delaunay triangulation and/or Voronoi mesh. Shewchuk's algorithms use the naive determinant of a matrix, and add terms if needed until the computation is exact.  It handles floating point round-off error.\n\n Robust predicates for fast adaptive floating point arithmetic.\n\nMaths\n\n\n Median.  I use an on average O(n) quickselect to find median values.\n\n\n cumsum.  Should this be a Kahan summation?\n\n\n cumprod\n\n\n std\n\n\n mean\n\n\n etc!\n\n\n Types (Already in stdlib_experimental_kinds.f90)\nMy entire library is built around these so its easy at least to switch those out.",
            "comments": []
        },
        {
            "number": 103,
            "user": "certik",
            "date": "2020-01-08 20:02:37+00:00",
            "title": "Porting everything from fortran-utils to stdlib",
            "text": "Here is my plan with https://github.com/certik/fortran-utils: I would like to port everything to stdlib. Once everything is in here, I will point users in the README to simply use stdlib, that fortran-utils is not developed anymore and users should switch to stdlib, which as all the functionality and more. I encourage other authors of similar libraries (listed in #1) to try to do the same.\nHere is the functionality in fortran-utils that needs to be ported:\n\n Types (dp) (Already in stdlib_experimental_kinds.f90)\n Constants (pi, e_, i_) (#99)\n Sorting (#98)\n Saving/loading 2D arrays (savetxt, loadtxt) (Already in stdlib_experimental_io.f90)\n Meshes (exponential, uniform) (#17)\n Cubic splines (#100)\n Saving/loading PPM images (#45)\n Lapack interface (and a few simple f90 wrappers like eigh, inv) (#10)\n HDF5 interface (#101)\n Special functions (#102)\n Optimization (#87)\n\nIt seems everything (except #101) would be a nice fit into the scope of stdlib. I think #101 should go into a separate library (at least at first), but the rest I think has a chance of getting in.\nI will use this issue to keep track of the progress.",
            "comments": [
                {
                    "user": "scivision",
                    "date": "2020-01-08 21:19:14+00:00",
                    "text": "I made a followup comment that I think #101 and similar can be interfaced via a shim. This can work for HDF5, FITS, etc. whatever someone wants to contribute a shim for. The user-facing stdlib API can be like:\nsavefile('foo.h5', x)\nloadfile('foo.h5', y)\nThe same interface can be used for libpng and other images. For h5fortran and nc4fortran the rank- and kind-polymorphism is already in those interfaces. For libpng or FITS, stdlib may need to provide the polymorphism.\nThese file formats would all be optional at configure-time. A fallback to raw binary is straightforward if desired."
                }
            ]
        },
        {
            "number": 102,
            "user": "certik",
            "date": "2020-01-08 20:00:21+00:00",
            "title": "Implement special functions",
            "text": "There are lots of implementations online.\nAs an example, here are the special functions that I needed in my projects over the past 10 years:\nhttps://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/src/special.f90\nhttps://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/special_functions.f90\nBeing able to standardize on the API for all or most of them would be a huge deal. Other languages:\nSciPy\nhttps://docs.scipy.org/doc/scipy/reference/special.html\nMatlab\nhttps://www.mathworks.com/help/matlab/special-functions-1.html\nJulia\nSeparate package: SpecialFunctions.jl",
            "comments": []
        },
        {
            "number": 101,
            "user": "certik",
            "date": "2020-01-08 19:55:01+00:00",
            "title": "HDF5 interface",
            "text": "fortran-utils has a very minimal HDF5 wrapper interface that is just a little bit higher level and easier to use: https://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/src/h5_utils.f90.\nBut I would honestly actually vote not to include this in stdlib, or maybe not initially. It feels to me that this would be better off in a separate package. What do you think?",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-01-08 20:04:51+00:00",
                    "text": "There is also the one of @scivision : https://github.com/scivision/h5fortran\nAnyway, since it depends on an external library I would not incluce in stdlib (at least now)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-08 20:07:10+00:00",
                    "text": "I think we will all be in agreement to rather contribute this into @scivision's h5fortran. So I am going to close this issue as out of scope for stdlib. At least in the foreseeable future."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-08 20:56:43+00:00",
                    "text": "I have tried to make the h5fortran (HDF5) and nc4fortran (NetCDF4) user-facing APIs as identical as possible, so that a user program can easily swap between HDF5 and NetCDF file IO by a configure-time flag.\nI used object-oriented interface h5fortran and nc4fortran because there are multiple internal variables to manipulate when doing non-trivial operations. The basic user-facing operations are like:\ntype(hdf_file) :: h\n\nh%initialize('foo.h5', 'rw')\nh%write('x', x)\nh%read('y', y)\nh%finalize()\nwrite() read() and other methods are rank-agnostic (scalar..7D) and kind-agnostic {real32,real64,int32,int64,character} within the limits of HDF5 and NetCDF. Yes they can use opaque data for really arbitrary stuff, but that wasn't my need for HPC simulation and data assimilation."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-08 21:01:00+00:00",
                    "text": "With regard to binary file I/O in my opinion, raw binary I/O should be discouraged for most cases in any programming language.\nThere are a lot of other scientific formats like CDF, FITS and so on, but for out-of-core and cloud storage/processing and broadest data science library support, it is best in my opinion to focus efforts on HDF5. I only made a NetCDF4 interface because it's a subset of HDF5 and used by the large simulation packages I  interface my models with."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-08 21:14:22+00:00",
                    "text": "I think HDF5 and the like could be handled with a stdlib shim that presents a user API like {loadtxt,savetxt}.  So instead of the h5fortran/nc4fortran initialize, write, finalize you would just have in stdlib\nsavefile('foo.h5', x)\nloadfile('foo.h5', y)\n\nlike other external libraries libpng etc., make it an option.\nstraightforward to implement in the near term.\ncan likewise add shims for FITS or other file formats contributors feel are important"
                },
                {
                    "user": "certik",
                    "date": "2020-01-08 21:50:03+00:00",
                    "text": "The interface like savefile('foo.h5', x) would make sense for stdlib. So I reopened this issue. Thanks for the idea @scivision."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-15 20:52:20+00:00",
                    "text": "I made a new release v2.5.0 of h5fortran, which now works as simply as:\nuse h5fortran\n\ncall h5write('foo.h5', '/x', x)\n\ncall h5read('bar.h5', '/y', y)\nthat's polymorphic scalar..7d, int32,int64,real32,real64"
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-15 21:49:25+00:00",
                    "text": "When it comes to providing modern Fortran interfaces to libraries like HDF5, NetCDF, MPI, etc., if there is already a package out there that reasonably meets the \"design principles\" of stdlib, like I presume h5fortran does, I see no reason for stdlib to throw a layer over the top of it and assimilate the package into stdlib. Stdlib doesn't need to be the Borg of Fortran libraries. Let people use the package directly. I think there ought to be a compelling reason and value for stdlib to provide the interface, like perhaps it does for lapack."
                },
                {
                    "user": "certik",
                    "date": "2020-01-15 22:04:10+00:00",
                    "text": "@nncarlson It's not black and white where to draw the line what goes into stdlib and what does not, but I think we are all in agreement here, as indicated above, that h5fortran should stay as a separate package. (h5fortran is on my todo list to get working with fpm.)"
                }
            ]
        },
        {
            "number": 100,
            "user": "certik",
            "date": "2020-01-08 19:51:45+00:00",
            "title": "Implement cubic splines interpolation",
            "text": "When some 1D data is given on a grid, and nothing more is known about it, then cubic splines are one of the best methods to interpolate it. It's relatively high order (compared to linear interpolation), so the result is smooth, but is not too high, so the result is not wiggly. In some sense, it's the optimum.\nAn example implementation: https://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/src/splines.f90",
            "comments": [
                {
                    "user": "rweed",
                    "date": "2020-01-09 02:31:59+00:00",
                    "text": "@certik, I have a version of the Fritsch/Carlson/Butland monotone cubic interpolation routines (PCHIP) that I refactored to modern Fortran (ie removed sphagetti code) from the original SLATEC code I can upload. Don't remember what the SLATEC license is though. Its set up to use REAL64 by default but I made buidling a REAL32 version a command line define option. I'll upload here if you want it."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-09 04:00:18+00:00",
                    "text": "I did the same thing!  https://github.com/jacobwilliams/PCHIP"
                },
                {
                    "user": "certik",
                    "date": "2020-01-09 04:04:38+00:00",
                    "text": "Well, let's join the forces!\n\u2026\nOn Wed, Jan 8, 2020, at 9:00 PM, Jacob Williams wrote:\n I did the same thing! https://github.com/jacobwilliams/PCHIP\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#100?email_source=notifications&email_token=AAAFAWHZVREA36NYIBSUSMTQ42ONFA5CNFSM4KENV3W2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIO3VHQ#issuecomment-572373662>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWBQ5BAEOFL4UXKZ6WTQ42ONFANCNFSM4KENV3WQ>."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-14 08:39:06+00:00",
                    "text": "Intel MKL library has a Fortran 90 interface to a set of functions for data fitting. The API is however task-based and not that intuitive compared to Python's or MATLAB's syntax. (I suppose this is for performance purposes if you have many repeated calls using the same set of knots.)\nIf we define the (high) stdlib level API would it be possible to use submodules to have both a custom implementation/refactored SLATEC and a second backend calling the Intel MKL routines?\nI know the SciPy library supports using Intel MKL in some of the routines, so it should be possible to do it here as well."
                },
                {
                    "user": "certik",
                    "date": "2020-01-14 13:35:19+00:00",
                    "text": "Yes, we should try to optionally use MKL also.\n\u2026\nOn Tue, Jan 14, 2020, at 1:39 AM, Ivan wrote:\n Intel MKL library has a Fortran 90 interface to a set of functions for\n data fitting\n <https://software.intel.com/en-us/mkl-developer-reference-fortran-data-fitting-computational-routines#FC83C653-2C9E-481A-BAF9-588A6AA544BF>. The API is however task-based and not that intuitive compared to Python's or MATLAB's syntax. (I suppose this is for performance purposes if you have many repeated calls using the same set of knots.)\n\n If we define the (high) `stdlib` level API would it be possible to use\n submodules to have both a custom implementation/refactored SLATEC and a\n second backend calling the Intel MKL routines?\n\n I know the SciPy library supports using Intel MKL in some of the\n routines, so it should be possible to do it here as well.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#100?email_source=notifications&email_token=AAAFAWDSC2A7CNKYCLLCCIDQ5V22XA5CNFSM4KENV3W2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEI3YPWQ#issuecomment-574064602>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWH2W7WZFDFEI7GGWF3Q5V22XANCNFSM4KENV3WQ>."
                }
            ]
        },
        {
            "number": 99,
            "user": "certik",
            "date": "2020-01-08 19:49:10+00:00",
            "title": "Implement constants module",
            "text": "At the very least, it would contain the following constants:\n\npi\ni_\ne_\n\nAn example implementation: https://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/src/constants.f90\nNote about naming: The convention that we discussed in fortran-utils 10 years ago was that single letter constants contain underscore so that they do not clash with user variables (\"e\" and \"i\" are frequently used as loop variables). But we can definitely revisit this and choose a different convention.",
            "comments": [
                {
                    "user": "marshallward",
                    "date": "2020-01-08 20:20:02+00:00",
                    "text": "Here are the libm constants (and names) for reference:\nhttps://www.gnu.org/software/libc/manual/html_node/Mathematical-Constants.html#Mathematical-Constants"
                },
                {
                    "user": "certik",
                    "date": "2020-01-08 20:25:43+00:00",
                    "text": "Julia seems to use Base.im, Base.MathConstants.pi, Base.MathConstants.\u212f, Base.MathConstants.eulergamma, ... (https://docs.julialang.org/en/v1/base/numbers/#Base.im)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-08 20:28:29+00:00",
                    "text": "Matlab uses pi. Other constants: https://www.mathworks.com/help/matlab/constants-and-test-matrices.html."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-09 16:14:39+00:00",
                    "text": "to avoid namespace clashes, the constants could be in a derived type consisting mostly of parameter like\nmc%pi  \nmc%tau"
                },
                {
                    "user": "certik",
                    "date": "2020-01-09 16:25:42+00:00",
                    "text": "We had that discussion at #49 about using derived types to workaround the insufficiency of Fortran's namespaces. I personally think it's not a good idea, you can read the arguments at #49.\nBut if the majority in the community wants to use a derived type for this, we can, especially while it is still in experimental. We can always revisit later.\nThe proper solution, in my opinion, is j3-fortran/fortran_proposals#1 and j3-fortran/fortran_proposals#86. If both are implemented, then one could do something like this:\nuse, namespace :: stdlib, only: constants\n...\nconstants%pi\n\nWhere constants is the module nested in stdlib. This would be equivalent to Python's from stdlib import constants."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-09 19:36:39+00:00",
                    "text": "I agree with @certik that the derived type solution is suboptimal, but I think it's the best that we can do with Fortran 2018. Once the standard is fixed (I wouldn't hold my breath meanwhile), we can revert to a better solution, similarly to what has been done with procedure optional argument default values and the optval function."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-09 22:13:44+00:00",
                    "text": "I think using a derived type for the constants is perfectly legitimate and if done \"properly\" acts exactly like a namespace and the user needn't even be aware that there is a derived type involved other than the \"%\" character which becomes part of the constant \"name\". For example,\nmodule math_constants\n  private\n  type :: private_type\n    real :: pi, e\n  end type\n  type(private_type), parameter, public :: mc = private_type(3.14, 2.71)\nend module\n\nuse math_constants\nprint *, mc%pi, mc%e\nend\nInterestingly, for the NAG compiler this has 0 overhead compared to using individual parameters; the mc structure doesn't even appear in the C code for the print statement -- it's been completely unwound to the actual constants."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-09 22:40:05+00:00",
                    "text": "That's an interesting technique. Will have to check with other compiler disassemble to see if zero overhead holds there too."
                },
                {
                    "user": "certik",
                    "date": "2020-01-09 23:05:22+00:00",
                    "text": "I propose we use this:\nmodule math_constants\n  private\n  real, parameter, public :: pi = 3.14, e_ = 2.71\nend module\n\nuse math_constants, only: pi, e_\nprint *, pi, e_\nend\nBoth the module and user code is shorter and simpler.\nUsing the derived type approach, how do I import just pi? I don't think you can. So all your user code will have to always type mc%pi.\nHere is an example from one of my codes\nVeeG = 4*pi*neG / G2\nMuch more readable than:\nVeeG = 4*mc%pi*neG / G2"
                },
                {
                    "user": "zjibben",
                    "date": "2020-01-09 23:41:51+00:00",
                    "text": "My personal preference is slightly toward @certik's bare parameters in a module, primarily for cleanliness in expressions. And very subjectively I realize, bundling constants into a single data object feels wrong. On the off chance there's a collision, one can always rename on use: use math_constants, only: mc_pi => pi. To me that's the superior compromise until true namespaces are available."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-10 00:39:01+00:00",
                    "text": "I want to clarify my earlier comment that I was not advocating for using the derived type approach in this case. I'm fairly ambivalent about it, and could go either way. I really just wanted to push back on the idea that this is misuse of derived types in general. I don't think it is. It provides a \"namespace\" like experience in lieu of having namespaces, and seems to do so without any overhead."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-13 05:57:40+00:00",
                    "text": "What precision should these constants be? Do we define, e.g., pi_sp, pi_dp, pi_qp and then expect the user to choose the one they want (giving them the chance to rename it)?\nAs for namespacing, I don't see the benefit here. Namespacing the constants seems like over-engineering, plus you lose the ability to just use pi or e_ as @certik mentioned."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-13 14:11:50+00:00",
                    "text": "What precision should these constants be? Do we define, e.g., pi_sp, pi_dp, pi_qp and then expect the user to choose the one they want (giving them the chance to rename it)?\n\nHow about we follow a pragmatic approach and implement only the highest possible precision type (\"qp\"?) with no suffix and then let Fortran implicitly take care of the conversions? Is it too much a \"quick and dirty\" solution?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-13 15:34:12+00:00",
                    "text": "Regarding derived type versus just variables in a module: let's do both, so that we can all get what we want and move on. So let's do this:\nmodule math_constants\nprivate  \nreal, parameter, public :: pi = 3.14, e_ = 2.71  \n \ntype :: private_type  \n    real :: pi = pi  \n    real :: e = e_  \nend type  \n \ntype(private_type), public, parameter :: mc = private_type()  \nend module\nThen this can be used both as:\nuse math_constants, only: pi, e_\nprint *, pi, e_\nend\nand as:\nuse math_constants, only: mc\nprint *, mc%pi, mc%e\nend\nI just tested it and it works.\nThere are essentially two camps here --- one side thinks it's an over engineering and an imperfect workaround for a fundamental deficiency of Fortran namespaces; the other side thinks it's worth using derived types as namespaces. The above approach gets both sides what they want, without forcing the other side to use an approach that feels wrong.\nSo let's try that and move on. We can do the same approach in #49.\n\nRegarding the constant's precision, that's a very good point. If we set them to the highest precision available in the compiler, as in this code:\nprogram test_pi\nuse stdlib_experimental_kinds, only: sp, dp, qp\nimplicit none\nreal(dp), parameter :: pi_dp    = 3.1415926535897932384626433832795_dp\nreal(qp), parameter :: pi_qp    = 3.1415926535897932384626433832795028841971_qp\n\n\nreal(dp) :: a\nreal(qp) :: b\n\na = pi_dp\nprint *, a\na = pi_qp\nprint *, a\n\nb = pi_dp\nprint *, b\nb = pi_qp\nprint *, b\n\nend program\nwhich prints:\n   3.1415926535897931     \n   3.1415926535897931     \n   3.14159265358979311599796346854418516      \n   3.14159265358979323846264338327950280      \n\nThen it looks like things behave correctly. But unfortunately gfortran gives a warning:\ntest_pi.f90:13:4:\n\n a = pi_qp\n    1\nWarning: Change of value in conversion from \u2018REAL(16)\u2019 to \u2018REAL(8)\u2019 at (1) [-Wconversion]\n\nActually I do not even know how to get rid of this warning, as this also doesn't work:\ntest_pi.f90:13:9:\n\n a = real(pi_qp, dp)\n         1\nWarning: Change of value in conversion from \u2018REAL(16)\u2019 to \u2018REAL(8)\u2019 at (1) [-Wconversion]\n\nSo we need to figure this out."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-13 15:58:12+00:00",
                    "text": "Actually I do not even know how to get rid of this warning, as this also doesn't work:\n\nUnfortunately, I had a quick look at the gcc manual and it doesn't seems possible :("
                },
                {
                    "user": "certik",
                    "date": "2020-01-13 16:05:57+00:00",
                    "text": "A pragmatic solution: given that double precision is no doubt the most widely used precision, then we can have:\nreal(sp), parameter :: pi_sp = ...\nreal(dp), parameter :: pi_dp = ...\nreal(qp), parameter :: pi_qp = ...\n\nreal(dp), parameter :: pi = pi_dp\nSo one can use pi_sp, pi_dp, pi_qp directly, and one can also just use pi in the most common case of double precision."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-13 16:30:38+00:00",
                    "text": "Would it be complicated to just ignore the warnings with some scripting? I don't like the idea to bend the implementation to the quirks of individual compilers (especially for warnings)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-13 16:36:35+00:00",
                    "text": "I checked Intel Fortran with -warn all and it does not warn about my code above. The PGI Fortran with -Minform=warn also does not warn (it does not support qp, so I changed qp -> dp and dp -> sp in the above example). Let's check other compilers too.\nI agree if this is only gfortran's quirk, then we can simply disable this warning for GFortran as a workaround and report the bug, and simply declare constants as the highest precision supported in the compiler (typically qp)."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-13 16:40:19+00:00",
                    "text": "Unfortunately, I can only test gfortran (...and lfortran, but I think there is someone more knowledgeable than me about it in this discussion :P), so I cannot tell what happens with NAG, IBM, PGI, etc..."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-13 17:07:30+00:00",
                    "text": "NAG does not warn about these type conversions."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-13 18:13:47+00:00",
                    "text": "I don't think gcc is wrong here.  -Wconversion warns of implicit conversions, and this is an implicit conversion from real(16) to real(8).\nHowever, it also seems to be balking on explicit conversions, e.g.\na = real(pi_qp, dp)\n\nwhich does feel wrong to me.\nUnfortunately I'm not sure the best way do this other than something like -Wall -Wno-conversion, but maybe there's a more explicit way to define conversions."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-13 18:24:07+00:00",
                    "text": "Unfortunately I'm not sure the best way do this other than something like -Wall -Wno-conversion, but maybe there's a more explicit way to define conversions.\n\nThanks @marshallward for finding the right gfortran flag (i.e. -Wno-conversion) and apologies for having missed that in the gcc manual (maybe I've looked in the wrong place).\n\nI don't think gcc is wrong here. -Wconversion warns of implicit conversions, and this is an implicit conversion from real(16) to real(8).\n\nI agree with you, but in this specific case, we don't need to worry about the warning because the implicit conversion it's intended and it is not caused by a distraction."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-13 18:32:39+00:00",
                    "text": "I wonder if there's a performance penalty for just providing the highest precision available on a compiler.\nI tested the following:\nprogram test\n    use, intrinsic :: iso_fortran_env, only: dp => real32, qp => real128\n    implicit none\n\n    real(dp), parameter :: pi_dp = 3.1415926535897932384626433832795_dp\n    real(qp), parameter :: pi_qp = 3.1415926535897932384626433832795028841971_qp\n\n    real(dp) :: x\n\n    x = 0.0_dp\n    x = x + ___________\nend program test\n\nwhere I replaced the blank with\n\npi_dp\npi_qp\nreal(pi_qp, dp)\n\nAfter compiling and disassembly, e.g.,\n$ gfortran test.f90\n$ objdump --disassemble a.out > dp.s\n\nExplicitly casting pi_qp down to dp produced identical assembly code as just using dp. Credit goes to gfortan's compile-time constant expression reduction, I expect.\nUsing pi_qp without the cast produced more complicated assembly code. The result is only a few instructions longer, but it introduces several more calls into what I think is the gfortran runtime library. That may or may not matter. Just some data.\nEdit: If I compile with -O3, all three variants produce the same assembly code."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-13 18:52:03+00:00",
                    "text": "I wonder if there's a performance penalty for just providing the highest precision available on a compiler.\n\nI like this idea, but there is (at least) one case where the user would have to be aware of the actual kind and explicitly down-cast if necessary: [ 0.0_dp, pi, 2*pi] would return an error if pi was quad kind"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-13 19:00:47+00:00",
                    "text": "I like this idea, but there is (at least) one case where the user would have to be aware of the actual kind and explicitly down-cast if necessary: [ 0.0_dp, pi, 2*pi] would return an error if pi was quad kind\n\nThe user would be aware of the kind if stdlib provides pi_qp instead of pi.\nProvding only pi_qp would be a solution half-way between providing only pi (or pi_) and providing all kinds (pi_sp,pi_dp, pi_qp)"
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-13 19:05:19+00:00",
                    "text": "I think -O3 is just pre-computing all of the constant expressions because it knows that x is zero, producing identical assembly, including the real(pi_qp, dp) conversion.\nIf I take out the x = 0.0_dp line, so that x has random garbage, then it's a little more clear what is happening, including the conversion steps by GCC (via soft-fp).\nReplacing pi_dp with pi_qp just adds this conversion code:\n< \tmovss\t.LC1(%rip), %xmm0\n< \tmovq    %rbp, %rdi\n< \taddss\t12(%rsp), %xmm0\n< \tmovq    %r13, 24(%rsp)\n< \tmovl    $12, 32(%rsp)\n< \tmovss   %xmm0, 12(%rsp)\n---\n> \tmovss\t12(%rsp), %xmm0\n> \tcall\t__extendsftf2@PLT\n> \tmovdqa\t.LC1(%rip), %xmm1\n> \tcall\t__addtf3@PLT\n> \tcall\t__trunctfsf2@PLT\n< \tmovq    %rbp, %rdi\n< \tmovq    %r13, 24(%rsp)\n< \tmovss   %xmm0, 12(%rsp)\n< \tmovl    $12, 32(%rsp)\n\nI don't thin this has anything to do with providing the quad precision numbers, it's just doing the necessary qp to dp conversion in x = x + pi_qp."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-13 19:28:27+00:00",
                    "text": "Curious what other compilers do when this is both compiled and run\n\nprogram testit\nuse,intrinsic :: iso_fortran_env, only : int8, int16, int32, int64\nimplicit none\nwrite(*,*)int(huge(1_int64),kind=int32)\nend program testit\n\nSomtimes I want a warning even from int() and real() as gfortran does. I would prefer that\nthe specific intrinsics for changing type not produce a warning but that I did get a warning over overflow/underflow, but the warning would make int() and real() IMPURE, I suppose.\nI had similar issues with defining a table of my own favorite constants in the past and so\ngave myself several choices (I really could not make up my mind and was new to modules and such anyway.  So I did this\n\nmodule M_constants\nuse, intrinsic :: iso_fortran_env, only : real32, real64, real128\nimplicit none\nreal(kind=real128),parameter ::      pi128=3.141592653589793238462643383279502884197169399375105820974944592307_real128\nreal(kind=real32),parameter :: pi32=real(pi128,kind=real32)\nreal(kind=real64),parameter :: pi64=real(pi128,kind=real64)\nend module M_constants\nmodule M_constants_32\nuse M_constants, only : pi=> pi32\nend module M_constants_32\nmodule M_constants_64\nuse M_constants, only : pi=> pi64\nend module M_constants_64\nmodule M_constants_128\nuse M_constants, only : pi=> pi128\nend module M_constants_128\n\nso without TOO much maintenance I could use it several different ways:\n\nprogram testit\ncall zero()\ncall one()\ncall two()\ncall three()\ncontains\nsubroutine zero()\nuse :: M_constants\nwrite(*,*)pi32/2\nend subroutine zero\nsubroutine one()\nuse :: M_constants, only : pi=>pi32\nwrite(*,*)pi/2\nend subroutine one\nsubroutine two()\nuse :: M_constants_32, only : pi\nimplicit none\nwrite(*,*)pi/2\nend subroutine two\nsubroutine three()\nuse :: M_constants_128, only : pi\nimplicit none\nwrite(*,*)pi/2\nend subroutine three\nend program testit\n\nI suppose it is only my personal story as the discussion shows opinions vary, but when I look thru code wh ere I used it, I almost always ended up using case1, and otherwise case0 out of the four cases above. It ends up I like being able to tell the type by the name myself; although I initially thought I wanted to use 'PI' everywhere.\n\u2026\n On January 13, 2020 at 1:13 PM Marshall Ward ***@***.***> wrote:\n\n\n     I don't think gcc is wrong here. -Wconversion warns of implicit conversions, and this is an implicit conversion from real(16) to real(8).\n\n     However, it also seems to be balking on explicit conversions, e.g.\n\n     a = real(pi_qp, dp)\n\n     which does feel wrong to me.\n\n     Unfortunately I'm not sure the best way do this other than something like -Wall -Wno-conversion, but maybe there's a more explicit way to define conversions.\n\n     \u2014\n     You are receiving this because you are subscribed to this thread.\n     Reply to this email directly, view it on GitHub #99?email_source=notifications&email_token=AHDWN3NQOK4CVIVID772ICLQ5SVN3A5CNFSM4KENU6B2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIZXDSQ#issuecomment-573796810 , or unsubscribe https://github.com/notifications/unsubscribe-auth/AHDWN3NAZLYVMNJUU4JFFCDQ5SVN3ANCNFSM4KENU6BQ ."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-13 19:41:14+00:00",
                    "text": "propogating to the larger type in expressions is not the only issue, but using the constants in expressions or values passed as arguments or building arrays might be the bigger issue.\n\nI have sometimes wished there was a way to declare an argument to propogate to the type required by the called routine,  like a built-in call to INT or REAL to the type required, sort of like K&R C propogated all the float values up before there were 10 000, types. Maybe even propogate down if the value fit.  Metamorphic variables and CLASS(*) and generic routines give the functionality I wanted without the possible costs of a gather/scatter to the other type and so on nowadays, I suppose.\n\u2026\n On January 13, 2020 at 1:32 PM nshaffer ***@***.***> wrote:\n\n\n     I wonder if there's a performance penalty for just providing the highest precision available on a compiler.\n\n     I tested the following:\n\n     program test\n         use, intrinsic :: iso_fortran_env, only: dp => real32, qp => real128\n         implicit none\n\n         real(dp), parameter :: pi_dp = 3.1415926535897932384626433832795_dp\n         real(qp), parameter :: pi_qp = 3.1415926535897932384626433832795028841971_qp\n\n         real(dp) :: x\n\n         x = 0.0_dp\n         x = x + ___________\n     end program test\n\n     where I replaced the blank with\n\n         * pi_dp\n         * pi_qp\n         * real(pi_qp, dp)\n\n     After compiling and disassembly, e.g.,\n\n     $ gfortran test.f90\n     $ objdump --disassemble a.out > dp.s\n\n     Explicitly casting pi_qp down to dp produced identical assembly code as just using dp. Credit goes to gfortan's compile-time constant expression reduction, I expect.\n\n     Using pi_qp without the cast produced more complicated assembly code. The result is only a few instructions longer, but it introduces several more calls into what I think is the gfortran runtime library. That may or may not matter. Just some data.\n\n     \u2014\n     You are receiving this because you are subscribed to this thread.\n     Reply to this email directly, view it on GitHub #99?email_source=notifications&email_token=AHDWN3KFGXNNY5X2MSP6573Q5SXUTA5CNFSM4KENU6B2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIZZIGQ#issuecomment-573805594 , or unsubscribe https://github.com/notifications/unsubscribe-auth/AHDWN3N6UCX4QBYEBSJ4RWTQ5SXUTANCNFSM4KENU6BQ ."
                },
                {
                    "user": "certik",
                    "date": "2020-01-13 22:33:10+00:00",
                    "text": "If there is a performance penalty at runtime in Release mode (with all optimizations on) when using pi_qp in double precision expression, then that's not acceptable I think."
                }
            ]
        },
        {
            "number": 98,
            "user": "certik",
            "date": "2020-01-08 19:44:41+00:00",
            "title": "Implement sorting algorithms",
            "text": "At the very least there needs to be some quick algorithm for sorting integers and reals. But I think we can implement several algorithms and the user can choose.\nThis will also be needed to implement #38.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-01-08 20:09:02+00:00",
                    "text": "Is it also an option to link to the algorithms provided by BLAS/LAPACK?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-08 20:16:34+00:00",
                    "text": "@jvdp1 I think so. We'll need to depend on Lapack for #10 anyway."
                },
                {
                    "user": "certik",
                    "date": "2020-01-08 20:21:55+00:00",
                    "text": "Here are inefficient implementations from fortran-utils: https://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/src/sorting.f90, the API however might be useful to get inspiration from. Here is more efficient implementation of quicksort: https://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/sorting.f90#L165. I think there will be much better implementations out there, including in Lapack."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-08 20:33:33+00:00",
                    "text": "Here is a mutli-threaded one:\nhttps://balsoftware.net/index.php/open-source/multi-thread-sort/\nNot sure what is the license."
                },
                {
                    "user": "rweed",
                    "date": "2020-01-09 02:07:57+00:00",
                    "text": "The following routines implement the version of quicksort outlined in Hanson's and Hopkins book and on the associated web site (http://www.siam.org/books/ot134). The publishers license is very permissive (at least as I read it). This version supports REAL32, REAL64, INT8, INT16, INT32, INT64, Character strings and arrays, and a user defined type. Unfortunately, the file tool for this page does not know anything about .f90 or .F90 file extensions. Here is the code:\nMain quicksort module: type specific routines are overloaded with generic qsort interface. Sorting can be in place or return a integer permutation array leaving original array untouched. Sorting can be in either ascending or descending order.\nquickSort.F90.txt\nA base user class that can be extended to define user specific classes. Specifies dummy methods for relational operators needed for sorting etc, a print method and an assignment method.\nuserClass.F90.txt\nA test program that tests sorting integers, reals, characters, and a user point class that is sorted on distance (Euclidean Norm)\ntestqsort.f90.txt\nThe point class used in test program. It is extended from the base User class\npoint.f90.txt"
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-13 04:06:28+00:00",
                    "text": "Here are some of mine:\n\nhttps://github.com/jacobwilliams/fortran-search-and-sort\nhttps://github.com/jacobwilliams/stringsort (see also here about natural sorting of strings)."
                }
            ]
        },
        {
            "number": 97,
            "user": "certik",
            "date": "2020-01-08 16:51:55+00:00",
            "title": "Add Goals and Motivation section into README",
            "text": "",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-08 18:52:19+00:00",
                    "text": "Thanks everybody for the review!"
                }
            ]
        },
        {
            "number": 96,
            "user": "nshaffer",
            "date": "2020-01-07 14:12:19+00:00",
            "title": "Make optval pure or pure elemental where possible",
            "text": "Exactly what is says on the tin.\n\nreal, integer, and logical versions of optval are now pure elemental\ncharacter version is now pure (no elemental b/c the return value is allocatable)\nnew tests for arrays of real, integer, and logical\n\n(sorry in advance for the whitespace diffs, forgot to M-x delete-trailing-whitespace the first time around)",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-07 14:49:29+00:00",
                    "text": "I resolved the conflicts with master, it turns out it was already made pure in master, but not elemental."
                }
            ]
        },
        {
            "number": 95,
            "user": "zbeekman",
            "date": "2020-01-06 19:22:48+00:00",
            "title": "Error stack class/object",
            "text": "I would like to implement an error stack class/object. This will be helpful for addressing #76 (message for errors inside of stdlib). The reasons why this is useful are that:\n\nYou can raise/signal errors deep within the call stack, even in pure (or maybe elemental too, I'll have to think more carefully about that) procedures, and then handle them at a higher level\nYou can maintain a call stack with the object and optionally include the file name, procedure name, and line number along with an error message and error type/severity\nIO for warnings, errors, statuses, etc. can be performed once outside performance critical and/or pure/elemental procedures\nYou could hook up some logging mechanism too, so that the file IO happens on return from pure procedures\n\nPerhaps this should be part of #72 (standard assert and macros) or the existing stdlib_experimental_error.f90 or perhaps it should be its own module.\nI'm waiting, in part, for #69 (string handling routines) to get to a point where there's some consensus, to take a crack at implementing that before proposing an implementation for this. String handling will be important for the manipulations required.\nSketch interface prototype\npure subroutine push(this, file_name, line, procedure_name)\n    !! caller calls this on line before call to callee\n    !! `file_name` can be set to a compile-time constant via CMake definition\n    !! or can use `__FILE__` macro, but this may overrun the line length\n    !! `line` can be passed `__LINE__` macro.\n    class(error_stack_t), intent(inout) :: this\n    character(len=*), intent(in) :: file_name\n    integer, intent(in) :: line\n    character(len=*), intent(in), optional :: procedure_name\nend subroutine push\nI like to let CMake ad a per-source-file definition, something like THIS_FILE that holds the relative path to the file in the source directory. It could fallback to __FILE__ when using manual makefiles. The benefit over __FILE__ is two fold:\n\nRelative paths are shorter than absolute paths and less likely to overrun the line length limit, and CMake can check the length and insert a newline w/ continuation if needed\nEmbedding absolute paths prevents builds from being reproducible and can make package managers thing that the software is not relocatable when it actually is.\n\nAlso, one or more arguments could be made optional. It would be wonderful if there was a way to query the name of the current scope in Fortran and if the programmer didn't need to make two separate calls, one to the callee and one push info onto the error stack. You could add file name, line number and error_stack arguments to all procedures and then the callee could push the data onto the stack as an alternative to the caller doing it.\nFeedback, advice and suggestions welcome here.\npure subroutine pop(this)\n    !! Called before/on return to caller\n    !! only removes entries from the stack if no errors are signaling,\n    !! otherwise preserve the call stack to the error, but decrement the depth\n    !! so that when the error is caught the stack can be cleaned up appropriately\n    class(error_stack_t), intent(inout) :: this\nend subroutine pop\npure subroutine signal(this, message, severity, error_type) ! Or raise?\n    !! Callee can signal or raise an exception and return control to caller\n    !! (or further up the call stack) for handling\n    class(error_stack_t), intent(inout) :: this\n    character(len=*), intent(in) :: message\n    integer, intent(in) :: severity\n    integer, intent(in), optional :: error_type\nend subroutine signal\nsubroutine catch(this, pop) ! maybe impure elemental?\n    !! Do IO to tty or log as is necessary and handle calls to `error stop` \n    !! or other actions based on severity\n    class(error_stack_t), intent(inout) :: this\n    logical, optional :: pop !! pop stack up to this callers depth\nend subroutine catch\nThe API needs some further thought, which is why I'd like feedback from others. In an ideal world, it would be awesome to have this act as a decorator and not have to call the push method before the caller calls the callee or not have to pass the file name and line number if the callee does the push.\nPreprocessor macro expansion could automatically expand multiple actual arguments on calls to other stdlib procedure to pass in the stack object, file name and line number but seems a bit too magic for my liking.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-06 19:32:50+00:00",
                    "text": "Thanks for the proposal. Can you give an example how would this be used in practice? Does one have to call pop and push manually (or with a macro) in every function/subroutine in a project?\nShouldn't better debugging and stacktraces capability be rather built into compilers themselves?"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 20:03:09+00:00",
                    "text": "Thanks for the proposal. Can you give an example how would this be used in practice?\n\nI'll update the original post with an example\n\nDoes one have to call pop and push manually (or with a macro) in every function/subroutine in a project?\n\nUnless someone can think of a better way to do this, then, \"yes\": Either the caller or callee must call pop and push starting at the depth where one wishes to catch and report errors and down into any procedures who will be raising/signalling errors.\nUpon further consideration, the design with the lease typing that does not require an object oriented decorator is to pass 3 extra arguments to each procedure:\n\nThe error_stack_t object\nThe __LINE__ macro as an integer literal actual argument (this will hold the line the procedure was called on)\nThe caller filename (either __FILE__ or a CMake defined relative path)\n\nThen the procedure can call push and pop on entry/exit and provide its own name as an optional argument. I'm going to update my original post to reflect this.\nFor other classes & objects that take an OOD/OOP approach you may be able to implement a decorator pattern where the classes being implemented use the error_stack_t class, probably via composition. I need to think on this particular aspect a bit more and look at other examples, as I do not have experience with decorator patterns in Fortran. The hard part is getting the file name and the line number where the procedure was called. With pre-processor macros this needs to happen in the same file/scope that the call is made.\n\nShouldn't better debugging and stacktraces capability be rather built into compilers themselves?\n\nAbsolutely! But I'm tired of waiting \ud83d\ude04. I should open a new issue over in the other J3 repo. In particular the following would be helpful in letting users write their own error handling, if we cannot get error handling into the language itself:\n\nfile_name(): Function to return the name of a source code file (effectively standardize the __FILE__ macro without it being a macro)\nline_number(): Function to return an integer of the line number of the file it was called\nscope_name(): Function to return (even the mangled, namespaced) symbol definition. Or as an alternative you could have:\nfunction_name(): Function to return the name of the current function\nsubroutine_name(): Function to return the name of the current subroutine\n\nOr, better still for error handling:\n\ncalled_from_file(): Function to return filename where the current procedure was called\ncalled_on_line(): Function to return the line number where the current procedure was called"
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 20:50:28+00:00",
                    "text": "Shouldn't better debugging and stacktraces capability be rather built into compilers themselves?\n\nAbsolutely! But I'm tired of waiting\n\nI am doing what I can. I could have been a lot further along, but I felt putting my time into stdlib and the J3 repo and getting us organized was worth getting a bit delayed.\nIn the meantime, here is how to get nice stacktraces from user code:\nhttps://github.com/trilinos/Trilinos/blob/4ddae567dc74b55dfa2fb7eb27c04a1808ba2475/packages/teuchos/core/src/Teuchos_stacktrace.hpp\nhttps://github.com/trilinos/Trilinos/blob/master/packages/teuchos/core/src/Teuchos_stacktrace.cpp\nI implemented that 10 years ago. Since then, there seem to be a few other libraries that can do that:\n\nhttps://github.com/boostorg/stacktrace\nhttps://github.com/dsiroky/cpp-traceback\n\nI think they all follow basically the same approach.\nI have not tested that with Fortran, only C and C++, but I think it would work."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 21:31:59+00:00",
                    "text": "I am doing what I can. I could have been a lot further along, but I felt putting my time into stdlib and the J3 repo and getting us organized was worth getting a bit delayed.\n\nI completely agree! Thanks for the hard work!"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 21:32:34+00:00",
                    "text": "I was editing my original post but lost the edits upon navigating to another link. I'll try to refine my ideas and add a usage example tonight."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-31 16:09:51+00:00",
                    "text": "I have an implementation of something that does pretty much what you're asking for here. https://gitlab.com/everythingfunctional/erloff\nIt uses a functional programming approach, and has some conveniences for callers to deal with errors/messages that come back. It enables subroutines to remain pure as well.\nHere are a couple projects I've made use of it as well:\n\nhttps://gitlab.com/everythingfunctional/quaff\nhttps://gitlab.com/everythingfunctional/jsonff\n\nLet me know if you have any questions about it."
                }
            ]
        },
        {
            "number": 94,
            "user": "certik",
            "date": "2020-01-06 19:10:23+00:00",
            "title": "Document workflow based on the discussion in #5",
            "text": "",
            "comments": [
                {
                    "user": "nncarlson",
                    "date": "2020-01-06 19:33:01+00:00",
                    "text": "I think item 5 is an absolute must, but I frankly think that item 4 should be accompanied by at least a draft of the specification. That is the API after all."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 19:39:57+00:00",
                    "text": "@nncarlson I like your idea that already at step 4. there should be a draft of the specification.\nWhat we can do is to write the specification for open to show how it could be done, and then require it for each new functionality before it gets merged."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-06 21:35:56+00:00",
                    "text": "Thanks for opening this PR, and I agree we should require a spec at step 4. I skimmed through and like what I see so far, but will give detailed read-through and suggestions later tonight."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 22:04:03+00:00",
                    "text": "I updated the document to include the specification requirement already in step 3."
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 00:34:29+00:00",
                    "text": "Mostly agree. Instead of stabilization, why not to call it standardization? And experimental vs standard.\n\u2026\nOn Mon, Jan 6, 2020, at 5:09 PM, Milan Curcic wrote:\n ***@***.**** approved this pull request.\n\n I like this workflow a lot. I have a few content and wording\n suggestions. I list them all here because I can't quite get the\n suggestions to workout for multiline edits.\n\n First, I suggest adding a statement at the beginning that would invite\n and encourage newcomers (to either stdlib or Fortran) to participate,\n something like:\n\n \"We welcome everyone and anyone to participate and propose additions to\n stdlib. It's okay if you don't have experience for specification or\n implementation, but have an idea for stdlib. If the idea is popular\n among the community, more experienced contributors will help it through\n all 5 steps.\"\n\n Use a keyword for each step to make it more memorable. Something like:\n\n  1. *Idea*: ...\n  2. *API*: ...\n  3. *Specification*: ...\n  4. *Implementation*: ...\n  5. *Stabilize*: ...\n Third, add a sentence to the end of each Step 1 and 2 to describe the\n key goal of the step (other steps are clear!), I suggest:\n\n  1. ... The goal of this step is to find out if the community is\n interested in having this functionality as part of stdlib.\n  2. ... This step is exploratory and its goal is to find out what\n should the API *look* and *feel* like.\n In Step 5 I suggest using the word \"stable\" instead of \"main\". (now you\n see why I called Step 5 Stabilize)\n\n In Step 4, I suggest instead of this:\n\n > We should not merge if there is a strong objection from the reviewers or from somebody in the wider community.\n\n To say:\n\n \"We can merge when there is majority approval (4/5) of the PR.\"\n\n Rationale: We shouldn't have any one person be able to block the PR\n from going forward if they strongly object. If I don't like the API or\n implementation but 4 other contributors strongly support it (because to\n successfully work through Steps 2 and 3 you have to strongly support\n it), I shouldn't be able to throw a wrench in. Majority support should\n be good enough for merge here. Step 3 is already quite strict as it\n requires a majority support for a spec, so in Step 4 we are likely to\n disagree only about internal implementation.\n\n Please adopt these edits if you like them. I approve this PR either way.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#94?email_source=notifications&email_token=AAAFAWGGY4QGQKPSXKXU2QTQ4PB4XA5CNFSM4KDI2ML2YY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCQ2ECBI#pullrequestreview-338968837>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWH7ESG62ACZIS3OSATQ4PB4XANCNFSM4KDI2MLQ>."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-07 00:51:22+00:00",
                    "text": "I think \"standard\" may be confusing, especially if we use the word \"Standardize\". It sounds a bit too close to \"become part of the Fortran Standard\". But that's not what we mean because we hope that some of the functions eventually transition from stdlib to the Standard. That would indeed be to \"Standardize\".\nNow, if we mean \"standard\" as \"accepted as part of the standard library\", then it implies that experimental is somehow non-standard, or not part of stdlib, which I think it is.\nI think it's just inconvenient jargon that there is both a standard and stdlib but they mean different things. What we're really doing here is transition from what everybody else calls \"development\" -> \"stable\"."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-07 00:52:17+00:00",
                    "text": "I think \"Standardize\" should be Step 6, 5-10 years in the future :)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 01:58:15+00:00",
                    "text": "How would you describe our \"stable\" section of stdlib?\nI think  we do more than just a regular stable branch from other projects.\n\u2026\nOn Mon, Jan 6, 2020, at 5:52 PM, Milan Curcic wrote:\n I think \"Standardize\" should be Step 6, 5-10 years in the future :)\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#94?email_source=notifications&email_token=AAAFAWEL7CUBEZBMQRGF2ETQ4PG4FA5CNFSM4KDI2ML2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIHJUEQ#issuecomment-571382290>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWC3TDRGPZPDYJX36DDQ4PG4FANCNFSM4KDI2MLQ>."
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 01:59:37+00:00",
                    "text": "For example we will require specification document, which other projects do not.\n\u2026\nOn Mon, Jan 6, 2020, at 6:57 PM, Ond\u0159ej \u010cert\u00edk wrote:\n How would you describe our \"stable\" section of stdlib?\n I think  we do more than just a regular stable branch from other projects.\n\n On Mon, Jan 6, 2020, at 5:52 PM, Milan Curcic wrote:\n > I think \"Standardize\" should be Step 6, 5-10 years in the future :)\n >\n > \u2014\n > You are receiving this because you authored the thread.\n > Reply to this email directly, view it on GitHub\n > <#94?email_source=notifications&email_token=AAAFAWEL7CUBEZBMQRGF2ETQ4PG4FA5CNFSM4KDI2ML2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIHJUEQ#issuecomment-571382290>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWC3TDRGPZPDYJX36DDQ4PG4FANCNFSM4KDI2MLQ>.\n >"
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-07 02:29:43+00:00",
                    "text": "How about \"release\"? It's been in experimental and now blessed for broad use."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-07 02:45:56+00:00",
                    "text": "I'd describe a feature in stable or main as:\n\nHas spent some time in experimental\nHas API that is unlikely to change in the future, as agreed on by the community\nHas a specification document\nAfter getting traction in external projects, is a candidate for proposal to Fortran standard committee"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-07 02:56:23+00:00",
                    "text": "I like release also."
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 22:41:30+00:00",
                    "text": "I am going to go ahead and merge this, as it is good enough, so that we can move on. Let's submit further PRs if somebody has any ideas for improvement."
                }
            ]
        },
        {
            "number": 93,
            "user": "scivision",
            "date": "2020-01-06 17:29:32+00:00",
            "title": "make real128 optional",
            "text": "fixes #88\nusing Fortran submodule. The Makefiles would need to accommodate these changes\nThis is a cleaner, more modular approach than #83, which this supercedes.\nTo use real128, one would do\ncmake -B build -DREAL128=true\nthen this method can be extended for real16 or other \"exotic\" kinds.\n\nalternatives:\n\ngenerated source code\njust enclosing large bits of code inside #ifdef",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-06 19:47:33+00:00",
                    "text": "Thanks @scivision!\nI personally find that the macros make things less readable and more complex to compile. But at the same time, we do want to have the functionality of compiling with Flang, and it is my understanding that unless the quadruple precision is not compiled, Flang will segfault.  That is the main motivation of this PR, correct?\nI was hoping to avoid using macros much, but there might not be another way."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-06 20:05:23+00:00",
                    "text": "Flang would still be broken with this (with the 2019 release, not sure about current dev version). Although Flang 2019 release is also missing real128.\nThis would be for Ifort or others not having real128"
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 20:23:59+00:00",
                    "text": "So unlike Flang, where I think I am fine to simply wait until they fix things, Intel Fortran is essential to support. However, our current master compiles and passes tests (including quadruple precision) just fine with ifort 19.0.4.243:\n$ cmake .\n-- The Fortran compiler identification is Intel 19.0.4.20190416\n...\n$ make\n...\n$ ctest\nTest project /users/certik/repos/stdlib\n      Start  1: always_skip\n 1/10 Test  #1: always_skip ......................***Skipped   0.00 sec\n      Start  2: always_fail\n 2/10 Test  #2: always_fail ......................   Passed    0.00 sec\n      Start  3: ascii\n 3/10 Test  #3: ascii ............................   Passed    0.00 sec\n      Start  4: loadtxt\n 4/10 Test  #4: loadtxt ..........................   Passed    0.01 sec\n      Start  5: savetxt\n 5/10 Test  #5: savetxt ..........................   Passed    0.02 sec\n      Start  6: loadtxt_qp\n 6/10 Test  #6: loadtxt_qp .......................   Passed    0.00 sec\n      Start  7: savetxt_qp\n 7/10 Test  #7: savetxt_qp .......................   Passed    0.01 sec\n      Start  8: open\n 8/10 Test  #8: open .............................   Passed    0.01 sec\n      Start  9: parse_mode\n 9/10 Test  #9: parse_mode .......................   Passed    0.00 sec\n      Start 10: optval\n10/10 Test #10: optval ...........................   Passed    0.00 sec\n\n100% tests passed, 0 tests failed out of 10\n\nLabel Time Summary:\nquadruple_precision    =   0.02 sec*proc (2 tests)\n\nTotal Test time (real) =   0.11 sec\n\nThe following tests did not run:\n\t  1 - always_skip (Skipped)\n\nWhich version of Intel Fortran do you have?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 20:28:50+00:00",
                    "text": "P.S. I also tried 18.0.5.20180823, 17.0.4.20170411, 16.0.3.20160415 and they all compile our current master and pass all tests.\nThe version 15.0.4.20150805 fails to compile with the error:\n[  3%] Building Fortran object src/CMakeFiles/fortran_stdlib.dir/stdlib_experimental_error.f90.o\n/users/certik/repos/stdlib/src/stdlib_experimental_error.f90(7): error #5082: Syntax error, found IDENTIFIER 'ERROR_STOP' when expecting one of: <END-OF-STATEMENT> ;\nmodule subroutine error_stop(msg, code)\n------------------^\n/users/certik/repos/stdlib/src/stdlib_experimental_error.f90(7): error #5082: Syntax error, found END-OF-STATEMENT when expecting one of: ( % [ . = =>\nmodule subroutine error_stop(msg, code)\n---------------------------------------^\n..."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-06 20:29:43+00:00",
                    "text": "OK I didn't actually check ifort, I assumed they were using a current version"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-06 20:30:48+00:00",
                    "text": "Intel's list of supported versions: https://software.intel.com/en-us/articles/intel-parallel-studio-xe-supported-and-unsupported-product-versions\nCurrently version 2019 (19.0.x) and 2020 (19.1.x) are supported."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-06 20:32:19+00:00",
                    "text": "well in any case, if there were a precision that needed/wanted to be optional, this is a non-generated source way to do it."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 20:37:14+00:00",
                    "text": "well in any case, if there were a precision that needed/wanted to be optional, this is a non-generated source way to do it.\n\nYes, let's discuss how to best do that. I don't see how to significantly simplify the approach in this PR.\nIf we use jin2for, then the approach we discussed so far was to pre-generate all kinds ahead of time (for all compilers) and create a release tarball. Which wouldn't quite work either, since not all compilers support all kinds. So even with jin2for, we would need some macros to allow to turn kinds on and off.\n@zbeekman any ideas how to best handle this?"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 22:37:52+00:00",
                    "text": "If we use jin2for, then the approach we discussed so far was to pre-generate all kinds ahead of time (for all compilers) and create a release tarball. Which wouldn't quite work either, since not all compilers support all kinds. So even with jin2for, we would need some macros to allow to turn kinds on and off.\n\nThis isn't quite true:\n\nWhich wouldn't quite work either, since not all compilers support all kinds.\n\nThe question becomes: how do we want to use jin2for? Jin2For will use the compiler to enumerate all available kinds from ISO_FORTRAN_ENV's array kinds compile time constants. These all automatically get an alias, a declaration and a kind. The problem (or solution depending on how you look at it) is that Jin2For doesn't assign any meaning to the kinds it finds. For example, if I use Jin2For with GFortran and do something like this:\nexample.t90\n{% for t in real_types %}\n{{t.decl}} :: a_{{t.alias}}\nreal(kind={{t.kind}}) :: b_{{t.alias}}\n{% endfor %}\n\nGenerate with:\njin2for -g gfortran-8 -e .F90 example.t90\n\nYou get:\nreal(4) :: a_r4\nreal(kind=4) :: b_r4\n\nreal(8) :: a_r8\nreal(kind=8) :: b_r8\n\nreal(10) :: a_r10\nreal(kind=10) :: b_r10\n\nreal(16) :: a_r16\nreal(kind=16) :: b_r16\nAs you can see I get a single, double, x86 80-bit and quad precision kind with GFortran. But if you use ifort (and pass -g ifort to jin2for) the emitted code will have only the kinds supported by ifort.\nBut, you don't have to query the compiler, or use the pre-defined types. The other two options are something like:\ninteger, parameter :: r32 = selected_real_kind(...\ninteger, parameter :: r64 = selected_real_kind(...\n! ...\n{% for t in [\"r32\", \"r64\", \"r128\"] %}\nreal({{t}}) :: a_{{t}}\nreal(kind={{t}}) :: b_{{t}}\n{% end for %}\n\nHere you don't use any of Jin2For's compiler introspection/kind & type enumeration and you must find a means of coding the introspection yourself or relying on a priori knowledge that all compilers we wish to support have the requested types. But the advantage is that you aren't (hopefuly) generating compiler specific code. It shouldin theory.... run on any compiler. You would have to provide logic through some other means for whether or not you want r128 to be present, probably via CMake.\nAlternatively, we could create and maintain the json files that Jin2For generates describing the kinds available from the compiler. These can then be passed to jin2for with the -f flag. This lets you generate code for all the compilers you have json files for. Testing that code, however, is another matter. You need access to the compiler to do this, so, in a way, this is like a bad solution to just querying the compiler for the available kinds. The advantage is that you can ship code to users even if you don't have access to that particular compiler, and the users do not need to run Jin2For. You just need someone to generate the json file."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 22:44:03+00:00",
                    "text": "Also, one advantage of approach 1 & 3 (using Jin2For on the client system w/ the client compiler to generate sources, approach 1 or pre-generating sources from all supported compilers via the introspection data) is that you can implement interfaces for all available kinds. As long as there are bugs with the more exotic kinds (a big ask I know) then you don't have to care about single, double, 80-bit, quat precision etc. you just emit code for all possible kinds a given compiler claims to support."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 23:34:52+00:00",
                    "text": "I understand that using jin2for at the end user machine would work, as it would simply generate the kinds that are available for the particular compiler.\nWhat I do not understand is how to pre-generate a tarball with already generated sources, so that when the user compiles it, the jin2for tool is not needed. That is what I had in mind doing, but if we have to generate different sources for different compilers, then I don't know how to approach it. Can you give an example how this would work?"
                },
                {
                    "user": "certik",
                    "date": "2020-02-03 19:55:13+00:00",
                    "text": "I think this PR can be closed, as we now have an equivalent feature in master I think."
                }
            ]
        },
        {
            "number": 92,
            "user": "scivision",
            "date": "2020-01-06 16:52:39+00:00",
            "title": "ci ctest enhancements",
            "text": "broken tests sometimes hang forever, and that's CTest's default, so make CTest have a finite timeout by default\ndon't rely on shell-specific || to catch test failures, use a platform-agnostic if:\ninvoke ctest directly to allow easier option access",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 18:00:38+00:00",
                    "text": "I think this is a sufficiently straightforward/uncontroversial and necessary PR, so I'm going to merge this.\nAs an aside, @certik I took a look at windows CI and integrating it into the main CI build matrix, but it's not immediately clear to me what the best way to get multiple/different versions of GFortran installed is. It looks like the windows CI has mingw64 by default which ships a GCC/GFortran. It also has the Chocolatey package manager, which can provide MSYS2, which gives a route to install multiple different GCCs on windows. However, I'm concerned that installing MSYS2, and then GCC may have quite a bit of overhead associated with it, and may also not map particularly well into the build matrix. What do you @certik and @scivision think? Should we test multiple GCCs on Windows? Should we experiment with MSYS2? Or should we leave things as they are now?"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-06 18:26:51+00:00",
                    "text": "I tried MSYS2 Github Action a couple months ago and it didn't work, it was in development. Haven't tried since.\nI think a lot of Homebrew/Chocolately users would be just using the latest release?\nCI for Meson itself just uses one MSYS and Cygwin version, while testing many versions of Visual Studio.\nAre most of the users with old GCC versions on Linux PC/HPC?\nMy thought at this time would be to check across GCC >= 6 stable versions on Linux, but just the default latest version on MacOS and Windows. Unless/until specific issues are noted."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 18:30:43+00:00",
                    "text": "I agree with @scivision to only test the latest GFortran on Windows. (And even on macOS.)\n@zbeekman in general, I think we can do anything as long as the tests run quick (as they do now)."
                }
            ]
        },
        {
            "number": 91,
            "user": "jvdp1",
            "date": "2020-01-06 15:33:34+00:00",
            "title": "Addition of access in the API of open function",
            "text": "Here is a proposition for allowing different accesses in the API of open.\nThe default access is stream for both formatted and unformatted files.\nThis is based on discussions in #86 and in #14, and needs further discussion.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-01-06 15:45:34+00:00",
                    "text": "Thinking a bit: we might not be able to support direct access with our open function because the open statement must contain the recl argument, in addition to access = direct.\nSo the direct access must most likely be deleted from this PR. Or we need an additional argument, but then our simple open function is becoming complex."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-06 15:49:43+00:00",
                    "text": "So the direct access must most likely be deleted from this PR. Or we need an additional argument, but then our simple open function is becoming complex.\n\nYep, otherwise soon we'd have the same old open, but now as a function. I don't think it's what we're looking for :)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-06 15:50:58+00:00",
                    "text": "So again, please please let's discuss API changes and additions in #14. It's very easy to just approve  quick and dirty PRs because they look good on the surface, but over time the API just get piled up on. Let's discuss and plan. What do we want to accomplish, why, and how."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-06 16:02:04+00:00",
                    "text": "Yep, otherwise soon we'd have the same old open, but now as a function. I don't think it's what we're looking for :)\nSo again, please please let's discuss API changes and additions in #14. It's very easy to just approve quick and dirty PRs because they look good on the surface, but over time the API just get piled up on. Let's discuss and plan. What do we want to accomplish, why, and how.\n\nI agree to both comments. If it is to get something like the open statement, then this function is not needed. IMHO the current open function can be tested and used as is.\nThe API needs more discussion if we want to extend it. It is also why I submitted this PR as a draft. So we can based our discussion on some codes."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 16:09:24+00:00",
                    "text": "I agree we need a plan. All I am saying is that the quality of discussion is much higher if we can discuss an actual code change, like this one. So thanks @jvdp1 for submitting a PR with this.\nI would not do direct for the reasons discussed above.\nIn that light, perhaps it's not worth doing \"sequential\" at all. The main motivation would be that current codes could start using our open for more things. But as documented here, some of the codes use \"direct\". So it seems that such usages would just use the old built-in open. And stdlib's open would just use stream."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 22:11:12+00:00",
                    "text": "I do think that it can be easier and more natural to discuss technical details over actual code like a PR, but I haven't been keeping up with the details.\nI am a strong proponent for using stream access wherever possible to be more interoperable, create smaller files, etc. If my memory serves me correctly, stream isn't mutually exclusive with direct access; A file written using one method may be read with the other subject to a few constraints and assumptions. Neither one have the pesky record length indicators in them, and direct access just indexes record*record_length bytes into the file. (I've spent a lot of time with a hex editor examining Fortran binary IO, but this was a while ago and I'm not 100% sure if the standard guarantees that compilers can't make up their own approach for some of this stuff.)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-07 00:27:04+00:00",
                    "text": "and direct access just indexes record*record_length bytes into the file\n\nExcept that it's not bytes on all compilers. With ifort you have to say -assume byterecl, see example here: https://gist.github.com/milancurcic/6590d74fbbd3e765832b823474623a27. Standard says it's system dependent.\nBut yes, your main point is, and I agree, we can read unformatted files written with direct access, using stream access just fine."
                }
            ]
        },
        {
            "number": 90,
            "user": "certik",
            "date": "2020-01-06 14:53:16+00:00",
            "title": "Use access = \"stream\" by default",
            "text": "See the discussion at #86.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-06 15:02:01+00:00",
                    "text": "(One builder is stuck, but it should pass, so I merged it.)"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 18:03:48+00:00",
                    "text": "LGTM! I was going to comment on this or suggest this."
                }
            ]
        },
        {
            "number": 89,
            "user": "pdebuyl",
            "date": "2020-01-06 13:47:48+00:00",
            "title": "Use explicit formatting in qsavetxt",
            "text": "ifort does not save 2d arrays of \"real(kind=qp)\" in a rectangular fashion with \"*\" formatting.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-06 22:16:50+00:00",
                    "text": "Fixes #88."
                }
            ]
        },
        {
            "number": 88,
            "user": "pdebuyl",
            "date": "2020-01-06 09:39:03+00:00",
            "title": "test_savetxt_qp fails with ifort",
            "text": "Using \"ifort (IFORT) 18.0.1 20171018\" on linux x86_64, test_savetxt_qp fails\nThe routine qsavetxt writes one number per line, which is allowed by the star format.\nI propose a fix in https://github.com/pdebuyl/stdlib/tree/qsavetxt_format_string , tested with said ifort and with gfortran 6.4.0 and 8.3.0.\nI have not opened a PR yet, as I don't know if ifort compatibility is considered necessary at this point. I would support keeping stdlib working with several compilers early on.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-01-06 10:03:50+00:00",
                    "text": "Is this problem related to #81? Maybe you could implement the same strategy as in #81 to avoid qp with Intel compilers and open a new PR.\nHowever, I think your fix could be also useful for very large arrays (to avoid multiple lines for one row of an array; I didn't test it yet). However, this implies a fixed format (e.g., 'f40.34), and the same should be done for spanddp.  Another option would be to discuss the API of loadtxtandsavetxt` to allow the user to specify its own format. See #16 ( comment ) and #14 for some discussions."
                },
                {
                    "user": "pdebuyl",
                    "date": "2020-01-06 10:17:47+00:00",
                    "text": "It is orthogonal to #81 I believe. ifort supports a qp type, it is only the write operation that does not output a \"ncol x nrow\" format.\nIssue #16 is of course related but consider extensions of loadtxt and savetxt. Here, I just fix the currrent version :-)\nI write a format string to avoid relying on a fixed format. The current format string can hold up to 999999 for the number of columns. At some point users should use HDF5 or another solution anyway."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 13:39:33+00:00",
                    "text": "Can you please submit a PR? Compatibility with ifort is essential.\n\u2026\nOn Mon, Jan 6, 2020, at 2:39 AM, Pierre de Buyl wrote:\n Using \"ifort (IFORT) 18.0.1 20171018\" on linux x86_64, test_savetxt_qp fails\n\n The routine qsavetxt writes one number per line, which is allowed by\n the star format.\n\n I propose a fix in\n https://github.com/pdebuyl/stdlib/tree/qsavetxt_format_string , tested\n with said ifort and with gfortran 6.4.0 and 8.3.0.\n\n I have not opened a PR yet, as I don't know if ifort compatibility is\n considered necessary at this point. I would support keeping stdlib\n working with several compilers early on.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#88?email_source=notifications&email_token=AAAFAWEVRGZIG544BQMK5N3Q4L33RA5CNFSM4KDB4AAKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IEFVYTA>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWFIF66C7CBXVP6IKLLQ4L33RANCNFSM4KDB4AAA>."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-06 17:30:49+00:00",
                    "text": "This would be addressed by #93"
                },
                {
                    "user": "pdebuyl",
                    "date": "2020-01-06 21:34:49+00:00",
                    "text": "@scivision ifort supports qp, it is only the * formatting that fails to generate colummar data files."
                },
                {
                    "user": "pdebuyl",
                    "date": "2020-01-06 21:35:12+00:00",
                    "text": "It is fixed actually, so I close the issue."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 22:16:28+00:00",
                    "text": "This was fixed by #89."
                }
            ]
        },
        {
            "number": 87,
            "user": "jacobwilliams",
            "date": "2020-01-05 21:01:31+00:00",
            "title": "Optimization, Root finding, and Equation Solvers",
            "text": "I'm willing to spearhead a module or set of modules containing:\n\ngeneral constrained and unconstrained nonlinear optimization (sqp, global optimization, etc.)\nnonlinear equation solving (newton, least squares, etc.)\nscalar minimizers and root solvers (fmin, zeroin, etc.)\n\nI have already modernized some classic codes and there are also some others with permissive licenses floating around. I am willing to merge mine into the stdlib. I need to gather then together and provide a nice interface so that a user can call any of the solvers in a similar way. We can have discussion on what that interface would look like. Here are some example codes:\n\nslsqp (SQP)\npikaia (genetic algorithm)\nBrent codes zeroin and fmin\nMinpack\nOther derivative-free bracketed root solvers such as bisection, Anderson-Bjorck, Muller, Pegasus, ...\nBasic Newton and/or Broyden solvers\nFilterSD\n\nEventually we could even provide (optional) integrations with larger third-party and/or commercial libraries such as IPOPT and/or SNOPT\nSee also\nNote that some of these in various Python packages are just wrappers to Fortran 77 codes (such as slsqp).\n\nScipy.optimize\nPyOpt\nNetlib opt",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-05 21:23:35+00:00",
                    "text": "Thank you! This would be super helpful.\n\nLet's discuss the user facing public API.\n\u2026\nOn Sun, Jan 5, 2020, at 2:01 PM, Jacob Williams wrote:\n I'm willing to spearhead a module or set of modules containing:\n\n  * general constrained and unconstrained nonlinear optimization (sqp,\n global optimization, etc.)\n  * nonlinear equation solving (newton, least squares, etc.)\n  * scalar minimizers and root solvers (fmin, zeroin, etc.)\n I have already modernized some classic codes and there are also some\n others with permissive licenses floating around. I am willing to merge\n mine into the stdlib. I need to gather then together and provide a nice\n interface so that a user can call any of the solvers in a similar way.\n We can have discussion on what that interface would look like. Here are\n some example codes:\n\n  * slsqp <https://github.com/jacobwilliams/slsqp> (SQP)\n  * pikaia <https://github.com/jacobwilliams/pikaia> (genetic algorithm)\n  * Brent codes zeroin and fmin\n <https://github.com/jacobwilliams/Fortran-Astrodynamics-Toolkit/blob/653236e66950782262eb1c2538f56e120d67f83e/src/brent_module.f90>\n  * Minpack\n <https://github.com/jacobwilliams/Fortran-Astrodynamics-Toolkit/blob/7f176fabc8c36cc1981349b02eeb6d8112f2bfbc/src/minpack_module.f90>\n  * Other derivative-free bracketed root solvers such as bisection,\n Anderson-Bjorck, Muller, Pegasus, ...\n  * Basic Newton and/or Broyden solvers\n  * FilterSD <https://projects.coin-or.org/filterSD>\n Eventually we could even provide (optional) integrations with larger\n third-party and/or commercial libraries such as IPOPT and/or SNOPT\n\n See also\n\n Note that some of these in various Python packages are just wrappers to\n Fortran 77 codes (such as slsqp).\n\n  * Scipy.optimize\n <https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html>\n  * PyOpt <http://www.pyopt.org/reference/optimizers.html>\n  * Netlib opt <https://www.netlib.org/opt/>\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#87?email_source=notifications&email_token=AAAFAWGQYP5UOW6FAZVDHP3Q4JDCZA5CNFSM4KC5DBQ2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IEDE5IA>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWGPY3KUNEQQFREEPSTQ4JDCZANCNFSM4KC5DBQQ>."
                },
                {
                    "user": "rweed",
                    "date": "2020-01-06 13:37:27+00:00",
                    "text": "I have refactored (ie pasta free) versions of Nodecal and Morales LBFGSB code, Turlach's quadratic programming code, and a couple of nature inspired algorithms (cuckoo search and Particle Swarm) optimizers I can contribute for optimization provided the original licenses for those codes are compatible. I know one is GPL2. I also have my versions of Brent's fmin and zeroin that I got from Frank Carmichaels PDAS site. He refactored the original FMM code towards F90."
                },
                {
                    "user": "rweed",
                    "date": "2020-01-06 13:44:00+00:00",
                    "text": "Also, forgot that I have a version of the Nelder-Mead simplex algorithm I can contribute."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-06 17:54:39+00:00",
                    "text": "@jacobwilliams how about MATH77? Those are amazing pieces of code...\nConcerning (optional) larger third-party libraries, I think FGSL deserves consideration even if there might be licence issues. Hopefully, they can be circumvented making its installation optional."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-06 18:33:26+00:00",
                    "text": "a set of functions one would find on a handheld scientific calculator in Fortran: https://github.com/scivision/rpn-calc-fortran#other-functions"
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-06 21:32:19+00:00",
                    "text": "@rweed Absolutely, we can use them! Although I think any GPL licensed code would be off limits since we don't want to make the whole library GPL, right?\n@epagone Yep, we can check Math77 for anything we can use. That has a permissive license."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-06 21:33:15+00:00",
                    "text": "@scivision Is that for a different topic? I think we should have a function parser in stdlib, that could be used there. I can make a new ticket for that."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 22:25:25+00:00",
                    "text": "The hard part and the main contribution of stdlib is to agree on a well designed API, that is approved, accepted and adopted by the wide Fortran community. The stdlib library then provides both this specification of the API, as well as a reference implementation.\nI agree the actual implementation can and should use well tested available code whenever possible (e.g. by porting the SciPy Fortran code into stdlib), instead of reinventing our own code. We should only write our own numerical code if there is no available permissive licensed code out there that would work. Or if we discover some bugs, or numerical issues (which can happen).\nYes, we can't use GPLed code, only permissive licenses like MIT or BSD."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-06 22:35:21+00:00",
                    "text": "My thinking is that it would be a high-level object oriented interface. Something like what I did for slsqp. I think this is the best way for modern codes of this type. The alternatives (forcing you to stuff your user data into giant work arrays, common blocks, or reverse communication, are unsatisfactory as far as I'm concerned).\nThere would be procedures for:\n\ninitializing the class, send in all the input parameters (tolerances, etc.)\nsolving the problem\ndestroying the class\n\nThere would be methods a user would have to provide:\n\nthe problem function (compute the objective function if present, and the constraints)\nthe gradient function (compute the gradient of the objective function and the constraints) -- for those methods that require gradients.\na function to report an iteration to the user\n\nThere would also be some mechanism for stopping the solve process (either within the problem or report function).\nOther notes:\n\nsome methods will have simple bounds (on the optimization variables), some may not.\nsome methods may require a dense gradient matrix, and other may use a sparse one."
                },
                {
                    "user": "rweed",
                    "date": "2020-01-06 22:58:44+00:00",
                    "text": "@jacobwilliams , In my code I usually (but not always - for old code its sometimes not practicle) use an empty abstract class (optimizers_t) and derive all of the base classes from that. I augment that with an abstract objective functions class. I think at a minimum if you go OO you will need something like these two classes.\nAlso, I could use a little guidance from those of you who are wise in the ways of software licenses. If I take a code written in another language (MATLAB and Python in this case) and completely rewrite it in Fortran (using none of the original source, just using the implementation as a guide) does the Fortran code inherit the license restrictions of the original code albeit in another language.\nActually, we probably need some sort of licensing guide that covers these kinds of issues and goes over whats usable and whats not (including copyrighted material from books etc)"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-06 23:24:24+00:00",
                    "text": "@jacobwilliams the functions are a bunch of polymorphic math functions that can readily be adapted in stdlib.\nThe simple REPL it has is a separate idea, if a pure Fortran REPL would be of interest."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 23:28:43+00:00",
                    "text": "If I take a code written in another language (MATLAB and Python in this case) and completely rewrite it in Fortran (using none of the original source, just using the implementation as a guide) does the Fortran code inherit the license restrictions of the original code albeit in another language.\n\nIf you take program in one language and rewrite it to another language, that is considered derivative work. So if the original is, say, GPL licensed, then your derivative work must also be GPL licensed. If you want to avoid that, you can do a so called clean room implementation: one person write a specification based on the original code, and another person takes that specification and creates a new implementation based on that without ever looking at the original code.\n\nMy thinking is that it would be a high-level object oriented interface.\n\n@jacobwilliams besides a high level interface, would you be against also having a low level non-OO API in stdlib if others volunteer it?"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-06 23:44:43+00:00",
                    "text": "A library for geodesy, geographic coordinate transforms for sensors, satellites, etc https://github.com/scivision/maptran3d"
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-07 16:53:02+00:00",
                    "text": "@rweed That sounds similar to what I was thinking. Do you have any of your examples in a repo somewhere I could examine? I hope to find some time soon to start working up an example.\n@certik I have no objection to a low-level interface. I think in some cases it would be fairly easy to make. FYI: if you look at the SLSQP code, you will notice that the original reverse-communication interface is still there, and that's what the oo interface calls. However, I don't want to impose this pattern on all the solvers, since it makes for somewhat weird and not straightforward code in my opinion. I think for a \"simple\" interface to an oo solver, all we'd need to do is make a subroutine where everything is passed in as arguments (including non-type bound functions), and then the class is just created and run inside this subroutine. It would be easy to do I think... but the devil is in the details..."
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 17:16:40+00:00",
                    "text": "@jacobwilliams perfect, I agree. Where there's a will, there's a way. I will support you (and anybody) on a nice OO interface, and if you support me (and others) on a nice low level non OO interface, then I think we all, as a community, will get what we want."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-07 17:50:27+00:00",
                    "text": "Another issue is to choose the algorithms to make available to solve a certain problem.\nE.g., for popular problems like one-dimensional root-finding there is plenty of choice (I'm afraid too much): there are some algorithms available in MATH77, @jacobwilliams has refactored and modernised zeroin and I am pretty sure there could be other good implementations already available (see John Burkardt's large collection). For the numerical integration of one-dimensional functions there are many strategies and implementations available, etc.\nShould we expose through the API all the routines available or we'll choose the \"best\" ones?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 18:47:18+00:00",
                    "text": "@epagone excellent question. I would allow the user to select the method, with some unified API. Let's look at how other projects do this, and then we can discuss what the best API would be.\nSciPy\nhttps://docs.scipy.org/doc/scipy/reference/optimize.html#root-finding\nIt looks like they have a root_scalar function that accepts a method argument:\n    root_scalar(method=\u2019brentq\u2019)\n    root_scalar(method=\u2019brenth\u2019)\n    root_scalar(method=\u2019bisect\u2019)\n    root_scalar(method=\u2019ridder\u2019)\n    root_scalar(method=\u2019newton\u2019)\n    root_scalar(method=\u2019toms748\u2019)\n    root_scalar(method=\u2019secant\u2019)\n    root_scalar(method=\u2019halley\u2019)\nand in addition, they provide functions for each algorithm, such as brentq, ridder, etc.\nMatlab\nMatlab has fzero, which seems to be just one particular method. Then they have a general method solve where one can set a solver argument. See also the section \"Algorithms\", but for root finding, it looks like they only have one method.\nJulia\nJulia has a separate package Roots.jl for this, which provides both Matlab like fzero and their own find_zero, which accepts a method as an argument (such as Bisection() or Newton()). The Roots.jl package was started as a result of this issue: JuliaLang/julia#2447, where you can find the initial discussion about the API."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-07 18:55:49+00:00",
                    "text": "FWIW I vote for the SciPy interface, i.e. a string argument that selects the method to call. Clean and modular. Maybe we still need to select the \"best\" algorithm (that will be the default choice) and make the string argument optional."
                },
                {
                    "user": "rweed",
                    "date": "2020-01-07 21:59:44+00:00",
                    "text": "@jacobwilliams I don't have the code in a repository but the following will give you an example of how I implement the abstract classes. I'll be the first to admint there is a lot of room for improvement but this works for my current applications.\nAn empty abstract class that is the parent class for all other optimizers. Probably could add some abstract methods but that forces you to implement all the abstract methods even if you don't need them all\noptimizerClass.F90.txt\nmodule with abstract classes for objective functions and constraints\nobjectiveFunctions.F90.txt\nThe basic class and subroutine interface for my cuckoo search code based on Walton's (see comments in module) modified cuckoo search MATLAB code which is unfortunately GPL2. I pass the objective function class as an argument instead of including it as a class\ndata via a procedure pointer. I have generic methods (optimizer, init, and dealloc) to do the basic things you need for initialization etc.\ncuckooSearch.F90.txt\nA set of standard test cases for unconstrained optimization illustrating use of objective function class\noptTestFunctions.f90.txt\nFinally a test program for the cuckoo search routines. Note the actual code uses a lot of utilities for random numbers and my implementation of various MATLAB functions\ntestMCS.f90.txt"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-14 09:06:13+00:00",
                    "text": "The Boost C++ library simply provides the routines under different names:\n\nRoot Finding Without Derivatives\n\n// Bisection\ntemplate <class F, class T, class Tol>\nstd::pair<T, T>\n   bisect(\n      F f,\n      T min,\n      T max,\n      Tol tol,\n      boost::uintmax_t& max_iter);\n\n// Bracket and Solve Root\ntemplate <class F, class T, class Tol>\nstd::pair<T, T>\n   bracket_and_solve_root(\n      F f,\n      const T& guess,\n      const T& factor,\n      bool rising,\n      Tol tol,\n      boost::uintmax_t& max_iter);\n\n // TOMS 748 algorithm\ntemplate <class F, class T, class Tol>\nstd::pair<T, T>\n   toms748_solve(\n      F f,\n      const T& a,\n      const T& b,\n      Tol tol,\n      boost::uintmax_t& max_iter);\n\nRoot Finding With Derivatives\n\n// Newton-Raphson\ntemplate <class F, class T>\nT newton_raphson_iterate(F f, T guess, T min, T max, int digits, boost::uintmax_t& max_iter);\n\n// Halley\ntemplate <class F, class T>\nT halley_iterate(F f, T guess, T min, T max, int digits, boost::uintmax_t& max_iter);\n\n// Schr'''&#xf6;'''der\ntemplate <class F, class T>\nT schroder_iterate(F f, T guess, T min, T max, int digits, boost::uintmax_t& max_iter);\n\nPersonally, I think the SciPy way fits to Fortran best, we provide both a root_scalar/ find_zero function where you specify the method using a string, and also a set of functions for each algorithm.\nThe find_zero can then pick a default method based on the arguments. In SciPy the default is Brent's algorithm for bracketed roots and Newton or secant if not; see the excerpt from SciPy root_scalar below:\n    # Pick a method if not specified.\n    # Use the \"best\" method available for the situation.\n    if not method:\n        if bracket:\n            method = 'brentq'\n        elif x0 is not None:\n            if fprime:\n                if fprime2:\n                    method = 'halley'\n                else:\n                    method = 'newton'\n            else:\n                method = 'secant'\n    if not method:\n        raise ValueError('Unable to select a solver as neither bracket '\n                         'nor starting point provided.')\nThe root solvers are a good project to test some type templating mechanism like Jin2For. Having to modify both the single and double precision versions of each solver would be annoying"
                },
                {
                    "user": "epagone",
                    "date": "2020-01-14 12:25:31+00:00",
                    "text": "I agree with almost everything written by @ivan-pi. The only variation that I would suggest is to make Brent's method the default for scalar root-finding without derivatives and Newton-Raphson's algorithm when a derivative is provided (as per the theory). Furthermore, practical implementations rarely code exactly the textbook methods: e.g. some solvers (I don't recall at the moment exactly and I cannot check) use Newton's method with bracketing to detect divergence. I would focus more on the practical implementations to decide on the use-cases, although I understand that we need to give it a clear name to make them selectable."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-15 18:51:16+00:00",
                    "text": "The NLopt library contains several constrained and unconstrained nonlinear optimization routines and comes with a Fortran interface (geared toward the old F77 style of Fortran). Ironically, many of the routines are translations of old Fortran ones to C using f2c. I find the NLopt API very intuitive and simple to use. I made a pull request with a modern Fortran interface for NLopt a while ago. Maybe it could serve as a template for the stdlib one."
                }
            ]
        },
        {
            "number": 86,
            "user": "jvdp1",
            "date": "2020-01-05 19:22:05+00:00",
            "title": "stdlib_experimental_io(open): support for unformatted sequential files",
            "text": "Addition of a support for opening unformatted sequential files",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2020-01-05 19:27:44+00:00",
                    "text": "Possibilities for:\n\naccess= \"direct | sequential | stream\"\nform= \"formatted | unformatted\"\n\nNow supported by open in stdlib_experimental_io\n\nsequential + formatted  (text files; t)\nsequential + unformatted (\"traditional\" Fortran binary files?; u)\nstream + unformatted (stream files; b or s)\n\nWhat about the direct access? How to support it (if needed)?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-05 19:39:53+00:00",
                    "text": "Couldn't we cover all reading and writing with only stream access?\nDo we need sequential and direct access? I thought they are edge cases covered under the more general stream access."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-05 19:52:41+00:00",
                    "text": "Couldn't we cover all reading and writing with only stream access?\nDo we need sequential and direct access? I thought they are edge cases covered under the more general stream access.\n\nPersonally I don't use \"sequential + unformatted\" and \"direct + unformatted\". But they seem to be used by some people: https://github.com/fortran-lang/stdlib/wiki/Usage-of-%22open%22\nSo I think it would be good to at least support \"sequential+unformatted\" (this PR). With these 3 options (t, s|b, an u) we may cover, let say 95(?)% of the open (simple) cases.\nNote: a sequential unformatted file can be read as a stream unformatted file if the specificities of a sequential unformtted file are considered when it is read. Not sure about a direct unformatted file."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 20:07:13+00:00",
                    "text": "I use unformatted sometimes --- the advantage is that it allows to quickly save large arrays from a simulation, that can be later post-processed by another Fortran code (compiled with the same compiler of course). The stream might be similarly fast (I don't know if it's as fast as unformatted on all platforms).\nI agree we should support text (t), binary (b) and unformatted (u).\nI personally would not designate both b and s for binary stream. I would only use b, as in Python. @jvdp1 in your opinion, what is the advantage of allowing two characters s and b to do exactly the same?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-05 20:15:16+00:00",
                    "text": "I personally would not designate both b and s for binary stream. I would only use b, as in Python. @jvdp1 in your opinion, what is the advantage of allowing two characters s and b to do exactly the same?\n\nThey exist a non-standard form=binary. So, using b for stream may be confusing. Mentioning both may clarify that b is used for unformatted stream files.\nIf people disagree with that, I can remove the s. Or we can keep it, and not advertise it. I will not be difficult with that."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 20:35:35+00:00",
                    "text": "Let's keep both for now, as we are in experimental. Let's get some experience using it and we can revisit later.\n\u2026\nOn Sun, Jan 5, 2020, at 1:15 PM, Jeremie Vandenplas wrote:\n >\n > I personally would not designate both `b` and `s` for binary stream. I would only use `b`, as in Python. @jvdp1 <https://github.com/jvdp1> in your opinion, what is the advantage of allowing two characters `s` and `b` to do exactly the same?\n\n They exist a non-standard `form=binary`. So, using `b` for `stream` may\n be confusing. Mentioning both may clarify that `b` is used for\n unformatted stream files.\n  If people disagree with that, I can remove the `s`. Or we can keep it,\n and not advertise it. I will not be difficult with that.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#86?email_source=notifications&email_token=AAAFAWAEYTOQWLNUML576I3Q4I5VLA5CNFSM4KC4WPQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEID6QUY#issuecomment-570943571>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWG4X66MQGAJWCCNPZDQ4I5VLANCNFSM4KC4WPQA>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-05 21:07:49+00:00",
                    "text": "@milancurcic Is it fine to keep (and merge) it as it is now implemented?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-05 21:48:18+00:00",
                    "text": "I think this API is problematic. Will write in more detail tonight."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-05 23:42:48+00:00",
                    "text": "Here's the problem in my view: This PR mixes up form (text/formatted or binary/unformatted) and access (sequential, direct, or stream).\nform is important for the user and should be part of the API. When you want text, you use t in mode (or leave it out because it's default). When you want binary, you use b in mode.\nRead/write/readwrite is also important for the user and should be part of the API. When you want to read- or write-only, you use r or w in the mode, respectively. r+ for read+write. a for append. We have this in master and so far we're conveniently mapping to Python's API.\naccess however merely specifies how you're reading or writing under the hood. Part of the reason why Fortran's I/O is so complicated is because user has to choose access also. And the access that you choose changes how read and write statements work:\n\nformatted+sequential is mostly okay because each read is one record (but still not my favorite -- I think we can do better by defaulting to formatted+stream)\nunformatted+sequential is problematic because it's not portable (record separator is compiler-dependent);\nunformatted+direct is useful (I use it also) for scenarios that @certik mentioned above, but you need to specify record length recl, and this is also compiler dependent (gfortran and ifort, one counts it as # of elements, the other one # of bytes, I always forget which one, it's a mess);\n\n\nI agree we should support text (t), binary (b) and unformatted (u).\n\nUnformatted == binary. We don't need u!! :)\nMy main point being, sequential or direct access modes, while useful, are specific ways of reading and writing that can more generally be done by stream. I don't think we should expose them in the API.\nI understand and agree that these are useful and there are projects using them. However, I don't think anybody's gonna take somebody else binary files written in sequential mode and try to read them using stdlib (and if they do, they can read it as long as they know what the records mean).\nWe should aim to design a clean API with one recommended way of reading and writing. I suggest that we take this to the drawing board in #14 and sketch out the API that we want, and beyond just open -- we should sketch out what should read and write look like."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-05 23:56:15+00:00",
                    "text": "Designing the API for read and write functions will guide whether open('somefile.txt', 'rt') should open in formatted+sequential or formatted+stream. In the former we'd be working with records and in the latter we'd be working with bytes. It's quite possible that we'll find that the latter will lead to a cleaner API for read and write."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 02:58:07+00:00",
                    "text": "@milancurcic if I understood what you wrote, you are proposing to keep the rwa modes and to also keep the two tb modes for text / binary. But beyond that you would not expose anything else, or perhaps expose it as other arguments to open, but not in the mode.\nTo be honest, the various combinations are quite complicated that I only use the t mode, and then I use both stream if I want to write binary files that are compiler independent (for example the PPM binary reader/writer uses stream) and as well as \"unformatted\" that is compiler dependent.\nAs long as we naturally capture 95% of all use cases, then I think that's good enough.\nHowever, when you use b in Python, that means binary that is compiler independent. So the only thing that corresponds to it in Fortran is the \"stream\" approach, even though it is technically \"access\". So I don't think it would make sense to use b for \"unformatted\" non-stream (sequential), because that would not be compiler independent.\nIn other words, this Python like API does not directly map to the \"form\" / \"access\" fields in Fortran. Rather, the idea that I had was to pick such combinations of \"form\", \"access\" and other parameters, so that the result is pretty much what you would expect when coming from Python. So there would always be combinations of open statement arguments that one cannot do in Python. But by exposing what Python does together with u for unformatted sequential, this would cover pretty much all practical use cases. And if you wanted some other combination, you can still use the original open statement."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 03:07:45+00:00",
                    "text": "Let's discuss some particular example. Using the current master:\ncharacter(:), allocatable :: filename\ninteger :: u, a(3)\n\n! Test mode \"w\"\nu = open(filename, \"w\")\nwrite(u, *) 1, 2, 3\nclose(u)\n\n! Test mode \"r\"\nu = open(filename, \"r\")\nread(u, *) a\ncall assert(all(a == [1, 2, 3]))\nclose(u)\nthe second open function is using the rt mode, which currently means formatted and sequential.\nIf you instead opened in formatted and stream, what would have to change in the above code to read the array \"a\" properly? What exactly is the difference between formatted/sequential and formatted/stream?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-06 03:14:20+00:00",
                    "text": "@certik Exactly!\nIn the API, expose what maps to Python's API, which is what we already have. rwa+ and tb modes map to action and form, respectively. access is an internal, Fortran-specific thing, which I don't think should be part of the user interface. At least we have an opportunity here to not expose it.\nRegarding the internal implementation, I suggest that we always open with access=stream, for both formatted (t) and unformatted (b) modes, and design read and write around that. Then we're working directly with bytes rather than records which are a historical Fortran artifact. I think this will lead to the simplest (and closest to Python) API for read and write functions."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-06 03:17:18+00:00",
                    "text": "If you instead opened in formatted and stream, what would have to change in the above code to read the array \"a\" properly? What exactly is the difference between formatted/sequential and formatted/stream?\n\nI don't know the answer and I'll need to play with it."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-06 03:30:02+00:00",
                    "text": "For text (form='formatted') sequential and stream access seem to be completely interchangeable, at least in this case (default formatting and integer array):\nSequential version:\ninteger :: u\ninteger :: a(3) = [1, 2, 3]\ninteger :: b(3) = 0\n\nopen(newunit=u, file='somefile.txt', status='unknown', &\n     action='write', access='sequential', form='formatted')\nwrite(u, *) a\nclose(u)\n\nopen(newunit=u, file='somefile.txt', status='old', &\n     action='read', access='sequential', form='formatted')\nread(u, *) b\nclose(u)\n\nprint *, all(a == b)\n\nend\nStream version\ninteger :: u\ninteger :: a(3) = [1, 2, 3]\ninteger :: b(3) = 0\n\nopen(newunit=u, file='somefile.txt', status='unknown', &\n     action='write', access='stream', form='formatted')\nwrite(u, *) a\nclose(u)\n\nopen(newunit=u, file='somefile.txt', status='old', &\n     action='read', access='stream', form='formatted')\nread(u, *) b\nclose(u)\n\nprint *, all(a == b)\n\nend"
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 03:32:57+00:00",
                    "text": "If you instead opened in formatted and stream, what would have to change in the above code to read the array \"a\" properly? What exactly is the difference between formatted/sequential and formatted/stream?\n\nI don't know the answer and I'll need to play with it.\n\nI tried this patch:\ndiff --git a/src/stdlib_experimental_io.f90 b/src/stdlib_experimental_io.f90\nindex f6e4a50..b3a115c 100644\n--- a/src/stdlib_experimental_io.f90\n+++ b/src/stdlib_experimental_io.f90\n@@ -332,7 +332,7 @@ end select\n \n select case (mode_(3:3))\n case('t')\n-    access_='sequential'\n+    access_='stream'\n     form_='formatted'\n case('b', 's')\n     access_='stream'\nand I can't see any difference... Tests still pass, etc.\nSo maybe we can just use stream everywhere for access and that's it. In which case the current master is already what is needed.\nThen for codes that use other \"access\", such as sequential, they will continue using the built-in open statement. And it might be that switching to \"stream\" is essentially with no downsides, and in that case they can use stdlib's open."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-06 03:38:20+00:00",
                    "text": "I'll experiment some more. This is a simple case. I'm curious if sequential and stream treat new lines in the same way.\nIn sequential mode, each read or write statement is one record and newline is inserted at the end. So if you do 3 reads, you read 3 lines. I'm not sure if stream works the same way. At the same time, I don't think we're necessarily looking for something to behave exactly like sequential. What matters is that we understand how stream works, and that we know that it can do what we need."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 03:51:43+00:00",
                    "text": "Well, I was really hoping that our open would work great with the built-in read and write. That would be the best scenario. Given how close we got, it seems it would be worth it.\nFor the OO interface, there you don't have to be compatible with any built-ins. So one can indeed design it in any way you like. Then we can provide all the necessary functions in the low level API. This open was the first one that I could think of. There might be more."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-06 03:58:46+00:00",
                    "text": "You're still compatible with built-in read and write statements. They'd just be reading/writing in stream mode rather than sequential.\nI don't argue for stream because I love it, but rather because I think sequential access makes for more awkward behavior and API."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 04:06:17+00:00",
                    "text": "Let's gain some experience with this, I need to see the details."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-06 08:51:41+00:00",
                    "text": "I see @milancurcic 's point.\nRegarding unformatted files, I don't see what are the advantages of unformatted sequential and unformatted direct over unformatted stream. Indeed, all files are \"binary\" files. unformatted sequential and unformatted direct needs 8 additional bytes per record compared to unformatted stream. And if a \"direct access\" is needed, the pos statement can be used with unformated stream (maybe with some restrictions for write). An additional advantage of unformatted stream is its interoperability with C binary streams (I mainly use unformatted stream for this specific advantage).\nThe only reason to support unformatted sequential and unformatted direct in stdlib open is for backward compatibility, since the stream access was introduced in the standard only in Fortran 2003.\nRegarding formatted files, I will only consider sequential and stream. From a simple example (see below; same results with gfortran and ifort), writing with formatted sequential and formatted stream provides the same (bit-wise) files. So it seems that sequential and stream treats the new lines in the same way.\nA nice thing of formatted stream is that data-driven record termination in the style of C text streams is allowed (following MRC). However, I couldn't  get the same bit-wise file as with the two other options.\nHere is some explanations by @zbeekman.\nSo my proposition is to close this PR, and to possibly change access = sequential to access = stream. Both text and binary files will be supported by our open (and it will cover 100% of my needs ;) ).\nThen we can open a new issue (or in #14) to discuss if we want to support sequential and direct accesses with our function open.\nIf we want to support all accesses, an easy thing would be to add a new optional argument in our function open:\n... function open(filename, mode, iostat, access)\n\nwhere mode = r|w|a|x|t|b|+ (or any combinations) and access = stream,seq,dir with stream being the default access.\nWith such an approach, it is still Python-like API. IMHO this would still be a clean API with one recommended way of reading and writing.\nprogram iofortran\n use, intrinsic:: iso_fortran_env, only: sp => real32\n implicit none\n integer::i,n,un,length\n real(sp)::r(3),rs(3)\n character(:),allocatable :: filename,cdummy\n\n n = 4\n rs = [ 1.1, 1.2, 1.3 ]\n\n filename='test.fseq'\n print*,'Formatted sequential: '//trim(filename)\n open(newunit=un,file=filename,status='replace',action='write'&\n      ,form='formatted',access='sequential')\n r=rs\n do i=1,n\n  write(un,'(*(f0.5,x))')r\n  r=r+1.\n enddo\n close(un)\n\n filename='test.fstr'\n print*,'Formatted stream: '//trim(filename)\n open(newunit=un,file=filename,status='replace',action='write'&\n      ,form='formatted',access='stream')\n r=rs\n do i=1,n\n  write(un,'(*(f0.5,x))')r\n  r=r+1.\n enddo\n close(un)\n\n filename='test.fstr.newline'\n print*,'Formatted stream: '//trim(filename)\n open(newunit=un,file=filename,status='replace',action='write'&\n      ,form='formatted',access='stream')\n r=rs\n do i=1,n,2\n  print*,i\n  write(un,'(3(f0.5,x),a,3(f0.5,x))')r,new_line(cdummy),r+1.\n  r=r+2.\n enddo\n close(un)\n\nend program\n\n$ md5sum test.fs*\n202f479b02a8ecbab6ed2b775efd055f  test.fseq\n202f479b02a8ecbab6ed2b775efd055f  test.fstr\na7328de08c49c61393f897a4bbafcf4c  test.fstr.newline"
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 14:45:42+00:00",
                    "text": "I agree. Let's use stream. Also function open(filename, mode, iostat, access) is a good idea --- it will allow to port pretty much any code out there, and it still simplifies the API."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-06 14:49:47+00:00",
                    "text": "Let's use stream.\n\nI will open a PR to modify sequential to stream. So it will be fixed.\n\nAlso function open(filename, mode, iostat, access) is a good idea --- it will allow to port pretty much\nany code out there, and it still simplifies the API.\n\nShould we discuss this API in #14? Or implementing it and opening a PR? What would be the best strategy such that many people can discuss it?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 14:55:47+00:00",
                    "text": "I will open a PR to modify sequential to stream.\n\nI just did in #90, sorry about that.\n\nShould we discuss this API in #14? Or implementing it and opening a PR? What would be the best strategy such that many people can discuss it?\n\nI would send a PR, so that we can discuss the actual code and an API, and we can comment at #14 to discuss this at the PR."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-06 14:58:32+00:00",
                    "text": "I would send a PR, so that we can discuss the actual code and an API, and we can comment at #14 to discuss this at the PR.\n\nI will start on it, if ok for you"
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 15:00:07+00:00",
                    "text": "I will start on it, if ok for you\n\nYes, thank you!"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-06 15:30:52+00:00",
                    "text": "Also function open(filename, mode, iostat, access) is a good idea --- it will allow to port pretty much any code out there, and it still simplifies the API.\n\nI think this is okay. I'm still skeptical that access will be useful, but at least it will be optional parameter. It doesn't hurt for now."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-06 15:39:06+00:00",
                    "text": "See #91 for discussion and implementation of access as an optional argument in open."
                }
            ]
        },
        {
            "number": 85,
            "user": "certik",
            "date": "2020-01-05 16:35:08+00:00",
            "title": "Discuss and possibly change `sp`, `dp`, `qp` kinds constants",
            "text": "We have not reached an agreement if we should be using sp, dp, qp or some other names. This is a subset of the issue #25. This current issue is only for the naming convention. Anything else should be discussed in #25.\nThis is not a pressing issue, as for now use use sp, dp, qp as placeholders to allow us to move on to implement an actual functionality. But we definitely have to reach an agreement before we consider moving from experimental to main.\nI was hoping doing a survey of all open source Fortran projects, as well as some closed source that I have access to, and then we'll see what the large community is actually using. Then we can decide what to do.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-13 16:29:42+00:00",
                    "text": "People in #25 who preferred different names than sp, dp and qp are: @jvdp1, @milancurcic, @marshallward. Others seem either fine with it, or not expressed an opinion.\nThe next candidate seems to be the names from iso_fortran_env, so real32, real64 and real128.\nLet's also discuss half precision. The natural names for iso_fortran_env would be real16 (j3-fortran/fortran_proposals#13) and bfloat16 (j3-fortran/fortran_proposals#3).\nThe shorter names could be hp for half precision. For bfloat16 there does not seem to be an established short name (some candidates could be bp, bfp, ..., but I would maybe just use bfloat16, as I assume it will not be as commonly used in Fortran codes as dp is).\n\nTo move this forward, how about using a similar multilayered approach as in other issues:\n\nThe stdlib_kinds module introduces real16, real32, real64, real128 names, the same as in iso_fortran_env.\nThen it also introduces aliases hp, sp, dp, qp.\n\nAnd we can use both, say in user codes. Regarding the stdlib code itself, we can use both for now also (depending who submits the code). Later, as we fix #35, and routinely support all integer and real kinds, I think a natural and consistent convention will arise for stdlib, as we gain experience.\n@jvdp1, @milancurcic, @marshallward, is that an acceptable compromise?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-13 18:45:24+00:00",
                    "text": "@jvdp1, @milancurcic, @marshallward, is that an acceptable compromise?\n\nI would suggest to use one of the 2, but not both, simply to avoid to go through all the codes in the lib, when a convention will be taken.\nMy preference is still for real16, real32, ... but I would be ok with the other one, especially since stdlib has its own kinds module."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-13 22:31:34+00:00",
                    "text": "I also prefer sp, dp, etc. over having both, which would be confusing to any reader unaware of this discussion."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-13 23:18:00+00:00",
                    "text": "I would prefer to not have two sets of naming schemes.\nI would also prefer not to just re-use the names from iso_fortran_env and have them point to the contents in iso_fortran_env.  I already somewhat consider those \"reserved\".\nAs the last ones standing, I guess that I would be fine with sp, dp, qp.\nStill not a fan of these, I think short two-letter names are better reserved for scratch variables (e.g. iteration counters) but I would also not wish such concerns to impede progress."
                },
                {
                    "user": "certik",
                    "date": "2020-01-13 23:23:52+00:00",
                    "text": "Ok then. I am fine with the current scheme also. We can revisit this later. For now I think we can close this issue."
                }
            ]
        },
        {
            "number": 84,
            "user": "rweed",
            "date": "2020-01-05 16:30:34+00:00",
            "title": "Consider using swig-fortran to access C++ STL",
            "text": "I'll just throw this out as an alternative to building stdlib from scratch. Seth Johnson at ORNL has a project that can generate SWIG bindings to the C++ STL for Fortran. (see https://github.com/swig-fortran). I ran across his project a few months back and thought it interesting but didn't do a deep dive into what issues where involved in using it for things like lists etc. More info in the following two PDFS\nJohnson_Automated_Fortran-C++_Bindings_ArXiv.pdf\nsiam-cse-johnsonsr.pdf",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-05 17:27:32+00:00",
                    "text": "STL can help with the containers and algorithms part of stdlib. I don't think it would help with any of the current functionality in our current master, would it? Or with the mathematics part.\n\nSee the README for the intended scope of stdlib.\n\nAlso if the C++ dependency could be only optional would be also helpful to lots of future users of stdlib.\n\u2026\nOn Sun, Jan 5, 2020, at 9:30 AM, rweed wrote:\n I'll just throw this out as an alternative to building stdlib from\n scratch. Seth Johnson at ORNL has a project that can generate SWIG\n bindings to the C++ STL for Fortran. (see\n https://github.com/swig-fortran). I ran across his project a few months\n back and thought it interesting but didn't do a deep dive into what\n issues where involved in using it for things like lists etc. More info\n in the following two PDFS\n Johnson_Automated_Fortran-C++_Bindings_ArXiv.pdf\n <https://github.com/fortran-lang/stdlib/files/4023624/Johnson_Automated_Fortran-C%2B%2B_Bindings_ArXiv.pdf>\n siam-cse-johnsonsr.pdf\n <https://github.com/fortran-lang/stdlib/files/4023626/siam-cse-johnsonsr.pdf>\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#84?email_source=notifications&email_token=AAAFAWE7OYLIVSQHT6H7JVTQ4IDKVA5CNFSM4KC4AFU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IECXI4Q>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWF5FXFROCEYK6KOICDQ4IDKVANCNFSM4KC4AFUQ>."
                },
                {
                    "user": "rweed",
                    "date": "2020-01-05 17:53:40+00:00",
                    "text": "Actually, I personnaly prefer a \"pure\" Fortran implementation if possible. I just put this forward as something that could be an option to provide some of the containers etc. needed for ADTs etc. if there is no consensus as to the best way to do it in Fortran. I agree it should only be an option (and only if its impracticle or time-consuming to do it in Fortran)."
                }
            ]
        },
        {
            "number": 83,
            "user": "scivision",
            "date": "2020-01-05 13:59:33+00:00",
            "title": "Make real128 optional",
            "text": "this same concept is readily extended to other types. Based on the current architecture, this seemed to be the most expedient way to make a kind optional.\nThe only thing lacking is the Makefiles--how would you prefer to handle having some files .F90 and some .f90. One way would be to just make all the files .F90 as there is no harm in preprocessing every file, and eventually all the files may have preprocessing anyway.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-05 17:15:23+00:00",
                    "text": "I merged the kinds module, I didn't see you sent this. It will have to be rebased, sorry about that.\n\nThe fact that .f90 are not automatically preprocessed unfortunately means that we probably have to change all file extensions to .F90.\n\nHowever, if there is a way to avoid the preprocessor, I think we should. In particular I think this PR is needed to make it work with Flang, correct?\n\nWhat does Flang segfault on exactly? Can the qp be imported in the use statement? But it segfaults when it is used?\n\u2026\nOn Sun, Jan 5, 2020, at 6:59 AM, Michael Hirsch, Ph.D. wrote:\n this same concept is readily extended to other types. Based on the\n current architecture, this seemed to be the most expedient way to make\n a kind optional.\n\n The only thing lacking is the Makefiles--how would you prefer to handle\n having some files .F90 and some .f90. One way would be to just make\n *all* the files .F90 as there is no harm in preprocessing every file,\n and eventually all the files may have preprocessing anyway.\n\n You can view, comment on, or merge this pull request online at:\n\n #83\n\n Commit Summary\n\n  * fence out real128 with preprocessor\n  * assume all tests are preprocessed .F90\n File Changes\n\n  * *M* src/CMakeLists.txt\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-0> (11)\n  * *M* src/Makefile.manual\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-1> (4)\n  * *R* src/stdlib_experimental_io.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-2> (15)\n  * *R* src/stdlib_experimental_optval.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-3> (13)\n  * *M* src/tests/CMakeLists.txt\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-4> (2)\n  * *M* src/tests/Makefile.manual.test.mk\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-5> (4)\n  * *R* src/tests/ascii/test_ascii.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-6> (0)\n  * *M* src/tests/io/CMakeLists.txt\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-7> (2)\n  * *M* src/tests/io/Makefile.manual\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-8> (12)\n  * *R* src/tests/io/test_loadtxt.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-9> (2)\n  * *R* src/tests/io/test_loadtxt_qp.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-10> (0)\n  * *R* src/tests/io/test_open.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-11> (0)\n  * *R* src/tests/io/test_parse_mode.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-12> (0)\n  * *R* src/tests/io/test_savetxt.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-13> (0)\n  * *R* src/tests/io/test_savetxt_qp.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-14> (0)\n  * *R* src/tests/optval/test_optval.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-15> (46)\n  * *R* src/tests/test_always_fail.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-16> (0)\n  * *R* src/tests/test_always_skip.F90\n <https://github.com/fortran-lang/stdlib/pull/83/files#diff-17> (0)\n Patch Links:\n\n  * https://github.com/fortran-lang/stdlib/pull/83.patch\n  * https://github.com/fortran-lang/stdlib/pull/83.diff\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#83?email_source=notifications&email_token=AAAFAWDLFMLLW5RP3Y4HK5LQ4HRULA5CNFSM4KC3LPZKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IECO7AQ>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWE6XJXUMRDJHXKG3ZTQ4HRULANCNFSM4KC3LPZA>."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-06 15:50:27+00:00",
                    "text": "Both PGI and Flang are broken in multiple ways for Fortran 2003. It might be best to just wait for them to fix themselves. However if there's any other non-universal kind we wish to add, it would currently be done perhaps like this, unless we refactored. E.g. if someone wants real16 or something.\nSo while this PR may be unnecessary as is, something like this would need to be done to accomodate kinds not available in all systems. Or a refactor."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-06 15:51:21+00:00",
                    "text": "So this PR fixes only part of the things wrong with Flang and PGI. The rest are due to improper implementation of Fortran 2003 in Flang/PGI."
                }
            ]
        },
        {
            "number": 82,
            "user": "jvdp1",
            "date": "2020-01-05 09:40:30+00:00",
            "title": "Addition of checks and use of stdlib_experimental_ascii",
            "text": "Additions/changes:\n\nsome checks in parse_mode to return errors for modes such as rr, rw, r++t, rbt. (Note: I couldn't add these tests in CMake, or it should be one per file)\nthe function open can return the iostat if requested\n(@certik) since #49 has been closed, whitechar is now replaced by is_blank\n\n@scivision : Because I added checks in the function parse_mode, it uses again if statements instead of select case. Good for you?",
            "comments": [
                {
                    "user": "scivision",
                    "date": "2020-01-05 13:28:13+00:00",
                    "text": "yes I think it's fine/necessary to use if here with the more complex conditions now present"
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 16:20:15+00:00",
                    "text": "Thank you @jvdp1 for doing this, it looks really good. I left some comments regarding the API and testing."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-05 16:44:47+00:00",
                    "text": "Thank you @jvdp1 for doing this, it looks really good. I left some comments regarding the API and testing.\n\nThanks for the review."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 17:30:37+00:00",
                    "text": "In your last commit, in the tests I think you forgot to add io in the 3rd test from last. (I am on my phone, so I can't comment there directly.)\n\u2026\nOn Sun, Jan 5, 2020, at 9:44 AM, Jeremie Vandenplas wrote:\n >\n > Thank you @jvdp1 <https://github.com/jvdp1> for doing this, it looks really good. I left some comments regarding the API and testing.\n\n Thanks for the review.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#82?email_source=notifications&email_token=AAAFAWAMZPEYHRA6CLBHG4TQ4IFABA5CNFSM4KC2LVWKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEID2WXQ#issuecomment-570927966>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWC5PDMQAP4A7WCAJSDQ4IFABANCNFSM4KC2LVWA>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-05 17:35:29+00:00",
                    "text": "In your last commit, in the tests I think you forgot to add io in the 3rd test from last. (I am on my phone, so I can't comment there directly.)\n\nResolved!"
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 17:44:46+00:00",
                    "text": "Perfect! I think it looks good now. +1 to merge. Go ahead and merge it if you want.\n\u2026\nOn Sun, Jan 5, 2020, at 10:35 AM, Jeremie Vandenplas wrote:\n >\n > In your last commit, in the tests I think you forgot to add io in the 3rd test from last. (I am on my phone, so I can't comment there directly.)\n\n Resolved!\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#82?email_source=notifications&email_token=AAAFAWBSWCWM3CRHCDSH4TDQ4IK6DA5CNFSM4KC2LVWKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEID3UBA#issuecomment-570931716>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWFV7PSVGON5DXLHNRDQ4IK6DANCNFSM4KC2LVWA>."
                }
            ]
        },
        {
            "number": 81,
            "user": "scivision",
            "date": "2020-01-05 05:30:40+00:00",
            "title": "PGI / Flang compilers not working",
            "text": "Due to bug(s) in PGI / Flang, the stdlib io and optval don't build. There are spurious errors like\nPGF90-F-0000-Internal compiler error. interf:new_symbol, symbol not found     630  (src/tests/io/test_loadtxt.f90: 2)\n\nfiddling around with the code, PGI will even give a similar error for implicit none\nBasically this seems a lot like other cases where there were bugs in PGI / Flang and not something wrong with stdlib. I did some attempts at workarounds in https://github.com/scivision/stdlib/tree/qp_opt\nOne could file a bug report with each of PGI and Flang, as the error is effectively identical, perhaps boiling it down to a minimum working example.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-05 06:24:52+00:00",
                    "text": "Is the issue around quadruple precision?"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-05 06:27:52+00:00",
                    "text": "Quadruple precision was part of the issue which I fixed with the #ifdef REAL128. However this remaining issue seems to be an actual compiler bug."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 06:40:29+00:00",
                    "text": "If it's too much of a hassle, we can wait with officially supporting Flang until they fix such issues."
                },
                {
                    "user": "rweed",
                    "date": "2020-01-05 16:49:49+00:00",
                    "text": "I've had similar issues with PGI and flang. I tried compiling my hashMap routines and both gave the same error (but with different equally confusing messages). I reported this to PGI about 1.5 years ago and haven't heard anything from them. Hopefully, flang/f18 will be more robust but I wouldn't rely on current PGI building anything that uses any OO features."
                },
                {
                    "user": "scivision",
                    "date": "2020-02-05 20:52:30+00:00",
                    "text": "My opinion on PGI & Flang re: stdlib is to wait for the next releases of PGI & Flang. They've each made a lot of progress in 2019 w.r.t. Fortran 2008 support.\n\nexpect no-charge PGI 20.4 in April-May 2020 if prior years' release schedule holds\nF18 is anticipated to come with LLVM 11 (F18 just missed the LLVM 10 merge window in Jan 2020)"
                }
            ]
        },
        {
            "number": 80,
            "user": "scivision",
            "date": "2020-01-05 04:43:23+00:00",
            "title": "use \"select case\" for clarity/brevity",
            "text": "using select case here is clearer since the condition doesn't need to include spaces, and briefer\nalso add \"pure\" where suitable",
            "comments": []
        },
        {
            "number": 79,
            "user": "scivision",
            "date": "2020-01-05 03:01:25+00:00",
            "title": "add missing implicit none, set compiler flags to force implicit none",
            "text": "also set minimum CMake version to 3.14 per prior discussion and add example check requiring CMake 3.14: real128",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-05 03:17:30+00:00",
                    "text": "I've never used -fimplicit-none. Should that be recommended to be used by default for all modern Fortran projects?"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-05 03:34:03+00:00",
                    "text": "yes -fimplicit-none was available at least back to Gfortran 4.1 (didn't try looking further back) and I don't think there are any drawbacks."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 03:51:33+00:00",
                    "text": "@scivision cool. This is relevant to: j3-fortran/fortran_proposals#90."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 06:29:38+00:00",
                    "text": "Thanks for the improvements!"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 18:10:07+00:00",
                    "text": "Thanks all!"
                }
            ]
        },
        {
            "number": 78,
            "user": "certik",
            "date": "2020-01-05 01:45:23+00:00",
            "title": "CMake: introduce ADDTEST macro",
            "text": "This simplifies the CMake code a lot.\n@zbeekman let me know if this goes in the direction that you prefer with CMake.",
            "comments": [
                {
                    "user": "scivision",
                    "date": "2020-01-05 02:15:26+00:00",
                    "text": "That seems like a nice macro, particularly since so many tests have that pattern"
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 06:28:05+00:00",
                    "text": "Thanks for the review!"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 18:07:55+00:00",
                    "text": "@certik nice one! Yes, this is exactly the sort of thing I would have done myself. I'm not 100% sure about having it as a macro instead of a function, but we can iterate on that idea later. Great starting point!"
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 19:17:49+00:00",
                    "text": "@zbeekman go ahead and create a function. I didn't even know you can create functions in CMake."
                }
            ]
        },
        {
            "number": 77,
            "user": "jvdp1",
            "date": "2020-01-04 23:08:52+00:00",
            "title": "Modification of the function parse_mode in stdlib_experimental_io",
            "text": "I modified the function parse_mode in stdlib_experimental_io.f90 to be more flexible.\nI also added a new test file test_parse_mode.f90 and removed associated tests from test_open (in case we would use a public parse_mode only for tests).\nI added several cases for testing parse_mode.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-05 00:15:29+00:00",
                    "text": "+1 from me to merge\n\u2026\nOn Sat, Jan 4, 2020, at 4:08 PM, Jeremie Vandenplas wrote:\n I modified the function `parse_mode` in `stdlib_experimental_io.f90` to\n be more flexible.\n  I also added a new test file `test_parse_mode.f90` and removed\n associated tests from `test_open` (in case we would use a public\n `parse_mode` only for tests).\n  I added several cases for testing `parse_mode`.\n\n You can view, comment on, or merge this pull request online at:\n\n #77\n\n Commit Summary\n\n  * modification of parse_mode + separation of test_open and\n test_parse_mode (+additional tests)\n  * renamed test_parse_mode subroutine for consistency\n File Changes\n\n  * *M* src/stdlib_experimental_io.f90\n <https://github.com/fortran-lang/stdlib/pull/77/files#diff-0> (37)\n  * *M* src/tests/io/CMakeLists.txt\n <https://github.com/fortran-lang/stdlib/pull/77/files#diff-1> (5)\n  * *M* src/tests/io/Makefile.manual\n <https://github.com/fortran-lang/stdlib/pull/77/files#diff-2> (1)\n  * *M* src/tests/io/test_open.f90\n <https://github.com/fortran-lang/stdlib/pull/77/files#diff-3> (44)\n  * *A* src/tests/io/test_parse_mode.f90\n <https://github.com/fortran-lang/stdlib/pull/77/files#diff-4> (171)\n Patch Links:\n\n  * https://github.com/fortran-lang/stdlib/pull/77.patch\n  * https://github.com/fortran-lang/stdlib/pull/77.diff\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#77?email_source=notifications&email_token=AAAFAWFDO6YKOP7ERLLRKKTQ4EJILA5CNFSM4KCYMGO2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IEBJACQ>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWFUWZW4OPNEFD54RITQ4EJILANCNFSM4KCYMGOQ>."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 00:43:18+00:00",
                    "text": "@jvdp1 thanks, it looks great! The only additional improvement that I can think of is if something calls it like this open(filename, \"rr\"). In Python this gives an error if \"r\" and other modes are used more than once. Also some other combinations are probably not allowed, like \"rw\", or \"rtb\". But as it is now, it's already very useful."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-05 08:12:39+00:00",
                    "text": "@jvdp1 thanks, it looks great! The only additional improvement that I can think of is if something calls it like this open(filename, \"rr\"). In Python this gives an error if \"r\" and other modes are used more than once. Also some other combinations are probably not allowed, like \"rw\", or \"rtb\". But as it is now, it's already very useful.\n\nThings like \"rr\" is not a problem, while things like \"rw\" are a problem. I will have a look to modify parse_mode to give an error when these cases are provided.\nEdit: This should be solved  with #82"
                }
            ]
        },
        {
            "number": 76,
            "user": "jvdp1",
            "date": "2020-01-04 10:59:07+00:00",
            "title": "Message for errors inside stdlib?",
            "text": "In stdlib_experimental_error.f90, there is the following example:\ncall error_stop(\"Invalid argument\")\nA similar case can be found in stdlib_experimental_io.f90.\nWhen running a large program, messages such as \"Invalid argument\" are quite useless. Should we discuss and agree on a good way to mention error messages, e.g.,\nERROR (_name_of_the_function_): Invalid argument (_argument_)",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 19:26:54+00:00",
                    "text": "The best way I've ever found to get good error messages and be able to do so even when using elemental or pure procedures is to define an error_stack_t class with a bunch of pure methods for pushing, popping, signalling (raising?) and then non-pure methods to catch and handle the errors.\nI opened #95 to get more feedback. It could be used for the purpose described in this issue."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 19:34:18+00:00",
                    "text": "A minimal improvement is to at least list the name of the function in the error message as @jvdp1 suggested. Ideally the compiler would be able to optionally generate a nice stacktrace when the program ends with a non-zero exit code."
                }
            ]
        },
        {
            "number": 75,
            "user": "pdebuyl",
            "date": "2020-01-03 20:14:43+00:00",
            "title": "Preprocessor",
            "text": "Will stdlib require a preprocessor? It is mentioned in #13 #35 and #72\nI suggest that this is discussed as it impacts the way the code is built and possibly the way users of stdlib will call certain features. Not that I have any definitive opinion on the topic, but as there was a discussion on cmake, compiler support and CI, this seems appropriate also for preprocessing.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-03 20:28:06+00:00",
                    "text": "Yes, it's relevant to how files should be named whether .f90 or .F90, etc. I really don't like the .F90 suffix, as the capital letter signals some old FORTRAN style code. I wish the convention was the other way round, that .f90 gets automatically preprocessed.\nIt seems the discussion at #35 seems to converge towards trying jin2for, instead of using a preprocessor.\nBut #72 would need one. Although in my own codes I do not use a preprocessor and just do call assert(...). It does not print the line number, but that could be fixed by printing the whole stacktrace, there are libraries that can do that (although they might not work on all platforms).\nGiven resistance to standardize a preprocessor in j3-fortran/fortran_proposals#65, I don't know what the best recommended practice is."
                },
                {
                    "user": "gronki",
                    "date": "2020-01-03 23:34:48+00:00",
                    "text": "Preprocessing can be forced upon by -cpp option in most compilers. I imagine that is compiler dependent though.\nI dislike uppercase .F90 too but I still use it in my projects as most compilers recognize this without the need for extra options. So I would imagine that would be the most fail-safe solution."
                },
                {
                    "user": "certik",
                    "date": "2020-04-02 22:52:16+00:00",
                    "text": "See the discussion in this and following comments: #72 (comment). Where we decided to just use .f90, but pass an appropriate compiler option (such as -fpp) to pre-process the files."
                },
                {
                    "user": "pdebuyl",
                    "date": "2020-04-03 12:13:12+00:00",
                    "text": "Hi @certik since I opened this issue, it became obvious that stdlib would rely on a preprocessor. I am thus closing the issue."
                }
            ]
        },
        {
            "number": 74,
            "user": "certik",
            "date": "2020-01-03 19:17:19+00:00",
            "title": "Further Makefile improvements",
            "text": "This further reduces the number of lines to maintain in Makefiles. The tests' Makefiles are now very short. In general we now simply list all the source files, similar to CMake.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-03 19:18:38+00:00",
                    "text": "@gronki, here is further simplification of the Makefiles. Let me know what you think."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 20:45:43+00:00",
                    "text": "Thanks for the review!"
                }
            ]
        },
        {
            "number": 73,
            "user": "nshaffer",
            "date": "2020-01-03 16:57:08+00:00",
            "title": "Preliminary implementation of default values",
            "text": "In support of #62\n\nNew module \"default_m\" which exports the generic function name \"default\"\nNew entries in src/CMakeLists.txt and src/Makefile.manual\n\nI've implemented a generic interface for real(sp), real(dp), real(qp), int16, int32, int64, logical, and character. I figure this is enough for a first pass. Complex types and discriminating between ASCII and UCS characters can come later. Probably no need to do specific logical kinds.\nWhat's missing right now is tests. I don't know how to use CTest, but I would like to learn if anyone can link me a decent tutorial.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-03 21:21:11+00:00",
                    "text": "Thanks @nshaffer. I resolved the conflict with master and committed to your branch. Make sure you pull it before adding more commits.\nAlso, I recommend people to submit PRs from a different branch than their master, so that they can use their master to track the upstream master (to rebase, merge, etc.)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 21:26:44+00:00",
                    "text": "Regarding the test, try to copy let's say the test_ascii test and its CMake setup. It should be straightforward. If you have any questions, let us know."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-04 00:59:50+00:00",
                    "text": "Thanks all for the comments. Seems like folks in #62 prefer the name \"optval\" so I converted to that everywhere and renamed the fallback argument \"default\", so that you can write optval(x, default=1.0) if you want to be explicit. Also wrote tests for all currently implemented types."
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 01:28:36+00:00",
                    "text": "Thank you! This is great. I'll review later tonight or tomorrow.\n\u2026\nOn Fri, Jan 3, 2020, at 5:59 PM, nshaffer wrote:\n Thanks all for the comments. Seems like folks in #62\n <#62> prefer the name\n \"optval\" so I converted to that everywhere and renamed the fallback\n argument \"default\", so that you can write either `optval(x,\n default=1.0)` if you want to be explicit. Also wrote tests for all\n currently implemented types.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#73?email_source=notifications&email_token=AAAFAWAYRYK3SLJO6IHLFUDQ37NQPA5CNFSM4KCPS462YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEICNLBI#issuecomment-570742149>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWDH262SE7MZ3L5F6OLQ37NQPANCNFSM4KCPS46Q>."
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 21:21:14+00:00",
                    "text": "Thanks @nshaffer for the work!"
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 21:27:17+00:00",
                    "text": "Here is the first usage of optval: a8416a1"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-04 22:15:15+00:00",
                    "text": "Cheers!\nIt occurs to me that optval should be pure elemental for the intrinsic types. Shall I tack that on here or open a new PR? (I've added a dev branch to my fork now, if that makes any difference.)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 22:15:53+00:00",
                    "text": "Yes, send another PR please against master, from a new branch."
                }
            ]
        },
        {
            "number": 72,
            "user": "rweed",
            "date": "2020-01-03 15:39:47+00:00",
            "title": "Implement standard assert subroutine and associated macros",
            "text": "Per @certiks request, I propose we extend his stdlib_experimental_error.f90 code to a standard assert subroutine and supplement it with some pre-processor macros. As an example here is my implementation of an assert routine and the associated macros\nassertions.f90\nassert.txt\nThe associated preprocessor macros are\nassert_macros.txt\nNote, these are my implementation of similar routine and macros found in the FTL project",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2020-01-03 20:25:45+00:00",
                    "text": "I think this is a good step forward. I planned to propose adding optional message to assert so that it can be used more universally for tests and validating user inputs, and this takes it even further with file, line, and optional abort on failure.\nI suggest everything but the first argument to be optional so it can be used in its minimal capacity.\nMinor nit-pick: assertion .NEQV. .TRUE. can be just .not. assertion."
                },
                {
                    "user": "rweed",
                    "date": "2020-01-03 20:53:57+00:00",
                    "text": "My primary use for assert was in testing which is why I have the two global variables (num_failed_asserts, and num_asserts). Usually you have several tests you want to perform at one time and want some record of the number of failed tests versus the number of tests and additional information as to when/where the failed test occured. However, I tried to also allow for the case where you want to use assert for error_handling in a given subroutine etc and do a hard abort/stop when an appropriate stop condition was met. A couple of things with my code.\n\n\nIK=>INT32 should be appended to the end of the USE ISO_FORTRAN_ENV. I normally have a module that defines IK but I removed it for simplicity.\n\n\nThere probably needs to be some kind of RESET_ASSERT subroutine to reset the num_failed_assert and num_assert values. Another option would be to make them PRIVATE and provide getter and setter functions but I considered that overkill for just two variables."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 21:10:01+00:00",
                    "text": "I think for testing, it's better to use or develop a more specific framework just for testing.\nI think the main advantage of the assert macro is to test things like sizes of arrays when entering a subroutine, and other conditions that the code depends on. And in Release mode the macro is not executed, so there is no overhead."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-02-02 12:49:13+00:00",
                    "text": "Have we considered using fypp for assert macros? We already have it as a dependency."
                },
                {
                    "user": "certik",
                    "date": "2020-03-23 21:39:28+00:00",
                    "text": "To clarify: this issue is for Debug time assert statements, that get skipped in Release mode. Testing framework is a different use case, to be discussed in #162. Note however, that a project like stdlib will have a test suite, executed by the testing framework (#162), and this will call functions from stdlib such as save_txt() to ensure they work, and those functions internally would have ASSERT macros that would ensure that things are internally consistent (in Debug mode).\n@milancurcic, @everythingfunctional I think stdlib should have such a macro.\nHowever, the issue is that then by default the files ending with .f90 are not pre-processed by default, so the macro would not work. I can see two approaches:\n\nrename all files to .F90\npass the proper compiler flag to the Fortran compiler in CMake (later on, once we switch to fpm, it would do the same)\n\nA third approach is to only do this for files that would use ASSERT. I don't like this third option, as we should be free to use ASSERT in any file, without having to fiddle with the build system or with a file extension.\nWhich approach do you prefer, 1) or 2)?\nI think I prefer 2), simply because using upper case extension feels old fashioned, I am not aware of any modern language that would require that. See also j3-fortran/fortran_proposals#56."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-03-23 21:51:25+00:00",
                    "text": "I think I would lean towards 2. A standard preprocessor is something Fortran probably should have settled on a long time ago. There are simply too many use cases for macros and preprocessor directives not too. I would be fine if fpm picked a preprocessor and just always used it, whether that file needed it or not."
                },
                {
                    "user": "certik",
                    "date": "2020-03-23 21:54:58+00:00",
                    "text": "@everythingfunctional exactly. See also j3-fortran/fortran_proposals#65 for a related discussion about standardizing a pre-processor.\nThe only issue that I can see is that the typical CPP preprocessor is pretty limited in what it can do, and it does not understand Fortran's syntax. fypp is an improvement. Even better would be to design intelligent macros for Fortran. That is all long term, a short term solution is to use CPP. However, I wouldn't like our choice to prevent us to implement intelligent macros in the future. However, for this we could use the edition keyword (j3-fortran/fortran_proposals#83) that we can specify in fpm.toml, just like Rust does it. So from some future moment, we could switch the pre-processor to something more intelligent and for legacy codes we would provide an option to explicitly keep using CPP for a particular file (one would have to specify that explicitly in fpm.toml if a newer edition was required)."
                },
                {
                    "user": "certik",
                    "date": "2020-04-02 22:51:10+00:00",
                    "text": "Also note that the NAG compilers do not pre-process .F90 automatically, instead one has to use the -fpp option, per open-mpi/ompi#7584. So that leaves us with option 2, as option 1 would not work anyway in all compilers."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-04-03 00:36:03+00:00",
                    "text": "NAG does automatically preprocess .F90 files. Mostly. The issue is on macOS with case insensitive file names as I understand it. But surely that must be a problem for all compilers that decide solely on the basis of the file name?"
                },
                {
                    "user": "aradi",
                    "date": "2020-04-03 04:57:35+00:00",
                    "text": "@certik Just to understand: According to your proposal some stdlibs files would then contain two different kind of macros: fypp-macros (when needed for generating \"generic\" interfaces) and cpp-style macros for the asserts? While technically possible (fypp's preprocessor instructions are orthogonal to the cpp instructions), wouldn't it be more to use only one preprocessor? Either cpp or fypp but not both? (And then, in case fypp is choosen, package it with stdlib (#133) to make sure, it does not become an extra dependency)?"
                },
                {
                    "user": "certik",
                    "date": "2020-04-03 05:32:40+00:00",
                    "text": "I am not sure. It seems we agree to just stick to .f90 and ensure we call the Fortran compilers with proper options. This also gives us the option to just use fypp, and not cpp.\nI think the best way forward is to simply try a few approaches and see which one works the best.\nCan fypp handle creating ASSERT like macros?"
                },
                {
                    "user": "aradi",
                    "date": "2020-04-03 06:06:20+00:00",
                    "text": "Yes, of course, it is possible to write macros which depending on a flag/variable create different codes, see the according exampe."
                }
            ]
        },
        {
            "number": 71,
            "user": "certik",
            "date": "2020-01-03 03:48:57+00:00",
            "title": "Implement open(filename, mode) and use it",
            "text": "Motivated by #14.\nPrior art:\nPython: open\nIn future PRs (or here) we can support the Python's modes 'a', 'x', 't'. The mode 'b' is binary in Python, which in Fortran would be access=stream. We can also support a Fortran specific mode 'u' which would mean form=\"unformatted\".\nThe other Python's options do not seem to have an equivalent in Fortran (I think), so they would not be supported.\nWe also need to add more tests for this.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-03 04:13:31+00:00",
                    "text": "@everythingfunctional, I was wondering if you can review this, I thought you might like it. The whole io module so far is modeled by Python/NumPy."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-03 04:20:24+00:00",
                    "text": "Sure thing."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 04:29:26+00:00",
                    "text": "If open is publicly exposed and imported, I think that prohibits the use of the open statement in the same scope.\n\nThat does not seem to be the case. As you can see, I am using the open statement in the function itself, and you can also use it outside of the function (I tested it). So it looks like we are free to use open.\nBut if there is some issue with the name, then my next favorite name would be fopen."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-03 04:32:44+00:00",
                    "text": "Nice! If there's no chance of conflict with the statement, I recommend keeping the name open, and likewise for future close, read, write, etc."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 04:36:33+00:00",
                    "text": "I cannot guarantee yet that there is not a chance of conflict, only that so far I didn't notice any issues in gfortran. But we can start with using open and if there are issues that come up, we can rename it (one can also rename it at import time in some corner case if needed)."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-03 04:41:03+00:00",
                    "text": "I'm still a bit torn between creating a new derived type to return with an OO interface vs just returning the unit number. But for now this is still experimental, and without all the rest of the OO interface wouldn't be of much use anyway."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 04:47:01+00:00",
                    "text": "@everythingfunctional as I proposed in #14 (comment), we should have both an OO and a low level interface. This PR is part of the low level interface. The high level interface needs to be designed, but the idea would be that it would simply be a thin wrapper on top of the low level interface."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 13:52:38+00:00",
                    "text": "I would like to support binary stream and unformatted files also, see the issue description. Do you have same case that you think would be hard to support?\n\u2026\nOn Fri, Jan 3, 2020, at 1:09 AM, Jeremie Vandenplas wrote:\n ***@***.**** commented on this pull request.\n\n It looks good to me. I have mainly minor suggestions.\n  Maybe it would be better to rename the function from `open` to\n `opentxt`, because this function is only for sequential formatted\n files. `opentxt` would also be in line with `savetxt` and `loadtxt`\n\n In src/stdlib_experimental_io.f90\n <#71 (comment)>:\n\n > +character(*), intent(in) :: filename\n +character(*), intent(in), optional :: mode\n +character(:), allocatable :: mode_\n +mode_ = \"r\"\n +if (present(mode)) mode_ = mode\n +! Note: the Fortran standard says that the default values for `status`\n and\n +! `action` are processor dependent, so we have to explicitly set them\n below\n +if (mode_ == \"r\") then\n +    open(newunit=u, file=filename, status=\"old\", action=\"read\")\n +else if (mode_ == \"w\") then\n +    open(newunit=u, file=filename, status=\"replace\", action=\"write\")\n +else if (mode_ == \"a\") then\n +    open(newunit=u, file=filename, position=\"append\", status=\"old\", &\n +        action=\"write\")\n +else\n +    call error_stop(\"Unsupported mode\")\n Are there some rules for error messages? Usually, I would mention\n something a bit more verbose to help the user, e.g.\n\n `     call error_stop(\"ERROR, open function: Unsupported mode\")\n `\n Maybe worthwhile to open an issue about that?\n\n In src/stdlib_experimental_io.f90\n <#71 (comment)>:\n\n > @@ -268,4 +269,39 @@ logical function whitechar(char) ! white character\n  end if\n  end function\n\n +integer function open(filename, mode) result(u)\n As written now, this 'open' function will be only for text files.\n However, Fortran also supports other types of files. So maybe we could\n name this function `opentxt`? (to be similar to `savetxt`, and\n `loadtxt`)\n\n In src/stdlib_experimental_io.f90\n <#71 (comment)>:\n\n > +!\n +! u = open(\"somefile.txt\", \"w\")\n +\n +! To append to the end of the file if it exists:\n +!\n +! u = open(\"somefile.txt\", \"a\")\n +\n +character(*), intent(in) :: filename\n +character(*), intent(in), optional :: mode\n +character(:), allocatable :: mode_\n +mode_ = \"r\"\n +if (present(mode)) mode_ = mode\n +! Note: the Fortran standard says that the default values for `status`\n and\n +! `action` are processor dependent, so we have to explicitly set them\n below\n +if (mode_ == \"r\") then\n +    open(newunit=u, file=filename, status=\"old\", action=\"read\")\n I would add at least `FORM=` and `ACCESS=` to explicitely show which\n type of files the function refers to.\n\n  \u2b07\ufe0f Suggested change -    open(newunit=u, file=filename, status=\"old\",\n action=\"read\")\n +    open(newunit=u, file=filename, status=\"old\", action=\"read\", &\n +             access='sequential', form='formatted')\n In src/stdlib_experimental_io.f90\n <#71 (comment)>:\n\n > +\n +! To append to the end of the file if it exists:\n +!\n +! u = open(\"somefile.txt\", \"a\")\n +\n +character(*), intent(in) :: filename\n +character(*), intent(in), optional :: mode\n +character(:), allocatable :: mode_\n +mode_ = \"r\"\n +if (present(mode)) mode_ = mode\n +! Note: the Fortran standard says that the default values for `status`\n and\n +! `action` are processor dependent, so we have to explicitly set them\n below\n +if (mode_ == \"r\") then\n +    open(newunit=u, file=filename, status=\"old\", action=\"read\")\n +else if (mode_ == \"w\") then\n +    open(newunit=u, file=filename, status=\"replace\", action=\"write\")\n  \u2b07\ufe0f Suggested change -    open(newunit=u, file=filename,\n status=\"replace\", action=\"write\")\n +    open(newunit=u, file=filename, status=\"replace\", action=\"write\", &\n +              access='sequential', form='formatted')\n In src/stdlib_experimental_io.f90\n <#71 (comment)>:\n\n > +! u = open(\"somefile.txt\", \"a\")\n +\n +character(*), intent(in) :: filename\n +character(*), intent(in), optional :: mode\n +character(:), allocatable :: mode_\n +mode_ = \"r\"\n +if (present(mode)) mode_ = mode\n +! Note: the Fortran standard says that the default values for `status`\n and\n +! `action` are processor dependent, so we have to explicitly set them\n below\n +if (mode_ == \"r\") then\n +    open(newunit=u, file=filename, status=\"old\", action=\"read\")\n +else if (mode_ == \"w\") then\n +    open(newunit=u, file=filename, status=\"replace\", action=\"write\")\n +else if (mode_ == \"a\") then\n +    open(newunit=u, file=filename, position=\"append\", status=\"old\", &\n +        action=\"write\")\n  \u2b07\ufe0f Suggested change -        action=\"write\")\n +        action=\"write\", access='sequential', form='formatted')\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#71?email_source=notifications&email_token=AAAFAWG7TMK27PV7WMFXAWLQ33XDTA5CNFSM4KCJHCOKYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCQSRWMY#pullrequestreview-337976115>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWAUQ4A3EH3SLHJI33TQ33XDTANCNFSM4KCJHCOA>."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-03 14:08:20+00:00",
                    "text": "I would like to support binary stream and unformatted files also, see the issue description. Do you have same case that you think would be hard to support?\n\nOK. It is fine for me. The name open is ok for me.\nThen I would suggest to already introduce the t for text mode, and add if ( mode_ == 'a' .or. mode_ == 'at') then   to show that we want to support more modes.\nThe Python x mode could be also arleady introduced (action = 'write', status = 'new' ).\nI can add some suggestions if you want/agree"
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 14:28:53+00:00",
                    "text": "Yes! I'll add all the modes in this PR then. If you can suggest me all the modes, that would be great. I'll add tests also.\n\u2026\nOn Fri, Jan 3, 2020, at 7:08 AM, Jeremie Vandenplas wrote:\n >\n > I would like to support binary stream and unformatted files also, see the issue description. Do you have same case that you think would be hard to support?\n\n OK. It is fine for me. The name `open` is ok for me.\n  Then I would suggest to already introduce the `t` for `text mode`, and\n add `if ( mode_ == 'a' .or. mode_ == 'at') then ` to show that we want\n to support more modes.\n\n The Python `x` mode could be also arleady introduced (`action =\n 'write', status = 'new'` ).\n\n I can add some suggestions if you want/agree\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#71?email_source=notifications&email_token=AAAFAWADTHTGXT64FDZMTUDQ35BFJA5CNFSM4KCJHCOKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIBGEPI#issuecomment-570581565>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWEAXF26KRAVV2FJZGTQ35BFJANCNFSM4KCJHCOA>."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 15:24:10+00:00",
                    "text": "form = \"unformatted\", access = \"append\" would be au. You can combine any of rwa with any of ust.\nWhat does form = \"unformatted\", access = \"direct\" do?\nAlso, what exactly does the non-standard extension form = \"binary\" do? Does it do anything that the mode s or u cannot do?\nThe goal of open as I had it in mind was to cover 99% of use cases that people have, and follow a familiar Python like interface. People know about the mode \"b\", and I think it very nicely maps to form = \"unformatted\", access = \"stream\", and if the non-standard form = \"binary\" does something different, then I would not encourage using it and rather use \"b\" for the standard \"stream\" as in Python.\nI started gathering all the \"open\" statements from projects here:\nhttps://github.com/fortran-lang/stdlib/wiki/List-of-popular-open-source-Fortran-projects\nat:\nhttps://github.com/fortran-lang/stdlib/wiki/Usage-of-%22open%22\nIt turns out the current list there already pretty much covers most projects. As long as we can cover all those use cases, we should be fine.\nOne missing piece is how errors are handled --- sometimes the code wants to handle errors itself. So we should have an optional iostat argument, that if it is present, we will return the error status there."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-03 15:46:50+00:00",
                    "text": "What does form = \"unformatted\", access = \"direct\" do?\n\nIt allows to read/write at a specific record using the rec statement in read/write, and it provides a form of random access to a file.\n\nAlso, what exactly does the non-standard extension form = \"binary\" do? Does it do anything that the mode s or u cannot do?\nThe goal of open as I had it in mind was to cover 99% of use cases that people have, and follow a familiar Python like interface. People know about the mode \"b\", and I think it very nicely maps to form = \"unformatted\", access = \"stream\", and if the non-standard form = \"binary\" does something different, then I would not encourage using it and rather use \"b\" for the standard \"stream\" as in Python.\n\nThe binary form should be similar to stream access (in the sense that it writes a sequence of bytes). Maybe could we use both 's' and 'b' for stream files?\n\nI should gather all the \"open\" statements from projects here:\nhttps://github.com/fortran-lang/stdlib/wiki/List-of-popular-open-source-Fortran-projects\nand see if we can cover them all.\n\nPossible combinations:\n\n\nform =  \"formatted\" | \"unformatted\" (| \"binary\")\n\n\naccess = \"direct\" | \"sequential\" | \"stream\" | \"append\"\n\n\nEdit: access = append is considered as sequential but it is positioned at the end of the file. So it seems useless if position= is used."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-03 16:04:51+00:00",
                    "text": "The options to Python's open are listed here. I would suggest starting with that specification as far as it makes sense in Fortran, and only adding other options if there is some use case that it doesn't cover."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-03 16:26:09+00:00",
                    "text": "The options to Python's open are listed here. I would suggest starting with that specification as far as it makes sense in Fortran, and only adding other options if there is some use case that it doesn't cover.\n\nCurrently, among all characters used for Python 's open, only b and + are missing. As discussed, b could be covered by stream files. I am not sure what does the +.\nPython does not seem to cover direct access, while it seems do be used in some Fortran libraries (I never use it myself; https://github.com/fortran-lang/stdlib/wiki/Usage-of-%22open%22 ). It may be simpler to ignore the direct access for now."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-03 16:45:20+00:00",
                    "text": "Modes 'w+' and 'w+b' open and truncate the file. Modes 'r+' and 'r+b' open the file with no truncation.\n\nSo, basically + means action = \"READWRITE\", with no other differences, (I think)."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-04 10:24:26+00:00",
                    "text": "@certik: I created a PR to your branch open from my branch opencertik. It was easier for me to make some suggestions.\nShortly, I added a function to parse the optional mode, and I extended it to the Python characters \"+\" for readwrite and \"b\"/\"s\" for stream files.\nCurrently, unformated files are not supported (but it would not difficult to implement with my suggestion), as well as access=direct(but I think we should discuss it broadly before implementing it)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 20:49:51+00:00",
                    "text": "@jvdp1 thank you! You were reading my mind, I wanted to implement it just like this."
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 21:16:49+00:00",
                    "text": "This is ready to go in as far as I am concerned. The implementation could be improved and all corner cases tested more, but for a first iteration I think it is good enough."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-04 21:19:31+00:00",
                    "text": "@jvdp1 thank you! You were reading my mind, I wanted to implement it just like this.\n\nHappy to help!\nQuestion/comment: I expected that the other would be always \"r/w/a/x\", followed (possibly) by '+' and then by \"t/b\". If we don't want to expect that order (e.g.,  to allow something like \"+br\") then the function parse_mode should be modified with a loop going through trim(adjustl(mode)).\nIt could be also more efficient than the current implementation."
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 21:25:55+00:00",
                    "text": "Question/comment: I expected that the other would be always \"r/w/a/x\", followed (possibly) by '+' and then by \"t/b\". If we don't want to expect that order (e.g., to allow something like \"+br\") then the function parse_mode should be modified with a loop going through trim(adjustl(mode)).\nIt could be also more efficient than the current implementation.\n\nI tested Python and it seems it can be in any order. And we should indeed modify parse_mode, to return it in \"canonical\" order.\nI won't have time to do that, but if you want, go ahead and work on it. Or we can merge first and submit a PR later, which would save me from constantly having to rebase and fix conflicts."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-04 21:40:18+00:00",
                    "text": "I tested Python and it seems it can be in any order. And we should indeed modify parse_mode, to return it in \"canonical\" order.\nI won't have time to do that, but if you want, go ahead and work on it. Or we can merge first and submit a PR later, which would save me from constantly having to rebase and fix conflicts.\n\nI just modify parse_mode for that in my branch opencertik. But as you suggested, it is probably better to merge first and than to submit another PR with the new implementation of parse_mode. I will be then able to add some tests for parse_mode with different orders."
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 22:05:21+00:00",
                    "text": "Ok, it seems that nobody is against this and everybody who commented likes it and @jvdp1 approved it, so I am going to go ahead and merge this. Then let's improve upon this with further PRs."
                }
            ]
        },
        {
            "number": 70,
            "user": "certik",
            "date": "2020-01-02 22:40:01+00:00",
            "title": "Refactor the manual Makefiles",
            "text": "Compile the quadruple precision loadtxt\nImplement \"make test\" to run tests and run them at the CI\nCreate a static libstdlib.a library and use it in tests\nUse more modern syntax and simplify\nPass in the FC/FCFLAGS variables automatically\nConsolidate stdlib tests targets",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-02 22:47:11+00:00",
                    "text": "Further simplifications can be made how the tests are handled to reduce code duplication in individual test directories (loadtxt and ascii), but we can do that later. The current design in this PR greatly simplifies the necessary changes to manual Makefiles required as part of #63 and #53."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 15:05:42+00:00",
                    "text": "@gronki, as another proponent of manual Makefiles (per your comments at j3-fortran/fortran_proposals#104 (comment)), I was wondering if you could please review this PR. I tried to simplify the Makefiles a lot."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 18:15:46+00:00",
                    "text": "Thanks @milancurcic for the review. I am rebasing on top of the latest master."
                },
                {
                    "user": "gronki",
                    "date": "2020-01-03 18:16:35+00:00",
                    "text": "@certik I only would suggest using FFLAGS for Fortran flags. I know there was an argument that FCFLAGS corresponds to f90+, but I think we should assume there is only one Fortran, and FFLAGS is clearly stated in gnu make manual as Fortran flags and followed by most Linux operating systems packages (such as rpmbuild that I use). I also think that .SUFFIXES is obsolete and not needed with new syntax using %. The rest is perfect!"
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 18:29:54+00:00",
                    "text": "@gronki thanks for the review! I fixed both things in 0d80b89 and 3400515.\nI am going to merge it now, and we can further improve upon this later."
                }
            ]
        },
        {
            "number": 69,
            "user": "ivan-pi",
            "date": "2020-01-02 19:19:33+00:00",
            "title": "String handling routines",
            "text": "Let's start a discussion on routines for string handling and manipulation. The thread over at j3-fortran already collected some ideas:\n\nsplit - given a separator, splits the string into some form of array\nupper/lower - convert a character string to all upper/lower case\n\nThe discussion also mentioned the proposed iso_varying_string module, which was supposed to include some string routines. I found three distinct implementations of this module:\n\nISO_VARYING_STRING Module by Rich Townsend\niso_varying_string implementation by Brad Richardson (@everythingfunctional)\nISO_VARYING_STRING due to J.L.Schonfelder (author of the iso_varying_string proposal; the module dates back to 1998)\n\nI also found the following Fortran libraries targeting string handling:\n\nStrings For Fortran by Brad Richardson @everythingfunctional\nFortran Character String Utilities by George Benthien\nM_STRINGS from Urban Jost @urbanjost (part of General-Purpose Fortran tools)\nString_Functions by David Frank\nStringiFor by Stefano Szaghi @szaghi\nfortranString from @bceverly\nfortran-string-utility-module by @tomedunn\nfortran-string from @dongli\nstrings by @jchristopherson\nfortran_libstring from @koiking213\nfortran-strings by @eengl\nflibs by @arjenmarkus contains several modules for handling strings\nfunctional-fortran by @milancurcic  implements several functions on strings\nZstdFortranLib by @zbeekman has some conversion to/from other intrinsic kinds, sub, gsub, split, join, and conversion on concatenation. WIP though\n\nIt is likely that several of the tools in the list of popular Fortran projects also contain some tools for working with strings. Given the numerous implementations it seems like this is one of the things where the absence of the standard \"... led to everybody re-inventing the wheel and to an unnecessary diversity in the most fundamental classes\" to borrow the quote of B. Stroustrup in a retrospective of the C++ language.\nFor comparison here are some links to descriptions of string handling functions in other programming languages:\n\nPython: String Methods, String constants, custom string formatting, template strings\nRuby: String class & methods\nD: std.string, std.utf, std.path, std.regex, std.ascii (see related issue #11), std.encoding, std.windows.charset, std.conv\nC: C string handling on wikipedia\nC++: std::string class, <string> header, C++ string handling on Wikipedia, Boost libraries for string and text processing\nJulia: Strings, Common operations\nMATLAB: Characters and Strings\nRust: Strings - Rust By Example, Primitive Type str, Struct std::string::String\n\nObviously, for now we should not aim to cover the full set of features available in other languages. Since the scope is quite big, it might be useful to break this issue into smaller issues for distinct operations (numeric converions, comparisons, finding the occurence of string in a larger string, joining and splitting, regular expressions).\nMy suggestion would be to start with some of the easy functions like capitalize, count, endswith, startswith, upper, lower, and the conversion routines from numeric types to strings and vice-versa.",
            "comments": [
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-02 19:27:57+00:00",
                    "text": "This is a great summary! I feel like most of what we need has already been done in these projects (and others), so mainly we need to just gather it all together. Some important things to decide:\n\nwhat do we call the string class? (I vote string).\nwhat do we call the various individual methods?\nAre they going to be OO (s.lower()) or functional (lower(s))?"
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-02 19:32:25+00:00",
                    "text": "Should we base it on the ISO_VARYING_STRING module? If so, the class is VARYING_STRING and the procedures are functional (lower(s)).\nShould we utilize intrinsic function names? like real(string, [kind, [status]]) and have it stop if the conversion fails and no status variable is provided?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-02 19:33:06+00:00",
                    "text": "functional-fortran implements several functions on strings:\n\nFurther, these functions (and their corresponding operators) are compatible with character strings: complement, empty, head, init, intersection, insert, last, reverse, set, sort, split, tail, and union.\n\n(Caution: split in functional-fortran is not quite what's been discussed at j3-fortran repo. It merely splits the string in two and returns the first or second part)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 19:37:41+00:00",
                    "text": "Thanks for this initiative and listing the current landscape. I think we definitely want stdlib to have good string support.\n(For conversion from real/integer numbers to strings, I implemented a function str to be used like this: https://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/tests/strings/test_str.f90, implemented here and here, so one can do things like \"Number i = \" // str(i) // \".\".)\n@ivan-pi do you want to go ahead and create a table of the basic subroutines and let's brainstorm how they should be named, to be consistent with other languages and/or the above various string implementations if possible. And also if they should be functions or subroutines and what arguments to accept."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 19:42:25+00:00",
                    "text": "@jacobwilliams is right about raising the question how to represent the string. We should start with that.\nI would recommend (as usual) to have a lowest level API that operates on the standard Fortran (allocatable where appropriate) character. Then, have a higher level API that operates on a string type, and simply calls the lower level API. Regarding a name, see #26, it seems most people agree that the convention to name derived type is to append _t, so it would be string_t.\nThat way people can use these low level API routines right away. For example in my codes I do not need to modify any data structures and can start using it. The higher level string_t API can then be used by codes that choose to refactor them, or in new codes. If the syntax is not as nice, some people might opt for the lower level API anyway."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-02 20:05:41+00:00",
                    "text": "I would vote that the low level API be based on functions, pure and elemental where possible and appropriate. I would stick with the Fortran convention of optional status parameters where there is the possibility of things going wrong, and if one is not provided and something goes wrong it crashes. I have tended to use that convention in any routines that go from a string to some intrinsic like:\nif (present(status)) then\n    read(string, *) result\nelse\n    read(string, *, iostat=status) result\nend if\n\nHonestly, I thought the ISO_VARYING_STRING standard did a great job of covering all of the intrinsic functions available for character(len=*) variables, and extending IO to work with that type (put, get, put_line). Aside from the strange interface for split I think it's a great starting point."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-02 20:15:12+00:00",
                    "text": "My plan was to go through the libraries above and create a table of the most commonly available routines in the next days.\nI agree we should consider both low-level routines which work directly on strings of type character(len=*) and a high-level string_t type.\nThe book Fortran Tools for VAX/VMS and MS-DOS by Jones & Crabtree contains a description of a Fortran string-handling library. Interestingly, they decided to use null-terminated strings like in C, meaning they needed to build a separate set of functions from the intrinsic ones (concatenation operator // and length function). They later used these tools to develop a compiler for a subset of the Fortran language itself! Their conclusion about strings was:\n\nFortran is often maligned for its lack of facilities for character-oriented processing. ... The apparent deficiency of Fortran for string manipulation is primarily because of the methods traditionally used rather than because of a shortcoming of the language itself. The main shortcoming of Fortran for string handling is the lack of a standard library of routines for often-needed functions. As Fortran programmers we are faced with a choice: we either invest the up-front effort required to create our own standard library or we live with the continuing effort of hacking together a solution each time we are presented with similar problems."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 20:15:18+00:00",
                    "text": "Where is the latest ISO_VARYING_STRING implementation? Most links are dead by now. The only version I was able to find so far is this one: http://fortrangis.sourceforge.net/doc/iso__varying__string_8F90_source.html."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-02 20:17:03+00:00",
                    "text": "Where is the latest ISO_VARYING_STRING implementation? Most links are dead by now. The only version I was able to find so far is this one: http://fortrangis.sourceforge.net/doc/iso__varying__string_8F90_source.html.\n\nI have linked three distinct implementations in the top post. The links from the gfortran compiler pages are dead as well as the link in Modern Fortran Explained by MCR.\nEdit: An informal description of the iso_varying_string module for Varying Length Character Strings in Fortran can be found at: http://numat.net/fortran/is1539-2-99.html"
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 20:24:58+00:00",
                    "text": "@ivan-pi thanks. I like your plan. It looks like the iso_varying_string is in the \"high-level\" API category, as it operates on a VARYING_STRING derived type. Our low-level API would be similar, but operating directly on character(len=*)."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-02 21:34:50+00:00",
                    "text": "Building the low-level API on character(len=*) variables will be problematic for some operations, since they can't be resized. The high-level API will need to call routines that operate on character(len=:),allocatable variables. So you may end up with two slightly different routines in some cases. So are there really three APIs?\n\ncharacter(len=*)\ncharacter(len=:),allocatable\nstring_t or whatever we call it\n\nThat seems complicated to me... but it would cover all the bases..."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-02 21:54:55+00:00",
                    "text": "I think there are two possible APIs here: intrinsic and derived-type one.\nFor the intrinsic API, character(len=*) works well for input strings. If the function will return a string of known size, you return a charecter(len=something) string. If unknown, you return an allocated character(len=:), allocatable string. User doesn't need to know which one it is.\nI also see the intrinsic one as the starting point. Higher-level (derived type) implementation is likely to use the intrinsic API internally."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-02 22:14:23+00:00",
                    "text": "My understanding, and somebody correct me if I don't have this quite right, is that the ISO_VARYING_STRING standard was created before character(len=:), allocatable (around 2001 I think?), but then when character(len=:), allocatable was added to the standard, it was supposed to function like variable length strings, and so the former was mostly abandoned. However, I have found most compilers to be buggy with their implementation. Memory leaks when used as the return from a function, failure to properly reallocate on assignment, false-positive warnings about accessing uninitialized memory, etc.\nIf allocatable character actually worked we wouldn't a new derived type for strings. You would just use the intrinsic type and move on. But I think as written in the standard, it probably will never truly work properly in all cases (especially as in read statements, since other allocatable arrays don't and aren't supposed to).\nIf there is a new type for strings, I don't think a lower level library or API should be exposed, and it should probably not be based on allocatable characters."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 23:12:00+00:00",
                    "text": "As I mentioned above, you can use this trick to return character(len=N) strings from functions. The downside is that the string operation gets executed twice --- once to compute the length in the pure procedure, and second time to actually return it. So we probably don't want to do it that way. What I was thinking is to do what @milancurcic suggested: use character(len=*) as well as character(len=N) where we can, and use character(len=:),allocatable to avoid doing the operation twice as I described above. And that's the low level API. Below I provide two examples: #69 (comment) and #69 (comment), to show one one would decide whether to expose character(len=*) or character(len=:), allocatable.\nAs @everythingfunctional mentioned, for example GFortran used to have huge problems with allocatable strings and leaked memory. The latest version has improved a lot. Given that this is standard Fortran, and stdlib is a standard library, I think it is ok if we depend on the standard, and if there are compiler bugs, we'll try to workaround them and ensure they are reported. Regarding read statements, see #14 that would handle that. I think we should at least try to create a consistent low level API, not give up without even trying. If it truly cannot be done, only then we'll have to do what you propose, and only expose the string_t type and report the bugs to compilers (and keep the list somewhere) and propose improvements to the language itself, so that it can be done in the future."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-02 23:29:07+00:00",
                    "text": "I thought you could only use intrinsic procedures in variable declaration statements. Learned something new. That's a neat trick, but like you said, not particularly efficient."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 23:33:29+00:00",
                    "text": "Let's discuss a simple example: upcase.\ncharacter(*)\nHere is an implementation:\nfunction upcase(s) result(t)\n! Returns string 's' in uppercase  \ncharacter(*), intent(in) :: s\ncharacter(len(s)) :: t\ninteger :: i, diff\nt = s; diff = ichar('A')-ichar('a')\ndo i = 1, len(t)\n    if (ichar(t(i:i)) >= ichar('a') .and. ichar(t(i:i)) <= ichar('z')) then\n        ! if lowercase, make uppercase\n        t(i:i) = char(ichar(t(i:i)) + diff)\n    end if\nend do\nend function\nWhen the user wants to use it, he could do this:\ncharacter(*), parameter :: s = \"Some string\"\ncharacter(:), allocatable :: a\nprint *, s\nallocate(character(len(s)) :: a)\na = upcase(s)\nprint *, a\nwhich prints:\n Some string\n SOME STRING\n\nThe main disadvantage of this approach is that the user needs to know the size ahead of time. In this case he knows --- it's the same size as the original string. Although modern gfortran has reallocatable LHS turned on, so then just this works:\ncharacter(*), parameter :: s = \"Some string\"\ncharacter(:), allocatable :: a\nprint *, s\na = upcase(s)\nprint *, a\nSo I think that would work for upcase.\ncharacter(:), allocatable\nHere is the implementation using character(:), allocatable\nfunction upcase(s) result(t)\n! Returns string 's' in uppercase\ncharacter(*), intent(in) :: s\ncharacter(:), allocatable :: t\ninteger :: i, diff\nt = s; diff = ichar('A')-ichar('a')\ndo i = 1, len(t)\n    if (ichar(t(i:i)) >= ichar('a') .and. ichar(t(i:i)) <= ichar('z')) then\n        ! if lowercase, make uppercase\n        t(i:i) = char(ichar(t(i:i)) + diff)\n    end if\nend do\nend function\nIt's still used like this:\ncharacter(*), parameter :: s = \"Some string\"\ncharacter(:), allocatable :: a\nprint *, s\na = upcase(s)\nprint *, a\nBut since this as an extra allocation inside upcase, I would think that in this case, the character(*) version is better."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 23:49:42+00:00",
                    "text": "Now let's discuss integer to string conversion, the two implementations:\ncharacter(*)\npure integer function str_int_len(i) result(sz)\n! Returns the length of the string representation of 'i'\ninteger, intent(in) :: i\ninteger, parameter :: MAX_STR = 100\ncharacter(MAX_STR) :: s\n! If 's' is too short (MAX_STR too small), Fortran will abort with:\n! \"Fortran runtime error: End of record\"\nwrite(s, '(i0)') i\nsz = len_trim(s)\nend function\n\npure function str_int(i) result(s)\n! Converts integer \"i\" to string\ninteger, intent(in) :: i\ncharacter(len=str_int_len(i)) :: s\nwrite(s, '(i0)') i\nend function\nAnd usage:\ncharacter(:), allocatable :: a\na = str_int(12345)\nprint *, a, len(a)\nwhich prints:\n 12345           5\n\ncharacter(:), allocatable\npure function str_int(i) result(s)\n! Converts integer \"i\" to string\ninteger, intent(in) :: i\ninteger, parameter :: MAX_STR = 100\ncharacter(MAX_STR) :: tmp\ncharacter(:), allocatable :: s\n! If 'tmp' is too short (MAX_STR too small), Fortran will abort with:\n! \"Fortran runtime error: End of record\"\nwrite(tmp, '(i0)') i\ns = trim(tmp)\nend function\nAnd usage:\ncharacter(:), allocatable :: a\na = str_int(12345)\nprint *, a, len(a)\nwhich prints:\n 12345           5\n\nDiscussion\nUnlike in the upcase (see previous comment), here the character(*) version is converting twice, so it is inefficient. The character(:), allocatable version just converts once, and so that would be the preferable API.\n(Note: if we implement our own integer to string conversion algorithm, then we avoid the ugly MAX_STR thing and the need to call trim. The above implementation was reused from my codes, where I just use the Fortran intrinsic conversion as part of write so that I save code.)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 00:08:44+00:00",
                    "text": "Here is my proposal for the low level API:\n\nUse character(*) where possible and efficient (see the previous two comments for examples how to decide)\nUse character(:), allocatable otherwise\nFor compilers that cannot compile the code (or leak memory): create a workaround subroutine with a different (less nice or less efficient) API and use that instead for those compilers only, and report the compiler bug and reference it in the code. As a community we have contacts to compiler vendors, and we can communicate this and help get this fixed. The long term goal would be to eventually have no workarounds in 3.\n\nUnfortunately some compilers might leak memory or segfault when such strings are used in derived types. Ultimately, long term, the compilers must be fixed. That's why I think the above proposal is a good one for the long term. In the short term, if we want to provide strings to users that actually work in all today's compilers, it might be that the only way is to create a string_t type not based on allocatable strings, in which case one could still use the low level API with the workarounds 1., 2., and 3., but make a copy of the result into the derived type string_t that is internally represented differently, so that today's compilers do not leak memory. That would be less efficient than providing a separate string implementation, but it's only a short term issue anyway, until compilers catch up. (Alternatively we can have an efficient duplicate implementation based on the internal string_t representation directly if we want better performance until compilers catch up.)"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-03 12:48:29+00:00",
                    "text": "Specifically for the case of integer to string conversion, you could also dynamically allocate a buffer for each integer kind and then trim the result into an allocatable character string:\n    function integer_to_string2(i) result(res)\n      character(len=:),allocatable :: res\n      integer, intent(in) :: i\n      character(len=range(i)+2) :: tmp\n      write(tmp,'(i0)') i\n      res = trim(tmp)\n    end function\nIf we want to avoid internal I/O this function becomes something like\n    function integer_to_string1(ival) result(str)\n        integer, intent(in) :: ival\n        character(len=:), allocatable :: str\n        integer, parameter :: ibuffer_len = range(ival)+2\n        character(len=ibuffer_len) :: buffer\n        integer :: i, sign, n\n\n        if (ival == 0) then\n            str = '0'\n            return\n        end if\n\n        sign = 1\n        if (ival < 0) sign = -1\n\n        n = abs(ival)\n        buffer = \"\"\n\n        i = ibuffer_len\n        do while (n > 0)\n            buffer(i:i) = char(mod(n,10) + ichar('0'))\n            n = n/10\n            i = i - 1\n        end do\n        if (sign == -1) then\n            buffer(i:i) = '-'\n            i = i - 1\n        end if\n\n        str = buffer(i+1:ibuffer_len)\n    end function\nFor processing floating point values the functions are much more difficult to develop compared to those using internal read and write statements."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-03 16:57:10+00:00",
                    "text": "I did some keyword searchs in the list of popular Fortran projects. It seems that most projects use their own set of character conversion and string handling routines for stuff like reading input values from files, parsing command line options, defining settings, etc..\nHere are the results of my search of some of the top projects:\n\n\n\nProject\n# of \"string\"\n# of \"character\"\n# of Fortran files\n\n\n\n\nElmerFEM\n248\n1319\n2076\n\n\nWRF\n306\n966\n1668\n\n\nfds\n16\n28\n41\n\n\nquantum-Espresso\n66\n472\n1516\n\n\nfluidity\n38\n279\n747\n\n\njson-fortran\n26\n47\n49\n\n\nfortranlib\n11\n18\n38\n\n\nNek5000\n54\n204\n336\n\n\ncp2k\n439\n1043\n1132\n\n\nnastran-95\n85\n551\n1838\n\n\nspecfem3d\n186\n404\n765\n\n\nnwchem\n323\n2768\n17214\n\n\ngtk-fortran\n59\n77\n92\n\n\ncfl3d\n14\n216\n397\n\n\nshtools\n2\n20\n113\n\n\narpack-ng\n1\n259\n332\n\n\n\nThe second and third column measure the number of Fortran files that contain the keywords string or character, respectively. This includes both command statements and comments so it may be a bit misleading.\nIn one of the codebases I even found this comment:\n    ! String parsing in Fortran\n    ! is such a pain\n    ! it's unreal"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-03 18:01:21+00:00",
                    "text": "Casing\nThe purpose of these functions is to return of copy of a character string ( either character(len=*) or a derived string type) with the case converted . The common variants are uppercase, lowercase, and titlecase.\nThe libraries cited in the first post contain the following function prototypes:\n! functional\nfunction str_upper(str)\nfunction str_lower(str)\nfunction str_swapcase(str)\npure function ucase(input)\npure function lcase(input)\nfunction str_lowercase(str)\nfunction str_uppercase(str)\nsubroutine str_convert_to_lowercase(str)\nsubroutine str_convert_to_uppercase(str)\npure elemental function lowercase_string(str)\nfunction uppercase(str)\nfunction lowercase(str)\n\n! object-oriented\nprocedure, pass(self) :: camelcase\nprocedure, pass(self) :: capitalize\nprocedure, pass(self) :: lower\nprocedure, pass(self) :: snakecase\nprocedure, pass(self) :: startcase\nprocedure, pass(self) :: upper\nfunction vstring_tolower(this[,first,last])\nfunction vstring_toupper(this[,first,last])\nfunction vstring_totitle(this[,first,last])\nSome versions will return a new string, while some work in place. In at least one of the functions, it did not convert the case of characters enclosed between quotation marks.\nThese are the similar functions available in other programming languages:\n\nPython: capitalize, lower, swapcase, upper\nRuby: capitalize, swapcase, upcase, downcase\nD: toLower, toLowerInPlace, toUpper, toUpperInPlace, asCapitalized, asLowerCase, asUpperCase\nMATLAB: lower, upper\nJulia: uppercase, lowercase, titlecase, uppercasefirst, lowercasefirst\nC++ (Boost): to_upper, to_lower,\nRust: to_uppercase, to_ascii_uppercase, to_lowercase, to_ascii_lowercase, make_ascii_uppercase, make_ascii_lowercase\n\nMy top three name picks are:\n\nuppercase/lowercase/titlecase\nto_upper/to_lower/to_title\nupper/lower/capitalize\n\nEdit: for consistency with the character conversions functions to_lower/to_upper in the module stdlib_experimental_ascii it is maybe better to go for option 2."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-03 18:04:30+00:00",
                    "text": "I'd like to add to the list of facilities here the overloaded operator * between integers and strings, so that you can do, like in Python:\nprint *, 3 * 'hello' ! prints 'hellohellohello'\nprint *, 'world' * 2 ! prints 'worldworld' \nIt's easy to make and use. The only downside I can think of is a somewhat weird API when importing it:\nuse stdlib_experimental_strings, only: operator(*)"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-03 18:23:25+00:00",
                    "text": "Yes, I have seen this kind of usage in one of the above mentioned libraries. I am not sure whether it is not perhaps better to promote the usage of the intrinsic repeat function. As the Zen of Python states: There should be one-- and preferably only one --obvious way to do it.\nA benefit of repeat is precisely that you avoid the import statement."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-03 19:31:26+00:00",
                    "text": "Oops, I didn't know about repeat. Indeed it's the way to go so I withdraw my proposal. I need to brush up on my canonical Fortran. :)"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-03 20:34:32+00:00",
                    "text": "It is really hard to have a day job and keep up with all these threads, so my apologies if I've missed something because I'm just skimming here. A few opinionated notes:\n\nRuby is my favorite language for string processing, and IMO is the best at it. If no one objects (especially @ivan-pi) I'll put links in the first post on this issue\nI have focussed mostly on some basic string handling (expanded template here) in my ZstdFortranLib project which I started only days before this project started, so I'm of a mind to possibly abandon it or work to integrate some of it here. It has:\n\nsplit: returns an array of characters where each entry is as long as the longest one\njoin: joins an array of characters\nsub: from Ruby, replaces the first occurance of a substring with a substitution, optional argument to replace the last string\ngsub: Replaces all occurrences with a substring\n//: Overloaded to allow concatenation of all real, logical, integer kinds with all character kinds\nto_i: Convert to integer (all kinds)\nto_r: Convert to real (all kinds)\nto_l: Convert to logical (all kinds)\nto_s: Convert anything to a string (all kinds)\nANSI formatting stuff that can be turned on/off globally for coloring and styling terminal output (thanks to using one of @szaghi's projects, FACE I believe)\n\n\n\nI need to look at the varying string and character array proposals in more detail.\nFWIW, I personally prefer the Ruby Python OO approaches with methods because it will make import statements much simpler: Pull in the string class and you get all the methods along with the type/class declaration. Now some operators may need to be pulled in as well if you want to be able to concatenate a real (lhs) with a string (rhs, can't have a TBP operator to the left of the object IIRC).\nI was thinking of starting a PR marrying my work on ZstdFortranLib with a UDT/Class approach rather than operating on raw character scalars and arrays which is awkward for things like split(). But now I need to catch up on the myriad of proposals and prior art, so don't hold your breath."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-03 20:37:13+00:00",
                    "text": "While there is an intrinsic implementation, repeat(), I still like the more concise syntax which has pretty clear meaning for anyone who has ever worked with languages like Python and Ruby. It would be nice if some of these syntactic sugar items were added to the standard rather than a standard library. But until then I would be happy with * overloaded for characters."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 20:42:17+00:00",
                    "text": "@zbeekman I am struggling with all the threads also, but that is good news. It means there is lots of momentum. If you can help us design a good low and high level API for strings (#69 (comment)), that would be great."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-03 20:45:47+00:00",
                    "text": "@certik k\n\nNow let's discuss integer to string conversion, the two implementations:\n\nI like your first one the most. With integers you can use some math to count up how many digits there are, and if you need a sign on the front, which completely removes the need to declare the max string length AND to do the IO twice. Instead you use integer and floating point math which (hopefully) will be reasonably quick. IIRC, I implemented something to do this in JSON-Fortran but I'll have to look for it.\nAlso, I don't mean to whine about not being able to keep up, and I agree that it's good, but it's hard to keep track of all the balls in the air."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-03 20:58:56+00:00",
                    "text": "After a brief search there are at least 3 ways to do this without performing the conversion to a string then counting digits:\n\nIteration:\nlen = 1\nif ( n < 0 ) len = 2\ndo\n  n = n / 10\n  if (n == 0) exit\n  len = len + 1\nend do\n\nTail recursion (same algorithm as above: It will be optimized to code above by compiler or it will be slower if the compiler uses recursion)\n\"One shot\" method using log10\nlen = floor( log10( real( abs( n ) ) ) + 1 )\nif ( n < 0 ) len = len + 1\n\n\nI would guess that 1 is the fastest way to do this, but it may depend on the compiler and hardware. 3 has conversion to a real, then log10 is probably computed iteratively, and it is converted back to an int, so 1. may be faster despite the loop."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 21:06:52+00:00",
                    "text": "@zbeekman great idea. I suspect even faster would be 1. together with putting the digits into the string right away. And thus using the \"allocatable\" approach. In your approach, you compute the length of the string in 1., but then you have to do a similar loop again when you do the actual string conversion. But your approach is definitely a huge improvement, so we could us my first approach above also with this."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-03 21:13:58+00:00",
                    "text": "Why not keep going a little here:\nelemental function int_str_len(n) result(res)\n    integer, value :: n\n    integer :: res\n\n\tres = merge(1, 2, i >= 0)\n\tdo\n        n = n / 10\n        if ( n == 0 ) return\n        res = res + 1\n    end do\nend function int_str_len\n\nI suspect even faster would be 1. together with putting the digits into the string right away. And thus using the \"allocatable\" approach.\n\nI prefer not working with allocatable character function results due to compiler bugs, but whether or not the compiler is implicitly generating a loop for write(s, '(i0)') i may be interesting from a performance perspective...\nDoh! Ah, the dangers of drinking from the fire-hose of fortran-lang/stdlib: It appears @ivan-pi has essentially already figured all this out and implemented a similar version above."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 21:29:00+00:00",
                    "text": "See also #69 (comment) how I propose to handle the compiler bugs."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-03 21:29:28+00:00",
                    "text": "Ruby is my favorite language for string processing, and IMO is the best at it. If no one objects (especially @ivan-pi) I'll put links in the first post on this issue\n\nFeel free to edit the first post. I only listed the languages that came off the top of my head.\n\nDoh! Ah, the dangers of drinking from the fire-hose of fortran-lang/stdlib: It appears @ivan-pi has essentially already figured all this out and implemented a similar version above.\n\nI adapted that version from a 1988 book on Fortran tools but took the \"one-shot\" approach to declare a sufficiently sized buffer. The range intrinsic essentially returns the value of floor(log10(huge(x)) converting the integer to a real first."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-03 21:44:24+00:00",
                    "text": "The range intrinsic essentially returns the value of floor(log10(huge(x)) converting the integer to a real first.\n\nYes I saw that. And then you cleverly work backwards from the temporary array local variable that holds the largest possible integer you could create. Pretty neat!\nI think at the end of the day the allocating the right length string issue is where we'll want some benchmarking with different popular compilers. I'm not convinced that internal IO would be slower than this, but I haven't bench marked it and would happily be wrong!"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-03 21:59:10+00:00",
                    "text": "In the book where I found this approach they say:\n\nThe reason for not using internal files is mainly to avoid Fortran I/O if possible on microcomputers with limited memory, with the hope that the host compiler won't include Fortran I/O in the executable image; it is also kind of nice to be able to do it on your own. In our tests of the IBM-PC progams that do not use Fortran I/O in the primitives, replacing versions of itoa and atoi using internal files with the ones shown here reduced the size of executable program by 21k bytes.\n\nI cannot say whether this is true also for modern Fortran compilers or, if it even matters given the large amount of memory available to us today."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-03 23:09:22+00:00",
                    "text": "To follow @gronki's original format of:\n\n\nname of the utility\nshort description\ndoes it exist in other languages\nproposed example of usage\n\n\nStrip\n\nRemove leading and trailing whitespace characters (null, horizontal tab, line feed, vertical tab, form feed, carriage return, space.)\nRuby: https://ruby-doc.org/core-2.6/String.html#method-i-strip\n\"    hello    \".strip   #=> \"hello\"\n\"\\tgoodbye\\r\\n\".strip   #=> \"goodbye\"\n\"\\x00\\t\\n\\v\\f\\r \".strip #=> \"\"\n\"hello\".strip           #=> \"hello\"\n\nFortran:\nstrip(\"\\tgoodbye\\r\\n\") ! \"goodbye\", where \\t is a tab char, \\n a new line etc.\nstrip(\"   hello     \") ! \"hello\"\nstrip(\"Hello\")         ! \"Hello\"\n!! Or maybe for a string class\ns%strip() ! returns \"hello\" from \"   hello   \", etc. as above\n\n\nChomp\n\nReturn string with default or optionally specified trailing record separator(s) removed. Think write(*,*) vs write(*,*, ADVANCE=\"NO\").\nRuby: https://ruby-doc.org/core-2.6/String.html#method-i-chomp\n\"hello\".chomp                #=> \"hello\"\n\"hello\\n\".chomp              #=> \"hello\"\n\"hello\\r\\n\".chomp            #=> \"hello\"\n\"hello\\n\\r\".chomp            #=> \"hello\\n\"\n\"hello\\r\".chomp              #=> \"hello\"\n\"hello \\n there\".chomp       #=> \"hello \\n there\"\n\"hello\".chomp(\"llo\")         #=> \"he\"\n\"hello\\r\\n\\r\\n\".chomp('')    #=> \"hello\"\n\"hello\\r\\n\\r\\r\\n\".chomp('')  #=> \"hello\\r\\n\\r\"\n!! Or use a TBP on a string class with passed first argument\n\nFortran:\nchomp(\"hello\")                   ! \"hello\"\nchomp(\"hello\\n\")                 ! \"hello\"\nchomp(\"hello\\r\\n\")               ! \"hello\"\nchomp(\"hello\\n\\r\")               ! \"hello\\n\"\nchomp(\"hello\\r\")                 ! \"hello\"\nchomp(\"hello \\n there\")          ! \"hello \\n there\"\nchomp(\"hello\", sep=\"llo\")        ! \"he\"\nchomp(\"hello\\r\\n\\r\\n\", sep=\"\")   ! \"hello\"\nchomp(\"hello\\r\\n\\r\\r\\n\", sep=\"\") ! \"hello\\r\\n\\r\"\n!! Or use a TBP on a string class with passed first argument\n\n\nSplit\n\nReturn an array of strings. This might be an array of raw characters padded out to the max length of any given element, or a ragged edge array of strings in a string class. Called without an argument or a single space remove leading and trailing whitespace and runs of multiple white space characters.\nRuby: https://ruby-doc.org/core-2.6/String.html#method-i-split\n\" now's  the time \".split       #=> [\"now's\", \"the\", \"time\"]\n\" now's  the time \".split(' ')  #=> [\"now's\", \"the\", \"time\"]\n\"mellow yellow\".split(\"ello\")   #=> [\"m\", \"w y\", \"w\"]\n\"1,2,,3,4,,\".split(',')         #=> [\"1\", \"2\", \"\", \"3\", \"4\"]\n\nFortran:\nsplit(\" now's  the time \")           ! [\"now's\", \"the\", \"time\"]\nsplit(\" now's  the time \", sep=' ')  ! [\"now's\", \"the\", \"time\"]\nsplit(\"mellow yellow\", sep=\"ello\")   ! [\"m\", \"w y\", \"w\"]\nsplit(\"1,2,,3,4,,\", sep=',')         ! [\"1\", \"2\", \"\", \"3\", \"4\"]\n\n\nJoin\n\nJoin an array of characters or string class using optional glue, like python, but I think the arguments are backwards in python for the object oriented case. i.e., list.join(glue) seems to make more sense to me.\nPython: https://docs.python.org/3.8/library/stdtypes.html#str.join\ns = \"-\"\ns.join(['1','2','3','4']) # '1-2-3-4'\n\nFortran:\njoin(['1','2','3','4'], glue='-') ! '1-2-3-4'\njoin(['1','2','3','4'])           ! '1234'\n!! Or for an OO class\ns = split('this, that, the other', sep=',')\n! this\n! that\n! the other\ns%join(',')                       ! 'this, that, the other'\ns%join()                          ! 'thisthatthe other'\n\n\nGsub\n\nGlobal substitution. Same as @jacobwilliams' string_replace as far as I can tell. Eventually it would be nice to support regular expressions like Ruby, but, for now, we should start smaller and just make it behave like:\nsed 's/<pattern>/<replacement>/g'\nKinda Ruby, Python and sed. Behave like Python without the optional count argument\nFortran:\ngsub(\"hello\", \"l\", \"L\") ! \"heLLo\"\ngsub(\"the quick brown fox jumped over the lazy dog\", \"the\", \"a\")\n    ! \"a quick brown fox jumped over a lazy dog\"\n!! Or OO approach\ns = \"hello\"\ns%sub(\"l\",\"L\")              ! \"heLLo\"\n\n\nSub\n\nReplace first (or last) instance of one substring with another\nAgain, similarities with Python and Ruby, but not an exact match\nFortran:\nsub(\"hello\", \"l\", \"L\") ! \"heLlo\"\nsub(\"hello\", \"l\", \"L\", back=.true.) ! \"helLo\"\nsub(\"the quick brown fox jumped over the lazy dog\", \"the\", \"a\")\n    ! \"a quick brown fox jumped over the lazy dog\"\nsub(\"the quick brown fox jumped over the lazy dog\", \"the\", \"a\", back=.true.)\n    ! \"the quick brown fox jumped over a lazy dog\"\n!! Or OO approach\ns = \"hello\"\ns%sub(\"l\",\"L\")              ! \"heLlo\"\ns%sub(\"l\",\"L\", back=.true.) ! \"helLo\"\n\n\nCenter\n\nPad and center a string to a given width\nRuby: https://ruby-doc.org/core-2.6/String.html#method-i-center\n\"hello\".center(4)         #=> \"hello\"\n\"hello\".center(20)        #=> \"       hello        \"\n\"hello\".center(20, '123') #=> \"1231231hello12312312\"\n\nFortran:\ncenter(\"hello\",4)        !  \"hello\"\ncenter(\"hello\",20) .     ! \"       hello        \"\ncenter(\"hello\",20,\"123\") ! \"1231231hello12312312\"\n!! Or OO approach with passed first variable as before\ns = \"hello\"\ns%center(20)       ! \"       hello        \"\ns%center(20,\"123\") ! \"1231231hello12312312\"\n\n\nConversion from character to real, integer, complex, logical, etc.\n\nConvert using TBPs or functions from real, complex, integer, logical to a string\nRuby's to_i, to_f, etc. https://ruby-doc.org/core-2.6/String.html#method-i-to_f\nFortran: Implementation details discussed somewhat above\n\nInteger, real, logical, complex conversion to character strings (ideally for all available kinds)\n\nConvert using internal io with a read statement under the generic * edit descriptor\nLike Ruby's to_s/to_str method and Python's .str()\nFortran:\n\nOverloaded concatenation\n\nUse to_int or whatever the names are to concatenate strings with integers, reals, complex and logical variables and handle the string conversion with the default rules\nOther languages: probably, but don't know of good examples off the top of my head\nFortran:\n\"file\" // i // \".txt\" ! \"file1.txt\" or \"file999.txt\" or \"file-20.txt\"\n100.0_rk // \" degrees celsius is when water boils\"\n! \"100.00 degrees celsius is when water boils\"\n! This should have a editable edit descriptor to control conversion, probably want to use a \"g\" edit descriptor as the default with sensible values\n\"Test failed? \" // .true. ! \"Test failed? true\"\n\n\n\nMost Python and Ruby string methods with idiomatic, and straightforward-ish implementations in Fortran would be great to have. Cases where intrinsics are already present need not be re-written unless we create a string class vs a functional style. Some others have no obvious or straightforward implementation until more infrastructure (like regex handling) is in place. Regex handlers will almost certainly need to use an external library, unless someone knows how to write parsers and lexers using tools that emit Fortran."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-03 23:11:40+00:00",
                    "text": "I think and important issue for us is to decide:\n\nFunctional only approach\nOO only approach\nBoth\n\nI don't think it would be that difficult to provide both a functional interface and an OO interface, and the OO interface could leverage the functional implementation in most places."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-03 23:13:02+00:00",
                    "text": "Also worth considering: Do we want basename, dirname, name_we, extname type of functions to be part of a string class or a file/os class/module?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 23:16:09+00:00",
                    "text": "Do we want basename, dirname, name_we, extname type of functions to be part of a string class or a file/os class/module?\n\nThat should be the OS module I would think.\n\nI think and important issue for us is to decide:\n1. Functional only approach\n\n2. OO only approach\n\n3. Both\n\n\nIt looks like 3. it should be, as we can all agree on that one and move on to actually implement this (as opposed to keep discussing whether to do 1. or 2.)."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-04 04:32:40+00:00",
                    "text": "Responding to some of @zbeekman proposals\nStrip\nDoesn't trim already do exactly this? Why have two functions to do exactly the same thing?\nChomp\nI think you need more examples about why this is needed. Is the idea not to remove trailing whitespace if it's not a record separator? I.e. chomp(\"hello \\n\") => \"hello \"\nSplit\nThere is some subtleties about how split works that need to be pointed out. In Python (and other languages?, I'd have to double check) the separator argument is taken as a list of possible separators, not as a pattern that must be found. (i.e. split(\"Hello ,World\", \", \") => [\"Hello\", \"World\"]).\nAlso, should empty strings be included in the resulting array? I think probably not, or you'd get something you probably didn't intend from a standard use case like split(\"A, list, of, words\", \", \") => [\"A\", \"\", \"list\", \"\", \"of\", \"\", \"words\"] due to the multiple separators next to each other.\nI've got an implementation of split (splitAt) here that behaves like Python's.\nGsub and sub\nThe replace function from the ISO_VARYING_STRING module combines these two uses into one interface (replace(string, target, substring, every, back)). I don't know if that's better or worse, just that there is already a precedent for it.\nConversion from character to real, integer, complex, logical, etc.\nWhat should happen if the string can't be converted? Most other languages throw exceptions that can be caught, but Fortran can't do that. Providing an optional iostat argument would seem to fit in with the Fortran \"style\".\nInteger, real, logical, complex conversion to character strings (ideally for all available kinds)\nThe question really is what format should real and complex numbers take. Use the f format specifier or g, or something else? To what precision? What about trailing zeros? or rounding for stuff like 1.00000000001? I've got an implementation here that picks the shorter string from regular vs scientific notation, removes trailing zeros, and give the full precision available for that kind if a number of significant digits isn't specified, but I'm not certain that's what everyone would prefer."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-01-05 11:23:50+00:00",
                    "text": "Like others, I have only skimmed the postings, so I may have missed it, but has the issue of meaningful trailing blanks been discussed? Normally trailing blanks are just an inconvenience and I guess with the allocatable-length strings we have now, the issue is less pressing, but some consideration does seem useful."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-01-05 11:30:20+00:00",
                    "text": "@zbeekman mentioned in #69 (comment) parsers and lexers implemented in Fortran. Some years ago I adjusted the SQLite \"lemon\" parser generator so that it will emit Fortran code - https://sourceforge.net/p/flibs/svncode/HEAD/tree/trunk/src/lemon/. I merely adjusted the code generation parts of the original code and I admit not having used it much, but it could be a starting point. In the same Flibs project: Paul Fossati created an interface for the PCRE library for regexps."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 16:24:20+00:00",
                    "text": "has the issue of meaningful trailing blanks been discussed?\n\nGreat question, I don't think we explicitly discussed this yet. I was hoping that we will assume and require that there are no trailing blanks (both in the low level as well as the OO API), unless the user wants them there (but in that case \"x\" and \"x \" will be treated as different strings). In particular, no need to call trim all over."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-01-06 13:42:11+00:00",
                    "text": "Quite possibly the absence of any magic character - \\0 for C-like languages and trailing blanks for Fortran - may automatically resolve the issue, but we will have to take care that such features/quirks do not sneak in ;)."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 21:59:44+00:00",
                    "text": "@everythingfunctional: I'm not in favor of unnecessary duplication either, and this is just a personal wishlist to shape discussion\n\nDoesn't trim already do exactly this? Why have two functions to do exactly the same thing?\n\nNo, trim only handles trailing blanks which are spaces unless I'm misunderstanding something. Strip handles leading and trailing whitespace of all forms.\n\nIs the idea not to remove trailing whitespace if it's not a record separator?\n\nYes and to provide flexibility on what that separator might be, e.g., commas after all elements except the last one in a list of items.\n\nThere is some subtleties about how split works that need to be pointed out.\n\nAgreed. I was quoting the way Ruby does it straight from Ruby's API docs, and I think the examples I posted spell out the semantics fairly well.\nIn my very opinionated opinion, Ruby is the best language for string handling, so I like APIs that match, where it makes sense, Rubys. But Python has good string handling too, certainly better than Fortran. Just proposing a way to do it, not saying we have to do it that way.\n\nThe replace function from the ISO_VARYING_STRING module combines these two uses into one interface (replace(string, target, substring, every, back)). I don't know if that's better or worse, just that there is already a precedent for it.\n\nI haven't had a chance to look at ISO_VARYING_STRING yet. If people like it and there's broad support (and, even better an implementation) then I would happily defer to replace and any other useful functions/utilities. But since we're making something new, I wanted to share what I like from Ruby.\n\nWhat should happen if the string can't be converted? Most other languages throw exceptions that can be caught, but Fortran can't do that. Providing an optional iostat argument would seem to fit in with the Fortran \"style\".\n\nVery good question. Where a function is doing the converting it should have an iostat argument. Typically you can convert from one character set into utf8/unicode, going in the other direction requires a check that the characters being converted from unicode exist in the other character set. For concatenation, you can convert asymmetric concatenation to ISO_10646 if it's present.\n\nThe question really is what format should real and complex numbers take. Use the f format specifier or g, or something else? To what precision? What about trailing zeros? or rounding for stuff like 1.00000000001?\n\nYes, I implemented similar logic in JSON-Fortran (with input and help from @jacobwilliams)\tI think it makes sense to provide some sane defaults with a function to let the user specify their own default output format for reals, complex, integers, etc."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 22:01:06+00:00",
                    "text": "Paul Fossati created an interface for the PCRE library for regexps.\n\nI was thinking that using this might be wise. But it introduces a (perhaps critical) external dependency, that may be an unpopular opinion."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 22:02:41+00:00",
                    "text": "has the issue of meaningful trailing blanks been discussed?\n\nOne of the nice things about most of the ruby APIs is that they give you some flexibility to change semantics for, e.g., repeated blanks, or other patterns. But a lot of this extended capability relies on a regex syntax, which, right now, is probably a non-starter."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 22:13:07+00:00",
                    "text": "In order to move this discussion forward --- it seems the implementations are (relatively) straightforward, the hard part is to agree on an API: a set of functions, their name, arguments for the low level API, and similarly for the high level API. If that's the case, @zbeekman, @ivan-pi do you want to start a document where we'll start discussing the function names and their arguments and functionality?\nI don't know if the best way is to open a few draft PRs with the document (I assume there will be a few competing versions at first), or if there is another way to discuss a full document."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 22:58:55+00:00",
                    "text": "Sure. I need to make myself familiar with N1375 and N1379 And see how it sits with what I had anticipated doing. There's no point reinventing the wheel, so if ISO_VARYING_STRING appeals to me and seems congruent with the opinions I've heard in this thread so far it might be a good starting point. @everythingfunctional seems to already have an MIT licensed implementation, so that could even be a good starting point."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 23:22:09+00:00",
                    "text": "ISO_VARYING_STRING operates on a derived type, so that is the high level API. The low level API would operate on character string directly.\nI was hoping to also have some document that compares different languages, like @ivan-pi did above, so that we can stay compatible with the API, whenever it makes sense."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-07 20:40:47+00:00",
                    "text": "I was hoping to also have some document that compares different languages, like @ivan-pi did above, so that we can stay compatible with the API, whenever it makes sense.\n\nI realized there is a page for this on Wikipedia:\nhttps://en.wikipedia.org/wiki/Comparison_of_programming_languages_(string_functions)\nAs you might notice many of the string functions do not have a Fortran equivalent. Exactly those are the ones we should try and implement here."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-07 20:57:25+00:00",
                    "text": "I don't know if the best way is to open a few draft PRs with the document (I assume there will be a few competing versions at first), or if there is another way to discuss a full document.\n\nBy document are you implying simply a markdown file? (ideally these string function specifications would later become part of the documentation)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 21:26:52+00:00",
                    "text": "@ivan-pi the wikipedia page you posted is perfect, that's what I was hoping to create. Now when this is done, I think all we need is just some markdown document where we start listing the Fortran functions and their names and arguments, and we will consult the wikipedia page to see how other languages do that. Maybe even Wiki would be good enough to start. Do you want to start a wiki page at https://github.com/fortran-lang/stdlib/wiki ?"
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-08 02:14:42+00:00",
                    "text": "\\\nMissed this. It looks bright with promise.  A lot to catch up on. A scanned the discussion and thought it was worth noting that conversion from a numeric value to a string is almost\nalways to build a message. Overloading the concatenation operator is a great way to do\nthat, but one of my favorite approaches is demonstrated in the MSG() function in the M_STRINGS module mentioned in the top post of the discussion. It allows constructs like\n\nmessage=msg('The value is',A,'which squared is ',A**2,'and it is either ',.true.,'or not')\n\nI find I use that type of function a lot.\n\nMore basic is that I saw mention of not using internal I/O to do the conversion to a string.\nThat is really important if you want your function to be safely called from an I/O function\nsuch as a WRITE, and to be able to use it from within a PURE function. The algorithms to do a floating point value as well as an INTEGER value  can be found back as far as the\n1968 version of \"Software Tools\" in Ratfor!\n\n\nBut in order of frustration that they are not there in Fortran is case conversion, then string splitting, then conversion to and from strings, then Regular Expressions.\n\nAnd I like the name \"center\" for centering a string, but I would vote for the name ADJUSTC() for a function that works on CHARACTER variables to complete the set (ADJUSTL(), ADJUSTR(), ...).\n\nA lot to catch up on here but a great step in the right direction, I think. Is the main objective to create a specification for the Fortran standard or to create a working library in the Public Domain (or both?). It wasn't quite clear to me. Assuming a working library emerges what will the LICENSE be and how will it be hosted and documented? Maybe I missed that part of the discussion? I'm not sure I'm starting in the right place, actually.\n\nAs a footnote,\nthe next most common issue being solved when converting a numeric value to a string is to present the number in a form the language does not support, like a non-standard base or perhaps in Roman numerals or in English text, for example."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-08 08:03:04+00:00",
                    "text": "More basic is that I saw mention of not using internal I/O to do the conversion to a string. That is really important if you want your function to be safely called from an I/O function such as a WRITE, and to be able to use it from within a PURE function. The algorithms to do a floating point value as well as an INTEGER value can be found back as far as the 1968 version of \"Software Tools\" in Ratfor!\n\nDid you avoid internal I/O in your library M_STRING? I never really thought about is internal I/O pure or not. But if that is really the case I would prefer to do our own string conversions routines.\n\nAnd I like the name \"center\" for centering a string, but I would vote for the name ADJUSTC() for a function that works on CHARACTER variables to complete the set (ADJUSTL(), ADJUSTR(), ...).\n\nWould you allow adjustc to have an optional width parameter or not? I like this name idea.\n\nIs the main objective to create a specification for the Fortran standard or to create a working library in the Public Domain (or both?)\n\nI think the initial purpose is to create a working library in the public domain (MIT or BSD license) which hopefully becomes standard in the feature. I guess a similar model is how some of the C++ Boost function libraries later become integrated into the language or the C++ standard library. You can read the related thread j3-fortran/fortran_proposals#104 for more information."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-08 14:43:38+00:00",
                    "text": "After checking the 2018 standard it says specifically the unit cannot be an integer or asterisk, which implies internal I/O is OK; but my compiler gives an error if I include any WRITE statement, so I guess that  internal I/O appears to be allowed.\n\n\nI do have versions of a metamorphic class that takes any intrinsic type and does no I/O but it is not in the github versions of M_STRINGS. I was actually going to make a version this week, by coincidence. Now that I see it is my compiler and not the standard stopping me from declaring the procedure PURE and I am trying to read through everything here I think I will play catch-up here instead.\n On January 8, 2020 at 3:03 AM Ivan ***@***.***> wrote:\n\n\n         > >\n >         More basic is that I saw mention of not using internal I/O to do the conversion to a string. That is really important if you want your function to be safely called from an I/O function such as a WRITE, and to be able to use it from within a PURE function. The algorithms to do a floating point value as well as an INTEGER value can be found back as far as the 1968 version of \"Software Tools\" in Ratfor!\n >\n >     >\n     Did you avoid internal I/O in your library M_STRING? I never really thought about is internal I/O pure or not. But if that is really the case I would prefer to do our own string conversions routines.\n\n         > >\n >         And I like the name \"center\" for centering a string, but I would vote for the name ADJUSTC() for a function that works on CHARACTER variables to complete the set (ADJUSTL(), ADJUSTR(), ...).\n >\n >     >\n     Would you allow adjustc to have an optional width parameter or not? I like this name idea.,\n\nI find the length useful particularly with centering, but find overloading adjustl and adjustr to have a length parameter useful too.  With centering in particular you are often doing something like   TITLE=adjustc(\"my title\",len(title))  and it takes quite a bit of fiddling using another routine around the fixed text otherwise.\n\u2026\n\n         > >\n >         Is the main objective to create a specification for the Fortran standard or to create a working library in the Public Domain (or both?)\n >\n >     >\n     I think the initial purpose is to create a working library in the public domain (MIT or BSD license) which hopefully becomes standard in the feature. I guess a similar model is how some of the C++ Boost function libraries later become integrated into the language or the C++ standard library. You can read the related thread [j3-fortran/fortran_proposals/#104](j3-fortran/fortran_proposals#104 j3-fortran/fortran_proposals#104 for more information.\n\n     \u2014\n     You are receiving this because you were mentioned.\n     Reply to this email directly, view it on GitHub #69?email_source=notifications&email_token=AHDWN3J53MZOILMO7WSPY7DQ4WCDXA5CNFSM4KCFW352YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEILQSII#issuecomment-571935009 , or unsubscribe https://github.com/notifications/unsubscribe-auth/AHDWN3KRISWEN277RKGU3VLQ4WCDXANCNFSM4KCFW35Q ."
                },
                {
                    "user": "arjenmarkus",
                    "date": "2020-01-08 15:06:46+00:00",
                    "text": "Re regexp: a couple of years ago I found a series of articles by Russ Cox about regular expression engines. The accompanying source code is not too difficult and I made a start rewriting it in Fortran. However, there is a flaw in my code and I never got around to correct it (the code is not too difficult but it is manipulating lists). I picked it up again. The result will not be a full-fledged RE engine \u00e0 la PCRE, but it will be Fortran only and it should be useable for not entirely trivial tasks."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-08 15:56:44+00:00",
                    "text": "I never really thought about is internal I/O pure or not. But if that is really the case I would prefer to do our own string conversions routines.\n\nBased on the fact that I was able to write pure toString functions here, internal I/O is pure."
                },
                {
                    "user": "certik",
                    "date": "2020-01-08 16:01:47+00:00",
                    "text": "@urbanjost thanks for the post. As @ivan-pi replied, the goal of this stdlib effort is to provide a Fortran Standard Library, i.e., both a library and a specification. See my answer to a similar question. The license is MIT (https://github.com/fortran-lang/stdlib/blob/006bedafc0d40ff381da2bd4455f61b5e11fc2ee/LICENSE), and we will only depend on 3rd party code that is MIT or BSD style licensed. The way we plan to achieve our goal it to have a large community designing the API and a rigorous (high bar) process to get new features in as documented in our WORKFLOW document. And we have been coordinating with the Fortran Standards Committee (this effort started at the J3 committee repository at j3-fortran/fortran_proposals#104), and also we are planning to getting them involved in the step 5 in the workflow (at least informally). Our goal is to get a wide community agreement and acceptance to adopt stdlib as the Fortran Standard Library. We will continue working closely with the Fortran Standard Committee and coordinate with them. I can imagine many arrangements in the future, up to even the Fortran Standard itself specifying a Standard Library; but that is far in the future. Right now our job is to get the community to agree on the APIs and to provide specifications and implementations and to build a community around it.\n(Update: we added the motivation into README: https://github.com/fortran-lang/stdlib#goals-and-motivation)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-08 16:07:41+00:00",
                    "text": "datetime-fortran used internal I/O in a pure function for a long time (since the beginning I think) and this built fine with gfortran and ifort.\nhttps://github.com/wavebitscientific/datetime-fortran/blob/d4683303e6319b6380bbf7717164f7d8f18e0f0d/src/lib/mod_datetime.f90#L1288"
                }
            ]
        },
        {
            "number": 68,
            "user": "milancurcic",
            "date": "2020-01-02 19:16:11+00:00",
            "title": "Linked list",
            "text": "Problem\nLinked list is one of the essential data structures beside an array. It allows you to add, insert, or remove elements in constant time, without re-allocating the whole structure.\nFortran doesn't have a linked list. There are 3rd party libraries, but no obvious go-to solution. Fortran stdlib should have a linked list. I would use it.\nExamples\n\nFLIBS by @arjenmarkus\nfortran-list by @LadaF\nflist by @jacobwilliams\nPolyCon by @cmacmackin\nPetaca by @nncarlson\nModern Fortran Explained by MRC has an implementation in Appendix C\nMany others?\n\nWhat kind of data can the linked list hold?\nThere's various levels of capability we could pursue:\n\nSingle type: Basically just like an array, but allows insertion in constant time;\nElements can be of any intrinsic type in a single list;\nCan take intrinsic type and user-defined derived types (is this even possible in current Fortran?)\n\nAPI\nI don't know, something like this?\nuse stdlib_experimental_collections, only :: List\ntype(List) :: a = List()\n\ncall a % append(42)\ncall a % append(3.141)\ncall a % append('text')\nprint *, a % get(2) ! prints 3.141\ncall a % remove(3) ! a is now List([42, 3.141])\ncall a % insert(2, 'hello') ! a is now List([42, 'hello', 3.141])\n\na = List([1, 2, 3]) ! instantiate a list from an array",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-02 19:24:48+00:00",
                    "text": "C++ has std::list for this. (I added Petaca to your Examples above.)\nI would mention that I personally have never had a need for a std::list in C++, nor any linked list implementation in Fortran, because linked list is very slow (to create, traverse, destrogy, ...) compared to just a regular array or std::vector. The only operation that might be faster is insertion or deletion of individual items in the middle. In my use cases, I typically need to add elements to the end, in which case array works great.\nBut since there are at least 6 different people who reimplemented this already in Fortran and given that C++ has it too in their standard library, I would say that this would be a good candidate to include in stdlib, so that if people want to use it, they can. So +1 from me."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-02 19:40:13+00:00",
                    "text": "In my use cases, I typically need to add elements to the end, in which case array works great.\n\nMe too, but how do you do it? I thought that appending to an array always re-allocates on heap, e.g.:\ninteger :: i\ninteger, allocatable :: a(:)\na = [integer ::]\ndo i = 1, 100000000\n  a = [a, i] ! re-allocates a on every append\nend do\nIt's okay, for small-to-moderate arrays, but for very large ones, isn't it crippling?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 20:00:51+00:00",
                    "text": "The canonical way is to pre-allocate the array and then append to it, like this:\ninteger :: i\ninteger, allocatable :: a(:)\nallocate(a(100000000))\ndo i = 1, 1000\n    a(i) = i\nend do\nThen you use your actual application to figure out what the maximum size of the array is (100000000 in this example), and then you can either keep a as is (only use the first 1000 elements, as in this example), or you can copy it to a smaller array. A real world example is e.g. here: https://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/sparse.f90#L111, the Bj_ array is pre-allocated to the maximum size first (determined from the sparse arrays), and then downsized before returning to the user: https://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/sparse.f90#L127. This is typically still much faster than a linked list implementation. If you don't know the size ahead of time, then you can set some maximum at compile time and fail the program if you go over it (real world example: https://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/basis.f90#L230) --- many times this is fine, as you can recompile the code easily. But sometimes that's not appropriate, so then you can also do what std::vector does --- it doubles the allocation every time you reach it, and copies the data. Here is a fast implementation of that that I use in LFortran (that's in C++, but one can do something similar in Fortran also): https://gitlab.com/lfortran/lfortran/blob/57d3b8077d884f0ff3945ad3a86b2da920e4b6b3/src/lfortran/parser/parser_stype.h#L22. All of these are fast options.\nBut as I said, it's good to have linked list in stdlib, if people prefer that, so that they do not need to reimplement it."
                },
                {
                    "user": "rweed",
                    "date": "2020-01-02 21:10:28+00:00",
                    "text": "First I think we need to define which types of linked list we need. I prefer a circular double-linked list as the basic type since its the type I use most in FEM codes etc. I also think we would need a single-link list to implement stacks and queues. Also do we need some form of reference counting. As to @milancurcic question as to current Fortran support list that can contain both intrinsic and user defined types, yes it can. I've implemented both a circular list class and a single link class using unlimited polymorphic variables. They works but are not pretty and will probably have poor perfomance when compared to a type specific list generated by pre-processing/templating methods ala the\nFortran Template Library approach."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-03 04:05:54+00:00",
                    "text": "Generic linked-list, or really any generic data structure, is really cumbersome with the current Fortran capabilities. They work, but you end up having to use a select type block every time you want to access the data. So for convenience you'd end up with some wrapper class or library, at which point you might as well have re-implemented for your specific use case. Until we get fully parameterized types or template capabilities I don't think these are a great idea."
                },
                {
                    "user": "victorsndvg",
                    "date": "2020-01-03 12:22:12+00:00",
                    "text": "I think the supported data types should be wrapped with containers in order to be extendible.\nIn the main issue (#1) containers are mentioned, but I don't see any other specific issue.\nI think FPL (https://github.com/victorsndvg/FPL) contains a smart implementation strategy for supporting native data types and allow to extend to other user defined data types. It contains lists, hash tables, etc. All of them depend on containers (aka wrappers) in order to manage different data types.\nI agree that with this kind of data types you don't get performance, but amazing flexibility. This kind of data types (usually) are not for computation purposes.\nEdit:\n\nNote 1: FPL data types naming is probably not good\nNote 2: Multiple dimensions management is another usual issue also treated by FPL"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-03 17:12:09+00:00",
                    "text": "I think many of the projects in the list of popular projects contain linked list implementations. Perhaps it would be good to do a grep over all of those repositories to get a feeling for linked list usage in production codes (e.g. whether they use generic lists supporting multiple kinds or only specific ones for the intrinsic kinds and potentially derived types)."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-03 17:27:02+00:00",
                    "text": "I agree with @everythingfunctional on this issue. There's a ton of up-front labor in implementing fully polymorphic containers, and I'm not convinced that they're that much more useful than having generic (but homogeneous) containers. That is, I don't think it's worthwhile to support, say, linked lists where each element is of arbitrary type.\nThe more common use case I find is to need a linked list of int32, say. Or a binary tree of class(my_derived_t). These can be implemented without select type all over the place. There's still the labor of implementing all the intrinsic types, but this can be templated.\nLetting users make containers of derived types is tricker. The common solution is to provide an abstract base class that users need to extend in order to have containers of derived types. I think that solution kind of sucks, but I have an alternate idea... Just ship source code templates that implement each container for class(__T__) and then let users run sed s/__T__/mytype/g on it to produce derived type containers on demand. (This will be slightly more involved for, e.g., mapping types, but just slightly).\nI confess I have not thought through if there is some great pitfall to this approach besides being slightly \"icky\" from a distribution p.o.v."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-03 18:24:13+00:00",
                    "text": "I'm in agreement with @nshaffer here.  I've done the linked-list-of class(*) variables in my own library which I use as a backend for some very specific things where such generality is needed. Otherwise it is incredibly clunky to use with all the select type and isn't an acceptable for general use, imo.\nSomeone else seemed to suggest that perhaps performance shouldn't be a concern here. I think it would be a big mistake to ignore performance. Linked lists come with their intrinsic performance overhead that most would be aware of, but any implementation that significantly added to that I would find unacceptable to include in a standard library.\nI think the best solution beyond intrinsic types, which could all have very performant implementations, would be, as @nshaffer suggested, to provide a literal template that a user could adapt for their particular case.  In fact that's more or less what I do myself."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-03 19:51:16+00:00",
                    "text": "A note on performance:\n\nYes linked lists have some overhead compared with arrays\nThey perform well for sorted data, and in instances where you're always manipulating one end of the list or the other, e.g., stacks, but, in general are NOT constant time lookup for random access read or insertion unless you're always operating on data \"nearby\"\nThey are a building block component for hash tables which are in general constant time insertion and lookup.\nIn some cases where storage needs vary greatly and dynamically in complex ways pre-allocating a huge array may not be feasible and you may want/need to use a linked list\n\nI think there is merit to providing classic data structures and algorithms. I would add hash tables to this list as well as binary-trees, octrees, K-D trees, and a number of others. Obviously they are not useful to all users and applications but having a decent implementation is worthwhile.\nI agree that right now the select type combinatorial explosion makes unlimited polymorphics nearly useless, and very awkward. In my opinion better generic programming should be the highest priority for the next major standard revision."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 20:08:29+00:00",
                    "text": "@zbeekman Generic programming will not make it to the next standard revision -- simply because there is no proposal that is ready. I think the latest most developed idea is pursued at j3-fortran/fortran_proposals#125, and we need everybody's help to help transform the idea into a solid proposal. Once we have a proposal that is community backed, I'll be happy to bring it to the committee and try to get it into the next standard."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-03 20:13:04+00:00",
                    "text": "I know @rouson is working with Magne who leads the Bergen Language Design Lab and also @tclune on generics. They have something here but I don't know how up to date it is with their current efforts. Hopefully they can combine efforts and we can get something in, we'll see."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 20:19:45+00:00",
                    "text": "Yes, the issue j3-fortran/fortran_proposals#125 is the latest based on our discussion with Magne at the last meeting. Anyway, let's move the discussion about this there, I just wanted to point this out, that we need help."
                },
                {
                    "user": "tclune",
                    "date": "2020-01-03 20:21:58+00:00",
                    "text": "In the mean time I have a project  https://github.com/Goddard-Fortran-Ecosystem/gFTL which provides (by far less elegant means) a generic container system.   Currently it supports  Vector and Map (ala C++ STL),  but also has Set which is used under the hood.\ngFTL uses the C preprocessor and requires explicit instantiation, but is still a real game changer for doing some common operations within Fortran.     I have a separate project gFTL-shared that provides common instantiations.\nBut I do look forward to the day that this could be done much more elegantly through a proper generic facility.    (And yes, I realize that other preprocessors could do what I have done more elegantly than the C preprocessor, but ...  cpp is already integrated into the build systems for the other projects I work with."
                },
                {
                    "user": "gronki",
                    "date": "2020-01-03 23:40:21+00:00",
                    "text": "I agree here with @zbeekman that linked lists are essential and I think the approach to preallocate array is very ineffective (cause then you have to check for overflow and re-allocate it etc). I also sadly agree that this is undoable in the current Fortran. Gotta wait for generics (or hopefully an intrinsic highly-optimized types for lists and dicts)."
                },
                {
                    "user": "LadaF",
                    "date": "2020-01-04 00:30:00+00:00",
                    "text": "Thanks for mentioning my little example (should have been updated a long\ntime ago). I do agree that `select type` is a big drawback and I use tye\nparametric version (using cpp macros) whereever possible. I think a linked\nlist is a useful structure in many areas, and so are also binary trees and\nother. Especially hn doing more CS stuff, as opposed to just scienific\ncomputation.\n\nAnd many thanks for linking the current work on a proposal. I have looked\nat Java interfaces as a possible alternative to multiple inheritance in\nnormal dynamic-dispatch polymorphism a long time ago. I did not realize the\ncloseness to Haskell type-classes and I did not realize it could be useful\nfor compile-time parallelism. I ill have to take more time to study it. I\nam still worried whether it will be optimizable to be as efficient as are\nC++ templates.\n\nBTW, Ond\u0159ej @certik I happen to be a member of the MFF XC skiing club you\nused to be in some years ago :) I know your fortran90.org and LFortran\nprojects but I did not know you were in J3.\n\n\nDne so 4. 1. 2020 0:40 u\u017eivatel Dominik Gronkiewicz <\nnotifications@github.com> napsal:\n\u2026\n I agree here with @zbeekman <https://github.com/zbeekman> that linked\n lists are essential and I think the approach to preallocate array is very\n ineffective (cause then you have to check for overflow and re-allocate it\n etc). I also sadly agree that this is undoable in the current Fortran.\n Gotta wait for generics (or hopefully an intrinsic highly-optimized types\n for lists and dicts).\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#68?email_source=notifications&email_token=AAFSIEJBJR6YAQX2UWDNTW3Q37EGNA5CNFSM4KCFV36KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEICKR7A#issuecomment-570730748>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAFSIEMGUOBUGC5JHT2EKLTQ37EGNANCNFSM4KCFV36A>\n ."
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 00:33:10+00:00",
                    "text": "@LadaF nice to meet you! Small world. You should put your name and photo at your GitHub profile if you can."
                }
            ]
        },
        {
            "number": 67,
            "user": "certik",
            "date": "2020-01-02 17:59:37+00:00",
            "title": "Parallel linalg",
            "text": "The modern Fortran API for a serial linear algebra (#10) seems natural.\nHow would that be extended to work in parallel using co-arrays? If there is a similar \"natural\" parallel API for linear algebra using modern Fortran, then that would be a good candidate for inclusion into stdlib, and we can have different backends that do the work (Scalapack, ..., perhaps even our own simpler reference implementation using co-arrays directly), that way if somebody writes a faster 3rd party library, then it could be plugged in as a backend, and user codes do not need to change, because they would already be using the stdlib API for parallel linear algebra.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-02 18:00:02+00:00",
                    "text": "@zbeekman you have a lot of experience with co-arrays, is there a way to do this?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-02 18:05:04+00:00",
                    "text": "The modern Fortran API for a serial linear algebra (#10) seems natural.\n\nWould this API also include shared-memory parallelization? Especially if it is based on BLAS/LAPACK."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 18:33:11+00:00",
                    "text": "Would this API also include shared-memory parallelization?\n\nIn the above I was thinking of distributed memory parallelization (MPI, co-arrays, ...).\nWhat are the options for shared-memory parallelization in Fortran? I am aware of do concurrent and openmp. It seems to me, and I could be wrong, that in terms of utility, the distributed memory is the most useful. It can still be run on shared-memory computer (i.e., a single node), but it can also be run on an HPC cluster. Most of the codes that I have been working with use MPI, but rarely they use OpenMP. That being said, I did write an OpenMP version of CSR matmul in my code and it gives about 2x to 4x speedup on 32 cores.... So terrible performance, but expected, since it is memory bound. I do not have an MPI version of CSR matmul, but it would run faster I would expect, due to the memory being distributed (on each core)."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 18:52:51+00:00",
                    "text": "In general, one should be able to implement parallel LA algorithms using coarrays. The coarray implementation may be shared memory, distributed memory, hybrid, etc. the standard doesn't specify. Part of the point of coarrays is to have a simpler API and programming model that can be divorced from the underlying implementation.\nThe trickier question is, perhaps, what should the interface look like? How much ownership and control should the client code have over the objects? Should the user create and pass coarrays? Or should there be a global array view that makes it appear as though you're working with normal arrays?\nLast I checked there were some non-trivial issues with the coarray specification in the standard that makes them challenging or impossible to use in some applications, especially computations on unstructured meshes and some other graph and graph-like  algorithms. I don't recall the details and I believe Salvatore Filippone (PSBLAS author) submitted a proposal to J3 to resolve it, or at least to highlight the issue in the standard.\nIntel provides a shared-memory coarray implementation on some platforms with some licenses, if I remember correctly. I think without parallel studio cluster edition, the Intel Fortran compiler has a shared memory coarray implementation. If you have the license for cluster edition I think that unlocks the MPI back end (or at least the SDK/compile time stuff).\nUsing coarrays is nice because it abstracts away the backend. OpenCoarrays main backend is MPI, but we have an experimental/partial one based on OpenSHMEM, and at one point in the past we were using GASNet. So I think coarrays are a natural and good choice for parallelism, but a few issues remain:\n\nSupport from compiler vendors, especially for a bunch of things like events and collectives for stuff that didn't make it into the 2008 standard\nOutstanding issues with asymmetric coarrays as I alluded to above\n\nOpenMP is nice because of its built in conditional compilation and support for GPUs and accelerators. Thread affinity and avoiding other threading issues is certainly tricky, however."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-02 18:55:53+00:00",
                    "text": "The book by Numrich - Parallel Programming with Co-arrays discusses an API for both sparse and dense linear algebra using co-arrays.\nI know that for PSBLAS they recently developed a co-array backend. A recent article discusses the topic (a draft is available somewhere on GitHub)."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 19:05:22+00:00",
                    "text": "If we can use or adopt parts of PSBLAS that would be nice, rather than reinventing the wheel."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 19:14:47+00:00",
                    "text": "@zbeekman I was lead to believe at the latest J3 meeting that co-arrays can be used today with GFortran, Intel and Cray for anything that MPI can be used, including unstructured meshes (that was my first question to them). But I haven't used co-arrays myself yet.\nMy understanding is also that you can mix and match co-arrays with MPI, is that correct?\nI would go ahead and try to figure out what the API should look like using co-arrays, and if we like it, we can work towards putting it into stdlib. If we can't agree on a good way due to fundamental limitations of co-arrays, then let's submit proposals to the J3 committee to fix it.\nI would think exposing co-arrays directly to the user would be the natural way lowest level API, similarly to the serial linalg API that just operates on arrays. Then, we can always see if there is some optional good higher level API, whether object oriented, or some global object (state?), similarly to how there can be an optional OO API on top of the serial linalg. Let's brainstorm this more on some example.\n@ivan-pi thanks for the pointers --- both links contain very useful info. They have done a lot of thinking about this, so we should see if we can use their API."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-02 19:39:05+00:00",
                    "text": "Most of the codes that I have been working with use MPI, but rarely they use OpenMP. That being said, I did write an OpenMP version of CSR matmul in my code and it gives about 2x to 4x speedup on 32 cores....\n\n@certik I usually rely on Sparse BLAS for such operations (http://www.netlib.org/utk/people/JackDongarra/etemplates/node381.html), mainly with the MKL version."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-02 19:41:14+00:00",
                    "text": "The book by Numrich - Parallel Programming with Co-arrays discusses an API for both sparse and dense linear algebra using co-arrays.\n\nI think it would be a good start.\n@ivan-pi Do you know if the library on which the book is based, is available somewhere? Many articles by Numrich mentioned it, but I am not sure if it has been released."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-02 19:47:11+00:00",
                    "text": "@ivan-pi Do you know if the library on which the book is based, is available somewhere? Many articles by Numrich mentioned it, but I am not sure if it has been released.\n\nI have not found the library anywhere and the book also doesn't offer any link. The book mostly contains only the subroutine prototypes and a description of the variables and some discussion of the API design."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 21:40:45+00:00",
                    "text": "@zbeekman I was lead to believe at the latest J3 meeting that co-arrays can be used today with GFortran, Intel and Cray for anything that MPI can be used, including unstructured meshes (that was my first question to them). But I haven't used co-arrays myself yet.\n\nYes, this is more or less true. However, I don't remember the particular issue, however I recall that @sfilippone found a subtlety with the standard that caused a large headache/impediment in realizing more complex data structures/machinery needed for unstructured meshes. I cannot immediately recall the details. Maybe the OpenCoarrays repo has issues discussing this or maybe Salvatore can remind me here.\n\nMy understanding is also that you can mix and match co-arrays with MPI, is that correct?\n\nYes, in theory this should be true. One complication is that if coarrays are implemented via MPI, then the compiler provided Fortran runtime is responsible for initializing MPI. This may not be ideal in certain situations. I think we implemented a configure time option in OpenCoarrays to return the global communicator to the user or delay MPI_init() and let the user call it. I'd have to double check."
                },
                {
                    "user": "sfilippone",
                    "date": "2020-01-07 08:02:41+00:00",
                    "text": "Hi there\nZaak is correct, there is a problem with the standard.\nThe problem arises as soon as you want to have a coarray component of a\nderived type: if you have a component in a derived type, which itself may\nbe in a derived type, etc. you have a hierarchy of \"container\" objects\nwhich ultimately includes a coarray.\nWith the current standard, it is forbidden for any of the containers to be\nALLOCATABLE (whereas the coarray itself is pretty much forced to be\nallocatable). This implies that the set of entities that may either be a\ncoarray or contain a coarray componet has to be fixed at compile time.\nI have proposed a change in the standard to lift this restriction; I did\nnot attend the latest meetings of the committe, but my colleague Damian\nRouson who coauthored the proposal did attend, and as far as I understand\nthe proposed change was approved. How long until it is supported in\ncompilers, I have no idea.\n\nHope this helps\nSalvatore\n\u2026\nOn Mon, Jan 6, 2020 at 9:40 PM zbeekman ***@***.***> wrote:\n @zbeekman <https://github.com/zbeekman> I was lead to believe at the\n latest J3 meeting that co-arrays can be used today with GFortran, Intel and\n Cray for anything that MPI can be used, including unstructured meshes (that\n was my first question to them). But I haven't used co-arrays myself yet.\n\n Yes, this is more or less true. However, I don't remember the particular\n issue, however I recall that @sfilippone <https://github.com/sfilippone>\n found a subtlety with the standard that caused a large headache/impediment\n in realizing more complex data structures/machinery needed for unstructured\n meshes. I cannot immediately recall the details. Maybe the OpenCoarrays\n repo has issues discussing this or maybe Salvatore can remind me here.\n\n My understanding is also that you can mix and match co-arrays with MPI, is\n that correct?\n\n Yes, in theory this should be true. One complication is that if coarrays\n are implemented via MPI, then the compiler provided Fortran runtime is\n responsible for initializing MPI. This may not be ideal in certain\n situations. I think we implemented a configure time option in OpenCoarrays\n to return the global communicator to the user or delay MPI_init() and let\n the user call it. I'd have to double check.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#67?email_source=notifications&email_token=AD274T6G5BMYJDDJ2XAOAN3Q4OQN5A5CNFSM4KCE7XVKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIG4CQY#issuecomment-571326787>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD274T3GV3PU6RFR63ANHD3Q4OQN5ANCNFSM4KCE7XVA>\n ."
                }
            ]
        },
        {
            "number": 66,
            "user": "certik",
            "date": "2020-01-02 17:42:18+00:00",
            "title": "Parallel algorithms in stdlib",
            "text": "Currently most of the features so far discussed are serial.\n\n\nShould we include parallel algorithms in stdlib?\n\n\nShould we use co-arrays or MPI?\n\n\nWhat would be some good initial parallel algorithms to start with?",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-02 17:46:57+00:00",
                    "text": "My own answers would be:\n\n\nGiven that Fortran has built-in support for parallelism via co-arrays, I would say that Fortran is intrinsically a parallel language. And in that case, I think it would be very beneficial if there is a set of algorithms that we all need and that would work with all or most production codes.\n\n\nI would say co-arrays would be natural, since those are built-in, unlike MPI.\n\n\nThe most useful (for me) would be dense and sparse linear algebra, and also parallel FFT. But the issue is that we would probably have to depend on a 3rd party library (scalapack, PSBLAS, parallel FFT libraries ...), and it's unclear if we can easily figure out an API so that we can have different backends. So perhaps as a first step, if there was some simpler set of parallel algorithms that are widely useful, we should start with those. Alternatively, we can try to bite the bullet and see if we can figure out an API, that all parallel FFT or parallel linear algebra libraries could be used as a backend. Just like there seems to be a \"natural\" modern Fortran API for linear algebra (#10), there might be a similar \"natural\" modern Fortran API for parallel linear algebra using co-arrays (#67)."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-02 18:54:04+00:00",
                    "text": "The book by Robert Numrich - Parallel programming with co-arrays contains some collective routines which would fit here. I don't have my copy nearby to be more specific, but I think it was reduction routines like min and max. Also some algorithms for dealing with graphs like the breadth first search."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 19:03:56+00:00",
                    "text": "FYI A bunch of parallel reduction routines are already part of the standard TS 18508. co_min co_max co_reduce etc. so they're all part of Fortran 2018 and supported in OpenCoarrays."
                }
            ]
        },
        {
            "number": 65,
            "user": "certik",
            "date": "2020-01-02 16:59:02+00:00",
            "title": "Split the loadtxt qp tests and skip them on Win",
            "text": "",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-02 17:02:06+00:00",
                    "text": "The print_array is duplicated a lot, but that will eventually be fixed by #40."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 18:21:48+00:00",
                    "text": "It seems that test_save.f90 has not been modified for qp.\n\nI think it is now. Let me know."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 19:01:59+00:00",
                    "text": "Thanks!"
                }
            ]
        },
        {
            "number": 64,
            "user": "certik",
            "date": "2020-01-02 16:19:06+00:00",
            "title": "CI: Test manual Makefiles",
            "text": "For now only on Linux and only with one compiler.",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 16:26:14+00:00",
                    "text": "@certik would you mind if I rebase this onto master and force-push to your branch? I changed the name of the workflow to CI.yml in #56"
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 16:38:49+00:00",
                    "text": "No, go ahead."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 16:44:42+00:00",
                    "text": "\ud83d\ude05 I figured it was probably OK, and used push --force-with-lease just incase... anyway, glad to see we're working through the PR backlog!"
                }
            ]
        },
        {
            "number": 63,
            "user": "certik",
            "date": "2020-01-02 16:13:16+00:00",
            "title": "Add stdlib_experimental_kinds.f90 and use it",
            "text": "This implements the latest discussion at #25.",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 17:09:40+00:00",
                    "text": "Looks like the Makefile needs updating."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 17:18:20+00:00",
                    "text": "@marshallward I think you were initially against having a kinds module, so I would like your feedback on this. This PR is based on the discussion in #25."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 17:33:42+00:00",
                    "text": "@marshallward I think you were initially against having a kinds module, so I would like your feedback on this. This PR is based on the discussion in #25.\n\nI think @jacobwilliams expressed some reservation in #13 too, but I might be reading between the lines too much."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 21:33:51+00:00",
                    "text": "I rebased on top of the latest master and resolved all conflicts."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 21:55:34+00:00",
                    "text": "I rebased again. The required Makefile changes are now minimal.\n@marshallward, @jacobwilliams just a reminder that this waits for you to review it, as you might have some objections to this."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-03 22:26:27+00:00",
                    "text": "@certik Sorry, missed this request back when I was still travelling, I will get caught up on this tonight and give my feedback."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-04 01:39:32+00:00",
                    "text": "I might revise my review and suggest that the 128 formats be dropped until they can be investigated robustly at build time (e.g. CMake)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 01:39:38+00:00",
                    "text": "I personally prefer to import the kinds from iso_fortran_env, but it seems most others preferred C. But now with the kinds module, this is easy to change.\n\nRegarding dp, sp and qp, it's not set in stone, we are still in experimental. I plan to do a thorough review of Fortran projects out there to get a better idea what the community uses.\n\nRegarding the quadruple precision, I think there is only one type: https://en.m.wikipedia.org/wiki/Quadruple-precision_floating-point_format\n\nBesides double precision there is also 80 bit. I think what you meant to say is that the C float128 might not always map to quadruple precision and might sometimes map to 80bit? If that's the case, then we should use the iso_fortran_env\n\u2026\nOn Fri, Jan 3, 2020, at 6:02 PM, Marshall Ward wrote:\n ***@***.**** commented on this pull request.\n\n In src/stdlib_experimental_kinds.f90\n <#63 (comment)>:\n\n > @@ -0,0 +1,10 @@\n +module stdlib_experimental_kinds\n +! Instead of iso_fortran_env, we use iso_c_binding, to be compatible\n with C\n +!use iso_fortran_env, only: sp=>real32, dp=>real64, qp=>real128\n +!use iso_fortran_env, only: int32, int64, int128\n +use iso_c_binding, only: sp=>c_float, dp=>c_double, qp=>c_float128\n +use iso_c_binding, only: int32=>c_int32_t, int64=>c_int64_t,\n int128=>c_int128_t\n Also, I think one does need to be careful with quad precision. On its\n own, it does not have a clear meaning. There are (at least) three\n active definitions:\n\n https://gcc.gnu.org/onlinedocs/gcc/Floating-Types.html\n\n For example, on my machine, `double` and `long double` both point to\n `_Float64`. My libc also defines a `_Float64x` which as best I can tell\n corresponds to the x86 float80 format.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#63?email_source=notifications&email_token=AAAFAWCIDSQYGNDYEKWYX6DQ37N27A5CNFSM4KCD6RGKYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCQVHR6I#discussion_r363005223>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWDMI7IENQKQ2KPX5GLQ37N27ANCNFSM4KCD6RGA>."
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 01:42:01+00:00",
                    "text": "Given that they currently work in master, I would suggest to keep quadruple precision, but create an issue with a todo list of things that we need to review and possibly change in experimental, before considering to move to main.\n\u2026\nOn Fri, Jan 3, 2020, at 6:39 PM, Marshall Ward wrote:\n I might revise my review and suggest that the 128 formats be dropped\n until they can be investigated robustly at build time (e.g. CMake).\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#63?email_source=notifications&email_token=AAAFAWFVGEEYB7NGCEPDNSLQ37SFLA5CNFSM4KCD6RGKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEICOHSI#issuecomment-570745801>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWCMCU7QK2VE3FFXDA3Q37SFLANCNFSM4KCD6RGA>."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-04 01:42:06+00:00",
                    "text": "@certik yes, that's a better way to put it.  There is a \"float128\", but it's often not what one gets when one requests a quad precision number.  (Maybe my brief experience on IBM Powers is showing?)\nI agree that iso_fortran_env might be safer in this case, assuming that the Fortran compiler does the heavy lifting here."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-04 01:49:09+00:00",
                    "text": "Also, given that this to be a reference library, are we sure about using c_int128_t and c_float128 when they are not defined in the standard?\nConditionally setting these inside a bit of GFortran preprocessing might be OK, though."
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 22:24:25+00:00",
                    "text": "@zbeekman, @scivision you were for using iso_c_binding here. Do you have any comments to @marshallward's review?\nI think iso_fortran_env is probably the safest. But if we can't get an agreement on this, then let's revisit this later.\nAs a compromise, we can stay with iso_fortran_env, as that's what's already in master.\n@marshallward would you be against introducing the stdlib_kinds module, even if we use iso_fortran_env inside?"
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-04 23:10:22+00:00",
                    "text": "I don't have any objection to a stdlib_kinds module, and pointing to iso_fortran_env is probably the better option, since it would presumably(?) resolve the platform-specific issues.  (It also helps that real128 is actually in the standard!)\nI apologize if it seemed like I was against the idea of providing such a module, I think it is very valuable!  I was only a bit resistant to the names (as usual), and the handling of quad types.\nIn the future I could see it being extended it to include kinds for more explicit types, such as float128, ibm128, and float80.\nThis situation could re-emerge with the many new architectures coming into the market and the newer formats like float16 and decimalN becoming more popular.  There may be value in providing kind IDs for these explicit data types."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 00:56:04+00:00",
                    "text": "@marshallward thanks for the clarification. So it seems we are all in agreement about having stdlib_kinds module. So I modified the PR to keep using iso_fortran_env as in master, but now it is in the module. Then let's create another PR or an issue where we can discuss if we want to change it to use iso_c_binding. I actually do not care at all about this, now when we have it at just one place in a stdlib_kinds module.\nRegarding the names of sp, dp, qp, this PR does not change anything either. I plan to do a wide survey soon of the open source Fortran codes and gather some data on this and we can revisit this in the future. Definitely before moving from experimental to main.\nAnyway, is anybody against merging this PR as is?"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-05 13:27:22+00:00",
                    "text": "I think it's fine to use iso_fortran_env and when/if issues arise with C interoperability, fix it then."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 16:35:28+00:00",
                    "text": "Ok then.  I am going to merge this, as we seem to be in agreement or not opposed to this latest version of the PR. Now we can easily change how the constants are defined in one module.\nAs for the naming, I created #85, so that we do not forget."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 18:15:38+00:00",
                    "text": "Yes, given the points raised, I think the best thing for now is to use iso_fortran_env thanks for the careful discussion and consideration everyone, especially @marshallward!"
                }
            ]
        },
        {
            "number": 62,
            "user": "nshaffer",
            "date": "2020-01-02 08:38:39+00:00",
            "title": "Facilitate default values of optional arguments",
            "text": "An annoyance with optional arguments is handling their default values. This usually looks something like:\nfunction mylog(x, base) result(y)\n    real, intent(in) :: x\n    real, intent(in), optional :: base\n    real :: y\n\n    real :: base_\n    \n    base_ = 10.0\n    if (present(base)) base_ = base\n    \n    y = log(x)/log(base_)\nend function mylog\n\nI propose to introduce a module that exports a generic function default which will in many cases allow for the elimination of the local copy of the optional argument. The above example could be rewritten\nfunction mylog(x, base) result(y)\n    use default_values, only: default\n    real, intent(in) :: x\n    real, intent(in), optional :: base\n    real :: y\n    \n    y = log(x)/log(default(10.0, base))\nend function mylog\n\nThis is a convenience, but it's incredibly handy. The module is very simple to write. See, e.g., this CLF post by Beliavsky, where I first learned of this trick. I put this in all my serious codes, as it removes a lot of the tedium and error potential with optional arguments.\nI can easily spin up a illustrative PR that can be fleshed out once we've decided how we're going to automate generic interfaces.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-02 13:36:19+00:00",
                    "text": "I like this a lot. I would flip the order of arguments:\n\ndefault(base, 10.0)\n\nSort of like Python's dictionary method get. Regarding the name, here are a few options:\n\n* default\n* argget\n* optarg\n* arg_default\n* opt_default\n* default_arg\n* optval\n* optget\n\nEdit: I'll just keep editing this comment to add all the options that we are discussing below."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-02 14:17:14+00:00",
                    "text": "I do like this, but the more frustrating issue for me is that I often need to define two variables in the same scope with identical purpose, in this case base_ and base.\nThis function would let you replace base_ with default(base, 10.0), and is very effective if base_ only appears once or twice.  But if you have to do this many times then it may not actually be what you want.\nI feel constrained because the optional input is the one which becomes part of the API, and therefore should be the most readable.  But it is often the internal variable which will appear the most throughout the function, which can make the function less readable.\nBut this is still an improvement for lots of cases.  I agree with @certik that default is too general of a name to use here.  (I should read more carefully...)"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-02 14:31:02+00:00",
                    "text": "The semantics of optional arguments make the \"natural\" order a little tricky. If we want the fallback value to come second, callers will have to explicitly make it a keyword arg. That is, consider the two implementations:\ndefault_first(to, x) result(y)\n    ! Return first arg if second is not present\n    !     default(1, 2) == 2\n    !     default(1) == 1 (\"x\" not present, so we get the fallback value)\n    integer, intent(in) :: to ! the fallback value\n    integer, intent(in), optional :: x\n    integer :: y\n\n    if (present(x)) then\n        y = x\n    else\n        y = to\n    end if\nend function default_first\n\nversus what is arguably the more natural ordering\ndefault_second(x, to) result(y)\n    ! Return second arg if first is not present\n    !     default(1, 2) == 1\n    !     default(2) (ERROR b/c nothing gets bound to \"to\", which is non-optional)\n    !     default(to=2) == 2 (no error b/c we've explicitly set \"to\")\n    integer, intent(in) :: to ! the fallback value\n    integer, intent(in), optional :: x\n    integer :: y\n\n    if (present(x)) then\n        y = x\n    else\n        y = to\n    end if\nend function default_second\n\nSo in practice, one would have to write expressions like default(x, to=6.0) in order to make the more natural ordering work. Omitting \"to=\" would be a compile-time error. It's a few more characters to do it this way, but it does read nicely. If we don't mind imposing mandatory keyword args on users, I'm happy doing it this way."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-02 14:34:04+00:00",
                    "text": "This is a nice option for simple cases.\nHowever, I am afraid a local variable would be needed for many cases if the optional variable is used many times, or if there are many optional variables. These would lead to several\nsubroutine sub1(var, var1, var2, var3)\n    ...., intent(in), optional::var1\n    ...., intent(in), optional::var2\n    ...., intent(in), optional::var3\n    .... default(var1, 0.10) ....\n    ... default(var2, .true.) ....\n    ...default(var3, 100)....\n    ...\n\nFor such cases, I would clearly prefer to use local variables. But it would be a nice addition in stdlib.\n\nI can easily spin up a illustrative PR that can be fleshed out once we've decided how we're going to automate generic interfaces.\n\nIt seems that a solution for #35 must be found to go forward in many issues."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-02 15:18:07+00:00",
                    "text": "I like it! Convenience with no apparent downsides. +1 for name default. I can't think of others."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-02 15:22:19+00:00",
                    "text": "Sorry, I misread the very post that I cited in my comment.  But I don't think default should be used here.  There are lots of uses for that name outside of variable defaults."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 15:37:10+00:00",
                    "text": "The ultimate fix would be to change the language: j3-fortran/fortran_proposals#22\nIn the meantime, I think this is a great idea for stdlib to at least make it a little bit easier.\n@marshallward regarding a name: yes, I also think it's too general, but from the alternatives that I listed, I like it the most. Do you have some other ideas for a name? Maybe default_arg? Or just optarg.\n@nshaffer right. Couldn't using overloaded subroutines somehow make this work?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 15:43:55+00:00",
                    "text": "@nshaffer this compiles for me with gfortran, but I don't know if it actually works:\nmodule stdlib_default\nimplicit none\n\ninterface default_second\n    module procedure default_second_1\n    module procedure default_second_2\nend interface\n\ncontains\n\n    function default_first(to, x) result(y)\n    ! Return first arg if second is not present\n    !     default(1, 2) == 2\n    !     default(1) == 1 (\"x\" not present, so we get the fallback value)\n    real, intent(in) :: to ! the fallback value\n    real, intent(in), optional :: x\n    real :: y\n\n    if (present(x)) then\n        y = x\n    else\n        y = to\n    end if\n    end function default_first\n\n    function default_second_1(to) result(y)\n    real, intent(in) :: to\n    real :: y\n    y = to\n    end function\n\n    function default_second_2(x, to) result(y)\n    real, intent(in) :: x\n    real, intent(in) :: to\n    real :: y\n    y = x\n    end function\n\nend module\n\nprogram A\nuse stdlib_default, only: default_first, default_second\nimplicit none\n\ncontains\n\n    function mylog(x, base) result(y)\n    real, intent(in) :: x\n    real, intent(in), optional :: base\n    real :: y\n\n    !y = log(x)/log(default_first(10.0, base))\n    y = log(x)/log(default_second(base, 10.0))\n    end function mylog\n\nend\nEdit: it probably does not work, because it will always call the default_second_2 version, even if base is not present.\nEdit 2: but this compiles:\nprogram A\nimplicit none\n\nprint *, mylog(16.)\nprint *, mylog(16., 2.)\n\ncontains\n\n    function default_second(x, to) result(y)\n    real, intent(in), optional :: x\n    real, intent(in) :: to\n    real :: y\n    if (present(x)) then\n        y = x\n    else\n        y = to\n    end if\n    end function\n\n    function mylog(x, base) result(y)\n    real, intent(in) :: x\n    real, intent(in), optional :: base\n    real :: y\n    y = log(x)/log(default_second(base, 10.0))\n    end function mylog\n\nend\nand prints:\n   1.20411992    \n   4.00000000    \n\nI think it works!"
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-02 16:21:03+00:00",
                    "text": "@marshallward regarding a name: yes, I also think it's too general, but from the alternatives that I listed, I like it the most. Do you have some other ideas for a name?\n\nSomething that refers to the optional keyword seems like the correct thing here.  opt_default captures the behavior, but it is a bit long.\nI'm leaning towards optval or something similar but it's not as elegant as default.  (optget also feels good to me, but it's perhaps a bit too close to C's getopt.)\nI generally feel uncertain about grabbing common keywords like this, which may be prevalent in existing codes or could become part of the language standard in the future.\nI'll think on it and post if anything else comes to mind.  I guess for now this is just a point of caution :)."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 16:35:14+00:00",
                    "text": "I like optval."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-03 16:16:19+00:00",
                    "text": "Edit 2: but this compiles:\nprogram A\nimplicit none\n\nprint *, mylog(16.)\nprint *, mylog(16., 2.)\n\ncontains\n\n    function default_second(x, to) result(y)\n    real, intent(in), optional :: x\n    real, intent(in) :: to\n    real :: y\n    if (present(x)) then\n        y = x\n    else\n        y = to\n    end if\n    end function\n\n    function mylog(x, base) result(y)\n    real, intent(in) :: x\n    real, intent(in), optional :: base\n    real :: y\n    y = log(x)/log(default_second(base, 10.0))\n    end function mylog\n\nend\nand prints:\n   1.20411992    \n   4.00000000    \n\nI think it works!\n\nOh, great! Yes, I see. In practice you will never actually call default_second with only one argument, so the dummy arguments will never get bound incorrectly. I will implement it this way.\nAs for naming, I have a strong preference for default because it matches so well with naming the fallback argument to. I think this outweighs the (negligible) downside of clashing with someone else's variable name or whatever. I think we have to demand that users take some minimal responsibility for being aware of the names they're importing with modules. I'm not going to die on this hill, though. We can hash it out in the PR discussion. Will try to submit today."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-03 16:45:38+00:00",
                    "text": "I'm less concerned about the ability of users to adapt than I am about preserving their right to use commonplace words for their own work.  (Users can always rename external functions, but I don't think that's something we ought to encourage.)  I also think it's perhaps too general to use default for the specific issue of function argument defaults.  And as mentioned before, I could also see this becoming a keyword in a future iteration of the language standard.\nBut I agree that default feels more elegant.  And if no one else is concerned about the objections that I've raised then I won't raise them again."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 21:25:27+00:00",
                    "text": "@milancurcic, @jvdp1, @zbeekman, @ivan-pi, @jacobwilliams what would be your preference for naming this? The top two contenders are default and probably optval."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-03 21:30:16+00:00",
                    "text": "what would be your preference for naming this? The top two contenders are default and probably optval.\n\nAmong the two options, I prefer optval. Users can always rename it to default if they prefer this name.\nFollowing @certik 's comment, opt_default has my highest preference, because it is more explicit than optval. But it is a bit long."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 21:31:58+00:00",
                    "text": "(@jvdp1 the rest of the options are listed at #62 (comment), if you like any of them better.)"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-03 21:36:35+00:00",
                    "text": "Of the options above I find optval the most meaningful. The name default is too general and does not confer well the meaning of the function - to process an optional value."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 23:01:22+00:00",
                    "text": "Note: if j3-fortran/fortran_proposals#22 gets accepted, then this:\n    function mylog(x, base) result(y)\n    real, intent(in) :: x\n    real, intent(in), optional :: base\n    real :: y\n    y = log(x)/log(optval(base, 10.0))\n    end function mylog\nbecomes just\n    function mylog(x, base) result(y)\n    real, intent(in) :: x\n    real, intent(in), optional, default :: base = 10\n    real :: y\n    y = log(x)/log(base)\n    end function mylog\nEverybody: if you like the language proposal, make sure you add +1 to it."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-06 17:55:30+00:00",
                    "text": "I too like opt_default better but am sufficiently happy with optval."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-06 18:20:32+00:00",
                    "text": "Hopefully I won't be shot for saying this, but I think that I also prefer opt_default."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-06 18:23:09+00:00",
                    "text": "Sorry I missed this. I like default best, optval second, and opt_default last."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 18:49:52+00:00",
                    "text": "It's in experimental, so we can rename it if we want to.\nIf we all sort all available names based on how we like them, I think there is a \"voting system\" that allows to select candidates that \"most people are ok with\". If I am just judging from the above, it seems nobody is very strongly against optval. It seems some people like default while others are opposed. The same with opt_default. I prefer optval over opt_default also."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-06 20:29:28+00:00",
                    "text": "The name should be as short as possible without being cryptic. This is because in practice, the function will often be called as part of a larger expression, e.g., the mylog examples upthread. The longer the function name, the more it obscures the expression it appears in."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 20:40:35+00:00",
                    "text": "Another idea is defval. Or shorter versions: dval, oval, darg, oarg, or even shorter: dv, ov, da, oa."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-06 21:32:04+00:00",
                    "text": "defval is problematic because def may mean \"define\" for many people, like me. optval is my favorite of any short names."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 22:28:50+00:00",
                    "text": "I agree, just few days ago I was thinking the same thing, that defval feels like define value."
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-02 06:48:49+00:00",
                    "text": "I started to look into the source code. Would be advisable to put into a single preprocessed format?\nIt is straigthforward, and a simple rewriting seems to work well. Additionally we already can add complex numbers (I don't know enough to add an implementation for ucs chars)"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-02-02 07:22:36+00:00",
                    "text": "@fiolj I submitted the PR before we'd come to any consensus about preprocessing. If you want to refactor it to use fypp templating, go for it. Same goes for adding complex cases (just be sure to add corresponding tests). I wouldn't bother with UCS yet."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-02 07:59:12+00:00",
                    "text": "@fiolj I think it is a good idea to use a preprocessed format for optval. I suggest that you submit a PR.\nRegarding complex numbers, I would suggest to add them to all modules (i.e. also in stdlib_experimental_stats and in stdlib_experimenal_io). S the whole library will support complex numbers. Would it be possible? I can help if needed. If a PR is open about complex,  I think it should be in a different PR than the one about optval."
                }
            ]
        },
        {
            "number": 61,
            "user": "certik",
            "date": "2019-12-31 23:34:03+00:00",
            "title": "Add Windows CI",
            "text": "I am trying to troubleshoot #58.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-31 23:49:54+00:00",
                    "text": "Here is the failure:\n2/3 Testing: load_text\n2/3 Test: load_text\nCommand: \"D:/a/stdlib/stdlib/build/src/tests/loadtxt/test_loadtxt.exe\" \"D:/a/stdlib/stdlib/build/src/tests/loadtxt\"\nDirectory: D:/a/stdlib/stdlib/src/tests/loadtxt\n\"load_text\" start time: Dec 31 23:46 Coordinated Universal Time\nOutput:\n----------------------------------------------------------\n Array, shape=(           4 ,           2 )\n   1.00000000       2.00000000    \n   3.00000000       4.00000000    \n   5.00000000       6.00000000    \n   7.00000000       8.00000000    \n Array, shape=(           4 ,           2 )\n   1.0000000000000000        2.0000000000000000     \n   3.0000000000000000        4.0000000000000000     \n   5.0000000000000000        6.0000000000000000     \n   7.0000000000000000        8.0000000000000000     \n Array, shape=(           4 ,           3 )\n   1.0000000000000000        2.0000000000000000        9.0000000000000000     \n   3.0000000000000000        4.0000000000000000        10.000000000000000     \n   5.0000000000000000        6.0000000000000000        11.000000000000000     \n   7.0000000000000000        8.0000000000000000        12.000000000000000     \n Array, shape=(          16 ,           2 )\n   1.0000000000000000E-008   91.999987593924899     \n   1.0241132548855634E-008   91.999987314749688     \n   1.0482337218958209E-008   91.999987035877282     \n   1.0723614031878819E-008   91.999986757297677     \n   1.0964963009194818E-008   91.999986479001350     \n   1.1206384172490366E-008   91.999986200979166     \n   1.1447877543355709E-008   91.999985923222511     \n   1.1689443143387538E-008   91.999985645723044     \n   1.1931080994189523E-008   91.999985368472906     \n   1.2172791117370886E-008   91.999985091464495     \n   1.2414573534548370E-008   91.999984814690578     \n   1.2656428267344438E-008   91.999984538144247     \n   1.2898355337388186E-008   91.999984261818796     \n   1.3140354766315149E-008   91.999983985707871     \n   1.3382426575767665E-008   91.999983709805363     \n   1.3624570787394342E-008   91.999983434105332     \n Array, shape=(           3 ,          10 )\n   1.5636717312299885E-010   4.5156817177622978E-007   4.9656862178073029E-006   5.0106866678118064E-005   5.0151867128122533E-004   5.0176362928751987E-003   5.5848764877645951E-002  0.32618374746711520        1.7639051761733842        9.4101331514118236     \n   8.2348196112966627E-010   4.5823931965629650E-007   5.0323976966079676E-006   5.0773981466124731E-005   5.0818981916129179E-004   5.0928786314535686E-003   5.6248925898183838E-002  0.32831192218075922        1.7752234390209392        9.4703270222745211     \n   2.0220116378489263E-009   4.7022461642348905E-007   5.1522506642798948E-006   5.1972511142843962E-005   5.2017511592848458E-004   5.2280580298917183E-003   5.6967849938248938E-002  0.33213537295325257        1.7955576815764616        9.5784705410250410     \n\nProgram received signal SIGSEGV: Segmentation fault - invalid memory reference.\n\nBacktrace for this error:\n#0  0xffffffff\n#1  0xffffffff\n#2  0xffffffff\n#3  0xffffffff\n#4  0xffffffff\n#5  0xffffffff\n#6  0xffffffff\n#7  0xffffffff\n<end of output>\nTest time =   0.02 sec\n----------------------------------------------------------\nTest Failed.\n\"load_text\" end time: Dec 31 23:46 Coordinated Universal Time\n\"load_text\" time elapsed: 00:00:00\n----------------------------------------------------------\n\nThat's weird, it looks like some compiler bug."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 16:27:30+00:00",
                    "text": "@scivision now all the tests pass! I disabled qp for now."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 16:32:06+00:00",
                    "text": "Given that the quadruple precision is buggy on Windows, probably the best way forward is to split the tests into a single/double file, and a quadruple file. The quadruple file test would be skipped on Windows."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 16:33:35+00:00",
                    "text": "@zbeekman do you want to merge this first, so that you can work on consolidating the CI into one file? And I can work on getting quadruple working again at least on Linux and macOS?"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 16:35:12+00:00",
                    "text": "@zbeekman do you want to merge this first, so that you can work on consolidating the CI into one file?\n\nSure that sounds good! Mind if I also rebase and merge #64?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 16:40:58+00:00",
                    "text": "No, that's why we should all allow \"edits by maintainers\" in our PRs.\nYes, if you can figure out how to consolidate the Windows test into the same matrix, I think this would be the best."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 16:41:28+00:00",
                    "text": "@zbeekman go ahead and merge this when you are ready."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 16:42:24+00:00",
                    "text": "No, that's why we should all allow \"edits by maintainers\" in our PRs.\n\nI think we're mis-communicating again, sorry, probably my fault. I'll merge this now."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 16:46:45+00:00",
                    "text": "(My \"No\" meant \"No, I don't mind\", as a reply to yours \"Mind if I also rebase and merge #64?\".)"
                }
            ]
        },
        {
            "number": 60,
            "user": "certik",
            "date": "2019-12-31 22:52:44+00:00",
            "title": "Use 4 spaces",
            "text": "",
            "comments": [
                {
                    "user": "certik",
                    "date": "2020-01-01 03:25:50+00:00",
                    "text": "Thanks for the review @zbeekman."
                }
            ]
        },
        {
            "number": 59,
            "user": "zbeekman",
            "date": "2019-12-31 18:44:42+00:00",
            "title": "Governance",
            "text": "Governance\nI feel that it is important to have some sort of formal governance. This should be in place in advance of when conflict arises, which is when you actually need it. While this issue is related to #5 (workflow), it is, in my opinion, distinct.\nA case study\nI was invited to be a Mac Homebrew maintainer in July 2018 right before a period of drawn out conflict mostly between a very active maintainer and the projects \"Lead Maintainer\". In addition, this conflict was born out of a technical issue with vocal users and contributors fanning the flames. If the organization had a more formal governance model then:\n\nThe decision making process for technical decisions would have some basis in a pre-established framework and therefore appear less arbitrary and personal\nA formal procedure would have been in place for resolving both technical and personal conflicts\n\nWithin 6 months the organization had its first ever in-person meeting, which I had the pleasure of attending, and ratified more formal bylaws. Since then I have never seen the same level of conflict between maintainers, or between users/contributors and maintainers (or the project itself).\nIssues to be addressed in bylaws or less formal governance\nAn imperfect list of the questions that need to be answered follows.\n\nHow are controversial decisions made? Who gets the final say?\nShould there be a technical steering committee? Or a project leader? Or both\nWhat sort of decisions should be put to a vote among some sort of membership?\nHow are differing levels of responsibility defined?\nWhat is the fortran-lang's formal or informal relationship to J3/WG5?\nHow can we setup an infrastructure and process to ensure the continued health and enthusiasm about this project as it (hopefully) grows?\nHow can we divide responsibilities amongst maintainers and contributors to ensure that important decisions don't get made under the radar, while ensuring that there is little to no unnecessary duplication of effort and reduce/prevent bikeshedding.\n\nCaveats\nOf course this is a very new & young project, and as such adopting formal bylaws is probably overkill. It's certainly not fun, and too much bureaucracy can certainly be harmful. But, giving people a framework for how decisions are made and finalized---especially controversial ones---makes the outcome easier to understand and tolerate when it isn't in your favor, and having a process to deal with controversial decisions and conflict is very nice to have BEFORE you need to use & apply it.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-31 19:21:16+00:00",
                    "text": "Currently until we build a community, the very last decision will be made by Milan and I. We promise to do our best to never actually need to use that power, and instead provide the platform and moderate the discussion so that all big decisions are made by community consensus.\n\nWe do not need other bureaucracy right now.\n\u2026\nOn Tue, Dec 31, 2019, at 11:44 AM, zbeekman wrote:\n Governance\n\n I feel that it is important to have some sort of formal governance.\n This should be in place in *advance* of when conflict arises, which is\n when you actually need it. While this issue is related to #5\n <#5> (workflow), it is, in\n my opinion, distinct.\n\n A case study\n\n I was invited to be a Mac Homebrew\n <https://github.com/homebrew/brew#who-are-you> maintainer in July 2018\n right before a period of drawn out conflict mostly between a very\n active maintainer and the projects \"Lead Maintainer\". In addition, this\n conflict was born out of a technical issue with vocal users and\n contributors fanning the flames. If the organization had a more formal\n governance model then:\n\n  1. The decision making process for technical decisions would have some\n basis in a pre-established framework and therefore appear less\n arbitrary and personal\n  2. A formal procedure would have been in place for resolving both\n technical and personal conflicts\n Within 6 months the organization had its first ever in-person meeting\n <https://brew.sh/2019/06/14/homebrew-maintainer-meeting/>, which I had\n the pleasure of attending, and ratified more formal bylaws\n <https://docs.brew.sh/Homebrew-Governance>. Since then I have never\n seen the same level of conflict between maintainers, or between\n users/contributors and maintainers (or the project itself).\n\n Issues to be addressed in bylaws or less formal governance\n\n An imperfect list of the questions that need to be answered follows.\n\n  1. How are controversial decisions made? Who gets the final say?\n  2. Should there be a technical steering committee? Or a project\n leader? Or both\n  3. What sort of decisions should be put to a vote among some sort of\n membership?\n  4. How are differing levels of responsibility defined?\n  5. What is the fortran-lang's formal or informal relationship to\n J3/WG5?\n  6. How can we setup an infrastructure and process to ensure the\n continued health and enthusiasm about this project as it (hopefully)\n grows?\n  7. How can we divide responsibilities amongst maintainers and\n contributors to ensure that important decisions don't get made under\n the radar, while ensuring that there is little to no unnecessary\n duplication of effort and reduce/prevent bikeshedding\n <https://en.wikipedia.org/wiki/Law_of_triviality>.\n Caveats\n\n Of course this is a very new & young project, and as such adopting\n formal bylaws is probably overkill. It's certainly not fun, and too\n much bureaucracy can certainly be harmful. But, giving people a\n framework for how decisions are made and finalized---especially\n controversial ones---makes the outcome easier to understand and\n tolerate when it isn't in your favor, and having a process to deal with\n controversial decisions and conflict is *very* nice to have *BEFORE*\n you need to use & apply it.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#59?email_source=notifications&email_token=AAAFAWDJFGPWGEZ27UVOVXTQ3OHJXA5CNFSM4KBXKMIKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IDQSKXA>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWDRB23YY2RPMTZS7MLQ3OHJXANCNFSM4KBXKMIA>."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 19:36:43+00:00",
                    "text": "Currently until we build a community, the very last decision will be made by Milan and I.\n\nGreat to know! At the very least letting people know this is helpful. Thanks!"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-01 00:34:47+00:00",
                    "text": "After considering this further and a high bandwidth discussion with Ondrej, I think it makes sense to table this discussion for a while until we\u2019ve gained a bit more momentum. I\u2019ll leave it open as a reminder, but won\u2019t be hurt if others feel it is a distraction and want to close it."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 20:37:17+00:00",
                    "text": "For now I think our current arrangement is good enough to allow us to both deliver and build a community and once our community grows and we build trust to each other, we can figure out more a formal structure later. For example I would like more serious approvals once we start moving things from \"experimental\" to \"main\", hopefully involving the J3 committee at some (perhaps informal) level. Right now we are in the \"experimental\" phase, and there our less formal arrangement should allow us to deliver. And if there are any disagreements, we can do a conference phone call, or even meet later on at some conference, and I am positive we can resolve any such differences."
                }
            ]
        },
        {
            "number": 58,
            "user": "scivision",
            "date": "2019-12-31 17:12:39+00:00",
            "title": "ci: add windows workflow",
            "text": "It can be advantageous to have distinct workflows on a per-operating system basis,\nto quickly see the scope of a failure.\nThis CI will fail until the quad-precision code is made conditional on a build system test (CMake >= 3.14 check_fortran_source_runs()) to make quad-precision optional in library and tests.\nIn the library, this can be done via Fortran submodule. In the test, it can be done via preprocessor #ifdef usereal128 or similar introduced via CMake as a result of configure checks",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-31 17:14:37+00:00",
                    "text": "Thanks! You can upgrade cmake, or do whatever needs to be done to make all tests pass."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 23:51:22+00:00",
                    "text": "I am trying to trouble shoot this in #61. Is this a compiler bug?"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-01 02:37:10+00:00",
                    "text": "I think it is a compiler bug it's not uncommon to find such things with rarer configurations like quad precision."
                },
                {
                    "user": "certik",
                    "date": "2020-01-01 03:24:33+00:00",
                    "text": "I see. Why don't we disable quad precision for now. I think having Windows tests is essential (more important than quad precision). Then we can re-enable quad precision in future PRs on platforms where it works."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 16:47:51+00:00",
                    "text": "This was merged as part of #61. Thanks @scivision!"
                }
            ]
        },
        {
            "number": 57,
            "user": "certik",
            "date": "2019-12-31 17:09:31+00:00",
            "title": "Let's use 4 spaces instead of 2",
            "text": "I think most people agreed to use 4 spaces instead of just 2.",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 17:40:00+00:00",
                    "text": "@certik you need to change .editorconfig too!\nI list the reasons why I changed it back to 2 below, but if you want 4 that's fine by me.\nEDIT: A bunch more people have weighed in on this thread so the results listed below are essentially moot, it looks like we're going with 4 spaces. \ud83c\udf89\nPreferences (from #3):\n\n@zbeekman: 2\n@milancurcic 2\n@jvdp1 1 or 2\n@longb don't care\n@gronki don't care\n@certik 4\n@ivan-pi 4\n@marshallward 4\n\n3 preferences for 2 spaces and 3 for 4 spaces.\nSo, as you can see there is effectively a tie.\nFurther considerations from #3\nMy further understanding from #3 was that a consensus was reached by the majority that:\n\nmodule, submodule and program units should be indented\nprocedure, type and interface bodies should be indented\nusual control constructs should be indented\nshould strive to stay within 80 chars, with a hard limit of 132\n\nGiven the concerns about line length when indenting procedure bodies etc. and the effective tie in preference for 2 vs 4 combined that 2 is the default for findent I thought it prudent to switch to 2. However, I may have misinterpreted or overstated the consensus reached on the other bullet points above.\nWe should pick a convention and finalize this decision so people can sink their teeth into writing some code.\nSetting up editorconfig for per-project style/indentation\nAlso, a note for @certik and other vim users: If you install the vim editorconfig plugin you won't have to mess with your global preferences. It will/should use the indentation specified in  .editorconfig when working on files for stdlib, and then your default when not. Many/most editors respect .editorconfig out of the box, and plugins for others, like Emacs are easily installed."
                },
                {
                    "user": "gronki",
                    "date": "2019-12-31 17:42:18+00:00",
                    "text": "Ugh.\n\nwt., 31 gru 2019, 18:40 u\u017cytkownik zbeekman <notifications@github.com>\nnapisa\u0142:\n\u2026\n ***@***.**** requested changes on this pull request.\n\n If you want to make this change, please edit .editorconfig\n <https://github.com/fortran-lang/stdlib/blob/master/.editorconfig> too\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#57?email_source=notifications&email_token=AC4NA3PANOA6BIQMKMMYMV3Q3N72TA5CNFSM4KBW3DS2YY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCQOKICQ#pullrequestreview-337421322>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AC4NA3OPG3PVAO3COUCYEWLQ3N72TANCNFSM4KBW3DSQ>\n ."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 17:45:11+00:00",
                    "text": "The survey is too small and not representative. Can you please list here the number of spaces used by the top 30 or more projects listed at:\n\nhttps://github.com/fortran-lang/stdlib/wiki/List-of-popular-open-source-Fortran-projects\n\n? That would be a lot more representative what the community at large uses.\n\u2026\nOn Tue, Dec 31, 2019, at 10:40 AM, zbeekman wrote:\n @certik <https://github.com/certik> you need to change `.editorconfig`\n <https://github.com/fortran-lang/stdlib/blob/master/.editorconfig> too!\n\n I list the reasons why I changed it back to 2 below, but if you want 4\n that's fine by me.\n\n Preferences (from #3 <#3>):\n\n  * @zbeekman <https://github.com/zbeekman>: 2\n  * @milancurcic <https://github.com/milancurcic> 2\n  * @jvdp1 <https://github.com/jvdp1> 1 or 2\n  * @longb <https://github.com/longb> don't care\n  * @gronki <https://github.com/gronki> don't care\n  * @certik <https://github.com/certik> 4\n  * @ivan-pi <https://github.com/ivan-pi> 4\n  * @marshallward <https://github.com/marshallward> 4\n *3* preferences for 2 spaces and *3* for 4 spaces.\n  So, as you can see there is effectively a tie.\n\n Further considerations from #3 <#3>\n\n My further understanding from #3\n <#3> was that a consensus\n was reached by the majority that:\n\n  * module, submodule and program units should be indented\n  * procedure, type and interface bodies should be indented\n  * usual control constructs should be indented\n  * should strive to stay within 80 chars, with a hard limit of 132\n Given the concerns about line length when indenting procedure bodies\n etc. and the effective tie in preference for 2 vs 4 combined that 2 is\n the default for `findent` I thought it prudent to switch to 2. However,\n I may have misinterpreted or overstated the consensus reached on the\n other bullet points above.\n\n We should pick a convention and finalize this decision so people can\n sink their teeth into writing some code.\n\n Setting up editorconfig for per-project style/indentation\n\n Also, a note for @certik <https://github.com/certik> and other vim\n users: If you install the vim editorconfig plugin\n <https://github.com/editorconfig/editorconfig-vim#readme> you won't\n have to mess with your global preferences. It will/should use the\n indentation specified in `.editorconfig`\n <https://github.com/fortran-lang/stdlib/blob/master/.editorconfig> when\n working on files for stdlib, and then your default when not. Many/most\n editors respect `.editorconfig` out of the box\n <https://editorconfig.org/#download>, and plugins for others, like\n Emacs <https://github.com/editorconfig/editorconfig-emacs#readme> are\n easily installed.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#57?email_source=notifications&email_token=AAAFAWDJANWVAHVFXIK6NZ3Q3N7XFA5CNFSM4KBW3DS2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEH4PPDA#issuecomment-569964428>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWCNHI2LFRRM7FSLDCTQ3N7XFANCNFSM4KBW3DSQ>."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-31 17:52:24+00:00",
                    "text": "Considering the development here, I change my preference to \"don't care\". :)\nI'd also approve of allowing both 2 and 4 spaces, not mixed together within a source file."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2019-12-31 17:52:42+00:00",
                    "text": "I vote for 4 spaces! :)"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 17:55:16+00:00",
                    "text": "I was only responding to your comment at the top of the PR and providing a rationale and evidence in support of my past decision:\n\nI think most people agreed to use 4 spaces instead of just 2.\n\nI'm fine with either. Listing the number of spaces used by the top Fortran projects is not a good use of my time.\nThe biggest one, OpenBLAS, appears to use 3 spaces FWIW.\nA final note before I completely abstain from further comment on indentation: Just because a library is big and popular doesn't mean we want to do what they did; tradition for tradition's sake alone isn't a compelling reason to do something! (If it were we'd all be writing F77 still.)\nAh, thank goodness, @jacobwilliams broke the tie!!! Haha. Yes, please god let us use 4 spaces, just make sure that .editorconfig is updated too."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-31 18:03:25+00:00",
                    "text": "Ugh.\n\n@gronki Please, please if you don't have anything constructive to add to the thread, just don't post. This is a good example of the kind of communication that isn't helpful. Please read Code of Conduct if you haven't yet."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-31 18:14:16+00:00",
                    "text": "Let's change my preference from 1 or 2 to don't care. I can easily adapt Vim."
                },
                {
                    "user": "septcolor",
                    "date": "2019-12-31 18:27:04+00:00",
                    "text": "Just FWIW, here are some indentation used by the standard libraries of some other languages (which I think may be more or less related to numerical computing).\n4 spaces:\n\nJulia\nhttps://github.com/JuliaLang/julia/blob/master/base/array.jl\nRust\nhttps://github.com/rust-lang/rust/blob/master/src/libcore/array/iter.rs\nD\nhttps://github.com/dlang/phobos/blob/master/std/array.d\nPython\n(I haven't checked this but probably)\n\n2 spaces:\n\nScala\nhttps://github.com/scala/scala/blob/v2.13.1/src/library/scala/math/Numeric.scala\nChapel\nhttps://github.com/chapel-lang/chapel/blob/master/modules/standard/Math.chpl\nNim\nhttps://github.com/nim-lang/Nim/blob/devel/lib/system.nim\n\n(I haven't checked other languages like JS, C#, Java, etc). So the choice seems to vary. I personally use 4 spaces for distinguishing block structures more clearly, but also feel that codes with 2 spaces are more compact. (I used 3 spaces for Fortran77, which was the default of Emacs at that time...)"
                },
                {
                    "user": "gronki",
                    "date": "2019-12-31 18:52:28+00:00",
                    "text": "Ugh.\n\n@gronki Please, please if you don't have anything constructive to add to the thread, just don't post. This is a good example of the kind of communication that isn't helpful. Please read Code of Conduct if you haven't yet.\n\nI know the Code of Conduct, what I basically meant is that it doesn't matter in my opinion considering the amount of decisions that have to be made that do matter. If you find my comments not constructive I think it's time from my side to move away to where I can actually help."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 18:58:01+00:00",
                    "text": "I'll open a PR to change back to 4 spaces, and fix .editorconfig to reflect this while I'm at it."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-31 18:59:30+00:00",
                    "text": "I know the Code of Conduct, what I basically meant is that it doesn't matter in my opinion considering the amount of decisions that have to be made that do matter. If you find my comments not constructive I think it's time from my side to move away to where I can actually help.\n\nThanks. I was addressing this specific comment and not your other posts, many of them helpful. Clean and constructive communication is important."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 19:08:25+00:00",
                    "text": "I am away from my computer. Please close this PR I am retracting it. Let's spend our time constructively.\n\nLet's submit a PR removing the requirement for 2 spaces. Or change it to 2 or 4 spaces.\n\nLet's not lose any more time with this.\n\nWe have bigger fish to fry.\n\u2026\nOn Tue, Dec 31, 2019, at 11:59 AM, Milan Curcic wrote:\n Thanks. I was addressing this specific comment and not your other\n posts, many of them helpful. Clean and constructive communication is\n important.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#57?email_source=notifications&email_token=AAAFAWHNLNJTDQEJIE7UGMTQ3OJBFA5CNFSM4KBW3DS2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEH4SBEQ#issuecomment-569974930>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWF4YCNLT3VBHI5CSULQ3OJBFANCNFSM4KBW3DSQ>."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 19:39:54+00:00",
                    "text": "Honestly I think everyone is fine with 4 at this point. I'll change the text to 2 or 4 if you prefer, but I'd rather pick one (4) that can be automated in hooks and checked in PRs."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-31 21:04:27+00:00",
                    "text": "normally I prefer 2 spaces for Fortran projects, where the procedures are often longer than ideal. Since this is a fresh project, there may be more consciousness of procedure cyclomatic complexity. Thus 4 spaces would be less likely to result in excessive indentation->too much line continuation."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 22:16:30+00:00",
                    "text": "@zbeekman and I talked about this on the phone. We can either choose now, or postpone this decision for later. We both prefer to decide now, because that allows us to setup automatic formatting at the CI, and move on. So we both agreed to make a choice now, see how it works for us, and we can revisit later if needed.\nThen the question is whether to choose 2 or 4 spaces today. We agreed to go with 4."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 22:53:50+00:00",
                    "text": "I created this PR via GitHub and it pushed a branch into the main repository. So I just created #60 from my own fork. I am going to close this PR in favor of #60."
                }
            ]
        },
        {
            "number": 56,
            "user": "zbeekman",
            "date": "2019-12-31 02:51:58+00:00",
            "title": "CI: Add automatic PR review for misspellings",
            "text": "Add bot to post comments/reviews on PRs for misspelling issues using reviewdog/action-misspell\nA new token may need to be created to allow comments to be posted on PRs instead of just PR status. This would have caught typos in my previous PRs. Token info is here: https://github.com/reviewdog/reviewdog#reporter-github-pullrequest-review-comment--reportergithub-pr-review",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-31 15:36:10+00:00",
                    "text": "This is what I see in the test:\n\nDoes that mean it passed it? How does it look like when it fails?\nCan you please rebase on top of the latest master, so that we can merge it?"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 16:09:32+00:00",
                    "text": "@certik: With the token setup correctly, it will comment in the PR if it detects misspellings in changed files:\n\nNo need to check the CI output by hand. We may need to create a new token and set it in the repo's secrets. I will rebase this onto master soon, but I need to run out for a moment right now."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 16:17:38+00:00",
                    "text": "Do you know how often this has false positives? Say reporting some correctly spelled Fortran variable names as misspelled?\n\u2026\nOn Tue, Dec 31, 2019, at 9:09 AM, zbeekman wrote:\n @certik <https://github.com/certik>: With the token setup correctly, it\n will comment in the PR if it detects misspellings in changed files:\n\n rd-image\n <https://user-images.githubusercontent.com/3797062/64926127-b8b0bc00-d834-11e9-97d5-5b6aa06dc573.png>\n\n No need to check the CI output by hand. We may need to create a new\n token and set it in the repo's secrets. I will rebase this onto master\n soon, but I need to run out for a moment right now.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#56?email_source=notifications&email_token=AAAFAWEPGT7XHFBOUYHRHALQ3NVD3A5CNFSM4KBSAVX2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEH4ML5I#issuecomment-569951733>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWHZR4ILFMPJAOKQYRDQ3NVD3ANCNFSM4KBSAVXQ>."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 17:06:44+00:00",
                    "text": "Do you know how often this has false positives? Say reporting some correctly spelled Fortran variable names as misspelled?\n\nIn my experience this almost never happens. It doesn't change the PR status just posts comments on the code, so false positives can be easily ignored. If it becomes an issue we can always remove it."
                },
                {
                    "user": "certik",
                    "date": "2020-01-01 03:27:03+00:00",
                    "text": "@zbeekman you should have push access and other rights to the repository. Go ahead and set this up if you have time.\nLet's try it, and if it works, great. If it doesn't work for us, we can remove it later."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 15:42:28+00:00",
                    "text": "Looks good to me. I'll leave it to you @zbeekman to merge and to set this up if some token has to be setup.\n\nGreat, and if it ever has too many false-positives, etc. we should disable it or tweak the scope.\nOne small issue regarding tokens: I'm happy to provide a personal access token with the correct scopes, however to add the secret to the repository someone with greater privileges (admin I think) will need to do so."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 16:01:39+00:00",
                    "text": "Send me the token by email and I'll put it there."
                }
            ]
        },
        {
            "number": 55,
            "user": "certik",
            "date": "2019-12-30 23:44:22+00:00",
            "title": "Test in-tree builds",
            "text": "This adds one in-tree build test for each platform, to ensure our CMake\nbuild system works both out-of-tree as well as in-tree.\nIn terms of costs, it seems to add 1s on one Linux build, and 3s on one macOS build.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-31 06:44:47+00:00",
                    "text": "Thanks for the review!"
                }
            ]
        },
        {
            "number": 54,
            "user": "scivision",
            "date": "2019-12-30 22:08:49+00:00",
            "title": "add system module",
            "text": "There are a number of capabilities it would be useful to bring from\ncstdlib and STL. This is an initial demonstration, replacing\nthe non-cross-compiler sleep() with a standard implementation that\nworks across compilers and operating systems, with millisecond integer\ninput.\nFor example, Intel compilers can hang at runtime if call sleep() is used without use ifport. This PR technique doesn't suffer from that issue across operating systems and compilers.\nThere are a number of other useful functions that can be implemented like this, including resolving absolute filenames and expanding ~ to user home path\nAdding CI for Windows brought an interesting corner case to light--runtime segfaults on Windows. I don't see these on my Windows Gfortran PC. This is a common type of corner case, tricky/shaky tests using uncommon features where it isn't feasible to whitelist/blacklist systems. A future PR would do a \"check_fortran_source_run()\" on a snippet of code to ensure the program can run instead of nuisance failure.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-30 22:16:28+00:00",
                    "text": "Thanks @scivision for pushing this. Can you create another PR where you get the Windows build working? I am working on reviewing #51 now, let's get that one in first.\nI like what you are trying to do, and let's get it polished an in."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-30 22:22:33+00:00",
                    "text": "Yes basically the CMake needs #51 to get working where I could put the necessary Windows stuff if. For these Windows tests, it will require CMake >= 3.14 to do the workaround. I added the feature to CMake 3.14 that makes it possible."
                },
                {
                    "user": "certik",
                    "date": "2019-12-30 22:43:20+00:00",
                    "text": "@scivision in that case we can depend on CMake 3.14, which I know @zbeekman would be very happy about. :)"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 02:13:00+00:00",
                    "text": "@scivision in that case we can depend on CMake 3.14, which I know @zbeekman would be very happy about. :)\n\nI told you there be bugs...  all's well that ends well."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 17:09:08+00:00",
                    "text": "I would strongly suggest to split the unrelated and approved parts of this PR into separate PRs, so that we can merge them:\n\nI'll have a go at this in a moment."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 22:00:58+00:00",
                    "text": "@scivision most of your other unrelated improvements in this PR have been merged into master. Do you want to submit a clean PR with just the system module?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 15:21:00+00:00",
                    "text": "@scivision I would like to merge your system module, but when you bundle unrelated CI changes, I don't want to just merge it, because some people might disagree with the CI changes, or want to further discuss them.\nDo you think it would be please possible to not bundle unrelated changes in a single PR?\nLet's split this PR, so that we can merge the system module, which I think is a great start and exactly as you say, it would allow us to use this approach for other things."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 18:51:36+00:00",
                    "text": "Let's not worry about formatting too much in individual PRs --- rather let's figure out how to do this automatically for all source files."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 18:57:22+00:00",
                    "text": "@zbeekman thanks for the review!\n@milancurcic can you please review this also?\nFor new functionality, I want several independent reviews, to prevent putting things in that might not be well designed or too bloated."
                },
                {
                    "user": "certik",
                    "date": "2020-01-08 22:02:22+00:00",
                    "text": "@milancurcic can you please review this also?\n@scivision sorry for the delay."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-27 01:25:56+00:00",
                    "text": "Are we discussing something like an interface to C system routines like often proposed for POSIX interfaces?  I use routines like that a lot but cooked my own (not sure how many platforms they would work on, but worked on all the ones I needed) in\nM_system.  A lot of compilers supported some variant of a \"POSIX\" interface, but in different ways, which made it highly non-portable. Never quite sure why this did not become part of the standard, especially when \"POSIX\" was a hot topic.  The only one I remember doing a full PXF interface was Cray.\nPS: FUNIX shows a lot of simple examples that use the interface. Shows how just the addition of a few things like those being proposed in stdlib make Fortran just as good if not better than most languages for creating basic utilities."
                },
                {
                    "user": "nncarlson",
                    "date": "2020-01-27 02:08:26+00:00",
                    "text": "The NAG compiler comes with a collection of intrinsic f90_unix_* modules that implement a bunch of POSIX stuff. They should be examples to consider if we wanted to head in that direction with stdlib. The documentation for them is here."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-27 04:17:35+00:00",
                    "text": "Almost the same list as I have; which is a good sign it can be done relatively generically.  Cray, Intel, and gfortran all have a lot of the same functionality as extensions, but all as proprietary extensions so not very portable. Probably others too. None are OOPs, which is interesting."
                }
            ]
        },
        {
            "number": 53,
            "user": "scivision",
            "date": "2019-12-30 20:36:43+00:00",
            "title": "error_stop to stderr and optional returncode",
            "text": "Users will probably expect error messages to be printed to stderr instead of stdout. This is especially important for programs that normally have a lot of stdout output or binary streams on stdout.\nThis also adds the option for user-specified error code, which can be used to signal a build system that a test should be skipped instead of failing. For example, maybe a skippable test requires external hardware that the build system cannot detect, but the running program does detect.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-30 23:19:48+00:00",
                    "text": "@scivision can you please rebase this on top of the latest master?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 17:00:05+00:00",
                    "text": "There are way too many changes in this PR and every time you push more code, I have to review the whole thing and it takes a lot of time.\nCan you please split the CMake improvements into a separate PR? We all agree we want that, let's get it merged. The action is also fine to have, plus the loadtxt/savetxt changes for working directory.\nI have some discussion about the other stuff. Let's discuss that later, once the agreed upon parts are merged in."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-31 17:09:55+00:00",
                    "text": "This PR is an atomic change to properly implement error stop in a Fortran 2008 and 2018 compiler-friendly way. I don't think it's feasible to make this PR smaller without breaking the CI or library."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 17:15:52+00:00",
                    "text": "Yes it is possible to make it smaller. I am busy today, but I will separate this PR into a smaller one either tonight or tomorrow."
                },
                {
                    "user": "certik",
                    "date": "2020-01-01 04:29:49+00:00",
                    "text": "I see. If the test returns 0 instead of 77 because some compiler doesn't support it (let's say) then it will \"pass\" even though it should fail.\n\nI think a more robust solution would be to actually test that the test returns the exit code 77, and pass the ctest test, otherwise fail it.\n\u2026\nOn Tue, Dec 31, 2019, at 8:59 PM, Michael Hirsch, Ph.D. wrote:\n ***@***.**** commented on this pull request.\n\n In src/tests/CMakeLists.txt\n <#53 (comment)>:\n\n > @@ -1,3 +1,12 @@\n  add_subdirectory(ascii)\n  add_subdirectory(loadtxt)\n\n +add_executable(test_skip test_skip.f90)\n +target_link_libraries(test_skip fortran_stdlib)\n +add_test(NAME AlwaysSkip COMMAND $<TARGET_FILE:test_skip>)\n +set_tests_properties(AlwaysSkip PROPERTIES SKIP_RETURN_CODE 77)\n It's testing that I can pass arbitrary return codes. There's a de facto\n standard that 77 means to skip a test, so 77 was a convenient\n alternative to the oft-used returncode 1 that was tested in AlwaysFail\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#53?email_source=notifications&email_token=AAAFAWAXI6X2NCH5SNFCYSTQ3QILVA5CNFSM4KBP64WKYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCQOWHSQ#discussion_r362301437>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWDRAOJZ3KL666YSZB3Q3QILVANCNFSM4KBP64WA>."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-01 04:41:38+00:00",
                    "text": "Yes the AlwaysSkip has that downside. I think to do that sort of test in a cross-platform way would most expediently be done by a Python script. Otherwise a per-platform approach would be needed. I think it's a test that would be unlikely to have any problem like that."
                },
                {
                    "user": "certik",
                    "date": "2020-01-01 05:58:39+00:00",
                    "text": "Yes, Bash probably isn't the most multiplatform, so it would have to be a Python script. The advantage is that cmake would show all tests as passed, none skipped.\n\u2026\nOn Tue, Dec 31, 2019, at 9:41 PM, Michael Hirsch, Ph.D. wrote:\n Yes the AlwaysSkip has that downside. I think to do that sort of test\n in a cross-platform way would most expediently be done by a Python\n script. Otherwise a per-platform approach would be needed. I think it's\n a test that would be unlikely to have any problem like that.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#53?email_source=notifications&email_token=AAAFAWGTCG6O4EYG24GXQPDQ3QNIFA5CNFSM4KBP64WKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEH45DLI#issuecomment-570020269>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWECGUSWHLDSNGZPU33Q3QNIFANCNFSM4KBP64WA>."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 17:18:25+00:00",
                    "text": "Yes, Bash probably isn't the most multiplatform, so it would have to be a Python script. The advantage is that cmake would show all tests as passed, none skipped.\n\nSuggestion: We could also use a CMake script as the test for return code by running cmake in script mode. That way users won't need python. You can achieve this by checking the RESULT_VARIABLE of execute_process().\nBut, perhaps a bigger question is: Should we check and require that compilers support return codes? I love using them, but do we want to rely on them vs behavior explicitly defined by the standard? (I.e., we look for specific test output to trigger test pass and fail status with CTest instead of return code.)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 18:14:27+00:00",
                    "text": "If it can be done in CMake itself, then I would prefer that over Python.\nRegarding return codes --- that's what ctest expects, but unfortunately I agree it is not standard in Fortran. But is there even an alternative?"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 18:30:41+00:00",
                    "text": "Regarding return codes --- that's what ctest expects, but unfortunately I agree it is not standard in Fortran. But is there even an alternative?\n\nYes, there are the test properties PASS_REGULAR_EXPRESSION and FAIL_REGULAR_EXPRESSION. I typically set both in my projects, and then use print or write to explicitly indicate success and failure."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 18:46:59+00:00",
                    "text": "@zbeekman I didn't know about that. We could use it.\nAlthough I think it's useful and perhaps simpler to use return codes --- as long as all compilers that we want to support (#15) work with it. We should definitely test that error_stop returns the correct return code, and if there is a compiler that does not support it, we might need to figure out some workaround (perhaps calling into the system C  API for that). Users would expect that error_stop will break their bash script, CI script, etc. So I think we have to do this anyway. And in that case, we might as well use return codes for the tests also."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 18:57:25+00:00",
                    "text": "To move ahead with this PR, I am fine to merge as is, and improve upon it later. For example to use the CMake script to check for the non-zero return code, so that ctest does not print the ugly **Skipped."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 21:24:00+00:00",
                    "text": "@milancurcic would you mind reviewing this also please? It looks like we all agree to merge it as is, and improve upon it later."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 15:00:04+00:00",
                    "text": "@milancurcic ping."
                }
            ]
        },
        {
            "number": 52,
            "user": "scivision",
            "date": "2019-12-30 19:46:22+00:00",
            "title": "Fortran 77 print instead of write(*,*)",
            "text": "I didn't see this discussed previously--\nwrite(*,*)\nis for printing to console. This makes it harder to recursively search files for where console output is given with special formatting etc.\nI would kindly suggest to consider Fortran 77 standard print, which is identical at the assembly code level.",
            "comments": [
                {
                    "user": "jacobwilliams",
                    "date": "2019-12-30 19:49:43+00:00",
                    "text": "Is write(*,*) really nonstandard? I never knew that."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-30 20:09:04+00:00",
                    "text": "yea I was wrong there, I was thinking in Fortran 2003 terms. In any case, I think the issue is over being able to find where non-stdout text is / is not being output, I have found it convenient to use print, which is identical from the compiler's perspective."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2019-12-30 22:57:58+00:00",
                    "text": "how about using output_unit?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-30 23:00:53+00:00",
                    "text": "I also only use print, never write(*,*). +1 to merge."
                },
                {
                    "user": "certik",
                    "date": "2019-12-30 23:03:01+00:00",
                    "text": "@jacobwilliams are you thinking of something like this:\nuse iso_fortran_env, only: output_unit\n...\nwrite (output_unit, *) ...\n? That seems more complicated than just:\nprint *, ..."
                }
            ]
        },
        {
            "number": 51,
            "user": "scivision",
            "date": "2019-12-30 19:34:52+00:00",
            "title": "improve cmake build",
            "text": "use CMAKE_Fortran_MODULE_DIRECTORY to avoid introspecting directory structure\ndon't build in-source, use test WORKING_DIRECTORY instead\nuse modern add_test() syntax to avoid introspecting project directory structure\nuse open(..., action=) to help indicate / safeguard intended file use\ndon't have to accommodate CMake <= 2.4 circa 2006\n\ncloses #47",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-30 19:40:47+00:00",
                    "text": "Thanks a lot. I like the spirit of these changes.\n\n One issue with the working directory is that the tests also create files. So they will pollute the working directory. That I think is not expected when you use a build directory that ctest will create files outside of it.\n\u2026\nOn Mon, Dec 30, 2019, at 12:34 PM, Michael Hirsch, Ph.D. wrote:\n   * use CMAKE_Fortran_MODULE_DIRECTORY to avoid introspecting directory\n structure\n  * don't build in-source, use test WORKING_DIRECTORY instead\n  * use modern add_test() syntax to avoid introspecting project\n directory structure\n  * use open(..., action=) to help indicate / safeguard intended file use\n  * don't have to accommodate CMake <= 2.4 circa 2006\n closes #47 <#47>\n\n You can view, comment on, or merge this pull request online at:\n\n #51\n\n Commit Summary\n\n  * improve cmake build\n File Changes\n\n  * *M* .github/workflows/main.yml\n <https://github.com/fortran-lang/stdlib/pull/51/files#diff-0> (6)\n  * *M* CMakeLists.txt\n <https://github.com/fortran-lang/stdlib/pull/51/files#diff-1> (11)\n  * *M* src/stdlib_experimental_io.f90\n <https://github.com/fortran-lang/stdlib/pull/51/files#diff-2> (18)\n  * *M* src/tests/ascii/CMakeLists.txt\n <https://github.com/fortran-lang/stdlib/pull/51/files#diff-3> (5)\n  * *M* src/tests/loadtxt/CMakeLists.txt\n <https://github.com/fortran-lang/stdlib/pull/51/files#diff-4> (11)\n Patch Links:\n\n  * https://github.com/fortran-lang/stdlib/pull/51.patch\n  * https://github.com/fortran-lang/stdlib/pull/51.diff\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#51?email_source=notifications&email_token=AAAFAWCAY6M2K7LQLIXZ77LQ3JEN3A5CNFSM4KBPQSB2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IDMTDMQ>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWGM5EJRSOQ7IJODS7TQ3JEN3ANCNFSM4KBPQSBQ>."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-30 20:02:25+00:00",
                    "text": "Thanks, I changed that test to accept an input directory argument, that will be in a build directory"
                },
                {
                    "user": "certik",
                    "date": "2019-12-30 22:39:26+00:00",
                    "text": "@scivision please allow people with push access to modify your source branch (it's a check box somewhere). Then I can commit my suggestions above and merge this. Tons of other PRs depend on this.\nhttps://help.github.com/en/github/collaborating-with-issues-and-pull-requests/allowing-changes-to-a-pull-request-branch-created-from-a-fork"
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 02:26:43+00:00",
                    "text": "I added in, and then approved it. Don't know why, because it should not be used.\n\u2026\nOn Mon, Dec 30, 2019, at 7:23 PM, zbeekman wrote:\n ***@***.**** approved this pull request.\n\n Other than @certik <https://github.com/certik>'s indentation issues,\n this looks like a big improvement to me. I don't know who added calls\n to `include_directories()` in and who approved the PR, but that is one\n of the ~5 CMake commands that should be blacklisted.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#51?email_source=notifications&email_token=AAAFAWFR4UJJAJZW37ZI6NLQ3KUK5A5CNFSM4KBPQSB2YY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCQNI3NI#pullrequestreview-337284533>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWF5VWVGFMLIC5HBV3TQ3KUK5ANCNFSM4KBPQSBQ>."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 02:36:39+00:00",
                    "text": "Looks like this is ready to \ud83d\udea2"
                }
            ]
        },
        {
            "number": 50,
            "user": "pdebuyl",
            "date": "2019-12-29 11:18:17+00:00",
            "title": "set the cmake build to out-of-source",
            "text": "Change the github workflow for the cmake build.\nI open the PR to trigger the workflow for the branch. The manual makefiles are not touched.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-29 15:30:57+00:00",
                    "text": "I suggest we test both in tree and out of tree.\n\nThe out of tree can be the default to test various compilers, etc. But on each platform we should have at least one test for in tree builds to ensure they still work.\n\u2026\nOn Sun, Dec 29, 2019, at 4:18 AM, Pierre de Buyl wrote:\n Change the github workflow for the cmake build.\n\n I open the PR to trigger the workflow for the branch. The manual\n makefiles are not touched.\n\n You can view, comment on, or merge this pull request online at:\n\n #50\n\n Commit Summary\n\n  * set the cmake build to out-of-source\n File Changes\n\n  * *M* .github/workflows/main.yml\n <https://github.com/fortran-lang/stdlib/pull/50/files#diff-0> (6)\n Patch Links:\n\n  * https://github.com/fortran-lang/stdlib/pull/50.patch\n  * https://github.com/fortran-lang/stdlib/pull/50.diff\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#50?email_source=notifications&email_token=AAAFAWCPMLOTFWZ2WDKIZ5LQ3CBPVA5CNFSM4KA22DJKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IDDA6JQ>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWDZGU22X5XMLDIZCG3Q3CBPVANCNFSM4KA22DJA>."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-29 22:29:11+00:00",
                    "text": "@certik\n\nI suggest we test both in tree and out of tree.\n\nOut of curiosity, what is the motivation for maintaining in-tree builds?\nOut-of-source builds are easier to cleanup after, and don't risk clobbering WIP changes. If we truly want to support both then I suppose we should test in source builds too, but I don't see a strong case for insisting on supporting both. In addition, out-of-source builds are more likely to fail from a misconfigured build system than in-source builds are.\nI don't care that much about whether or not we want to support in source builds, but we don't want a combinatorial explosion of our build matrix if we can avoid it."
                },
                {
                    "user": "pdebuyl",
                    "date": "2019-12-30 10:33:19+00:00",
                    "text": "I removed the comment. I didn't see that one could accept \"suggested commits\" online and did it via the CLI.\nRegarding in-tree builds, I don't use them in my projects, I don't know how useful they are.\nI proposed the cmake patch because I tested the build on my computer with the \"idiomatic\"\nmkdir build\ncd build\ncmake ..\nmake\n\nMaybe we need test users, with different coding habits."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-30 17:23:23+00:00",
                    "text": "It seems @certik is one such \"test user\" as he reported elsewhere that he typically does in-tree CMake builds... Given the goal of supporting Makefiles and CMake, I would advocate for in-source builds being \"unsupported\". Interested parties can still try to keep them working, but I don't want to explode our CI test matrix anymore than 3 oses and 3 versions of Fortran compilers, unless there is a really good reason."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2019-12-30 18:56:46+00:00",
                    "text": "I don't think we should encourage in-source builds. :)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-30 23:33:12+00:00",
                    "text": "This PR is ready to go in, so I am going to merge it."
                },
                {
                    "user": "certik",
                    "date": "2019-12-30 23:48:43+00:00",
                    "text": "I submitted #55 for in-tree CI tests."
                }
            ]
        },
        {
            "number": 49,
            "user": "ivan-pi",
            "date": "2019-12-28 18:28:37+00:00",
            "title": "Place ASCII control characters in derived type ",
            "text": "As discussed in #11, I have moved the ascii control characters into a derived type. A single instance of this type (with the parameter attribute) is exposed to the public and can be accesed using\nuse stdlib_experimental_ascii, only: ascii_control_char \nwrite(*,*) ascii_control_char%TAB//\"Hello\"//ascii_control_char%LF\nThe ascii character validation and conversion procedures are now elemental and work on character arrays. One of the tests has been modified to demonstrate this by allocating character arrays filled with different subsets of characters and generating a true/false table:\n          is_control\n          | is_printable\n          | | is_whitespace\n          | | | is_blank\n          | | | | is_graphical\n          | | | | | is_punctuation\n          | | | | | | is_alphanum\n          | | | | | | | is_alpha\n          | | | | | | | | is_upper\n          | | | | | | | | | is_lower\n          | | | | | | | | | | is_digit\n decimal  | | | | | | | | | | | is_hex_digit\n -------------------------------------------\n     0-8  T F F F F F F F F F F F\n       9  T F T T F F F F F F F F\n   10-13  T F T F F F F F F F F F\n   14-31  T F F F F F F F F F F F\n      32  F T T T F F F F F F F F\n   33-47  F T F F T T F F F F F F\n   48-57  F T F F T F T F F F T T\n   58-64  F T F F T T F F F F F F\n   65-70  F T F F T F T T T F F T\n   71-90  F T F F T F T T T F F F\n   91-96  F T F F T T F F F F F F\n  97-102  F T F F T F T T F T F T\n 103-122  F T F F T F T T F T F F\n 123-126  F T F F T T F F F F F F\n     127  T F F F F F F F F F F F\n\nLast, I have replaced the whitechar function in stdlib_experimental_io with the is_blank function from the ascii module.",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2019-12-28 21:16:44+00:00",
                    "text": "I tried to squash two commits. I am not sure what went wrong with the MacOS tests as the ubuntu tests run successfully."
                },
                {
                    "user": "certik",
                    "date": "2019-12-29 06:37:55+00:00",
                    "text": "I think this is fine. Generally it's better not to use derived types in a library because it forces all applications to also use them, even if they don't want to. But in this case it seems it is ok, it's used more like a namesoace.\n\u2026\nOn Sat, Dec 28, 2019, at 2:16 PM, Ivan wrote:\n I tried to squash two commits. I am not sure what went wrong with the\n MacOS tests as the ubuntu tests run successfully.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#49?email_source=notifications&email_token=AAAFAWFVONKCF5OJRBAQCGTQ2663ZA5CNFSM4KAQP46KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHYSKAA#issuecomment-569451776>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWF3YWDY324JAA7VJDDQ2663ZANCNFSM4KAQP46A>."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-29 13:50:59+00:00",
                    "text": "Looks good to me. @certik In what scenario would an application not want to use a derived type?\nWe should fix the MacOS builds before merging though. I don't know what's going on there and GitHub is not letting me expand the details for the step that fails."
                },
                {
                    "user": "certik",
                    "date": "2019-12-29 15:07:29+00:00",
                    "text": "It doesn't quite apply in this PR, but a good example is a sparse CSR matrix, represented by three arrays Ap, Aj,  Ax. We will provide operations on it, such as matmul. The lowest level public API should simply accept the three arrays as input arguments, not use a derived type CSRMatrix. The reason for that is that as an application I would like to have a choice what data structures I use. If we only accept CSRMatrix as an argument then the application is forced to use it and what if this is some big production code that already uses its own derived type for CSR matrix, perhaps with a few more members such as name, or some other application specific metadata? Then the application is forced to create CSRMatrix derived type and copy the arrays there, or it is forced to redo its data structures. Not optimal. If on the other hand we provide an API that only accepts the three arrays directly, then the application simply passes the arrays in from its internal data structure directly.\n\nStdlib can still optionally provide a higher level API that uses the CSRMatrix derived type.\n\nSo the answer is: as an application I would almost always like to use a derived type for a CSR matrix, but on my own terms. Not forced by a library like stdlib.\n\nCSR matrix is an example where most people including me would agree a derived type simplifies code and generally is appropriate for an end application. Other use cases, such as saveppm and creating an Image_t derived type, are much worse. The best is to leave applications the freedom to decide what derived types to use and when; and in stdlib to provide the actual functionality to operate on a CSR matrix or PPM images.\n\u2026\nOn Sun, Dec 29, 2019, at 6:50 AM, Milan Curcic wrote:\n Looks good to me. @certik <https://github.com/certik> In what scenario\n would an application not want to use a derived type?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#49?email_source=notifications&email_token=AAAFAWF2NTBK2GDN4RZ4EVLQ3CTMHA5CNFSM4KAQP46KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHY75SY#issuecomment-569507531>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWD5GZR6VNAJPXWEPKLQ3CTMHANCNFSM4KAQP46A>."
                },
                {
                    "user": "gronki",
                    "date": "2019-12-29 16:27:31+00:00",
                    "text": "I agree with @certik that placing character constants in a derived type is\na bad design decision. Derived types are not designed to store constants.\nThey are not namespaces. They should be not used as namespaces. If somebody\ncares about pollution of name space, they can use only operator which was\ndesigned exactly for that. I think we should use things as are intended and\nnot poorly implement ideas from other languages. Or the result will be a\nFrankenstein.\n\nniedz., 29 gru 2019, 16:07 u\u017cytkownik Ond\u0159ej \u010cert\u00edk <\nnotifications@github.com> napisa\u0142:\n\u2026\n It doesn't quite apply in this PR, but a good example is a sparse CSR\n matrix, represented by three arrays Ap, Aj, Ax. We will provide operations\n on it, such as matmul. The lowest level public API should simply accept the\n three arrays as input arguments, not use a derived type CSRMatrix. The\n reason for that is that as an application I would like to have a choice\n what data structures I use. If we only accept CSRMatrix as an argument then\n the application is forced to use it and what if this is some big production\n code that already uses its own derived type for CSR matrix, perhaps with a\n few more members such as name, or some other application specific metadata?\n Then the application is forced to create CSRMatrix derived type and copy\n the arrays there, or it is forced to redo its data structures. Not optimal.\n If on the other hand we provide an API that only accepts the three arrays\n directly, then the application simply passes the arrays in from its\n internal data structure directly.\n\n Stdlib can still optionally provide a higher level API that uses the\n CSRMatrix derived type.\n\n So the answer is: as an application I would almost always like to use a\n derived type for a CSR matrix, but on my own terms. Not forced by a library\n like stdlib.\n\n CSR matrix is an example where most people including me would agree a\n derived type simplifies code and generally is appropriate for an end\n application. Other use cases, such as saveppm and creating an Image_t\n derived type, are much worse. The best is to leave applications the freedom\n to decide what derived types to use and when; and in stdlib to provide the\n actual functionality to operate on a CSR matrix or PPM images.\n\n On Sun, Dec 29, 2019, at 6:50 AM, Milan Curcic wrote:\n > Looks good to me. @certik <https://github.com/certik> In what scenario\n > would an application not want to use a derived type?\n >\n > \u2014\n > You are receiving this because you were mentioned.\n > Reply to this email directly, view it on GitHub\n > <\n #49?email_source=notifications&email_token=AAAFAWF2NTBK2GDN4RZ4EVLQ3CTMHA5CNFSM4KAQP46KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHY75SY#issuecomment-569507531>,\n or unsubscribe <\n https://github.com/notifications/unsubscribe-auth/AAAFAWD5GZR6VNAJPXWEPKLQ3CTMHANCNFSM4KAQP46A\n >.\n >\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#49?email_source=notifications&email_token=AC4NA3MIX72375GFEPZNVD3Q3C4LHA5CNFSM4KAQP46KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHZBPIQ#issuecomment-569513890>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AC4NA3OOJPFL5MU24ZNHGSDQ3C4LHANCNFSM4KAQP46A>\n ."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-29 17:04:02+00:00",
                    "text": "Thank you @certik and @gronki for explaining your opinions. It is good we discuss this usage case as it sets a precedence and will also influence future design choices.\nIf we do not want the control character constants to polute the stdlib_experimental_ascii namespace, aside from the current PR which wraps them in a derived type (only exposing a single instance publically), we could put them in a separate module stdlib_experimental_ascii_constants along with the other constant character sequences (letters, digits).\nWe could also just give them longer names, e.g. ascii_control_char_tab instead of the current tab, and thereby hopefully prevent name clashes.\n@gronki Do you offer any other suggestions?"
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-29 18:07:01+00:00",
                    "text": "If we do not want the control character constants to polute the stdlib_experimental_ascii namespace, aside from the current PR which wraps them in a derived type (only exposing a single instance publically), we could put them in a separate module stdlib_experimental_ascii_constants along with the other constant character sequences (letters, digits).\n\nI agree with the comments. And this @ivan-pi 's solution is a solution I often use in my programs. If a user doesn't need constants, he doesn't need to call the module. While not ideal, it would also allow the use to simply write\nuse stdlib_experimental_ascii\nwithout a need to specify what it just wants.\n\nWe could also just give them longer names, e.g. ascii_control_char_tab instead of the current tab, and thereby hopefully prevent name clashes\n\nMaybe the name of the module could be used in front of the variable, e.g., for stdlib_experimental_ascii_constants, tab would become stdlib_ascii_constants_tab (where I remove the experimental since it would be eventually removed).\nI am afraid that something like ascii_control_char_xxx is still too generic. Also, using the names of the module in the names of the variables may help to find its origin in complex libraries."
                },
                {
                    "user": "certik",
                    "date": "2019-12-29 21:55:12+00:00",
                    "text": "Let's put them in a separate module then? In that case their names can stay as is, cannot they?\n\nThere is an open issue to make modules work as namespaces here:\n\nj3-fortran/fortran_proposals#1\n\nWhich would solve a lot of these issues. I do not recommend people to \"use some_module\" without the \"only\" part. Just like in Python.\n\u2026\nOn Sun, Dec 29, 2019, at 11:07 AM, Jeremie Vandenplas wrote:\n >\n > If we do not want the control character constants to polute the `stdlib_experimental_ascii` namespace, aside from the current PR which wraps them in a derived type (only exposing a single instance publically), we could put them in a separate module `stdlib_experimental_ascii_constants` along with the other constant character sequences (letters, digits).\n\n I agree with the comments. And this @ivan-pi\n <https://github.com/ivan-pi> 's solution is a solution I often use in\n my programs. If a user doesn't need constants, he doesn't need to call\n the module. While not ideal, it would also allow the use to simply write\n `use stdlib_experimental_ascii`\n  without a need to specify what it just wants.\n\n > We could also just give them longer names, e.g. ascii_control_char_tab instead of the current tab, and thereby hopefully prevent name clashes\n\n Maybe the name of the module could be used in front of the variable,\n e.g., for `stdlib_experimental_ascii_constants`, `tab` would become\n `stdlib_ascii_constants_tab` (where I remove the `experimental` since\n it would be eventually removed).\n  I am afraid that something like `ascii_control_char_xxx` is still too\n generic. Also, using the names of the module in the names of the\n variables may help to find its origin in complex libraries.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#49?email_source=notifications&email_token=AAAFAWBEWFDVM5T7A6J47WDQ3DRMNA5CNFSM4KAQP46KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHZFCSY#issuecomment-569528651>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWH7D42PQEWJ2C66KXTQ3DRMNANCNFSM4KAQP46A>."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-29 22:59:59+00:00",
                    "text": "@ivan-pi I suspect the failures are just \"cloud\" issues. I'm not a member of the fortran-lang org, however, so I cannot re-run the CI test to confirm this. Given that the failures won't expand their logs, this is most likely the cause of the issue."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-30 02:09:22+00:00",
                    "text": "It doesn't quite apply in this PR, but a good example is a sparse CSR matrix, represented by three arrays Ap, Aj, Ax. We will provide operations on it, such as matmul. The lowest level public API should simply accept the three arrays as input arguments, not use a derived type CSRMatrix.\n\nI agree, you're talking in the context of providing procedural/functional vs. object-oriented APIs. Here it's meant exactly to emulate a namespace."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-30 02:20:17+00:00",
                    "text": "@gronki Can you elaborate why you think it's a bad design choice? What are the specific caveats or downsides? I don't see them right now.\nNo matter if we adopt it here or not, I'd bet that it'd come up again as we keep working on stdlib. It'd be good for all of us to understand what are the downsides. I don't care if it was originally intended for a purpose or not. What I care about is what is the problem we're trying to solve and does the proposed method solve it.\nDifferent question is whether this is a problem at all. That's why I asked about this in #11."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-30 02:28:54+00:00",
                    "text": "Let's put them in a separate module then? In that case their names can stay as is, cannot they?\n\nI think this solves only the scenario of user doing use stdlib_experimental_ascii, to prevent populating the global namespace with 33 short-named constants. The same user would do use stdlib_experimental_ascii_constants to get the control characters, which is convenient but against our recommended use of modules (use ..., only ...:). The downside is small complexity overhead from having a separate module. I don't recommend this approach.\nAlternatives that remain are:\n\nPrefix control constants with ascii_. This would solve the problem of polluting a namespace in the event of use stdlib_experimental_ascii.\nLeave as is (reject this PR) and reconsider only in the event of users complaining.\n\nI like both latter options better than adding the constants module."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 00:20:46+00:00",
                    "text": "I restarted the checks, but I don't know if it did anything... GitHub actions might not be as production ready as I was hoping.\nWe can move to Azure pipelines, which can also check all three platforms (Linux, macOS and Windows) in one framework.\nOtherwise we can do Travis + AppVeyor."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 03:32:03+00:00",
                    "text": "The conflict may need to be resolved too. I'll try reproducing CI locally on macOS to see if there's anything obvious."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-03 17:23:17+00:00",
                    "text": "Let's keep this ball rolling. How do we want to proceed?\nOptions:\n\nEmulate namespace with derived type (this PR). Supported by @ivan-pi and myself, cautiously supported by @certik; @gronki against (if you can provide some concrete downsides or caveats it would help!)\nPrefix control constants with ascii_. This would prevent polluting the global namespace with 33 short constants, but doesn't make it any easier to import;\nMark this as \"not a problem\" (reject this PR)\n\n@jvdp1 @marshallward @jacobwilliams do you mind chiming in?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-03 17:23:45+00:00",
                    "text": "Also, @zbeekman what do you think?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 21:02:08+00:00",
                    "text": "By priority, my first preference is to simply reject the PR. My personal opinion is that we should not use derived type for everything to try to emulate namespaces. Rather, let's work on fixing this issue: j3-fortran/fortran_proposals#1 and then this issue: j3-fortran/fortran_proposals#86. With those fixed, one could access it by std%ascii%tab. I recommend against doing use stdlib_ascii, but rather always use, stdlib_ascii, only: tab. So there is no polluting.\nMy second preference is to put them in a separate module, that will not be imported by default when you use stdlib_ascii, so it won't pollute the namespace.\nMy last preference is a derived type. But these particular constants will not be used that often, so if the majority wants a derived type, then I am fine with that.\nMore pragmatically, this is in the experimental module, so we can always revert this change later."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-03 21:21:18+00:00",
                    "text": "My preferences would be:\n\nto move all ASCII control characters AND constant character sequences in another module (with, e.g., stdlib_ascii_ or ascii_, in front of them).\nto put  all ASCII control characters AND constant character sequences in a public derive type.\nto let the module as it was, BUT still adding stdlib_ascii_ or ascii_ (or similar) in front of the control characters and others. There will be always someone who will do use stdlib_ascii without only, and this will most likely lead to problems because of the existence of some ff, lf, bel,...\n\nMy feelind is that we should find, at least, something to avoid polluting namespaces by variables as ff, lf, bel,..."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-03 22:42:07+00:00",
                    "text": "This may be controversial, and I'm not necessarily saying this is the right approach\u2122\ufe0f: What if everything was wrapped up in an object including the procedures as TBPs/methods?\n\nIf I understand correctly you mean something along the lines of:\ntype :: ascii_tools_t\ncontains\n... procedures for character conversion, etc.\nend type\ntype(ascii_tools_t) :: ascii_tools = ascii_tools_t()\nThe user would then import a single instance of this derived type and just call the TPB/methods, completely avoiding the hassle of listing ten different functions:\nuse std_ascii, only: at => ascii_tools\nprint *, at%is_upper('A') ! prints T\nIt is kind of like a swiss-army knife. You only take out the tool you need. I would like to see what the others thoughts are on this one, however I having the feeling it is somehow too radically different to what most users are accustomed too.\n\nGiven the replies from @certik, @jvdp1, and @zbeekman  we are now at 50/50 for or against using a derived type to emulate a namespace. While it would be easier to judge with some real world usage examples in the end it might turn out more comfortable to move the constants to a different module, e.g. std_ascii_constants. Then someone who just needs the tab character and carriage return can easily do:\nuse stdlib_ascii_constants, only: ascii_TAB, ascii_CR\n\nand someone who wants all control characters will just leave the only part out. You can always wrap the constants into a derived type in the client code (I am here reversing the argument of @zbeekman).\nUnder the solution with a separate module, would the sequences for letters, digits, whitespace, and punctuation stay in the current module or would they move to the new one?\nCould we use this issue to further motivate the development of namespaces over at j3-fortran? With the namespace syntax, we could have:\nuse, namespace :: ctr => ascii_constants\nprint *, ctr%TAB//\"Hello\"//ctr%CR//ctr%LF"
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 22:46:51+00:00",
                    "text": "Could we use this issue to further motivate the development of namespaces over at j3-fortran? With the namespace syntax, we could have:\n\nYes!! Please do. Comment at the issue. Then go to j3-fortran/fortran_proposals#122, and put this high in your priority list. :)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-05 03:34:54+00:00",
                    "text": "I'm not adding a separate module just for these constants. It only solves half of the problem and introduces complexity cost.\nConsidering we don't have majority agreement on way forward, I agree we should shelf this away (close PR) as @certik suggested."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 03:46:33+00:00",
                    "text": "Ok. Let's close this one for now.\nThis does not mean that we are saying \"no\" forever. It's just that we can't reach a solid agreement on this right now, and let's use our energy on things where we can reach an agreement. Once we get more users, we can revisit this."
                },
                {
                    "user": "marshallward",
                    "date": "2020-01-06 15:42:12+00:00",
                    "text": "We have successfully used a class-like type in Australia's main climate model's library, libaccessom2.  (All credit to the author, @nichannah, who designed and programmed this class, and would probably be very interested in the efforts going on here.)\nThe definition is based on procedure statements:\nhttps://github.com/COSIMA/libaccessom2/blob/9fda758e017b5d1c55e7f39797da351317fb9390/libcouple/src/accessom2.F90#L19-L103\nThe overhead to load it is very low:\nhttps://github.com/mom-ocean/MOM5/blob/50dc61e9d77c181e6ad0047925fafdcead64d87a/src/accessom_coupler/ocean_solo.F90#L111\nHere is the accessom2 class in action:\nhttps://github.com/mom-ocean/MOM5/blob/50dc61e9d77c181e6ad0047925fafdcead64d87a/src/accessom_coupler/ocean_solo.F90#L228-L257\nI am a big fan of this approach.  It worked well on our supercomputer, which was your typical hornet's nest of old and new libraries, so it is hopefully reasonably robust these days.\nI could see a design approach using procedure adapted to the ASCII methods here.\nAnd big apologies for taking so long to reply, I'm slowly getting caught up on all the activities going on here."
                },
                {
                    "user": "epagone",
                    "date": "2020-01-09 19:32:54+00:00",
                    "text": "As a user, I would prefer the OO implementation along the lines suggested by @zbeekman and @marshallward . As soon as the standard is fixed (as suggested by @certik), then the interface can be simplified or changed. My 2 cent."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-09 20:01:23+00:00",
                    "text": "We have successfully used a class-like type in Australia's main climate model's library, libaccessom2. (All credit to the author, @nichannah, who designed and programmed this class, and would probably be very interested in the efforts going on here.)\n\nAlways nice to stumble upon datetime-fortran used in the wild :)"
                }
            ]
        },
        {
            "number": 48,
            "user": "pdebuyl",
            "date": "2019-12-26 14:30:15+00:00",
            "title": "copy the test datafiles for test_loadtxt",
            "text": "Allow the test to run in an out-of-source build tree.\nWorks by copying the test data to ${CMAKE_CURRENT_BINARY_DIR}.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-26 20:48:42+00:00",
                    "text": "+1 to merge\n\u2026\nOn Thu, Dec 26, 2019, at 10:13 AM, Ivan wrote:\n ***@***.**** approved this pull request.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#48?email_source=notifications&email_token=AAAFAWAE6SX6PH2DEVLANUTQ2TQ2DA5CNFSM4J7L4VX2YY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCQH2X5A#pullrequestreview-336571380>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWAUFN33ATSB4X2CXOLQ2TQ2DANCNFSM4J7L4VXQ>."
                },
                {
                    "user": "certik",
                    "date": "2019-12-27 00:10:28+00:00",
                    "text": "As a new PR, can someone please submit tests for out of tree builds? And also for the Make buildsystem.\n\u2026\nOn Thu, Dec 26, 2019, at 4:33 PM, Milan Curcic wrote:\n Merged #48 <#48> into master.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#48?email_source=notifications&email_token=AAAFAWBT3NM45H3KE55FTDLQ2U5OJA5CNFSM4J7L4VX2YY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOVVX76GQ#event-2909798170>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWB46LXRSKG7C3WEQEDQ2U5OJANCNFSM4J7L4VXQ>."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-27 00:41:06+00:00",
                    "text": "I only tested it locally. I will take some time in the next few days to learn how GitHub Actions work."
                }
            ]
        },
        {
            "number": 47,
            "user": "pdebuyl",
            "date": "2019-12-26 13:33:01+00:00",
            "title": "CMake build in place or copy test files",
            "text": "Without the datafiles, the test would fail on my machine when running an out of source build.\nThe branch here https://github.com/pdebuyl/stdlib/tree/cmake_copy_dat_files make a copy of the data files. I preferred to open an issue since I don't know if a PR would be of any use here.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-26 14:12:54+00:00",
                    "text": "Can you please submit a PR to fix CMake to work out of tree?\n\nThat would be very helpful. Thanks!\n\u2026\nOn Thu, Dec 26, 2019, at 6:33 AM, Pierre de Buyl wrote:\n Without the datafiles, the test would fail on my machine when running\n an out of source build.\n\n The branch here\n https://github.com/pdebuyl/stdlib/tree/cmake_copy_dat_files make a copy\n of the data files. I preferred to open an issue since I don't know if a\n PR would be of any use here.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#47?email_source=notifications&email_token=AAAFAWDSUB6FYPHENDYXGR3Q2SXA5A5CNFSM4J7LQNNKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4ICWYTRQ>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWEOAQSCBT23YFOFF2TQ2SXA5ANCNFSM4J7LQNNA>."
                }
            ]
        },
        {
            "number": 46,
            "user": "milancurcic",
            "date": "2019-12-24 21:30:28+00:00",
            "title": "Update manual makefiles",
            "text": "This PR:\n\nRemoves old (dummy) source files mod_stdlib.f90 and test_dummy.f90\nUpdates manual Makefiles so they build the library and tests\nUpdates the README to include build instructions with CMake or manual Makefiles",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2019-12-26 23:36:40+00:00",
                    "text": "Considering #48, can we rename Makefile.manual to just Makefile and require out-of-source builds for CMake? This would do away with having to make -f Makefile.manual which is quite tedious."
                },
                {
                    "user": "certik",
                    "date": "2019-12-27 00:19:16+00:00",
                    "text": "I use in tree builds often. Since most users would presumably use cmake, is there a problem keeping the Makefiles as is?\n\nI think both in tree and out of tree builds are very useful.\n\u2026\nOn Thu, Dec 26, 2019, at 4:36 PM, Milan Curcic wrote:\n Considering #48 <#48>, can\n we rename `Makefile.manual` to just `Makefile` and require\n out-of-source builds for CMake? This would do away with having to `make\n -f Makefile.manual` which is quite tedious.\n\n \u2014\n You are receiving this because your review was requested.\n Reply to this email directly, view it on GitHub\n <#46?email_source=notifications&email_token=AAAFAWFIFRFVXL7U2O7PVALQ2U5YTA5CNFSM4J7A2Y6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHWIWXA#issuecomment-569150300>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWF3FXBWSGLGQXLSNR3Q2U5YTANCNFSM4J7A2Y6A>."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-27 00:27:24+00:00",
                    "text": "No problem, it's just verbose. I normally use CMake, and manual Makefiles only when I update them, i.e. this PR.\nI realize now that this may even serve to motivate using CMake, for those who are on the fence."
                },
                {
                    "user": "certik",
                    "date": "2019-12-27 16:10:43+00:00",
                    "text": "It's verbose, but if we rename, then in tree cmake builds overwrite them, and the git wants to commit those changes which is really annoying with no easy fix, as cmake doesn't allow to rename the generated makefiles.\n\u2026\nOn Thu, Dec 26, 2019, at 5:27 PM, Milan Curcic wrote:\n No problem, it's just verbose. I normally use CMake, and manual\n Makefiles only when I update them, i.e. this PR.\n\n I realize now that this may even serve to motivate using CMake, for\n those who are on the fence.\n\n \u2014\n You are receiving this because your review was requested.\n Reply to this email directly, view it on GitHub\n <#46?email_source=notifications&email_token=AAAFAWHXFWO3YDFVVE5SB63Q2VDWZA5CNFSM4J7A2Y6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHWJ6XY#issuecomment-569155423>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWEQVTUDTB64K3LNOJLQ2VDWZANCNFSM4J7A2Y6A>."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-29 22:32:53+00:00",
                    "text": "Relevant to the discussion in #50: do we want to maintain (test) in source and out of source CMake builds. Out of source is cleaner IMO, and less error prone, but I don't care that much other than pointing out that this is yet another combinatorial expansion of build systems beyond maintaining CMake in parallel to Makefiles, now we need to maintain (i.e., test) in source builds and out of source builds. This seems like unnecessary complexity to me."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-30 21:56:06+00:00",
                    "text": "@certik Can this be merged? We can add the tests with manual Makefiles to CI in a separate PR."
                },
                {
                    "user": "certik",
                    "date": "2019-12-30 22:36:11+00:00",
                    "text": "I agree, let's merge this and improve upon it with further PRs."
                }
            ]
        },
        {
            "number": 45,
            "user": "certik",
            "date": "2019-12-24 00:05:30+00:00",
            "title": "Reading and writing common image formats, ppm, tiff, jpeg, png",
            "text": "Here is an example implementation of loading and saving ppm: https://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/src/ppm.f90. The advantage of the ppm format is that it is simple to write such readers and writers. Then one can use external tools (such as pnmtopng) to convert to more common formats. So perhaps tiff, jpeg and png are not initially needed and ppm might be enough to allow to work with images in Fortran.\nPrior art:\n\nMatlab: imread can read BMP, JPEG, PNG, CUR, PPM, GIF, PBM, RAS, HDF4, PCX, TIFF, ICO, PGM and XWD files. See also imwrite.\nSciPy: imread uses Python Imaging Library (PIL) to read the image; PIL supports: BMP, DIB, EPS, GIF, ICNS, ICO, IM, JPEG, MSP, PCX, PNG, PPM, SGI, SPIDER, TGA, TIFF, WebP, XBM. See also imsave.\nJulia: Images.jl package has a nice comparison page with SciPy and Matlab; can read at least PNG, GIF, TIFF, JPEG.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-24 00:39:34+00:00",
                    "text": "If we only do PPM, that can be easily done in pure Fortran. For almost all the other formats we would have to depend on a 3rd party library.\nIt feels like supporting all the formats might be a better fit for a separate library from stdlib, because at least initially I think we should stay in pure Fortran and only have minimal external dependencies to make the distribution of stdlib easier.\nBut since PPM can be supported easily in pure Fortran, it would allow codes to export and import images by using some external tool to convert to and from PPM first, which seems like it might be valuable enough to include in stdlib."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-24 01:44:09+00:00",
                    "text": "PPM is good enough for start! I agree on the advantage of pure Fortran implementation. We can adopt your implementations, they're good. I also have a P3 writer (same as P6, but ascii)."
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 06:26:10+00:00",
                    "text": "Perfect, let's do it. Yes, we can support both ascii and binary PPM and a few related formats."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-24 20:35:39+00:00",
                    "text": "What module would this belong to? stdlib_experimental_io or its own stdlib_experimental_image? On one hand, I think this fits thematically in io. However, we anticipate that io will grow further and would be split in smaller modules eventually, so maybe a dedicated module is more fitting.\nI'm happy to prepare a PR with loadppm and saveppm implementations for P3 and P6 formats -- basically take your code and add P3 implementations. Other formats may be implemented later if desired.\nHow should we handle choosing a format? For loadppm I think we can have just one specific procedure, because the format is specified in the file header and the user doesn't have to specify which format it is. However, for saveppm, user should somehow specify which format we're storing into. We can just use different procedures directly:\n\nsaveppm_p3\nsaveppm_p6\n\nWe could also have a thin wrapper and specify it with the format argument:\nsubroutine saveppm(filename, img, format)\n  ...\n  if (format == 'P3') then\n    call saveppm_p3(filename, img)\n  else if (format == 'P6') then\n    call saveppm_p3(filename, img)\n  else\n    call error_stop()\n  end if\nend subroutine saveppm"
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 20:44:59+00:00",
                    "text": "Let's use stdlib_experimental_io for now. I would use stdlib_experimental_image if we plan to support more image routines. In SciPy it is in scipy.misc. Also, SciPy and Matlab calls this imread. However, their imread can read all kinds of image formats. Since we will only do PPM at first, I think it's fine to call it load / saveppm. We can later add imread as we support more formats.\nRegarding the API, I agree with your choice. I would further make the format argument optional, and if it is not present, probably choose P6 (binary) as the default.\nP.S. Isn't format a \"reserved\" word? If so, you can use fmt instead."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-24 22:43:24+00:00",
                    "text": "Isn't format a \"reserved\" word? If so, you can use fmt instead.\n\nI don't think Fortran has reserved words. fmt is also a keyword in read() and write() statements. I do prefer fmt here because it's shorter and clear what it means.\nI like the idea of P6 as default."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-25 10:58:25+00:00",
                    "text": "For some applications I had in the past a graymap PPM (P2 or P5) would have sufficed. Specifically, I could use a ppm as a porosity map in a Lattice Boltzmann simulation. Since these only require a rank 2 array (i and j image coordinates) vs a rank 3 array (i, j, and rgb) it would be easy to support these too."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2019-12-30 19:56:32+00:00",
                    "text": "FYI: pure Fortran gif (even animated) library here: https://github.com/jacobwilliams/FGIF"
                },
                {
                    "user": "certik",
                    "date": "2019-12-30 19:58:44+00:00",
                    "text": "@jacobwilliams this is great! It might not be that difficult to provide pure Fortran readers / writers to other image formats also."
                },
                {
                    "user": "gronki",
                    "date": "2019-12-31 17:53:53+00:00",
                    "text": "IMHO this is easily implemented as part of the ecosystem with iso_c_binding to currently existing libraries. There is no need complicating stuff by making competing solutions in stdlib (even for ppm). And one would need unsigned types to make it work in any decent way."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 18:02:16+00:00",
                    "text": "There is no need complicating stuff by making competing solutions in stdlib (even for ppm). And one would need unsigned types to make it work in any decent way.\n\nOften there is a compelling case to write something in Fortran so that the community can contribute and fix it, but for certain cases, especially file formats, if there is a widely used existing library that stdlib can provide a Fortran interface for then that reduces complexity and reduces maintenance burden, while ensuring a higher quality of implementation.\nIn this particular case we should be pragmatic and include implementations only where:\n\nThere is already a popular and well tested Fortran version we can adopt\nIt is easy to write and maintain (e.g., PPM)\nThere is no suitable extant implementation for which a Fortran interface can be created"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-31 18:11:19+00:00",
                    "text": "@gronki Can you list C library candidates? I know of stb and libpng. What do you have in mind?\nWe should absolutely weigh-out the complexity of pure Fortran vs. C-interop implementations. In case of ppm, the pure Fortran implementation is so simple that I can't imagine a similar Fortran-C interface would be any simpler. I may be wrong though.\nInvolving any external C library would add the complexity of a dependency. While I'm not against external dependencies in stdlib (Python has them), I think we should consider them as a last resort."
                },
                {
                    "user": "gronki",
                    "date": "2019-12-31 18:39:50+00:00",
                    "text": "But is reading and writing ppm's worth the burden of the maintenance? Don't get me wrong but it's not a serious image format. PPM is short for \"i don't feel like googling libpng manual\". I see no value of having a ppm implementation but maybe my opinion is isolated.\nI have never heard about stb before. I personally used libgdal, libpng and cfitsio in my field (from Fortran). All of them mature, stable and insanely easy to use by iso_c_binding (or even to wrap in a derived type). (edit: Actually, cfitsio has a f77 interface included.) I think it would be nice to have a stable and up-to-date bindings as a part of the ecosystem (whether they make it into stdlib or not) but I see absolutely no need to put any effort in implementing a worse version of what is already done.\nOne a side note, I feel that not having certain bindings for popular format handling libraries is the actual problem we are trying to solve here. Fortran does have PNG or JPG handling. But it takes too much effort (one has to write their own binding rather than have a ready-to-use interface such as C or Python)."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 18:53:50+00:00",
                    "text": "We should absolutely weigh-out the complexity of pure Fortran vs. C-interop implementations. In case of ppm, the pure Fortran implementation is so simple that I can't imagine a similar Fortran-C interface would be any simpler. I may be wrong though.\n\n@milancurcic Exactly how I feel. Well said.\n\nInvolving any external C library would add the complexity of a dependency. While I'm not against external dependencies in stdlib (Python has them), I think we should consider them as a last resort.\n\nThis is very true. But in the case where an external library already does it---and does it well---and adding a roll-your-own implementation in the standard library adds unacceptable complexity, then I think a choice should be made about either:\n\nCreating an interface for the extant external library\nNot including it in the standard library\n\nElon Musk recently said something like this when talking about SpaceX Starship:\n\nThe best design is an un-design. It has no moving parts, no points of failure, no maintenance and development costs, no documentation to write or protocols to create and follow.\n\nObviously we want convenience and utility in a standard library but it needs to be provided in a sustainable way.\n(And, yes, I know Musk is a bit mad, but he has some moments of wisdom/genius.)"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-31 19:11:30+00:00",
                    "text": "But in the case where an external library already does it---and does it well---and adding a roll-your-own implementation in the standard library adds unacceptable complexity, then I think a choice should be made about either:\n\nCreating an interface for the extant external library\nNot including it in the standard library\n\n\nI agree! It seems to me that any format that would need compression like zlib would fall into one of these two categories. (if we need to include zlib as a dependency, this lowers the bar to entry to an external image library as a dependency as well).\n@gronki Let's focus on PNG and libpng -- do you have example interfaces that we can look at? Would you like to contribute them to stdlib?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 22:47:54+00:00",
                    "text": "The idea of PPM is that they made the format simple enough so that anybody can easily read and write it from any language. Then you can use external tools to convert it to more common formats.\nThe cost of any dependency should not be underestimated. For example, I would suggest to make such dependencies optional, at least initially. Not every (future) user of stdlib wants to use images, and having them require to install 10 libraries for the 10 image formats that we will support (but they don't need), that I think is not worth it."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-01 09:24:41+00:00",
                    "text": "I would suggest to avoid non-optional dependencies as much as possible, except if there are installed on several OSes per default (or are very common and expected to be already installed).\nOtherwise, if a user wants to use stdlib that depends on (exotic) dependencies, on a machine on which he is not an admin (e.g. on a HPC), that user may have issues to install the depencies and stdlib itself. stdlib should help the user with Fortran, not to learn him how to install various libraries (automatically or not;locally or not).\nHaving said that, I also think we should avoid to \"translate\" existing and well-developed C-librairies into Fortran.\nOptional dependencies would then be a good solution IMHO."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2020-01-02 19:22:20+00:00",
                    "text": "I also agree that we shouldn't re-implement rock solid libs written in other languages (I was also thinking of something like libcurl). The stdlib CMake project needs to be set up so that if you don't have some external lib installed, it builds it without that component.\nBut, also keep in mind that this is a volunteer project. If somebody wants to spend their time writing the world's most amazing Fortran PPM interface, I have absolutely no objection to them doing that. :)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 19:47:50+00:00",
                    "text": "Looks like we are all in agreement on the following:\n\n\nLet's figure out the natural API, no matter how it is actually implemented\n\n\nLet's start using external libraries optionally to implement as many formats as we can. This should always be available as an option.\n\n\nLet's also have pure Fortran backends, as people voluntarily write them. (E.g., the PPM one is already written.) Setup our CMake / Make so that people can choose which one to use (whether our \"reference\" pure Fortran implementation if available, or a 3rd party library if available).\n\n\nLet me know if you all agree with the above, and if you think this will satisfy everybody."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-27 00:48:18+00:00",
                    "text": "M_pixel\nwas designed as a simple self-contained vector library for PPM files for use in a graphics class.  The Fortran-based GIF utilities mentioned previously worked great in conjunction with it for making simple GIF and animated GIF examples.   PPM is very good (of course) for programs that are basically manipulating pixels; this could use some polish and needs a higher-level axis routine added, and prettier fonts but if anyone ones something in self-contained Fortran to start with feel free to take a look.\nIn a batch environment the venerable NetPBM and ImageMagik filters worked seamlessly to convert the PPM files to just about any image file format around. With command-level packages like that the PPM format was basically just as good for single-image graphics files as any other, and easiest to convert to other formats. It is a bit verbose so it was almost always converted to something else on the spot.  We actually let the programs write multiple images sequentially to a single file and then split them with a post-processor to make multi-plot formats like Adobe PDF. The main irritation with PPM files is they are only designed to represent one frame.\nIt was designed to be compatible (Originally) with the VOGLE/M_graph library, which supports a lot of vector output formats but very little pixel-level graphics; so anyone that used VOGLE in the past\nshould find it very familiar."
                },
                {
                    "user": "vmagnin",
                    "date": "2020-06-28 13:11:05+00:00",
                    "text": "2\\. Let's start using external libraries optionally to implement as many formats as we can.\n\n\nThe C GdkPixbuf library can save files in \"jpeg\", \"png\", \"tiff\", \"ico\" or \"bmp\":\nhttps://developer.gnome.org/gdk-pixbuf/stable/\nSee my Discourse post for a Fortran example:\nhttps://fortran-lang.discourse.group/t/making-computer-graphics-in-fortran-without-gui-just-creating-a-png/"
                }
            ]
        },
        {
            "number": 44,
            "user": "gronki",
            "date": "2019-12-23 19:59:21+00:00",
            "title": "packaging ecosystem experiment",
            "text": "Sorry if this post is irrelevant to this repo. I am posting here because I understand people here are mostly package maintainers, so I think it's the right recipients for this post. I can move away to not mess this place if this project takes off.\nI just saw this repo for the first time and my first fear was \"it is not going to work\". Standard library in C, Python, IDL or other languages I had experience with would hold the most essential functions possible. Here half of the proposals or more are extremely particular features. The do not fit in stdlib. These proposals are awesome but more suitable for packaging ecosystem (that we discussed in the other repo) than an stdlib.\nI am so happy that there is this movement because since I started using fortran I've felt frustration and I thought nobody shared it. Then I realized some people have the same issues and then founders of fortran-lang project have made the amazing effort to organize these chaotic movement into streamed and targeted action. Since it's Christmas time I wanted to express my thankfulness for this from the bottom of my heart.\nI wanted to ask if anyone is willing to participate in a following experimental project.\nHow about we try to take a dozen of packages (each of us created or maintains at least one) and attempt to make an experimental packaging ecosystem that will hold all of them. So we use currently existing and mature tools (make, gcc, gfortran) just to make it work on one platform (I think it should be linux/unix because it's the easiest and free). If that takes off and we reach the critical mass, we might expand to cover all needs (Windows, other compilers).\nI am willing to put my effort (as I have a bit of free time now), however I have had no experience with packaging other than pypi and rpm (which is mostly binary packages). I know some people have mentioned they worked with some of source based packaging systems that could work for Fortran.\nIn this issue, instead of discussing whether it's a good idea or not, I would like to collect suggestions and advice of tools and solutions that would make it possible in the fastest time.\nWe need:\n\npeople who have experiences with packaging systems to share them and/or use their expertise to help setting things up\npackage developers/maintainers that are willing to add their packages\npeople who can provide some basic infrastructure for testing (I can share my RPi server for the start)\nusers to test the solutions\n\nAgain, despite my personal feels, I do not want to argue which of the solutions (stdlib vs packaging ecosystem) is superior. I just want to make a demostration working product in a short time.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-23 20:07:10+00:00",
                    "text": "@gronki thanks for taking part of our repositories by providing feedback and suggestions and ideas.\nRegarding the core of this issue, isn't this a duplicate of j3-fortran/fortran_proposals#55? If so, let's close it and move the discussion there?\nFor the record, I think we need both a standard library, and a packaging ecosystem (like Python, Julia or Matlab has). These are orthogonal efforts."
                },
                {
                    "user": "gronki",
                    "date": "2019-12-23 20:22:08+00:00",
                    "text": "I wanted to make it a separate thread but I might as well continue in the other one. Whatever you decide. :)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 20:32:54+00:00",
                    "text": "We can keep discussing here. Building upon what has been discussed at j3-fortran/fortran_proposals#55, what exactly is your proposal?\nBuild a new source distribution? How will it differ from Spack?\nBuild a new binary distribution? How will it differ from Conda?\nOr to contribute Fortran packages to either Spack or Conda together with any possible fixes for Spack/Conda to make them work better with Fortran?\nOr something like Pip or Cargo or the Julia package manager, which seem to be a mix of source and binary packages?\nThe issue is that most Fortran codes depend on non-Fortran packages such as Lapack, FFTW and others, and so we have to package those also."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-23 21:26:43+00:00",
                    "text": "Great idea, thanks Dominik. I agree with Ondrej it's an orthogonal effort to this (stdlib), but I do see it fitting as a separate project in fortran-lang, alongside stdlib. It's good to discuss it here. Stdlib wouldn't compete with packages provided by the package manager, it would be one of them. See how many packages there are just on GitHub: https://github.com/fortran-lang/stdlib/wiki/List-of-popular-open-source-Fortran-projects.\nFrom the surface, it does seem like Spack is the best candidate for this, though I haven't used it so I can't say from experience. From description of what it does, it seems most appropriate to me."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-23 21:31:09+00:00",
                    "text": "Standard library in C, Python, IDL or other languages I had experience with would hold the most essential functions possible. Here half of the proposals or more are extremely particular features. The do not fit in stdlib.\n\nGreat! Each proposal issue is exactly there so that we can all say we want this in stdlib or we don't want this. This is such a young project (8 days I believe) that I didn't catch a breath to open some proposals for what I'd like to see in stdlib (but I will soon :)).\nPlease join us! We need to hear from everybody what should stdlib look and act like, made by community, for the community. We don't have the answers yet and we're learning along the way."
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 22:01:54+00:00",
                    "text": "As I mentioned in j3-fortran/fortran_proposals#55, unfortunately Spack does not run on Windows, which is a deal breaker. However, Spack shows what it takes to make a successful source distribution --- it's not easy at all.\nHowever, Spack, Conda and similar solutions are general solutions that work for any language. I feel that there is still a need for a language specific solution (Pip, Cargo, Julia Pkg, ...). This is something that we have a chance of implementing. Here are some ideas:\n\n\nMany Fortran packages that people create are pure Fortran (including, at the moment, this stdlib). 90% of the time, we always need to do the same --- specify Fortran module dependencies (for Make, or let CMake figure them out), build the Fortran files with the given compiler in the correct order and the correct options (typically either Debug or Release, specific to each compiler), and then typically build a shared or static library or an executable. For example I think the vast majority of Python packages at https://pypi.org/ are just pure Python packages. So for pure Fortran packages, we can create our own packaging solution --- initially it would be just some TOML or YAML file that specifies a list of Fortran files together with some meta information. Then the packaging tool can take this and generate: Makefiles, CMake, Conda and Spack packages, etc. All the complex stuff like locating the proper Fortran compiler on each platform (i.e. depending on the right Spack or Conda compiler package) is the same for all pure Fortran packages and so can be encoded in our \"tool\". In particular, I am 100% confident we can write a \"tool\" to get pure Fortran packages building reliably on all platforms including Windows and depending on each other.\n\n\nWhat about the non-pure Fortran packages (the vast majority of codes at https://github.com/fortran-lang/stdlib/wiki/List-of-popular-open-source-Fortran-projects) and what about non-Fortran dependencies (again the vast majority of those codes) such as MPI, FFTW, etc.? That's the hard part. A pragmatic approach would be to use another package manager for these, such as Conda or Spack, or apt-get. Our \"tool\" can even support many of these. Then in our \"tool\" TOML description for a non-pure Fortran package, one would specify the dependencies as Conda, Spack or apt-get packages.\n\n\nWe need to brainstorm all the details here.\nLet's take FFTW as an example. Our \"tool\" can have a package for FFTW, described as TOML. In the TOML description, we would list how to install the package using all backends that our \"tool\" supports, that is, it would look like this:\n[install]\nconda=\"fftw\"\napt-get=\"libfftw3-dev\"\nspack=\"fftw\"\nyum=\"...\"\napk=\"...\"\nand our \"tool\" would know how to use all these backends to install the package. On each platform the user would select a preferable backend, and our \"tool\" would know how to either install, or check that fftw is installed, and if not, tell the user \"please install fftw by apt install libfftw3-dev\". So this mechanism should work to ensure fftw is reliably installed on all platforms. I expect that there will be differences how apt-get versus conda installs fftw, so our fftw package in our \"tool\" will have to have some metadata to correct some stuff if needed for a given backend (for example if apt-get installs some files in some wrong location, then our \"tool\" must know where to find them).\nSummary of the idea: our \"tool\" can be a source distribution for pure Fortran packages, and it would piggy back on other general package managers for non-pure Fortran dependencies.\nFinally what about most of the codes at https://github.com/fortran-lang/stdlib/wiki/List-of-popular-open-source-Fortran-projects that have both non-pure Fortran dependencies and are themselves a non-pure Fortran package? I don't have an answer right now. Part of the answer is that those codes are typically end applications. If one has a complex Python based application (such as https://www.sagemath.org/), that will be hard to package as a pip package also. So end applications will have their own complicated build system and distribution. They could still use our \"tool\" to install and manage most of their dependencies, and our \"tool\" should make that easy."
                },
                {
                    "user": "gronki",
                    "date": "2019-12-23 23:11:22+00:00",
                    "text": "Windows is unfortunate, but Windows users can still install packages the \"old way\". To use the package manager, it is possible install one of the few popular linux distros using Windows Subsystem for Linux. We should make sure that the package system works with that.\nActually my idea was exactly what @certik described: in the first and foremost step, it should be a tool allowing to manage dependencies. In the second step, it can be used to distribute small apps (in general, apps that can be easily encapsulated and packaged). The biggest packages will certainly be a challenge and at this point it's hard to predict all the issues that will come up.\nI would certainly prefer not reinventing the wheel and using one of the existing solutions. Writing our own tool would be possible but we will certainly make so many mistakes that others have already made I am not sure if we have human resources for this. Also, as I understand, spack already contains lots of typical HPC codes in its repository, which would greatly diminish the problem of having to package LAPACK, MPI etc.\nIf we decide to write our own tool, IMO the tool should be absolutely minimal in my opinion and only handle things that cannot be done in a different way. So generating Makefiles, package information etc should be the responsibility of the developer. Again, all about human resources and maintenance.\nI'm currently torn between the two (spack/conda vs own tool), let's wait for more voices. :)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 23:54:20+00:00",
                    "text": "Re Windows: I am afraid the Windows Subsystem for Linux is not an acceptable solution --- some people cannot use it, and those will be left out. I think the right solution is to build and install natively. It's actually not that hard, and cmake has great support on Windows.\nOne issue with Conda, being a binary package manager, is that it uses gfortran. So if you want to build with Intel Fortran, you are out of luck and you can't reuse any dependencies from Conda build with gfortran. Spack fixes this issue by allowing you to choose a compiler for all the dependencies. But it doesn't work on Windows.\nI personally just use Conda, as at least it works everywhere, even if with just one compiler."
                },
                {
                    "user": "pdebuyl",
                    "date": "2019-12-26 10:15:54+00:00",
                    "text": "There is also the use case (not discussed above if I understand well) of having the packages already available. On HPC systems, packages are often available by loading the compiler environment or by using the module system. In that case, the \"tool\" should make sure that the libraries are found and compiled.\nAlso, regarding build systems, I wrote on my experience with git and CMake here: http://pdebuyl.be/blog/2018/fortran-cmake-git.html I think it is relevant for packaging in the sense that it should cover all pure Fortran packages, as well as Fortran/C packages."
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 00:20:08+00:00",
                    "text": "I would like to move this forward. I think we have a sufficient community around stdlib now that we can pull this off. Here are my current ideas:\n\nI will study Rust's Cargo in detail. I think it is the closest to what we want\nLet's restrict and agree upon a \"standard\" how to write Fortran packages, that the \"tool\" would understand. That's why we need to do it as a community. Part of this is:\n\nSet directory layout\nRestriction that module name is the same as filename and that each file is either a module, submodule or a main program\nWhere tests are and how they are named\n... whatever else is needed to reduce complexity, and thus make the \"tool\" doable\n\n\nLet's start with pure Fortran, then later figure out how to do mixed Fortran / non-Fortran projects\nInitially only pure Fortran dependencies, later we will figure out how to do non-Fortran deps\nIt must work on Linux, macOS, Windows and HPC (compatible with the typical \"module\" setup on most HPC systems)\nThe \"tool\" would understand that it is building a Fortran project and understand the above package \"standard\" and all the semantics. Just like cmake understands more semantics than make, and thus it is simpler to use, this \"tool\" would be even higher level than cmake. All the Fortran specific compiler and platform details would be encoded.\nIt would be able to generate a build system as a backend, for example it could generate the current CMake as well as the current manual Makefile system in stdlib.  It knows all the semantic information to be able to do that.\n\nWho would have time to help me brainstorm some of these ideas in more detail and help me with coding and then especially testing?\nHere is some FAQ:\n\nHow is this different to Spack or Conda? None of them know about Fortran, so they do not know the semantics of the Fortran project. That's why Rust has Cargo that knows the semantics. Our \"tool\" can generate a Spack or Conda package as another backend (besides cmake and manual Make)\nHow is this different to CMake? CMake knows a lot about Fortran, but not enough. It must work with any setup. Our \"tool\" will restrict how a Fortran package is structured, and take advantage of it. Just like CMake could know about Rust, but Rust still has Cargo, because Cargo knows more, and thus is easier."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 07:12:08+00:00",
                    "text": "Here are some relevant blog posts about package management in Rust vs C++:\nhttps://blog.pierre.marijon.fr/why-i-stopped-c/\nhttp://cliffle.com/blog/m4vga-in-rust/\nI only used Rust as a user so far, not a developer, to compile some end applications. And the experience was very smooth. I think we can create something similar for Fortran."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-05 18:23:46+00:00",
                    "text": "I'm in.\nI agree that Cargo is most like what we're looking for.\nAdditional levels of complexity that we'll have over Cargo:\n\nAll Rust packages start with Cargo in mind, whereas Fortran packages are all built a bit differently, even within a single build system like CMake or autotools\nThere's one Rust compiler vs several Fortran compilers. Different Fortran packages will have different levels of compiler support\n\nShould fpm (Fortran Package Manager) expect libraries to fit it, or should fpm adapt to different structures and build rules of projects? I think the latter -- more difficult to implement but it would allow us to have a larger ecosystem.\nAnother consideration: should fpm require packages to maintain a \"registry\" file (yaml, toml or whatever we choose) or would the complete build rules be maintained solely on fpm end?\nLet's set some specs for the MVP. I suggest:\n\nCan install stdlib from GitHub\nCan list available and installed packages (will be only stdlib for start)\nCan show help/available options\nSupports one compiler (gfortran) and one build backend (cmake) initially"
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 20:19:52+00:00",
                    "text": "Here is what @milancurcic and I agreed on so far:\n\nFpm would be both a package manager and a build system\nIt would use CMake (and possibly also Make) as backends\nThere would be a configure file, let's call it (for now) fpm.toml, where one specifies the Fortran files and any other metadata that fpm needs.\nCMake would be hidden from the user --- fpm would call appropriate cmake commands, but the user would interact with fpm.\nfpm would be able to install all dependencies into per project basis, like Cargo does"
                },
                {
                    "user": "certik",
                    "date": "2020-01-09 18:49:44+00:00",
                    "text": "Ok, I've started playing with Rust, or to be specific, with Cargo, which is their build manager. Here is how to get an overview what it does:\nhttps://doc.rust-lang.org/cargo/guide/index.html\nand in particular, Cargo assumes this layout:\nhttps://doc.rust-lang.org/cargo/guide/project-layout.html\nand here are more details about it:\nhttps://doc.rust-lang.org/cargo/reference/manifest.html#the-project-layout\nAnd I suggest we do something very similar (if not exactly the same) for Fortran. Cargo pretty much figures out which files to build and which binaries and libraries and tests and examples all automatically, even for large projects. So fpm would understand the structure, and then it can generate CMake or Make or any other build system to actually build it, and later on it can even build the project itself.\nI need more time to learn Cargo and get experience using it and also Rust itself, so that I can see how this can be adopted for Fortran. So I need some project to learn this, so I was thinking I'll implement a prototype for fpm in Rust itself. That will allow me to get enough experience with it. Regarding which language to use for the production version of fpm, here are the requirements for fpm:\n\nsingle binary\nworks on Linux, macOS, Windows and HPC machines\nquick to start (it's a command line tool, so it must be very fast)\n\nSo Python is out, because it's hard to create a single binary and to make it start and work quickly, as well as to distribute all the dependencies and ensure they work. I was going to use C++. But if the Rust prototype goes well, Rust would also work I think --- the advantage over C++ is that Rust has all the nice (easy to install!) packages to handle TOML, downloads, filesystem, etc."
                },
                {
                    "user": "scivision",
                    "date": "2020-01-09 20:03:38+00:00",
                    "text": "Requests:\nCMake generator selection\nallow for different CMake generators that consumer of fpm packages can specify. E.g. Visual Studio, Ninja, GNU Make. With CMake >= 3.15, the end-user can set environment variable CMAKE_GENERATOR.  Maybe CMake Generator could be an fpm command line option.\nallow non-CMake backends\nSome major projects have switched away from autotools/make to meson/ninja. I think it would be good that even if CMake is the primary fpm choice, we don't make fpm so intertwined with CMake that fpm can't build non-CMake projects. This could be done a couple different ways, maybe even via CMake ExternalProject calling Meson."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-09 20:12:13+00:00",
                    "text": "@scivision Yes, good and important point, Ondrej and I discussed this briefly. Eventually, CMake would be one of possible backends, and each could have their own backends (or.... generators? Confusing name IMO). The challenge, of course, would be to design fpm with the possibilities in mind."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-09 20:16:07+00:00",
                    "text": "@certik +1 for Rust. Another potential candidate could be Go, which I hear is simple to learn and program and has great networking and system facilities built-in.\nI'll be happy to learn and participate in this project regardless of the implementation language."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-09 20:18:47+00:00",
                    "text": "In addition to requirements for fpm that @certik listed, I think it's important to also consider further design and implementation requirements:\n\nNetworking is built-in and easy to use\nFile system manipulation is easy to use"
                },
                {
                    "user": "certik",
                    "date": "2020-01-09 22:04:40+00:00",
                    "text": "Yes, I need to look at Go more --- I used it a few times and I wasn't impressed with their dependency management. But as an implementation language for fpm, it would also work and perhaps be even better, because Go is I think much easier to learn than Rust.\n@scivision yes, it should be able to work any backend as you described. However, I want to point out, that just like Cargo works, fpm would be only responsible for building pure Fortran parts of the package / application. And for the pure Fortran part, fpm would have a few backends (Make, CMake, Meson, Ninja, ..., as well as its own), but the backend would generate the CMake files to build the project. It would not reuse your own hand written files.\nSo for already existing projects, they would have two options:\n\nsimply continue using their current build system, and from fpm's perspective they would simply look like non Fortran part of the project; and as you said, we should make sure fpm is well aware how to call into CMake automatically, so that in most cases things just work\nor they would migrate to fpm (by migrating their directory structure and filenames, writing the appropriate fpm.toml and removing their hand written CMake files, and then fpm would be responsible to building it). In this mode, you would not even know it is using CMake underneath (well, you would see the left over cmake files), it would be fpm's responsibility that things build (no matter what backend it uses underneath).\n\nI am still figuring out how Cargo handles non-Rust parts, but it seems you are responsible for building them yourself (using any build system you want), and probably you specify how to link them in."
                },
                {
                    "user": "certik",
                    "date": "2020-01-12 23:07:54+00:00",
                    "text": "@milancurcic here is a very minimal prototype: https://gitlab.com/certik/fpm. Can you try it out (see README) and let me know what you think? Let's discuss it and brainstorm some more.\nOverall, I must say I really like the Rust ecosystem, the package manager (Cargo) etc. There are libraries for anything that we would need. I would like exactly the same for Fortran. Regarding the Rust language itself, I think for what we need we don't seem to require any advanced features (such as the borrow checker) and so it's actually not difficult to learn. And the Rust compiler provides excellent error messages."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-12 23:35:56+00:00",
                    "text": "Great! I'll play with it and let you know."
                },
                {
                    "user": "certik",
                    "date": "2020-01-13 17:52:03+00:00",
                    "text": "@milancurcic once you have a look at it, I mainly need your feedback on:\n\ncan we make this work in general?\n\nIf the answer is yes, then I suggest we create a new repository fortran-lang/fpm and start brainstorming there, as there are a lot of orthogonal issues that we have to discuss. Until then, I'll use this issue.\n\n\n\nHosting of packages: for now we will not have our own maintained central place such as crates.io (that will come later). For now we will use a git repository (GitHub, GitLab and other places will work) as well as just url for a tarball. That way we don't need to host anything ourselves at first. (fortran-lang/fpm#4)\n\n\nHow to support packages that do not conform to our \"standard layout\" (to be specified...). Some examples of such a package would be reference Lapack, or Arpack. The way to do that is that we create a new repository, say certik/lapack.fpm, which will have fpm.toml, in there it would specify the url to the actual sources (https://github.com/Reference-LAPACK/lapack) and a build script, which would build the sources (using CMake in this case) and install them into some $PREFIX provided by fpm and fpm takes it from there. This approach also works for non Fortran packages --- the build script either builds it, or requires it from the system (where it can be provided by, e.g., Spack). Either way this is a clean way to hook this up into the fpm ecosystem. (fortran-lang/fpm#6)\n\n\nNaming of fpm.toml. Cargo names Cargo.toml with capital C, and as explained in https://doc.rust-lang.org/cargo/faq.html#why-cargotoml, to \"ensure that the manifest was grouped with other similar configuration files in directory listings. Sorting files often puts capital letters before lowercase letters, ensuring files like Makefile and Cargo.toml are placed together.\" If we want to do the same, the candidates are Fpm.toml and FPM.toml. I think fpm.toml looks better. But using a capital letter would make it similar to CMakeLists.txt also. We might want to devise a different name or naming scheme. Any ideas? (fortran-lang/fpm#5)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-14 02:40:31+00:00",
                    "text": "I played with it. So far so good. I've also built a few Rust projects in the past so this experience was similar. A bit strange was that the test examples were included with the package manager, but I understand that this is a minimal proof of concept.\n\ncan we make this work in general?\n\nYes! It will be a steep climb but I don't see why it wouldn't work from a technical point of view. Building a rich ecosystem is a different story but we need to start somewhere. Please go ahead and create fortran-lang/fpm.\nLet's discuss your specific questions/issues there. I have some ideas."
                },
                {
                    "user": "certik",
                    "date": "2020-01-14 04:44:53+00:00",
                    "text": "Thanks for the review, I'll start a new repository.\n\nWhere would you include the tests if not in the repository? Testing will be essential to ensure fpm works in all cases.\n\u2026\nOn Mon, Jan 13, 2020, at 7:40 PM, Milan Curcic wrote:\n I played with it. So far so good. I've also built a few Rust projects\n in the past so this experience was similar. A bit strange was that the\n test examples were included with the package manager, but I understand\n that this is a minimal proof of concept.\n\n > can we make this work in general?\n\n Yes! It will be a steep climb but I don't see why it wouldn't work from\n a technical point of view. Building a rich ecosystem is a different\n story but we need to start somewhere. Please go ahead and create\n fortran-lang/fpm.\n\n Let's discuss your specific questions/issues there. I have some ideas.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#44?email_source=notifications&email_token=AAAFAWAFBYCR2YH7VI565IDQ5UQZ7A5CNFSM4J6XR34KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEI3B7IA#issuecomment-573972384>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWBKL7QCRIZP62F7AYLQ5UQZ7ANCNFSM4J6XR34A>."
                },
                {
                    "user": "certik",
                    "date": "2020-01-14 06:04:37+00:00",
                    "text": "Here is the repository: https://github.com/fortran-lang/fpm. I moved from GitLab-CI to GitHub CI, for now only Linux and macOS is tested. Tests pass. Let's open issues in that repository and continue the discussion."
                }
            ]
        },
        {
            "number": 43,
            "user": "certik",
            "date": "2019-12-23 19:07:42+00:00",
            "title": "Add initial scope for stdlib",
            "text": "In this PR, let's try to summarize the agreed upon scope from #1. I suggest we keep this very general, because we will have to discuss in each case the details of what should be in, but it would be very helpful to have general guidelines of what the scope is, to guide people when proposing ideas for stdlib.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-23 19:13:27+00:00",
                    "text": "Perhaps we can write it like this:\n\nUtilities (Containers, Algorithms, Strings, Files, OS/Environment integration, Unit testing & assertions stuff, Logging, Searching and sorting, ...)\nMathematics (Linear algebra, Sparse matrices, Special functions, FFT, Random numbers, Statistics, ODE solvers, Numerical integration, Optimization, ...)\n\nand list things that we seem to agree should be part of it, and leave the ... in there to show that more ideas, along the lines of the listed items, are allowed. Instead of Utilities and Mathematics, is there a way to structure the future contents in a few more categories?\nMatlab has nice top level categories and subcategories: https://www.mathworks.com/help/matlab/mathematics.html. In addition to what is in there, we need to have the Utilities (is there a better name?) section listed above. Besides the Matlab list and Utilities, is there anything else we want to include?"
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-23 20:28:20+00:00",
                    "text": "Not sure what \"algorithms\" includes. So maybe something like that:\n\nUtilities (Containers, Strings, Files, OS/Environment integration, Unit testing & assertions stuff, Logging,  ...)\nAlgorithms (Searching and sorting, merging, ...)\nMathematics (Linear algebra, Sparse matrices, Special functions, FFT, Random numbers, Statistics, ODE solvers, Numerical integration, Optimization, ...)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 20:42:00+00:00",
                    "text": "@jvdp1 thanks! I updated the PR based on your feedback."
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 22:22:43+00:00",
                    "text": "@milancurcic any ideas here? This will not be set in stone (we will iterate on this in the future), but I feel we do need at least some general guidelines today of what is in scope, and some general guidelines of what is not in scope.\nHere are some ideas of what is not in scope:\n\nphysics specific algorithms: electronic structure, fluid dynamics, ...\nspecific mathematical methods: finite difference support, finite element support (except  sparse matrices, which are in scope, because they are not tied to a specific mathematical method, but apply to all kinds of fields, such as finite differences, finite volumes, graphs, etc.)\nhighly optimized specific algorithms that require tens of thousands of lines to implement, such as OpenBlas --- if the algorithm and infrastructure requires a project on its own, then stdlib can perhaps depend on it, but it should not be part of stdlib itself.\n\nSome ideas of what is in scope:\n\n\nThings that are applicable to more than one field, and that can be implemented in a single module (preferably) with the order of ~1000 lines (could be a bit more) per feature as opposed to a 100,000 lines per feature, and that can be (preferably) done in Fortran, as opposed to OpenBlas which must be done in assembly.\n\n\nIn some sense, stdlib would contain a \"reference implementation\" of the algorithms, similar to reference LAPACK. We will try to optimize as much as we can of course, in Fortran. Then compiler vendors can provide a highly optimized versions in assembly (OpenBLAS or MKL). We can even provide some highly optimized versions ourselves, as an option, but the pure Fortran reference implementation would be the main and default implementation.\n\n\nLet's discuss this, and finish this PR relatively soon (even if it is not 100% perfect), so that people know what the goal of stdlib is."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-23 23:52:19+00:00",
                    "text": "The categories listed are quite broad and I agree with the overall direction.\nHere are some specific items that I would like to have, most fit within the broad categories listed. First, a reasonable list of items for stdlib -- would be immediately applicable, and libraries already exist:\n\nGeneric linked list and dictionary;\nString functions and perhaps even String type;\nHigh-level interface to I/O (#14)\nInterface to processes (POSIX)\n\nNow, for a less reasonable wishlist, these are the things that I am particularly interested, but may or may not be fitting for stdlib:\n\nA parallel array (abstraction over coarrays);\nReading and writing common image formats, ppm, tiff, jpeg, png (#45);\nInterface to SQL (sqlite would cover most needs, @arjenmarkus has an interface);\nA web client and server, with a stack of common protocols (UDP, TCP, HTTP) (once you have items 1, 2, and 4, this becomes much easier to implement).\n\nThese latter items would take a longer journey, first through their own standalone libraries, and later could be evaluated for stdlib."
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 00:09:12+00:00",
                    "text": "What would be the advantage / use case for 8.? Python does have a basic webserver in the standard library. But I am curious what application Fortran users would like to use a web server for."
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 00:12:36+00:00",
                    "text": "It seems in the first phase, we should only include things for which we already have prior implementations, it's \"just\" about agreeing on the API, and making the implementation complete with regards to all combinations of real and integer kinds and other corner cases.\nFor things that there is no prior implementation, or the implementation is not straightforward, we should probably first have them in separate libraries, and only later consider inclusion into stdlib, as you said."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-24 01:31:49+00:00",
                    "text": "A Fortran web client would allow Fortran programs to read data over the network. This is only becoming more useful as more and more data is stored in the cloud, typically in flat object stores. For example applications, weather (100% Fortran) and ocean (99% Fortran) prediction systems rely on external data that is downloaded periodically. In typical workflows, this is done in some other language or some external tool from shell, like wget or curl.\nThe kind of gluing of tools and languages that is ubiquitous to weather prediction systems (and other similar systems) is not for any other reason but that Fortran is adequate for heavy and parallel compute, but not much more of the workflow -- downloading and storing data, logging, databases etc. If Fortran was adequate for the other tasks, the whole system would be implemented in the same language.\nThis specific example can then be extended to any web service out there that is serving data via HTTP or similar protocol. You make a request, get a JSON dict from it. All of a sudden, Fortran programs have direct access to a zillion existing web services. Great!\nA web server would provide similar, but reverse. If you'd like a Fortran app to serve data (whether it's logging data from an instrument or a parallel CFD solver) to web clients (any tool or programming language -- they all speak the same language), now you can. A single-user use case would be a long-running HPC application that logs progress through the web server. Now you can watch it from your browser, rather than going through your terminal, ssh, and tail the log file.\nA web server + client is a convenient way to interoperate programs written in any language, as long as you properly match their HTTP APIs. Over a network or locally.\nI think this is one of the things where it's not easy to imagine that this would be useful in Fortran, only because it hasn't been easy to do in Fortran, so nobody did it.\nI agree that this is a task for a specialized library for the time being."
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 06:21:05+00:00",
                    "text": "@milancurcic I see. Yes, I think you are right. Being able to create JSON based HTTP API would be very useful."
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 18:12:35+00:00",
                    "text": "Let's keep iterating on this. How about:\n\nIn the first phase, we are trying to stay in pure Fortran and most of these items already have a prior Fortran implementation by various people, and our job is to agree with a wide community on the API. This is our initial scope:\n\nUtilities (strings, files, OS/environment integration and interface to processes, unit testing & assertions, logging, high level interface to IO, ...)\nAlgorithms and containers (searching and sorting, merging, hash tables / dictionaries, ...)\nMathematics (linear algebra, sparse matrices, special functions, fast Fourier transform, random numbers, statistics, ordinary differential equations, numerical integration, optimization, ...)\nReading and writing images (PPM, ...)\n\nThe following items are potential features (they should start as separate projects and we can discuss later if they should be included):\n\nA parallel array (abstraction over coarrays);\nReading and writing more common image formats beyond PPM: tiff, jpeg, png\nInterface to SQL (sqlite would cover most needs)\nA web client and server, with a stack of common protocols (UDP, TCP, HTTP)\n\nHere are example items that are not in scope:\n\nphysics specific algorithms: electronic structure, fluid dynamics, ...\nspecific mathematical methods: finite difference support, finite element support (except sparse matrices, which are in scope, because they are not tied to a specific mathematical method, but apply to all kinds of fields, such as finite differences, finite volumes, graphs, etc.)\nhighly optimized specific algorithms that require tens of thousands of lines to implement, such as OpenBlas --- if the algorithm and infrastructure requires a project on its own, then stdlib can perhaps depend on it, but it should not be part of stdlib itself."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-24 18:23:57+00:00",
                    "text": "Reading and writing images (PPM, ...)\n\n\nShould it not be in utilities? Otherwise, I would create a specific item for I/O operations:\n\"I/O operations: files, high-level interface for IO, reading and writing PPM images\"\n\nphysics specific algorithms: electronic structure, fluid dynamics, ...\nI would write:\n\"field-specific (e.g., physics) algorithm:...\",\nNot everybody programming in Fortran works in physics ;)\n\nFor the rest, I think it is a good first general presentation."
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 19:04:58+00:00",
                    "text": "Good point, let's put images into Utilities for now. It will be PPM only, so I think Utilities is a good fit for it now.\nYes, field-specific is better. Do you have some examples of non-physics fields that we can list there?"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-24 19:34:03+00:00",
                    "text": "specific mathematical methods: finite difference support\n\nI'd argue that basic finite difference (analog to numpy.diff()) would be quite generally useful and in scope. Think of just calculating a first derivative of a time series or a gradient. I agree that this shouldn't cover all the fancy 17th order finite difference schemes, but a simple 1st order diff() would go a long way."
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 19:44:27+00:00",
                    "text": "I'd argue that basic finite difference (analog to numpy.diff()) would be quite generally useful and in scope. Think of just calculating a first derivative of a time series or a gradient. I agree that this shouldn't cover all the fancy 17th order finite difference schemes, but a simple 1st order diff() would go a long way.\n\nYeah, I was thinking that too.\nI just want to have some examples that are clearly out of scope, so that we have some guidelines to prevent growing stdlib into a huge bloated library doing everything."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-24 22:25:28+00:00",
                    "text": "Yes, field-specific is better. Do you have some examples of non-physics fields that we can list there?\n\n@certik A non-physics example: quantitative genetics"
                },
                {
                    "user": "arjenmarkus",
                    "date": "2019-12-27 20:19:14+00:00",
                    "text": "Wrt Milan's point 7: the SQLite interface in my Flibs project (http://flibs.sf.org - yes, I should probably move it to Github ;)) could definitely use a \"facelift\", as the interface implementation predates the ISO C binding that now makes life so much easier."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-29 22:40:22+00:00",
                    "text": "This can be a living document. I think all these ideas are good, and we shouldn't get too hung up on the details quite yet. Providing broad scopes, and some specific examples is certainly worthwhile, and I've liked everything I've seen here. \ud83d\udc4f"
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 18:52:07+00:00",
                    "text": "Looks like we mostly agree. So I am going to merge it, as this is better to have at least some scope in the README than nothing. And we can iterate on this as we go."
                }
            ]
        },
        {
            "number": 42,
            "user": "zbeekman",
            "date": "2019-12-22 22:08:38+00:00",
            "title": "Style guide (see #3)",
            "text": "",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-24 17:55:49+00:00",
                    "text": "Thanks for writing it down. I think this mostly captures the style guide that most people agree on. I left some comments."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-29 21:58:59+00:00",
                    "text": "I've decided to not add the enforcement half of this work quite yet, and let this PR be a place to discuss what the style guide is, before any effort to enforce it is made. (After all, setting style conventions seems to be a necessary prerequisite to trying to enforce any.)"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-30 20:47:13+00:00",
                    "text": "@milancurcic Just out of curiosity, do we want to codify/formalize how code reviews and PRs work? When is it OK to merge? By whom? This gets into a bigger issue: governance, but we can punt on that for a bit."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-30 21:32:47+00:00",
                    "text": "Yes, we should discuss that in #5 and come up with some workflow to start with."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 02:02:04+00:00",
                    "text": "+1 to merge\n\u2026\nOn Mon, Dec 30, 2019, at 7:00 PM, zbeekman wrote:\n @zbeekman <https://github.com/zbeekman> requested your review on: #42\n <#42> Style guide (see #3\n <#3>).\n\n \u2014\n You are receiving this because your review was requested.\n Reply to this email directly, view it on GitHub\n <#42?email_source=notifications&email_token=AAAFAWHMSXCRFYB6FO4UNLTQ3KRSRA5CNFSM4J6NXAAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOVW7PRLI#event-2914973869>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWBC2RRJWNN7BXYQZVDQ3KRSRANCNFSM4J6NXAAA>."
                }
            ]
        },
        {
            "number": 41,
            "user": "certik",
            "date": "2019-12-22 20:01:50+00:00",
            "title": "What CMake version to require",
            "text": "What minimal CMake version should we require?",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2019-12-22 21:18:17+00:00",
                    "text": "I think we should look at the features we want to use in our CMake builds, and then get to the lowest version that satisfies all. I anticipate that of users who have and would use CMake to build stdlib, many don't have the latest version, and some (like me) get their CMake from the OS package manager. When the OS support for CMake runs our, you stay with that CMake version. My version is 3.14.3.\nI don't see this as a general philosophy we should take, but rather an exception we should make for CMake -- it's changing a lot throughout versions, newest versions are not ubiquitous among systems that have CMake, and CMake itself is not ubiquitous among systems in general. For some advanced users, it may be easy to get the latest CMake on their system. For the majority it isn't, from my experience with other HPC users that I've support in the past, and for my readers it's the same. A novice Fortran programmer should have an easy time getting started with stdlib.\n\nIf it's decided not use a suitably new CMake I probably won't be motivated to contribute.\n\n@zbeekman Can you write in more detail what would be suitably new CMake? What are the features that you need? We're not using MPI or submodules yet. Let's worry about updating our CMake system when we do.\nAlso can you elaborate on what do you mean by being motivated to contribute? Do you mean you wouldn't be motivated to maintain somewhat older-version CMake builds, or you wouldn't be motivated to contribute to stdlib at all?"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 21:48:26+00:00",
                    "text": "I think 3.14.3 should be the minimal version due to good submodule support and other bug fixes. As I noted on the PR where @certik and I were discussing this:\n\nIt's trivial to download and install a statically linked, relocatable, pre-compiled binary. On linux the self-extracting script is easy to use and lets you put this in your home directory if you don't have root, or in the \"normal\" location.\nKitware cryptographically signs these so you can be pretty darn confident you're not falling victim to an open source supply chain attack\nYou can always install the latest CMake with pip, into your USERBASE prefix or the system wide site-packages\nIf a makefile is also being maintained and/or we expect consumers to copy sources into their source tree and bring their own build system there is little/no harm in using a newer CMake.\n\nWhile we're not currently using any submodules, separating the interface and implementation helps avoid circular dependencies and makes the builds faster once we have more SLOC.\n\nnewest versions are not ubiquitous among systems that have CMake\n\nvery sad, but true\n\nand CMake itself is not ubiquitous among systems in general\n\nI don't think this is really true anymore...\n\nIf it's decided not use a suitably new CMake I probably won't be motivated to contribute.\n\nSorry, I was getting a little grumpy. But at the end of the day it's so frustrating as a Fortran programmer to be handicapped by lack of good Fortran support in tools, compilers, and open libraries. CMake is one of the few tools out there with GREAT, first class Fortran support. Handicapping my ability to write and build good Fortran simply because user X only has a super antiquated CMake version installed by default on their system would likely lead me to become frustrated and stop contributing all together or fork the project and maintain my own version with a suitably sophisticated build system. Especially given how easy it is to get a binary distribution of CMake and install it in your home directory."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-23 02:09:07+00:00",
                    "text": "Sorry, I was getting a little grumpy. But at the end of the day it's so frustrating as a Fortran programmer to be handicapped by lack of good Fortran support in tools, compilers, and open libraries. CMake is one of the few tools out there with GREAT, first class Fortran support.\n\nNo worries, it happens to all of us, and I agree that CMake offers great first class Fortran support. It's the right tool to build a project like this.\n\nHandicapping my ability to write and build good Fortran simply because user X only has a super antiquated CMake version installed by default on their system would likely lead me to become frustrated and stop contributing all together or fork the project and maintain my own version with a suitably sophisticated build system.\n\nI don't think anybody here in the community wants that. From knowing the community and people involved here so far, I think it's highly unlikely that we'd choose to hold back on some obvious beneficial features of CMake in order to keep one or few users happy. In the end, for users like that, there will be the manual Makefiles, and they'll be able to build one way or another. CMake is here to make a) our lives easier, and b) lives of stdlib users that have a recent-enough CMake. I believe it's part of our mission, and in stdlib's best interest, to make the scope of b) as wide as possible. We can do this by choosing to not enforce the latest CMake, but to use a reasonably recent version that delivers what we need.\nIn summary, to broaden the scope of stdlib users that will build stdlib using CMake (ultimately, I think most of us here prefer that to manual Makefiles), we need to chose the oldest version that we can, while not handicapping any developer's work with Fortran or CMake.\n\nHandicapping my ability to write and build good Fortran\n\nWe need to all get clear and explicit about what are the features we need from CMake. This is exactly what this issue is for. Let's discuss. Zaak, can you spell out exactly what you need from it so that you don't feel handicapped for Fortran development? It's important that we get clear on these so that you can get what you need for your work, and which is supported by the community."
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 03:19:03+00:00",
                    "text": "It's a friction between developers (who want to use the latest language, the latest compilers and the latest tools) and users, who want exactly the opposite: they want our library to work with the compilers they have and tools that they have. And we definitely want to ensure that our code is used by as many users as possible. At the same time, we want to get as many developers as possible. So we have to strike a balance. @zbeekman I think all we are asking is that you try to work with us and I think we can figure out a compromise so that you will get what you want, while our (future) users also get what they want."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-30 07:01:49+00:00",
                    "text": "Sure, I get that users want things to just work.\n\nAnd I don\u2019t disagree with the sentiment. Sometimes you cannot adopt the\nlatest and greatest technology X due to stability, availability, ease of\nuse etc.\n\nThat\u2019s WHY I want to use 3.14.3. I write CMake under the assumption that it\nwill be 3.14.3 or later because of 1) submodule support and 2) bug fixes\nand features that I can\u2019t immediately recall. I have no desire to track\nthese bugs & features down or re-litigate their resolution. At work I\u2019m\nresponsible for the build system, CI and final integration of a large\nFortran based (with C and C++) multi-physics code used at a government\nagency that is required to build and run on macOS, Linux and Windows. My\ndesire to use 3.14.3 or greater is born out of my experience with that\nproject. I don\u2019t remember what was fixed in which particular version of\nCMake, nor do I want to have to remember.\n\nWe don\u2019t have to bump the minimum required version but I can\u2019t promise that\nI won\u2019t accidentally contribute code that requires a newer version. It will\nwork on my machine. It will work during CI. But if a feature that\u2019s not\npresent on an older CMake < 3.13.4 is used then it may fail if someone\nattempts to build with an older CMake. Given the goal to have vanilla\nMakefiles and/or bring your own build system combined with the ease of\ninstalling CMake binaries I cant see how this could possibly be a better\noutcome for users. (Kitware hosts a PPA, you can install the latest CMake\nwith pip or Conda, and they provide relocatable statically linked\nbinaries.) As a user I\u2019d much rather have my build system tell me: go get a\nnewer CMake, instead of having to run down a bug in the build system itself\n(in the underlying tool or the implementation).\n\u2026\nOn Sun, Dec 22, 2019 at 10:19 PM Ond\u0159ej \u010cert\u00edk ***@***.***> wrote:\n It's a friction between developers (who want to use the latest language,\n the latest compilers and the latest tools) and users, who want exactly the\n opposite: they want our library to work with the compilers they have and\n tools that they have. And we definitely want to ensure that our code is\n used by as many users as possible. At the same time, we want to get as many\n developers as possible. So we have to strike a balance. @zbeekman\n <https://github.com/zbeekman> I think all we are asking is that you try\n to work with us and I think we can figure out a compromise so that you will\n get what you want, while our (future) users also get what they want.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#41?email_source=notifications&email_token=AACEIPE4RKHIIYW2HF37FQTQ2AU2RA5CNFSM4J6NIRVKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHQC25Y#issuecomment-568339831>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AACEIPCC7GPNTZMRWCPFDK3Q2AU2RANCNFSM4J6NIRVA>\n ."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-30 16:17:46+00:00",
                    "text": "So, just to summarize I advocate for using 3.14.3 because:\n\nSubmodule support\nIt's what I'm used to\nCMake is very easy to install as a binary, an alternate Makefile system is being provided and users are assumed to just plunk the sources into their own source tree in many cases and bring their own build system\nBy the time lots of people start adopting this library 3.14.3 will be pretty old anyway\nI know there are a number of bugs and other issues that have bitten me in versions prior to 3.14.3 in my extensive experience supporting large Fortran & mixed language apps on the three major OSes including supporting Intel Fortran and MSVS builds on Windows\nI can't keep track of all the fixed bugs, new features, etc. and frankly don't want to put in the effort to test older versions and adapt to not using constructs & features added before 3.14.3\nA user with an old CMake that hits a bug (either in CMake itself or the build system implementation) will be more irritated than a users who is pointed in the direction of upgrading their CMake if they want to use CMake instead of the Makefiles or their own solution."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-30 18:22:50+00:00",
                    "text": "Thanks Zaak, I'm getting a bit better idea on where you are on this.\nMy impression is that many of your concerns about this assume that you'd be the only person maintaining the build system, which I hope doesn't happen considering that we're building a community here. There's already several of us and more people will get involved in time.\nI also understand that Zaak, you implicitly agree that we need some CMake versions for specific features, and not just because, is that right? Your point 1) (submodules) + bug fixes is an important one. Although we're not using submodules yet, we likely will soon. It's worth it to think ahead. In this case, one of us (no pressure on you) could do the research about the minimum CMake version that we need now, and bump it up to 3.14.3 later in 2020 when we start using submodules.\nBtw, I can't find anything about submodules in the release notes for 3.14. Was the submodule support perhaps added before or after 3.14?\n@marshallward @jacobwilliams @ivan-pi @jvdp1 @scivision Do you mind weighing in here with\nyour perspective? I'd like to get as many eyes on this as we can.\nQuestion for everybody: do we really need cmake_minimum_required? What if we didn't enfoce it in the CMakeLists, but stated in the README what is the recommended version? In this scenario, we don't penalize users with CMake versions that can build stdlib but don't meet the cmake_minimum_required.\nThis approach only takes care of the scenario where we enforce some later CMake version that we don't yet need. If we can agree to do the proper research and determine the correct CMake version needed, then we can just require that one."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-30 18:52:02+00:00",
                    "text": "Btw, I can't find anything about submodules in the release notes for 3.14. Was the submodule support perhaps added before or after 3.14?\n\nSubmodule support was added in 3.13 (IIRC) but it was broken/buggy.\n\nQuestion for everybody: do we really need cmake_minimum_required? What if we didn't enforce it in the CMakeLists, but stated in the README what is the recommended version? In this scenario, we don't penalize users with CMake versions that can build stdlib but don't meet the cmake_minimum_required.\n\nYou need it because:\n\nIt influences whether new or old behavior is used for CMake policies. These are a mechanism to change behavior and let projects opt-in to the new behavior over time. So this may have unintended consequences even if the build appears to work, it's conceivable that a difference in policy might cause unintended things to happen at runtime.\nAll policies will be set to old\nCMake adds new syntax and features over time. Using these without setting the correct cmake_minimum_requred means that you're telling your users I promise that your CMake will work with my build system, but then it doesn't.\n\nIn my opinion it's non-optional because it leads to unexpected variability.\nAt the end of the day the goal is to make life easy on users and developers. People have a tendency to hate CMake to begin with. Providing a build system without cmake_minimum_required will inevitably lead to someone using ancient CMake 2.8 and failures galore. Providing an inaccurate cmake_minimum_required will lead to a build failure or misconfiguration that will be much more frustrating than being told up front to upgrade CMake.\n\nMy impression is that many of your concerns about this assume that you'd be the only person maintaining the build system, which I hope doesn't happen considering that we're building a community here. There's already several of us and more people will get involved in time.\n\nWell, I hope to help out a lot, and my fear is more that I will contribute code to the build system that will cause a problem for users down the road. I don't want to write buggy code, and for users to swear off this project (or CMake) because of a mistake on my part. I'm looking forward to working with all of you on the build system and every other part of this project."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-30 18:55:04+00:00",
                    "text": "Fortran submodule: minimum CMake 3.12\nusing this Fortran stdlib as CMake ExternalProject: CMake 3.13 makes this much easier via target_link_directories()\n\nI agree, there were substantial developer and user quality-of-life improvements in CMake 3.13 and 3.14. However to start, I think 3.12 may be enough--let's see if it gets too annoying. That is, consider supporting CMake back to 3.12 until it becomes a real-life issue.\nEnsuring project works with minimum CMake version\nThe method I use to ensure CMake 3.12 is OK is CI using Ubuntu 18.04 that has CMake 3.12. Simultaneously I have other CI images with the latest CMake release.\nancient CMake\nparts of stdlib that don't use Fortran submodule can be supported back to CMake 3.7, where CMake statements can be used to fence off submodule targets like\nif(CMAKE_VERSION VERSION_LESS 3.12)\nCMake older than 3.7 is substantially more difficult to support. I don't have any projects that support older than CMake 3.7. Almost all my Fortran projects require at least CMake 3.12 due to Fortran submodule."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-30 18:58:54+00:00",
                    "text": "if\ncmake_minimum_required(VERSION 3.12)\nis omitted, CMake emits several lines of warnings and proceeds. I think this line should be included to avoid issues with CMake policies as Zaak noted above."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-30 19:02:39+00:00",
                    "text": "So in my opinion, I would start off with minimum CMake 3.12 and then see if:\n\ntoo many users complain about wanting older CMake\ntoo many devs complain about accommodating older CMake"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-30 20:43:35+00:00",
                    "text": "Fortran submodule: minimum CMake 3.12\n\n\nFor the record, significant issues persisted until 3.13.4. I can try to find the bug(s) if anyone really cares, but I do not trust CMake < 3.13.4 to work reliably on all 3 oses with Fortran Submodules."
                },
                {
                    "user": "certik",
                    "date": "2019-12-30 23:28:10+00:00",
                    "text": "I follow a pragmatic approach, that I recommend we follow also:\n\n\nUse the oldest possible CMake that still works on all platforms.\n\n\nIf substantial amount of ugly hacks and code have to be implemented in our CMake files, that would be eliminated if we simply upgraded CMake, then we should strongly consider upgrading CMake, when this case arises, and make the decision which CMake version to upgrade to based on the actual feature needed in a given PR.\n\n\nUntil now this discussion was not relevant, because our CMake build system was clean and worked with old CMake. In #54 the new Windows CI would either require ugly hacks, or an upgraded CMake. As I commented there (#54 (comment)), let's upgrade CMake to 3.14.\n@zbeekman if I may recommend, why not to follow the approach I just outlined above?\nInstead of imposing tools on others that might not be necessary, let's assume that we are all reasonable and let's instead spend our energy and discussions on the actual API of stdlib and other things that actually matter to our (future) users. If some of our tools choice forces us to create complicated workarounds, let's instead upgrade our tools.\nWe have much bigger fish to fry than a CMake version."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-31 00:08:09+00:00",
                    "text": "To have more complete use of Fortran syntax, some of that syntax needs to be tested at build configure time as maintaining whitelists for OS and compiler versions would be an endless task. That would be another clear driver for CMake 3.14 along with the CMake bugs for modern Fortran before CMake 3.14"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 03:50:22+00:00",
                    "text": "Until now this discussion was not relevant, because our CMake build system was clean and worked with old CMake. In #54 the new Windows CI would either require ugly hacks, or an upgraded CMake. As I commented there (#54 (comment)), let's upgrade CMake to 3.14.\n\nI think a lot of the text (NOT quoted here) in that comment is now outdated and conflicts with your edit, @certik. Based on discussion in #54 do we all now see a case for setting the minimum to 3.14? There are other bugs and issues in addition to the reasons mentioned above and in #54 too, but, again, I don't have the time or energy to recall and hunt them all down. (Although, given the amount of back and forth, that might have been less work: you guys are sticklers \ud83d\ude1c.)"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 03:51:35+00:00",
                    "text": "(and if we're in agreement, close this issue... a new one can always be opened if someone wants to downgrade \ud83d\ude31 or upgrade \ud83d\udc7f CMake.)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 07:07:43+00:00",
                    "text": "I think a lot of the text (NOT quoted here) in that comment is now outdated and conflicts with your edit, @certik.\n\nI don't follow.\nMy question is, do you agree with my proposition in #41 (comment), or not? And if not, why not?"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-31 16:15:36+00:00",
                    "text": "and if we're in agreement, close this issue\n\nIMO, no need to rush. Let's keep it open and have the discussion going. Plus, I don't want to hide this thread from the top of the issues page.\nIt's not the specific version number that matters, but the process through which we arrive there. I'm not convinced we've nailed down the process.\nI agree that the Windows tests are indeed important and agree that we can go with 3.14. As a bonus, we get the bug-free submodule, which will be important when we start adding submodules."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 16:26:50+00:00",
                    "text": "I agree. You may safely disregard my comment about @certik's edited post... My point was that when your comment was edited, at one point it seemed inconsistent to me. At the end of the day I agree with you. Thankfully @scivision has pointed out some compelling cases to upgrade the version, where my memory for specifics has failed me.\nPlease accept my apology if you think I've seemed contrary, difficult, arbitrary or cantankerous, that was never my intention.\nAt any rate, I believe we are all in agreement. I agree with everything you (@certik) and @milancurcic have said, and I'm happy that someone else pointed out a few of the concrete reasons why 3.14 should be used. I did not want to bump the minimum version solely to have newer features despite the fact that I couldn't easily point to defects it resolves or needed capabilities it added.\nAs far as the process goes, I completely agree that it should NOT be upgraded unless there is a compelling concrete need. I don't foresee us wanting to version bump beyond 3.14 anytime soon, and should that occasion occur, it will be based on a recent bug discovery or missing feature so it will be easy to articulate & remember at the time it comes up. (In contrast to the ~2 years of running down compiler and CMake bugs for the project I contribute to for work.)\nSo I 100% agree with the general principle of not upgrading unless there is a need. I also fully anticipate being able to express that need with concrete examples should it arise in the future as we work on stdlib.\nWe can keep this issue open if you think it requires further discussion or want other people to weigh in."
                }
            ]
        },
        {
            "number": 40,
            "user": "certik",
            "date": "2019-12-22 19:47:12+00:00",
            "title": "Pretty printing of matrices (and multidimensional arrays)",
            "text": "Currently the standard Fortran's print *, A prints a 2D array A as a 1D list of numbers. Rather, I would like stdlib to have a function print_array (we can discuss a better name) that would print the array as NumPy:\n>>> numpy.arange(10000).reshape(250,40)\narray([[   0,    1,    2, ...,   37,   38,   39],\n       [  40,   41,   42, ...,   77,   78,   79],\n       [  80,   81,   82, ...,  117,  118,  119],\n       ..., \n       [9880, 9881, 9882, ..., 9917, 9918, 9919],\n       [9920, 9921, 9922, ..., 9957, 9958, 9959],\n       [9960, 9961, 9962, ..., 9997, 9998, 9999]])\n\nor Julia:\njulia> B = [1 2; 3 4; 5 6; 7 8; 9 10]\n5\u00d72 Array{Int64,2}:\n 1   2\n 3   4\n 5   6\n 7   8\n 9  10\n\nJulia can also use nice unicode characters for ... and vertical ... if the array is too large.\nThen we should use this function at \n  \n    \n      stdlib/src/tests/loadtxt/test_loadtxt.f90\n    \n    \n         Line 21\n      in\n      ae5591f\n    \n    \n    \n    \n\n        \n          \n           subroutine print_array(a) \n        \n    \n  \n\n and other places.\nThen compilers can perhaps optionally use such print_array as default in the Fortran's language print statement.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2019-12-22 21:43:36+00:00",
                    "text": "My preference is for a format like Julia 's one. It would be also a similar format as savetxt."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-24 19:02:16+00:00",
                    "text": "One prior art - Algorithm 892: DISPMODULE, a Fortran 95 module for pretty-printing matrices\nhttps://dl.acm.org/citation.cfm?id=1486531\nThe code can be downloaded from netlib: http://netlib.org/toms/892.zip"
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-24 22:21:00+00:00",
                    "text": "One prior art - Algorithm 892: DISPMODULE, a Fortran 95 module for pretty-printing matrices\nhttps://dl.acm.org/citation.cfm?id=1486531\nThe code can be downloaded from netlib: http://netlib.org/toms/892.zip\n\nThank you for mentioning this librabry. It seems to be quite complete and flexible. Could we use it (with some modernisations) in stdlib (license?)?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-25 11:18:44+00:00",
                    "text": "Code published in TOMS is under the ACM Software License Agreement which allows usage for non-commercial purposes. I think that it is not compatible with what we want to achieve here.\nI know Scipy contains the TOMS 748 algorithm. I checked and it looks like they wrote their own implementation."
                },
                {
                    "user": "certik",
                    "date": "2019-12-25 14:00:58+00:00",
                    "text": "Yes, unfortunately we can't use their code. But we can at least learn from their thought process when designing their API.\n\u2026\nOn Wed, Dec 25, 2019, at 4:18 AM, Ivan wrote:\n Code published in TOMS is under the ACM Software License Agreement\n <https://www.acm.org/publications/policies/software-copyright-notice>\n which allows usage for non-commercial purposes. I think that it is not\n compatible with what we want to achieve here.\n\n I know Scipy contains the TOMS 748\n <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.toms748.html> algorithm. I checked and it looks like they wrote their own implementation.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#40?email_source=notifications&email_token=AAAFAWHHON7IYCGO345O3XTQ2M6RLA5CNFSM4J6NHD4KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHUIVQQ#issuecomment-568888002>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWDSHGHXBI7DIL2DO4TQ2M6RLANCNFSM4J6NHD4A>."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-25 15:07:41+00:00",
                    "text": "I had a look at the DISPMODULE API and it is indeed very nice and flexible supporting different formats (e.g. with a title, numbered rows and columns, precision, separators) and even printing several matrices adjacent to one another.\nTaking a peak inside I can say that it would be beneficial to first start work on our own string module to handle conversion of reals/integers/logicals to character strings and some tools to parse format strings."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-25 19:20:37+00:00",
                    "text": "Taking a peak inside I can say that it would be beneficial to first start work on our own string module to handle conversion of reals/integers/logicals to character strings and some tools to parse format strings.\n\nI agree with that. I would also add that I think it would be goood to first take a discussion on the issue #35 , because it will be the same problem for this issue #40 (i.e., printing matrices of different kinds).\nAlso, since we not use DISPMODULE, we could base this API on those of savetxt. Afterall, savetxt write a matrix to a file instead to the standard output."
                }
            ]
        },
        {
            "number": 39,
            "user": "zbeekman",
            "date": "2019-12-22 19:45:16+00:00",
            "title": "CI(gha): test w/ multiple GFortrans & macOS too",
            "text": "Replaces #30\nTest GFortran 7,8 & 9 on macOS and Linux\nAlso, install newer CMake on CI using pip.",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 19:53:13+00:00",
                    "text": "@certik This should be ready for review"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 19:54:01+00:00",
                    "text": "I'd like to rebase on the latest commits, and switch to out of source build. But I can do the latter in a separate PR I guess."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 19:55:52+00:00",
                    "text": "This looks great! Thank you. Yes, if you could rebase on top of the latest master, just in case.\nThen in separate PR after this is merged, we can get it working in out of tree builds."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-22 20:01:15+00:00",
                    "text": "Fantastic! Good to merge IMO."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 20:02:48+00:00",
                    "text": "@certik @milancurcic rebased on latest master"
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 20:12:43+00:00",
                    "text": "It's in! Thanks a lot @zbeekman, this is super helpful. Now we just need to get Windows covered, and we'll be in good shape."
                }
            ]
        },
        {
            "number": 38,
            "user": "certik",
            "date": "2019-12-22 19:40:53+00:00",
            "title": "Sparse matrix support",
            "text": "Prior art in other languages:\n\nSciPy: https://docs.scipy.org/doc/scipy/reference/sparse.html\nMatlab: https://www.mathworks.com/help/matlab/ref/sparse.html\nJulia: https://docs.julialang.org/en/v1/stdlib/SparseArrays/index.html\n\nIn Fortran (I keep this list updated with all implementations posted in this issue):\n\n@certik: https://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/sparse.f90\n@jvdp1: https://github.com/jvdp1/libsparse\n@sfilippone: https://github.com/sfilippone/psblas3\n@victorsndvg: https://github.com/fempar/fempar/tree/experimental/Sources/Lib/LinearAlgebra/SparseMatrix\n@danshapero: https://github.com/danshapero/sigma\nhttps://github.com/cp2k/dbcsr\nhttps://github.com/TRIBO-Pprime/MSOLV\nYale sparse matrix package: http://www.netlib.no/netlib/ode/yale.f\n\nI really like the SciPy simple non-OO implementation, and I have ported it to modern Fortran in the link above. If people also want an OO implementation, then it can be build on top as an option.\nOne thing that I found out is that one must sort the indices and the overall speed very much depends on how quickly one can sort it. I ended up using quicksort, but it might be even faster to use some specialized sorting algorithm (such as Timsort) because in practice, the indices have subsections that are already sorted (typically coming from some local to global mapping as in finite elements), but overall it is not sorted.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2019-12-22 22:02:47+00:00",
                    "text": "A non-OO implementation could be an easier start indeed.\nAn issue we may need to discuss about sparse matrices is that NNZ may be larger than integer(4).\nAlso we will need to discuss the formats to support. COO and CRS3 could be a good start.\n\nOne thing that I found out is that one must sort the indices and the overall speed very much depends on how quickly one can sort it. I ended up using quicksort, but it might be even faster to use some specialized sorting algorithm (such as Timsort) because in practice, the indices have subsections that are already sorted (typically coming from some local to global mapping as in finite elements), but overall it is not sorted.\n\nIn my field, entries are added to a sparse matrix in a quite random way. Therefore, the indices are far to be sorted, even in a row. Therefore, I use quicksort as implemented in LAPACK."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 22:06:41+00:00",
                    "text": "@jvdp1 eventually we can support all the formats like SciPy does. It's quite a bit of work, and so for my own work I just did COO and CSR, since I didn't have time to implement the others, but for stdlib, I think we have the manpower to implement all useful formats."
                },
                {
                    "user": "rweed",
                    "date": "2019-12-23 21:12:06+00:00",
                    "text": "For sparse matrix support I suggest you look at the PSBLAS3 project of Filippone and Buttari. Its Object-Oriented Fortran 2003/2008.  Go to\nhttps://github.com/sfilippone/psblas3\nI also recommend you read the papers listed there for ideas about implementing sparse matrix support in OO Fortran and the various \"design patterns\" associated with sparse matrices.\nI like there approach to supporting different storage types. COO is used as input and the \"bridge\" type to all other storage formats. You only write converters to/from COO and your chosen storage format. Reduces the explosion of code trying to go directly from say CRS and other formats. For a \"simple\" sparse grid implementation, I use an approach similar to Java Sparse Arrays which is sorta like a CRS. I find it makes Matvecs simple"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 17:06:10+00:00",
                    "text": "@rweed Thanks for the suggestion! I agree, and have been using PSBLAS in a number of projects for work. I added the suggestion to the list of prior art at the top."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 17:26:03+00:00",
                    "text": "Also, I'm not really sure where this class of sparse linear-algebra routines would belong, but I often see very large tridiagonal, and pentadiagonal systems. To my (admittedly limited) knowledge, there are not many good parallel algorithms for the solutions of these systems and there are not parallel algorithms in extant linear algebra libraries. The best/most promising algorithm that I know of is the SPIKE algorithm, but I've never seen a library that included it. I have a half-decent version specialized for tridiagonal matrices, and would love to see this and any other approaches implemented in the linear algebra portion of the stdlib.\nShould I open a new issue for this, or does it fit within the general sparse matrix support category?"
                },
                {
                    "user": "sfilippone",
                    "date": "2020-01-02 17:29:57+00:00",
                    "text": "As the author of PSBLAS, I am very much aware of the need to sort indices,\nand this is taken care *internally* in my library, so that there is no\nburden on the user.\nAnd no, quicksort is not the best choice. I normally use a special version\nof merge sort, adapted from TAOCP.\nHope this helps\nSalvatore\n\u2026\nOn Thu, Jan 2, 2020 at 5:04 PM Ond\u0159ej \u010cert\u00edk ***@***.***> wrote:\n Prior art:\n\n    - SciPy: https://docs.scipy.org/doc/scipy/reference/sparse.html\n    - Matlab: https://www.mathworks.com/help/matlab/ref/sparse.html\n    - Julia:\n    https://docs.julialang.org/en/v1/stdlib/SparseArrays/index.html\n    - @certik <https://github.com/certik>:\n    https://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/sparse.f90\n    - @jvdp1 <https://github.com/jvdp1>: https://github.com/jvdp1/libsparse\n    - @sfilippone <https://github.com/sfilippone>:\n    https://github.com/sfilippone/psblas3\n\n There are probably many more implementations. I really like the SciPy\n simple non-OO implementation, and I have ported it to modern Fortran in the\n link above. If people also want an OO implementation, then it can be build\n on top as an option.\n\n One thing that I found out is that one must sort the indices\n <https://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/sparse.f90#L185>\n and the overall speed very much depends on how quickly one can sort it. I\n ended up using quicksort, but it might be even faster to use some\n specialized sorting algorithm (such as Timsort\n <https://en.wikipedia.org/wiki/Timsort>) because in practice, the indices\n have subsections that are already sorted (typically coming from some local\n to global mapping as in finite elements), but overall it is not sorted.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#38?email_source=notifications&email_token=AD274TY6ANZGMIDAYNGDX5DQ3YNANA5CNFSM4J6NGRLKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4ICGREGQ>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD274TZUQE4LA53J5SW6ASTQ3YNANANCNFSM4J6NGRLA>\n ."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 17:54:53+00:00",
                    "text": "Thanks @sfilippone for the feedback! Indeed, I also suspect quicksort is not the best choice.\n@zbeekman, I would start with COO, CSR that we all agree we need. Then as we are figuring out the API, let's think how tridiagonal (Lapack has those) and pentadiagonal systems fit in. Also, initially I was thinking of sticking to serial implementations.\nWe'll have to figure out how to best tackle parallel algorithms in stdlib, but I think that's an issue on its own, so I created #66 for it."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 18:27:30+00:00",
                    "text": "@certik good idea. Do you happen to know the name of the Lapack procedure for diagonal matrices? I remember looking for a good serial implementation too and not finding it, but perhaps I was only focused on parallel implementations."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 18:40:20+00:00",
                    "text": "@zbeekman yes, I have used dstevd for eigenvalues of a tridiagonal matrix. If you just need a regular solve, then for example dptsv will do it."
                },
                {
                    "user": "victorsndvg",
                    "date": "2020-01-03 12:38:11+00:00",
                    "text": "I don't know if this could be useful, but in FEMPAR project we have implemented an OO extendible sparse matrix based on Filipone PSBLAS sparse matrix. It's complicated ... but performs quite well.\nhttps://github.com/fempar/fempar/tree/experimental/Sources/Lib/LinearAlgebra/SparseMatrix"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-01-07 21:20:00+00:00",
                    "text": "Then as we are figuring out the API, let's think how tridiagonal (Lapack has those) and pentadiagonal systems fit in. Also, initially I was thinking of sticking to serial implementations.\n\nPentadiagonal matrices can be treated with the banded solvers in LAPACK, but they require a special storage scheme. I have some simple examples available:\n\nBanded (four diagonals): https://gist.github.com/ivan-pi/a9c905065af75362c786c2032ac48c56\nTridiagonal: https://gist.github.com/ivan-pi/9d7af8257392ec7340075d63c738fd79\n\nThe ancient Yale sparse matrix package has routines for ordering and solving both systems of symmetric and asymmetric sparse systems of equations. I don't know if the algorithms they used were any good though.\nA few other Fortran sparse matrix libraries include:\n\nsigma by @danshapero\ndbcsr\nmsolv is a common API to several direct sparse matrix solvers (UMFPACK, SuperLU, MUMPS)"
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-15 17:41:01+00:00",
                    "text": "@certik What is the status of this discussion? From the previous posts I understand that there is a number of related projects, some discussion about technical aspects but it is not clear to me if there is a work started to create this library in stdlib (or even have people decided that this proposal for a sparse matrix library has passed step 1 of the Workflow in workflow.md).\nSorry for what I am missing.\nWilliams"
                },
                {
                    "user": "certik",
                    "date": "2020-05-15 18:02:53+00:00",
                    "text": "@ghwilliams the status of the discussion at this issue as I understand it is that there is a general agreement that we want this, and so now we need to start implementing it, say the COO / CSR subset to get started, then submit a PR with a draft of a specification and then people will comment if they like it or not.\nIt should be designed taking into account the discussion above and all the other libraries as linked at the top post.\nIf you want to go ahead to take a lead on this one, that would be great. I'll help out as much as I can."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-15 19:18:02+00:00",
                    "text": "Ok @certik . I will try to direct the discussion toward more concrete conclusions. So I will follow the workglow.md guide line and move on to Step 2. Defining an API.\nSo, I will post here later some ideas for the API. Anyone else interested could contribute as well. Let's just keep the focus now, as I said, on step 2 of the guideline because I think the step one was already confirmed unless someone comes and say \"Not too fast Williams\".\nLet's move.\nregards\nWilliams"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-15 19:28:57+00:00",
                    "text": "@ghwilliams I agree, let's move! Good to go forward with step 2 (API) as far as I'm concerned.\nI'm happy you're here."
                },
                {
                    "user": "rweed",
                    "date": "2020-05-15 19:45:11+00:00",
                    "text": "Before trying to reinvent the wheel check out PSBLAS 3 which is a parallel Fortran 2003 OOP\nimplementation of sparse matrixes (see http://people.uniroma2.it/salvatore.filippone/psblas and the\nselected publications listed)."
                },
                {
                    "user": "sfilippone",
                    "date": "2020-05-15 19:52:50+00:00",
                    "text": "The psblas software can now be found at\nhttps://github.com/sfilippone/psblas3\nThe design is still being tweaked, it is very stable as far as the \"serial\"\n(or, intra-node) part is concerned.\nFor the MPI part, I have some ideas in mind in terms of improvements of the\nAPI, which I plan to tackle later on.\nAny suggestions and discussions are welcome.\n\nSalvatore\n\u2026\nOn Fri, 15 May 2020, 21:45 rweed, ***@***.***> wrote:\n Before trying to reinvent the wheel check out PSBLAS 3 which is a parallel\n Fortran 2003 OOP\n implementation of sparse matrixes (see\n http://people.uniroma2.it/salvatore.filippone/psblas and the\n selected publications listed).\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#38 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD274T7E56VMBU5PQGXGSZTRRWLVLANCNFSM4J6NGRLA>\n ."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-15 19:53:49+00:00",
                    "text": "Good point @rweed.\n@certik What's missing in the 4 existing Fortran implementations that you listed? Or do you suggest that one of the existing implementations is provided under stdlib?\nPerhaps naive questions, but I'm not too familiar with this domain."
                },
                {
                    "user": "sfilippone",
                    "date": "2020-05-15 19:55:34+00:00",
                    "text": "In particular the current development branch introduces a very important\nfeature: I have four different integer KINDs\npsb_mpk_ <= psb_ipk_ <= psb_lpk_ <= psb_epk_\nwhere:\npsb_mpk_ is always 4 bytes;\npsb_ipk_ is the  integer kind of indices local to a process\npsb_lpk_ is the integer kind of global indices\npsb_epk_ is always 8 bytes,\nand the size of IPK and LPK is chosen at configure time.\n\nS.\n\nOn Fri, May 15, 2020 at 9:52 PM Salvatore Filippone <\nfilippone.salvatore@gmail.com> wrote:\n\u2026\n The psblas software can now be found at\n https://github.com/sfilippone/psblas3\n The design is still being tweaked, it is very stable as far as the\n \"serial\" (or, intra-node) part is concerned.\n For the MPI part, I have some ideas in mind in terms of improvements of\n the API, which I plan to tackle later on.\n Any suggestions and discussions are welcome.\n\n Salvatore\n\n\n On Fri, 15 May 2020, 21:45 rweed, ***@***.***> wrote:\n\n> Before trying to reinvent the wheel check out PSBLAS 3 which is a\n> parallel Fortran 2003 OOP\n> implementation of sparse matrixes (see\n> http://people.uniroma2.it/salvatore.filippone/psblas and the\n> selected publications listed).\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <#38 (comment)>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AD274T7E56VMBU5PQGXGSZTRRWLVLANCNFSM4J6NGRLA>\n> .\n>"
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-15 21:01:03+00:00",
                    "text": "I'm going to keep a document for the specification of the API. I will collect all the suggestions posted here for the API. In a first round I will include many suggestions for data structures/algorithms in the previous posts, also taking the other libraries as a reference. After some time I will propose to filter this list to get a final list of features to go in a version 1 of the API.\nIt will be good also to decide later on a deadline for the conclusion of step 2. In this way we can have something material after a finite amount of time.\nJust as a side note, initially I'm planning to keep Object Oriented solutions out and focus on a clean, procedural design. The reason for that is to notenter an infinite loop of discussions about the pros and cons of one design or another. Let's choose one and move on.\nI plan to write the API document using MS Word but if anyone has another suggestion for writing the text (latex, notepad, whatever), for me it is ok, just let me know.\nWilliams"
                },
                {
                    "user": "certik",
                    "date": "2020-05-15 21:25:54+00:00",
                    "text": "In general most people agree to do both, have a low level procedural (no side effects) design, and then have an optional higher level OO design.\nI would recommend to start with a serial design for COO and CSR matrices and let's start the discussion on the API for those.\nI updated all the Fortran implementations in the comment above that were suggested so far.\nMost of them are either fully OO, or partially OO. The only procedural implementations that I found are:\n\nhfsolver (mine)\nYale\npsblas3 (only some parts, e.g. sorting seems to be implemented in a procedural way)\n\nSo those three can serve as an inspiration for the low level API. The rest of the packages can serve as an inspiration for the OO API."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-15 22:14:16+00:00",
                    "text": "Ok @certik, the representations of the sparse matrices are certainly in the core of this work, I will start writing some text about the objectives of the API, its ambition and philosophy (e.g. to have a minimum number of functions/subroutines instead of being extensive as I envision now) and in a more technical section I will start writing about these two formats to start with.\nTomorrow I will have something to show."
                },
                {
                    "user": "certik",
                    "date": "2020-05-15 22:23:46+00:00",
                    "text": "@ghwilliams perfect, looking forward!"
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-16 14:36:28+00:00",
                    "text": "Hello everybody.\nI started writing the API document. I'm sending both a MS Word and pdf file. Although it doesn't have too much written it certainly will serve as a concrete place to develop the ideas for the API. anyone who wants to contribute can edit directly the Word file.\nDiscussing ideas for the API having this document as a convergence point certainly will make the discussions more oriented toward our goals.\nStdlib Sparse matrix API.docx\nStdlib Sparse matrix API.pdf\nOf course any suggestions, critiques are welcome."
                },
                {
                    "user": "certik",
                    "date": "2020-05-16 14:49:53+00:00",
                    "text": "Thanks @ghwilliams for starting it. Would it be ok to use Markdown and put the document on our wiki? That way others can easily edit and it's easier to view, and later it will be easier to create the specification document, which also uses Markdown.\nRegarding indexing, in Fortran the standard is to start from 1, so that's what I would recommend."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-16 15:14:12+00:00",
                    "text": "Of course, having the document in the wiki is much better just let me know how to do that."
                },
                {
                    "user": "certik",
                    "date": "2020-05-16 15:34:00+00:00",
                    "text": "Here is the API that I propose for serial COO and CSR functionality: #189"
                },
                {
                    "user": "certik",
                    "date": "2020-05-16 15:37:42+00:00",
                    "text": "@ghwilliams click on the Wiki tab (https://github.com/fortran-lang/stdlib/wiki) and click on the green \"New Page\" button to create a new page, and create a page and then keep editing it."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-16 15:39:24+00:00",
                    "text": "Ok. Sohuld I merge with the information in #189?"
                },
                {
                    "user": "certik",
                    "date": "2020-05-16 15:40:58+00:00",
                    "text": "@ghwilliams in #189 we have to discuss as a community if this is an API that we would like to use, or if not, how to improve it. I submitted the code so that we have something more concrete to discuss and so that people can compile and run it and play with it."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-16 15:46:50+00:00",
                    "text": "Allright, how #189 then relates to this document that Im creating? Because in my document we are going to propose an API with the same purpose right?"
                },
                {
                    "user": "certik",
                    "date": "2020-05-16 15:49:33+00:00",
                    "text": "@ghwilliams yes, exactly. The PR #189 provides code implementation of an API that you are writing the specs for in the document. In order to efficiently discuss the API, it is helpful to have code that implements it, so that we can play with it."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-16 15:54:16+00:00",
                    "text": "Ok I will continue then writing the API document in the wiki. It is good to keep track of all the posts here related to it."
                },
                {
                    "user": "certik",
                    "date": "2020-05-16 16:17:35+00:00",
                    "text": "Absolutely! Thank you for your help.\n\u2026\nOn Sat, May 16, 2020, at 9:54 AM, Williams A. Lima wrote:\n\n\n Ok I will continue then writing the API document in the wiki. It is\n good to keep track of all the posts here related to it.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#38 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWA5FXQBGYVC2NFIXE3RR2ZLHANCNFSM4J6NGRLA>."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-16 16:20:45+00:00",
                    "text": "I created the wiki page with all the information in the previous Word file. But there are some formatting issues to be corrected. I've never used Markdown before and I don't know about its capabilities to render math.\nAnyway, I will continue working on the API from there."
                },
                {
                    "user": "rweed",
                    "date": "2020-05-16 16:25:04+00:00",
                    "text": "I would like to suggest that as policy COO will be used as the bridge format for implementing new sparse formats, for initializing an existing format and conversion to/from other formats. I believe\nIMSL does this for their sparse matrix support and if I remember correctly so does PSBLAS. The\nadvantage of this is people implementing a new format only have to write code to go to/from COO\n(or whatever format is selected) instead of having to support direct conversion to all the other formats that might eventually be impemented. I'm guessing this is standard practice in most other sparse matrix packages."
                },
                {
                    "user": "certik",
                    "date": "2020-05-16 16:28:59+00:00",
                    "text": "Yes, that's exactly how I proposed it in the PR.\n\u2026\nOn Sat, May 16, 2020, at 10:25 AM, rweed wrote:\n\n\n I would like to suggest that as policy COO will be used as the bridge\n format for implementing new sparse formats, for initializing an\n existing format and conversion to/from other formats. I believe\n  IMSL does this for their sparse matrix support and if I remember\n correctly so does PSBLAS. The\n  advantage of this is people implementing a new format only have to\n write code to go to/from COO\n  (or whatever format is selected) instead of having to support direct\n conversion to all the other formats that might eventually be\n impemented. I'm guessing this is standard practice in most other sparse\n matrix packages.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#38 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWAIX5BXZTITAHRXU2DRR246XANCNFSM4J6NGRLA>."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-16 16:31:59+00:00",
                    "text": "Yes SPARSKIT does the same. I will add some text about it."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-16 16:48:59+00:00",
                    "text": "@certik I would like to include an image in the wiki page. Clicking the wiki edit tool asks me for a url but the file is in my local computer. The alternative, I think, is to have the image file uploaded to the repository but I don't have write access to it, I guess."
                },
                {
                    "user": "certik",
                    "date": "2020-05-16 16:58:03+00:00",
                    "text": "We'll give you access, once I get to a computer. For now you can upload the images, e.g., to a gist:\n\nhttps://remarkablemark.org/blog/2016/06/16/how-to-add-image-to-gist/\n\nAnd link them from the wiki.\n\u2026\nOn Sat, May 16, 2020, at 10:49 AM, Williams A. Lima wrote:\n\n\n @certik <https://github.com/certik> I would like to include an image in\n the wiki page. Clicking the wiki edit tool asks me for a url but the\n file is in my local computer. The alternative, I think, is to have the\n image file uploaded to the repository but I don't have write access to\n it, I guess.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#38 (comment)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWGD4LGT2LH3NUUKPBTRR27YNANCNFSM4J6NGRLA>."
                },
                {
                    "user": "sfilippone",
                    "date": "2020-05-16 17:01:34+00:00",
                    "text": "The COO format is the most flexible when it comes to shuffling and\ntransforming data, including:\n1. Having multiple coefficients with the same indices (very common in the\nmatrix construction phase in finite element applications)\n2. Applying index transformations (e.g.: transposing)\n3. Moving from  a row-oriented to a column-oriented ordering.\nYou will need at least two flags, one flag that declares a sorting has been\napplied, another denoting whether it's row- or column-oriented\nAnd you will need to define a processing strategy in dealing with repeated\nentries.\nOn the other hand, it is practically always slower when it comes to\nactually applying the matrix operator e.g. in a matrix-vector product.\n\nSalvatore\n\u2026\nOn Sat, May 16, 2020 at 6:32 PM Williams A. Lima ***@***.***> wrote:\n Yes SPARSKIT does the same. I will add some text about it.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#38 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD274T5AYAS3V445TUAHIULRR25YZANCNFSM4J6NGRLA>\n ."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-16 17:18:17+00:00",
                    "text": "I added (wiki page) some ideas for the relation between the storage format and the routines in the API.\nI'm still working on that."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-05-16 19:09:53+00:00",
                    "text": "I don't think it has been linked previously, but on netlib there is a folder of templates for sparse solvers:\n\nhttps://www.netlib.org/templates/\n\nSection 4.3.1 of the documentation provides a survey of sparse storage formats."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-16 19:45:57+00:00",
                    "text": "I know that book. If you can look at the wiki and leave some comments it will be greatly appreciated.\nThanks."
                },
                {
                    "user": "sfilippone",
                    "date": "2020-05-17 06:57:26+00:00",
                    "text": "PSBLAS is OO when it comes to the sparse matrices (all storage formats are\nderived from a base type) and uses the STATE design pattern (a sparse\nmatrix is a two-layered object) to allow an individual matrix object to\nchange storage format at runtime.\n\nThe sorting routines are procedural but with compile-time generics\nresolution, for performance.\nAnd please, please, please: DO NOT default to quicksort. Please. It's just\nnot suitable for sorting the kind of distributions you find in the indices\nof sparse matrices (multiple repetitions, small range of values with\nrespect to number of indices, multiple sorted subsequences etc.)\nMy implementation of mergesort is (in my quite long experience) better in\nthis context.\n\u2026\nOn Fri, May 15, 2020 at 11:26 PM Ond\u0159ej \u010cert\u00edk ***@***.***> wrote:\n In general most people agree to do both, have a low level procedural (no\n side effects) design, and then have an optional higher level OO design.\n\n I would recommend to start with a serial design for COO and CSR matrices\n and let's start the discussion on the API for those.\n\n I updated all the Fortran implementations in the comment above that were\n suggested so far.\n\n Most of them are either fully OO, or partially OO. The only procedural\n implementations that I found are:\n\n    - hfsolver (mine)\n    - Yale\n    - psblas3 (only some parts, e.g. sorting seems to be implemented in a\n    procedural way)\n\n So those three can serve as an inspiration for the low level API. The rest\n of the packages can serve as an inspiration for the OO API.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#38 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD274TZASNDALFU7OHBTCPDRRWXPDANCNFSM4J6NGRLA>\n ."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-17 10:01:12+00:00",
                    "text": "Thanks @sfilippone ."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-17 12:59:51+00:00",
                    "text": "Today I found this interesting work: https://www.math.uzh.ch/pages/spam/\nGood to add to the list of references."
                },
                {
                    "user": "certik",
                    "date": "2020-05-17 13:18:06+00:00",
                    "text": "@sfilippone thanks for the information. As I wrote in #189, I also suggest we do not default to quicksort."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-18 23:22:08+00:00",
                    "text": "I've been editing the wiki (https://github.com/fortran-lang/stdlib/wiki/Stdlib-Sparse-matrix-API) and I would like to have some feedback to know if I am in the right direction. Any comments are welcome.\nAmong many things that need to be incorporated I would like to add state variables for the derived types representing the matrices, similar to what is done in PSBLAS (build, assembled, update)."
                },
                {
                    "user": "certik",
                    "date": "2020-05-19 00:44:06+00:00",
                    "text": "@ghwilliams thanks a lot for creating the page and suggesting an API.\nMy main feedback is that it looks like this would be the high level API -- or middle level, depending on how we want to view it, but not the low level API. Because it uses a derived type to store the CSR matrix, which I also ended up doing in my application, but I suggest for the low level API to not do that, unless absolutely necessary (which it isn't in this case), because you are then forcing your derived type on all applications. As an example, I would not be able to just use a routine from stdlib in my code, because I already use a different derived type for the CSR matrix. In the same way, unless PSBLAS moves to this derived type, it would not be able to use the subroutines either.\nSo for that reason, I propose for the low level API to be roughly in the sense of #189, and then the high level API roughly what you wrote in your wiki, or what PSBLAS and other libraries are using."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-19 09:45:56+00:00",
                    "text": "Thanks @certik . I will work on your suggestions."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-20 10:21:20+00:00",
                    "text": "I separated the design now in low and middle level parts. Low level subroutines take plain arrays of integers/real/complex values for the elements in the matrix representation.\nBut I would like to discuss here one particular aspect of the design of this API. It was suggested, and I'm following this suggestion, to have a preferred matrix format against with all the API core subroutines would be written and then have conversion routines for the other formats. The drawback of this approach, as far as I can see now, is that the data will be duplicated requiring, broadly speaking, two times RAM during the API calls."
                },
                {
                    "user": "sfilippone",
                    "date": "2020-05-20 10:34:39+00:00",
                    "text": "Some amount of data duplication is unavoidable unless you force the user to\nstick to one and only one data storage format, which is not practical.\nTo make the best of the situation you may want to define data conversion\nroutines in two flavours, CPY and MOV.\n\nS.\n\u2026\nOn Wed, May 20, 2020 at 12:21 PM Williams A. Lima ***@***.***> wrote:\n I separated the design now in low and middle level parts. Low level\n subroutines take plain arrays of integers/real/complex values for the\n elements in the matrix representation.\n But I would like to discuss here one particular aspect of the design of\n this API. It was suggested, and I'm following this suggestion, to have a\n preferred matrix format against with all the API core subroutines would be\n written and then have conversion routines for the other formats. The\n drawback of this approach, as far as I can see now, is that the data will\n be duplicated requiring, broadly speaking, two times RAM during the API\n calls.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#38 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD274T2TTNS2FTRGVHKQB4TRSOVK7ANCNFSM4J6NGRLA>\n ."
                },
                {
                    "user": "ghwilliams",
                    "date": "2020-05-21 10:48:20+00:00",
                    "text": "@sfilippone I will look at psblas (and other libs) to see how this problem is approached.\nI don't like the idea of duplicating data/code so I will try to find a good solution that will not blamed by users regarding its performance nor by developers for having to write many versions of a routine for each data representation.."
                },
                {
                    "user": "sfilippone",
                    "date": "2020-05-21 11:00:46+00:00",
                    "text": "Your code can\n  Be quick to write and compact\n  Be very fast\n  Require the minimum possible amount of memory\n\nbut you only get to pick two...\n\u2026\nOn Thu, May 21, 2020 at 12:48 PM Williams A. Lima ***@***.***> wrote:\n @sfilippone <https://github.com/sfilippone> I will look at psblas (and\n other libs) to see how this problem is approached.\n I don't like the idea of duplicating data/code so I will try to find a\n good solution that will not blamed by users regarding its performance nor\n by developers for having to write many versions of a routine for each data\n representation..\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#38 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AD274T6KLQAFCJFSRERA7FTRSUBIFANCNFSM4J6NGRLA>\n ."
                }
            ]
        },
        {
            "number": 37,
            "user": "jvdp1",
            "date": "2019-12-22 19:26:28+00:00",
            "title": "Single and quadruple precisions for load/savetxt",
            "text": "",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-22 19:50:16+00:00",
                    "text": "This is +1 from me to merge as is. The changes are straightforward, they do not change the public API and they all happen in experimental, so I am going to merge it."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 19:51:36+00:00",
                    "text": "@jvdp1 thanks for the contribution!"
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-02 05:39:58+00:00",
                    "text": "I've mentioned in the issue on quadrature that I'd like to have implementations for integrating complex functions. I think, that seeing as complex numbers are implemented in fortran, we could include them in the library. I've made the modifications to common.fypp, stdlib_experimental_io.fypp, and test_savetxt.f90 to add support to loadtxt and savetxt for complex numbers. Is that desired? Should I open a pull request?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-02-02 08:07:41+00:00",
                    "text": "@fiolj same comment as in #62 comment: I think it is a good idea to add complex numbers to the library. Because it is an addition to already existing API, I suggest to open a PR.\nCould you also add them to sdtlib_experimental_stat, please? So the whole library would support complex numbers. The community can then further discuss its utility/wish around a PR."
                },
                {
                    "user": "fiolj",
                    "date": "2020-02-02 14:10:23+00:00",
                    "text": "Yes @jvdp1, I'll try this week to put in stats, probably not before tuesday or wednesday. When I was to do it I realized that I should start with io\nI just put the pull request to stdlib_experimental_io, and modified optval, I'll put this also in stats."
                }
            ]
        },
        {
            "number": 36,
            "user": "milancurcic",
            "date": "2019-12-22 18:22:02+00:00",
            "title": "Manual Makefiles: Do we want them and how to maintain them?",
            "text": "Related to #2 and #7. Let's discuss here whether we should maintain manual Makefiles (besides CMake).\nFirst some pros and cons to this.\nPros:\n\nPeople who don't have CMake can still build the code with just make;\nComes built-in on most Linux systems;\nOthers?\n\nCons:\n\nNeed to be maintained and updated often. This is especially problematic with fast-moving and experimental APIs.\nOthers?\n\nSecond, how much is this desired by the community? Use this issue to speak up.\nOverall I like the convenience of plain Makefiles, and I like being able to see exactly what they're doing. However, in presence of a working CMake setup, I'm not likely to use them so I don't care as much for it. I never ever use systems that don't have access to CMake.\nThird, if we do want manual Makefiles, how to we develop and maintain them? Should every contributor be responsible for adding their code to the Makefile? Otherwise, would we need a volunteer Makefile maintainer?",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-22 18:37:35+00:00",
                    "text": "I think the most important advantage of manual Makefiles is:\n\nExplicitly shows how to build the project with all the compiler options pretty much spelled out explicitly. Thus providing a clean and clear instructions how to build the project --- i.e., how to copy the stdlib_*.f90 files into production codes and how to update the production code's build system to build those.\n\nRegarding how to maintain it, that's easy: our CI will build both CMake and manual Makefiles. Contributors submit a PR. If they forgot to update the Makefiles, then the CI fails, so they will get alerted, and most contributors will know how to fix it up, if they add a new module or add a new test file. For anything more complicated, we help them.\nYes, I am very happy to volunteer as a Makefile maintainer, in addition to all the other things I already implicitly volunteered for: CMake maintainer, git maintainer (helping contributors with git), etc. So by keeping things simple, I hope we can have lots of people being able to maintain our infrastructure."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 18:42:56+00:00",
                    "text": "It seems the most common changes to the build system that occasional contributors have to do are:\n\nadding a new module\nadding a test (possibly with some test data files)\n\nI think that's pretty much it. A change like adding a new dependency (say Lapack, or FFTW) would have to be handled by us anyway, as it requires changes to our CI, documentation, etc."
                },
                {
                    "user": "gronki",
                    "date": "2019-12-23 19:25:36+00:00",
                    "text": "Please have a look at my fortdep project. It can auto-generate dependencies and entire makefiles. If there are any issues i can fix/implement them in priority mode."
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 19:39:20+00:00",
                    "text": "@gronki thanks! Here is the direct link: https://github.com/gronki/fortdep"
                }
            ]
        },
        {
            "number": 35,
            "user": "milancurcic",
            "date": "2019-12-22 15:44:48+00:00",
            "title": "How to implement same procedures for different numeric kinds",
            "text": "This question comes up in #34 and elsewhere. How to implement specific procedures that work on different kinds (sp, dp, qp, int8, int16, int32, int64) as well as characters, where the body of the procedure is the same (can be copy/pasted entirely without breaking it). Let's first just focus on this scenario, and we can consider more complex cases later.\nI know of a few approaches:\n\n\nRepeat the code, that is, implement all specific procedures explicitly. That's what I did in functional-fortran, see https://github.com/wavebitscientific/functional-fortran/blob/master/src/lib/mod_functional.f90. Repeating is fine if you do it once and forget about it. The upside is that you can see the specific code and it needs no extra tooling. The downside is combinatorial explosion if you have procedures that are to handle all combinations of types and kinds. Most procedures are rather simple (one or two arguments), and I ended up with > 3K lines of code for 23 generic procedures. Most work was in editing the argument types to specific procedures, and less work was in copy/pasting of the repeatable content. I don't recommend this approach for stdlib.\n\n\nApproach 1 can be somewhat eased by explicitly typing out the interfaces, and using #include 'procedure_body.inc', defined in a separate file. Then your procedure body collapses to one line. This reduces the total amount of code, but not so much the amount of work needed, as most work is in spelling out the interfaces. This approach still doesn't need extra tooling as a C preprocessor comes with all compilers that I'm aware of.\n\n\nUse a custom preprocessor or templating tool. For example, a function that returns a set of an array:\n\n\npure recursive function set(x) result(res)\n  integer, intent(in) :: x(:) !! Input array\n  integer, allocatable :: res(:)\n  if(size(x) > 1)then\n    res = [x(1), set(pack(x(2:), .not. x(2:) == x(1)))]\n  else\n    res = x\n  endif\nend function set\nA template could look like this:\npure recursive function set(x) result(res)\n  {int*, real*}, intent(in) :: x(:) !! Input array\n  {int*, real*}, allocatable :: res(:)\n  ... ! body omitted for brevity\nend function set\nor similar, where the custom preprocessor would spit out specific procedures for all integer and real kinds. Some additional or alternative syntax would be needed if you wanted all combinations of type kinds between arguments.\nThere may be tools that do this already, and I think @zbeekman mentioned one that he uses. In general, for stdlib I think this is the way to go because we are likely to see many procedures that support multiple arguments with inter-compatible type kinds. The downside (strong downside IMO) is that we're likely to introduce a tool dependency that also depends on another language. If the community agrees, we can use this thread to review existing tools and which would be most fitting for stdlib.\nLet's say we pick a tool to do the templating for us, we have two choices:\na) Have user build specifics from templates. In this scenario, the user must install the templating tool in order to build stdlib. I think we should avoid this.\nb) Use the templating tool as developers only, and maintain the pre-built specifics in the repo. This means that when we're adding new code that will work on many type kinds, we use the tool on our end to generate the source, and commit that source to the repo (alongside the templates in a separate, \"for developers\" directory).\nAssuming we can find a fitting tool, I'm in favor of the 3b approach here. There may be other approaches I'm not aware of or forgot about. What do you think and any other ideas?",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-22 16:38:47+00:00",
                    "text": "Actually I propose 3c).\nc) The git repository contains the templated code, depends on a 3rd party tool, and does not contain any autogenerated files. Then we created release tarballs automatically on a CI. A release tarball contains all the necessary generated files and the only dependencies are cmake (or make) and a Fortran compiler, and does not contain the git history, the templated files, nor any CI files and other things that are not needed to actually build the library. Users, as well as distributions (Debian, Ubuntu, Homebrew, Conda, Spack, etc.) only use the tarball, not the git repository.\nI follow exactly this approach with LFortran, and it seems to work great. The advantage is that the git repository does not have autogenerated files, which greatly simplifies PRs (a simple diff versus hundreds of lines of modified autogenerated files) and makes it obvious how things should be modified --- so that people who want to contribute do not accidentally modify the autogenerated files, or forget to generate the files. Rather, the files are automatically generated using a CI, so they are always generated correctly."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-22 16:44:31+00:00",
                    "text": "Great! I didn't think of this and indeed it seems to me like the best way to go."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:08:34+00:00",
                    "text": "The best templating tool I have found is Jin2For. It uses Jinja2 templating which people may be familiar with from web technology stuff and is the templating back end for FORD. These are Python based, which is likely a language that Fortran developers may be familiar with. It can auto-generate default type aliases, kind info, and declarations by querying the compiler and enumerating ISO_Fortran_ENV's real_kinds, integer_kinds, logical_kinds and character_kinds array.\nBy providing a generic implementation for each intrinsic kind (where it is sensible to do this) the user doesn't need to care about setting dp, sp, rk, or whatever other convention you have for selecting kinds. Things just work\u2122\ufe0f. The downside is that compilers are not required to support all kinds, so you end up generating code specific to the kinds that a given compiler supports. This is not necessarily a bad thing, but it means that you may want to distribute different source versions tailored to different compilers. Since Fortran doesn't have a standard/interoperable ABI this is not really an issue at all, IMO."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-22 17:38:27+00:00",
                    "text": "I reviewed jin2for and I like its simplicity (a minimal and to the point tool) and the fact that it uses an existing templating language rather than inventing a new one. I think it's a good candidate."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 17:58:57+00:00",
                    "text": "Let's try to use jin2for and see how it goes.\nIn general, I think the Fortran language itself should make it easier to write subroutines that operate on different kinds. This is something I would love to experiment with in LFortran in the future, and using jin2for is a solid starting point -- the future goal would be to simplify the syntax using (future) Fortran features."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-23 10:01:59+00:00",
                    "text": "I gave a try to jin2for with loadtxt/savetxt (see https://github.com/jvdp1/stdlib/blob/loadtxt_autogen/src/stdlib_experimental_io.F90  and other tests/loadtxt/*.F90 files).\nI am not sure how it should be done with cases that involve both integer and real kinds. Should the pre-defined templates be used? If yes, how to use kinds defined as sp, dp, qp?\nAnyway, jin2for seems to be a nice and useful tool, and the option 3c proposed by @certik seems to be a good approach (not implement in my branch)."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-23 12:03:28+00:00",
                    "text": "What are the disadvantages of using CPP for this?  I am worried about deepening the necessity on external tools, which can hinder portability.\nCPP is always almost always available and often baked into the compiler (I think it's literally a library inside gfortran). Another advantage of CPP is that the compiler is often aware of the step, and debugging can point directly to the template file, rather then a copy placed in some scratch directory for which the user is unaware.\nWe've used it in FMS for this task without much issue.  Readability and debugging are the only major drawbacks, but this would be true fur any templating approach.\n(I'm on the road right now but can supplement with links when I get a chance.)"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-23 12:29:05+00:00",
                    "text": "As far as I understand CPP is more limited in what can be done with it. I'm surprised that you could do this with CPP alone.\nIn the scenario 3c, the external tool is required only of stdlib developers and not of end users, so I don't see much of a portability issue."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-23 12:33:19+00:00",
                    "text": "This post outlines what we can do with FMS with CPP templating:\nj3-fortran/fortran_proposals#4 (comment)"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-23 14:21:50+00:00",
                    "text": "Thanks @marshallward, I just read the comment and the sources you linked and I agree, it does seem quite bloated and is likely to get more complicated when considering different combinations of argument types and kinds.\nI think this illustrates well the downsides -- with CPP we can't loop, but only define/undefine macros and branch. There may be more esoteric stuff to it, but this is what I've seen.\n@jvdp1 I looked at your templates and the code is quite clean and readable to my eyes. I like it. We probably shouldn't use the .F90 suffix here -- .F90 is still a valid Fortran source file, whereas these templates aren't. I think jin2for suggests .t90 suffix for templates."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-23 15:40:55+00:00",
                    "text": "I tried to implement the IO module with CPP template (see https://github.com/jvdp1/stdlib/tree/loadtxt_cpp/src ).\nHonestly I was easier for me to use CPP (it passed the CI) than jin2for. I could also extend the IO module to integers using CPP. For these simple subroutines, using CPP is easy to implement. But using CPP could become quite difficult when combining multiple options.\n\n@jvdp1 I looked at your templates and the code is quite clean and readable to my eyes. I like it. We probably shouldn't use the .F90 suffix here -- .F90 is still a valid Fortran source file, whereas these templates aren't. I think jin2for suggests .t90 suffix for templates.\n\n@milancurcic  I followed the syntax implemented by @zbeekman in one of his libraries. I agree that the .t90 suffix might be better."
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 18:47:10+00:00",
                    "text": "@jvdp1 thanks a lot for implementing both approaches. Here they are, side by side:\n\nCPP: https://github.com/jvdp1/stdlib/blob/7f246a2b75ed0e6f584e2f820776cf80530dd8e6/src/stdlib_experimental_io.F90 (165 lines + 42 lines in loadtxt.inc and 25 lines in savetxt.inc, total of 232 lines)\njin2for: https://github.com/jvdp1/stdlib/blob/0ee94604f5b39283f6054d23be00547f4eaec51a/src/stdlib_experimental_io.F90 (149 lines)\n\nIt seems the jin2for version is a lot shorter. Am I right? Was it more difficult to implement because it is new, but as we (now) have an example how to use it, it will be perhaps even easier than CPP?"
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-23 18:58:46+00:00",
                    "text": "@certik jin2for is indeed less verbose, and I think less error prone in this example.\njin2for was more difficult because it was new (e.g., I couldn't extend the subroutines to support integers (as I did with CPP), but I didn't try hard to find the solution; @zbeekman may have some hints).\nBoth approaches have pros and cons (e.g., CPP passed the CI without any change to it, while it was not the case for jin2for)."
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 19:37:05+00:00",
                    "text": "@jvdp1 we have to update our CI to support jin2for obviously. I would not hold it against it. :)"
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-24 05:29:33+00:00",
                    "text": "I can see the advantages of jin2for, most notably iteration, and think option 3c addresses my concerns about portability.  I also agree that the files should use the t90suffix, or at least not [fF].90.\nI had resisted Jinja2 integration in another project, because I was concerned that the Jinja2 tokens may clash with the native file's own tokenisation (usually various config files); Jinja2's syntax was designed to safely work with HTML and not much else.  But I also wondered if I was being too conservative.\nAre there any known limitations to using Jinja2 on Fortran markup, such as token mix ups?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 06:29:23+00:00",
                    "text": "Does Fortran use { for anything? The combination {% is almost for sure safe. And if there is some possibility of a clash, I think we can tackle it on a case by case basis by rewriting things appropriately."
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 06:32:58+00:00",
                    "text": "Down the road, I would like to prototype some of this limited templated functionality into LFortran and then propose it for the Fortran language itself. jin2for is a good start, as the code looks pretty nice. If Fortran language was extended, then the syntax would get even better perhaps. And LFortran could in the future be used instead of jin2for to do the rewrite, until all compilers support it."
                },
                {
                    "user": "nshaffer",
                    "date": "2019-12-30 14:41:31+00:00",
                    "text": "I was really hoping that lexical macro processing would get re-introduced into this upcoming Fortran standard. In fact, a fleshed-out macro processing specification was already given in Fortran 2008 drafts (e.g., https://j3-fortran.org/doc/year/07/07-007.pdf) but was dropped then. It was also considered for the upcoming standard as a means of supporting generic programming. But we know how that went.\nAfter templating/macro processing was forgone for F2020, I looked into m4 as a solution for my own generic-interface-producing needs, since it is the tool gfortran uses to generate specific implementations of generic intrinsics. Its strengths are its power and that is a standard POSIX utility. It has been fun to learn, but I do not think it is a good solution for a standard library. POSIX standardization is not enough to compensate for the fact that it's really hard for a 21st century programmer to grok and I think it will lead to heavy technical debt. The other downside is that it's hard to make m4 programs look like marked-up Fortran source, so that it could be tricky to \"port\" the m4 workflow to a hypothetical standard macro/templating scheme (assuming J3 ever produces one)."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-30 17:35:27+00:00",
                    "text": "I slightly modified the CPP implementation (https://github.com/jvdp1/stdlib/tree/loadtxt_cpp) to clarify a few things, and renamed the files .F90 to .t90 (https://github.com/jvdp1/stdlib/tree/loadtxt_autogen).\nThese 2 options seem to be the most acceptable among all proposed. Should we make a choice now?"
                },
                {
                    "user": "nshaffer",
                    "date": "2019-12-30 20:57:02+00:00",
                    "text": "One thing I don't understand about the cpp approach shown is what it does better than, e.g.,\nmodule ex\n    use iso_fortran_env, only: real32, real64, int32, int64\n    implicit none\n\n    interface foo\n        module procedure foo_real32\n        module procedure foo_real64\n        module procedure foo_int32\n        module procedure foo_int64\n    end interface foo\n\ncontains\n\n    function foo(x) result(y)\n        real(real32), intent(in) :: x\n        real(real32) :: y\n        include \"foo.inc\"\n    end function foo    \n\n! etc.       \nend module ex\n\nThe main downside of this approach is the repetition of each subroutine \"skeleton\" and the need to manually populate the interface blocks, but the cpp example has those same issues at the cost of introducing a foreign (albeit well-supported) program. I see cpp as having the worst of both worlds: it's an external tool, but it's not significantly more powerful (in this application) compared with the technique above. Of course, this assessment is invalid if I've overlooked some cpp technique that's not used in the examples posted so far."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-30 21:22:19+00:00",
                    "text": "One thing I don't understand about the cpp approach shown is what it does better than, e.g.,\n\nWith this proposed scenario, 1 file per skeleton would be needed (if I understand well your proposition), while with the CPP approach, all skeletons could be included in 1 same file. CPP is an external tool, but it is well supported by most compilers. However, I don't appreciate the use of additional .inc files in both approaches.\nThe jin2for approach also requires an external tool. While no additional files were used in my example, jin2for might require them for more complex implementations.\nHowever, if we use a strategy as described by @certik where end users and distributions only use tarballs automatically generated by a CI, using an external tool should not be a problem."
                },
                {
                    "user": "nshaffer",
                    "date": "2019-12-30 23:57:47+00:00",
                    "text": "One thing I don't understand about the cpp approach shown is what it does better than, e.g.,\n\nWith this proposed scenario, 1 file per skeleton would be needed (if I understand well your proposition), while with the CPP approach, all skeletons could be included in 1 same file. CPP is an external tool, but it is well supported by most compilers. However, I don't appreciate the use of additional .inc files in both approaches.\n\nI didn't show it, but you would include \"foo.inc\" for each type you want to implement. This works as long as the contents of \"foo.inc\" are actually type-generic. I think this is totally equivalent to the cpp approach. I also dislike the disembodied \".inc\" files, but it is the most economical approach the standard gives us right now.\n\nThe jin2for approach also requires an external tool. While no additional files were used in my example, jin2for might require them for more complex implementations.\nHowever, if we use a strategy as described by @certik where end users and distributions only use tarballs automatically generated by a CI, using an external tool should not be a problem.\nAgreed. This is the best-sounding approach, provided we trust the external tool will continue to be maintained until we have proper generics facilities in the standard and in compilers."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 04:05:47+00:00",
                    "text": "I haven't gone through this thread in the detail it deserves yet, but a few broad observations:\n\nSometimes Jin2For and pre-processing via cpp or fpp (Intel) are not mutually exclusive and mixing them can be an elegant solution where simpler approaches are exceedingly complex\nJin2For's compiler interrogation is great, but, for the scope of this project, we should probably limit kinds to the most reasonable/common kinds\nJin2For's generic macro, looping and other capabilities make it quite powerful with or without it's compiler introspection\n\nThe biggest problem with the automatically generated types is that they are very non-portable: They basically interrogate the available kinds from iso_fortran_env and then just blindly use them. So using the default aliases & kinds provided by this and generating them from GFortran may (almost certainly will, but I have yet to confirm) generate code that can't run with Intel's ifort.\nMy personal preference is to use Jin2For, but don't use the built in type declarations, aliases and kinds that are created from compiler introspection. Instead, for reals at least, attempt to target single, double and quad precision. CMake introspection can be used to confirm which kinds exist for a given compiler and then Jin2For can be used to generate interfaces and implementations for each kind supported by the compiler.\nOtherwise, if you use the built in t.decl, t.alias, t.kind macros you will be generating code specific to the compiler being used that won't be portable.\nSince the existence of various kinds is not guaranteed by the standard, much less the integer associated with each kind, this is a rather sticky situation. But I would rather loop over a list of kinds (possibly generated from CMake introspection) using Jin2For templates than contend with the awkward square peg in a round hole that is CPP and other non-standardized pre-processing. The advantages of Jin2For (or Jinja2 really...) are its widespread use in other domains (so that it is battle hardened and good enough to be popular) and the fact that it's Python based and extensible.\nBut, by preprocessing the code for the end user so they don't need Jin2For (unless we want to provide different pre-processed code for different compilers) you lose a non-trivial quantity of its utility. Whereas if you can stick to standardized fortran and a subset of cpp/fpp that's implemented in all major compilers then the user can do the code pre-processing themselves at configure/build time."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 22:25:25+00:00",
                    "text": "The ideal solution for this would be j3-fortran/fortran_proposals#128 in my opinion. But we'll have to probably wait some time for that."
                },
                {
                    "user": "aradi",
                    "date": "2020-01-12 21:18:59+00:00",
                    "text": "As an alternative to Jin2For, you may also consider the Fypp preprocessor for generating templates. (Disclaimer: I am the main author of Fypp). It has similar loops as Jin2For and additionally also offers macros, so it could  be also used for the assert macros (#72). It consists of a single (Python) source file and can be, therefore, easily shipped with the library, so that the build only requires a standard Python (2.6, 2.7 or 3.x) installation."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-12 23:13:33+00:00",
                    "text": "I like fypp a lot. Having the author in Fortran community is a huge plus IMO.\nWhat do you think about taking a minimal example function and comparing the jin2for and fypp syntax next to each other? For example:\ninteger function sum(a, b)\n  integer, intent(in) :: a\n  integer, intent(in) :: b\n  sum = a + b\nend function sum\nRequirements:\n\na and b can be any of real(sp), real(dp), real(qp), integer(int8), integer(int16), integer(int32), integer(int64), as defined in stdlib_experimental_kinds.f90;\nResult is of whichever is the higher kind between a and b.\n\nThe preprocessed source code would result in 49 specific functions.\nWhat would the template look like with jin2for and fypp? What would the invocation look like? Let's compare them side by side."
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-13 05:43:01+00:00",
                    "text": "Here's a go at using fypp for the task. I used it in some personal projects a couple years back, but I only really know the basics. This is a pretty naive implementation. \ufffcGist\nThe only snag I ran into was fypp not liking constructions like\n#:for i, (k, t) in enumerate(zip(KINDS, TYPES))\n...\n#:endfor\n\nNot sure if that's a bug or if fypp just doesn't do multi-level tuple unpacking. It's easy to work around in this case, at least."
                },
                {
                    "user": "aradi",
                    "date": "2020-01-13 09:18:46+00:00",
                    "text": "@nshaffer fypp currently does not support multi-level tuple unpacking due to technical reasons. It could be extended if this really made a huge difference in the user experience. (As it is a preprocessor, I try to keep it as simple as possible to prevent people doing something with it, which they should do in Fortran instead \ud83d\ude09)\nYou example is very neat. In some cases we may also need to loop over ranks. It would then need a simple macro and an additional loop more:\n#:def ranksuffix(rank)\n#{if rank > 0}#(${\":\" + \",:\" * (rank - 1)}$)#{endif}#\n#:enddef\n\n#:set ranks = range(6)\n...\n#:for rank in ranks\n  some_type, ... :: a${ranksuffix(rank)}$\n#:endfor"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-13 18:07:12+00:00",
                    "text": "@aradi Cool, thanks for confirming that about tuple unpacking. I think it's not a problem overall, I just let my Python instincts take the reins. The less-fancy version I arrived at is arguably better."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-13 18:54:26+00:00",
                    "text": "@aradi @nshaffer Thank you for the examples with fypp.\nfypp seems quite flexible, and I like @aradi 's example with loops over ranks (we may actually need that for functions like mean(array), variance(array), ... :) ). So I think this feature has to be considered seriously. Such a feature may be tedious to implement with cpp (and I don't know if it would be possible with jin2for).\nAn additional advantage is that the author @aradi is involved in the Fortran community."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-13 19:50:46+00:00",
                    "text": "fypp is interesting. Knew it existed but had not tried it. I have used m4 for that type of thing and just never liked the syntax. So I have used the bash shell and \"here\" documents. I made make(1) rules for the suffix \".shf\" that say to execute the file as a bash shell and use the standard output to make a *.f90 file. Works great for me, and bash has all the looping and access to output from commands and can query the system type and everything itself\nSince bash is readily available and I am quite familiar with it that has worked great for me, although I\ndoubt I will get any converts by mentioning it.  Anyway maybe I will quit doing that after giving fypp a better look. Thanks for the enticing examples\n\u2026\n On January 13, 2020 at 1:54 PM Jeremie Vandenplas ***@***.***> wrote:\n\n\n     @aradi https://github.com/aradi @nshaffer https://github.com/nshaffer Thank you for the examples with fypp.\n\n     fypp seems quite flexible, and I like @aradi https://github.com/aradi 's example with loops over ranks (we may actually need that for functions like mean(array), variance(array), ... :) ). So I think this feature has to be considered seriously. Such a feature may be tedious to implement with cpp (and I don't know if it would be possible with jin2for).\n\n     An additional advantage is that the author @aradi https://github.com/aradi is involved in the Fortran community.\n\n     \u2014\n     You are receiving this because you are subscribed to this thread.\n     Reply to this email directly, view it on GitHub #35?email_source=notifications&email_token=AHDWN3OBAQFOPEHPDRCGEF3Q5S2GJA5CNFSM4J6MKIL2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIZ3S6A#issuecomment-573815160 , or unsubscribe https://github.com/notifications/unsubscribe-auth/AHDWN3ODMUOOVUG37ODXOZDQ5S2GJANCNFSM4J6MKILQ ."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-17 10:39:55+00:00",
                    "text": "Here  fypp is used to generate loadtxt for all kinds, based on @nshaffer  's example.\nEarlier I also did it with cpp and jin2for. Among the three implementations, fypp is the most complete (i.e., implemented for all kinds for loadtxt).\nWithout any research (I could have spent more time in jin2for to extend it to integers, but it was not straightforward for me), fypp was also the easiest one to use for me. cpp may come tedious for more complex cases (e.g., for loops over ranks)."
                }
            ]
        },
        {
            "number": 34,
            "user": "jvdp1",
            "date": "2019-12-22 08:18:20+00:00",
            "title": "Progress on loadtxt and savetxt (proposition)",
            "text": "@certik\n*I modified the subroutines for sp to avoid a temporary copy of the input/output array in dp. This approach would have been aslso difficult to extent to qp.\n*I added two subroutines for qp.\n@ALL:\nTo be discussed:\n*For loading, I implemented two ways: 1)copy-paste of the subroutines and changing the precision and 2)unlimited polymorphic objects. We need to decide which approach to use.\n*I would be happy to extent loadtxt and savetxt to integer (1,4,8,16). Is there a way to do it automatically? Or should I repeat it manually (all subroutines will be the same, except for the type of the arrays)?\n*Should we add other options, like presence of an header, max columns/rows to load,... (similar to Numpy)?",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-22 14:34:20+00:00",
                    "text": "Thanks a lot for this work! My comments:\n\n\nWould you mind merging in the latest master to pick up the CI tests?\n\n\nBefore we merge this, we should polish up the history (it seems to have my old commits that are already in master, etc.)\n\n\nThe refactoring to number_of_columns and number_of_rows_numeric is good.\n\n\nAdding qloadtxt and qsavetxt is good.\n\n\nRegarding the savetxt_poly, that's an interesting idea. My comments are: a) do all compilers support this on all platforms? b) Will the compiler messages be clear if the user passes in incorrect / unsupported type? c) The public API should be just savetxt, not savetxt_poly.\n\n\nThere are tools that people have mentioned that allow to generate code from a template. In something like this, when the code is literally the same, just the type changes, It might make sense to use them in this case. Then it should be trivial to also extend this for integers.\n\n\nI suggest you split this PR into two. In one PR do 1., 2., 3., 4. Then I can pretty much review & merge right away. In the other PR do 5. and we can discuss the various pros and cons. It might take some time to reach an agreement.  In some future PR, we can also implement 6."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 16:24:25+00:00",
                    "text": "The branch is quite messed up. For some reason GitHub shows a diff against the CI file, which it should not.\nFirst of all, you should be using a branch in your repository other than master.\nHere is how you can work. First fix your remotes. Here are mine:\n$ git remote -v\nondrej\tgit@github.com:certik/stdlib.git (fetch)\nondrej\tgit@github.com:certik/stdlib.git (push)\norigin\thttps://github.com/fortran-lang/stdlib.git (fetch)\norigin\thttps://github.com/fortran-lang/stdlib.git (push)\n\nSo do\ngit remote add jvdp1 git@github.com:jvdp1/stdlib.git\n\nand if your origin does not point to https://github.com/fortran-lang/stdlib.git, do:\ngit remote rename origin old-origin\ngit remote add origin https://github.com/fortran-lang/stdlib.git\n\nThen once your remotes are fixed, do from your current master:\ngit checkout -b loadtxt\ngit fetch origin master:master\ngit merge master\ngit push jvdp1 loadtxt\n\nThis will create a branch loadtxt from your current master, then merge the actual origin master, and finally push into your fork. Then you can create a new PR from it and things should start looking much better."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-22 16:54:37+00:00",
                    "text": "@certik Thank you for the procedure. I just followed it, and here is the result:\n$ git remote -v\njvdp1\thttps://github.com/jvdp1/stdlib.git (fetch)\njvdp1\thttps://github.com/jvdp1/stdlib.git (push)\norigin\thttps://github.com/fortran-lang/stdlib.git (fetch)\norigin\thttps://github.com/fortran-lang/stdlib.git (push)\n$ git branch -a\n* loadtxt\n  master\n  remotes/jvdp1/HEAD -> jvdp1/master\n  remotes/jvdp1/io\n  remotes/jvdp1/loadtxt\n  remotes/jvdp1/master\n  remotes/origin/master\n\n\nShould I close this PR, and create a new one from loadtxt?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 17:10:39+00:00",
                    "text": "Keep this one open for now. But create a new one from the loadtxt branch."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-22 17:22:31+00:00",
                    "text": "Keep this one open for now. But create a new one from the loadtxt branch.\n\nI am afraid that if I do a PR from loadtxt, it will still have all the commits."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 17:55:45+00:00",
                    "text": "If you want, I can push a branch that's polished and you can then pull it and create a PR from it."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-22 18:02:45+00:00",
                    "text": "If you want, I can push a branch that's polished and you can then pull it and create a PR from it.\n\nOk. Let 's do that."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 19:22:26+00:00",
                    "text": "There you go:\ngit fetch https://github.com/certik/stdlib loadtxt2:loadtxt2\ngit checkout loadtxt2\ngit push jvdp1 loadtxt2\n\nI used your name and email to create the commit."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-22 19:28:41+00:00",
                    "text": "There you go:\ngit fetch https://github.com/certik/stdlib loadtxt2:loadtxt2\ngit checkout loadtxt2\ngit push jvdp1 loadtxt2\n\n\nThanks @certik for your help. Not sure what you did but it worked. See the new PR."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 20:14:32+00:00",
                    "text": "All I've done is to take your branch (master), put it into a new branch loadtxt2, and then I merged with \"master\" (the latest official master) and then I did git reset master, which squashed all the commits, and then git commit -a --author=\"...\" and that's it."
                }
            ]
        },
        {
            "number": 33,
            "user": "certik",
            "date": "2019-12-22 05:01:39+00:00",
            "title": "Test every PR and master on Linux",
            "text": "We will implement macOS and Windows testing in other PRs. This way at\nleast Linux testing is done.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-22 05:04:36+00:00",
                    "text": "@ivan-pi, would you mind reviewing this PR please? I would like to merge it in before your PR #32, so that we can test it on the CI."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-22 05:11:44+00:00",
                    "text": "Great! Looks good to me, and it seems like it works. This also helps me learn Github actions. Thanks, Ondrej."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 14:07:18+00:00",
                    "text": "Thanks @ivan-pi and @milancurcic. Yes, we'll have to test a lot more compilers and versions and platforms than this. But it's a start."
                }
            ]
        },
        {
            "number": 32,
            "user": "ivan-pi",
            "date": "2019-12-22 00:41:59+00:00",
            "title": "Add module for validating ASCII characters and upper/lower conversion",
            "text": "This PR addresses #11 (there are a few open question left there).\nTested with both the gfortran and Intel Fortran compilers for the 'default' (ascii) character set.\nThe tests are essentially a port of those at https://github.com/dlang/phobos/blob/master/std/ascii.d (hopefully not a licensing issue?).",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-22 14:08:08+00:00",
                    "text": "Would you mind rebasing on top of the latest master to pick up the CI tests?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 14:54:57+00:00",
                    "text": "So I think this looks really nice. The public API seems nicely done, the naming convention I think is good.\nWill the is_* functions work with utf8 strings?\nThe to_upper and to_lower will only work on the ascii parts of an utf8 string I assume.\nPython calls these just upper and lower methods (they work with Unicode). In C, they are called toupper and tolower. Finally in C++, Boost has to_upper and to_lower. There is also a nice table here: #11 (comment)\nI think using to_upper is readable."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 15:00:30+00:00",
                    "text": "Python also has an isupper method. Should we also implement is_upper and is_lower?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 15:04:08+00:00",
                    "text": "General question: should we maintain stdlib_ascii and stdlib_unicode, or should we simply have stdlib_string, and all methods would automatically work with utf8?\nI think getting the unicode working (as in Python) will be some work, so we can start with stdlib_ascii, then in another PR we can see how many of these extend to unicode and create stdlib_unicode or merge them. Since this is all in experimental, we can do that.\nThings like to_upper just need to be extended to support Unicode (utf8), see the Python documentation. Here is an example in Python:\n>>> name = \"Ond\u0159ej \u010cert\u00edk\"\n>>> name\n'Ond\u0159ej \u010cert\u00edk'\n>>> name.upper()\n'OND\u0158EJ \u010cERT\u00cdK'\n>>> name.lower()\n'ond\u0159ej \u010dert\u00edk'\n\nYou can see the upper and lower works with Unicode characters (utf8)."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-22 21:08:10+00:00",
                    "text": "I think we should have separate modules for ASCII and Unicode characters. In fact using only the intrinsic Fortran character functions (achar and iachar) it is not possible to find say uppercase Slavic letters \u010d, \u0161, \u017e... I think it will be necessary to interface with C to achieve Unicode support. A second issue is that some preprocessing will be necessary, as not all Fortran compilers support the extended Unicode character set.\nThe current ascii module already contains is_upper and is_lower characters. At the moment all functions in the ascii module are limited to work on single characters. They are meant as support functions for a separate string module.\nI will rebase and import explicitly the public functions for the test driver asap."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 21:39:06+00:00",
                    "text": "@ivan-pi yes, if it is not possible to merge unicode with ascii, then we need two modules."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 21:58:36+00:00",
                    "text": "The other thing is --- since you used https://github.com/dlang/phobos/blob/434429f273d0359744b6d3ba9db36d3bef1c7593/std/ascii.d as the original, we have to cite their license.\nOverall this looks good to me. It would be nice to get some more reviews on this before we merge. @marshallward, @jacobwilliams, @milancurcic do you have any feedback on the API here?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 06:23:25+00:00",
                    "text": "@milancurcic thanks for the review.\n@ivan-pi would you mind updating whitechar in stdlib_experimental_io to use your new functionality please? That should save some code."
                },
                {
                    "user": "dev-zero",
                    "date": "2020-04-24 10:28:40+00:00",
                    "text": "since I've been pointed here, this project might be interesting: https://github.com/lemire/fastvalidate-utf-8 althought I don't see how that could be implemented in Fortran given missing inline assembly."
                },
                {
                    "user": "certik",
                    "date": "2020-04-24 16:17:41+00:00",
                    "text": "@dev-zero thanks! I made a comment in #11 (comment)."
                }
            ]
        },
        {
            "number": 31,
            "user": "certik",
            "date": "2019-12-22 00:23:24+00:00",
            "title": "Add initial GitHub CI",
            "text": "This is an empty CI using GitHub Actions. Once this is in master, we can send PRs modifying it to do what we need.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-22 00:25:04+00:00",
                    "text": "I am going to go ahead and merge this, so that I can send a PR with the actual CI."
                }
            ]
        },
        {
            "number": 30,
            "user": "certik",
            "date": "2019-12-21 23:26:49+00:00",
            "title": "Add initial GitHub CI",
            "text": "TODO:\n\n Install gfortran on Linux\n Install gfortran on macOS\n Install gfortran on Windows",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-22 00:28:15+00:00",
                    "text": "Cool, now the CI runs. (It fails, because gfortran is not installed.)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 00:39:07+00:00",
                    "text": "First, I requested to include gfortran by default at actions/virtual-environments#202. In the meantime, we need to install it by hand."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 00:45:27+00:00",
                    "text": "Things install on Linux now and tests pass. Now we need to figure out how to install GFortran on macOS and Windows."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 05:00:11+00:00",
                    "text": "I guess we have to install our own Conda on macOS and Windows."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 05:03:31+00:00",
                    "text": "It's going to take some time to get this PR ready. In the meantime I contributed just the Linux build in #33, so that we have at least some kind of testing."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:17:01+00:00",
                    "text": "@certik Do we have to use conda? I'd rather just use pip, pipenv, etc."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:18:43+00:00",
                    "text": "I'd recommend not using conda, except maybe on windows... Is flang from conda F18, or \"legacy\" flang? I have a lot of experience with CI, so I may submit a competing PR, at least to get macOS up and running and some odds and ends for macOS and linux."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 17:41:13+00:00",
                    "text": "@zbeekman can you submit a PR getting Fortran working on macOS and Windows using Github Actions? That would be super helpful. We don't need to use Conda."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:47:11+00:00",
                    "text": "I'm happy to submit a PR.. I'll start with mac and linux, windows will take some time for me to figure out... namely, which compiler to use and how to install it? (Cygwin? Msys2? Mingw? WSL?)"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 18:04:19+00:00",
                    "text": "(On windows I always use Intel, which is hard to do on CI)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 18:12:57+00:00",
                    "text": "Linux is already done. If you can do just macOS with gfortran, that would be super helpful. Then we'll go from there.\n\u2026\nOn Sun, Dec 22, 2019, at 10:47 AM, zbeekman wrote:\n I'm happy to submit a PR.. I'll start with mac and linux, windows will\n take some time for me to figure out... namely, which compiler to use\n and how to install it? (Cygwin? Msys2? Mingw? WSL?)\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#30?email_source=notifications&email_token=AAAFAWC24YAHIJRE243Z66DQZ6R2BA5CNFSM4J6JGAGKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHPV7DY#issuecomment-568287119>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWEDQMXTSBJPMXRF5KTQZ6R2BANCNFSM4J6JGAGA>."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 18:23:51+00:00",
                    "text": "Can I get us a newer gfortran on Linux? And a newer CMake? We should be using 3.14 at least for submodule support."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 19:02:56+00:00",
                    "text": "Can I get us a newer gfortran on Linux? And a newer CMake? We should be using 3.14 at least for submodule support.\n\nWe have to extend our CI to test with newer and older gfortran, so yes (in addition). Regarding CMake, I would suggest to require the oldest possible version that still works. Right now we do not use submodules, so I would not require a newer CMake until we need some feature from it, and then we can discuss if it is worth dropping older version support. That's related to #15. For submodules we would need to investigate the compilers that we want to support if they actually support submodules.\nEither way, I suggest you submit several PRs that are small, so that we can reach an agreement quickly and merge it (as opposed to a large PR with a complicated CI system).\nThe most useful PR right now would be to get just macOS working. The PR can look like #33, but it installs gfortran on macOS instead.\nThe second most useful would be a PR for Windows. Probably the mingw-w64 from msys2 is the most \"native\" solution.\nOnce we have all three platforms covered, then we can extend our CI to test multiple compiler versions, as well as different compilers (Flang, and perhaps even Intel)."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 19:05:30+00:00",
                    "text": "Installing CMake binaries is so trivial I think it's worthwhile using more up-to-date versions. You can download statically linked, re-locatable binaries for all major OSes.\nI'll start by opening a PR with multiple versions of GFortran for Linux and mac, then I'll look into windows..."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 19:05:54+00:00",
                    "text": "FYI, your loadtxt CMake doesn't work with out of source builds."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 19:13:23+00:00",
                    "text": "Yes, we need to fix the out of tree builds and test them on the CI\n\nInstalling CMake binaries is so trivial I think it's worthwhile using more up-to-date versions. You can download statically linked, re-locatable binaries for all major OSes.\n\nOn many HPC systems they either do not have an internet connection, or if the do, they do not like you to be installing binaries from the internet. So being able to install using the preinstalled CMake and Fortran versions is a huge plus. In order to increase chances that things just work with default pre-installed versions, we should only require a newer CMake if we absolutely need the latest features. Besides submodules, which other feature do you find useful in newer CMake?"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 19:39:39+00:00",
                    "text": "On all the HPC systems I've ever run on grabbing a statically linked binary and putting it in my home directory has never been an issue. I check the GPG signature and cryptographic checksums and I'm off to the races.\nThere are a number of features that I like in newer CMake and I can't keep track of which version each was added in. For example, I think it's nice to declare a target and then add sources to it later. There are also bug fixes for FindMPI and in transient usage requirements... Using submodules is also pretty compelling, because it separates the interface from the implementation and speeds up builds.\nIf it's decided not use a suitably new CMake I probably won't be motivated to contribute. Why use CMake at all then? Why not just use Makefiles? We're already handy capped as we wait on compiler vendors to implement or fix new Fortran language features and I don't see a compelling reason to not use a suitably Fortran aware build system. If people are \"just grabbing sources and putting them in their build trees\" then it doesn't matter whether or not they're allowed to grab CMake binaries."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 20:02:10+00:00",
                    "text": "@zbeekman thank you for improving the CI build system.\nYou have a good point that since I think we'll probably decide to maintain manual Makefiles at #36, we might be able to get away with requiring the very lastest CMake, as for people who don't have the latest CMake, they can just use manual Makefiles. Let's move the discussion to #41.\nI am closing this PR in favor of #39."
                }
            ]
        },
        {
            "number": 29,
            "user": "certik",
            "date": "2019-12-21 04:50:02+00:00",
            "title": "Use autoformatting, enforced by CI",
            "text": "@zbeekman wrote:\nBest thing I've found so far is findent and eclint for Fortran. findent works off an actual AST and claims to test against all code examples in the latest Modern Fortran Explained by MRC, so it should be robust. Probably won't help with this particular style issue, but I haven't been using it in earnest yet as I just discovered it (and added it to Homebrew).",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 16:50:52+00:00",
                    "text": "What about local pre-commit hooks too? The pre-commit project is pretty great.\nI also think we should get an editorconfig file going asap"
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 16:56:00+00:00",
                    "text": "What happens when people submit a PR without setting up pre commit hooks? For example by directly modifying files at GitHub and submitting the PR online?"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:10:47+00:00",
                    "text": "We can have the PR run the pre-commit hooks during CI too... We could even have running CMake (or at build time) detect a build from git, see if the current author has made any commits and install hooks for them if they have... I'm happy to use it or not use it, but I've found it very helpful personally."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 00:48:53+00:00",
                    "text": "Let's setup automatic formatting check on a CI:\n\nUse a tool (findent if it works)\nWrite documentation how each developer can use it before submitting a PR\nRun this on CI for each PR and fail the tests if they are not formatted correctly\nIf it is not formatted correctly, make a patch available somehow that the PR author can simply apply (in case they do not have the findent installed). Here is an example how to do that in SymEngine: https://github.com/symengine/symengine/blob/861c64569a3543744f166dc63b6ff574c7344b02/bin/travis_clang_format.sh\n\nLater, let's also:\n\nCreate a bot that will provide the correct patch. Here is an example PR that shows how it works: symengine/symengine#1530, I can't find a PR now where the formatting is incorrect (the bot provides copy & paste instructions how to fix it by downloading the patch and applying it)."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 03:44:27+00:00",
                    "text": "Let's get some of those ready to merge PRs in before I start work on any of this. There are a bunch that are ready to ship. I'd merge them myself because I think everyone is in agreement, but I'm not part of the fortran-lang org."
                }
            ]
        },
        {
            "number": 28,
            "user": "certik",
            "date": "2019-12-20 19:58:29+00:00",
            "title": "List of popular open source Fortran projects",
            "text": "In order to more easily judge how Fortran developers actually use Fortran in real production codes (this can be useful for issues like #25), let's maintain a list of popular open source Fortran projects here, sorted by the number of stars at GitHub (in parentheses).\nThe list was moved to a Wiki:\nhttps://github.com/fortran-lang/stdlib/wiki/List-of-popular-open-source-Fortran-projects",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-20 20:00:55+00:00",
                    "text": "Everybody, can you please help find Fortran projects at GitHub that have more than let's say ~30 stars, so that we have a complete list above? I will update the issue description. GitHub makes this really hard to find for some reason."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-20 20:11:03+00:00",
                    "text": "Maybe activate the wiki for this?\nAlso I feel obliged to link MOM6: https://github.com/NOAA-GFDL/MOM6\n(The GFDL framework almost hits the threshold at 29: https://github.com/NOAA-GFDL/FMS)"
                },
                {
                    "user": "jacobwilliams",
                    "date": "2019-12-20 20:27:59+00:00",
                    "text": "Here are mine:\n\njson-fortran [178]\nbspline-fortran [82]\npyplot-fortran [65]\nFortran-Astrodynamics-Toolkit [65]\nslsqp [30]\nfortran-csv-module [30]"
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 20:33:35+00:00",
                    "text": "I am moving this to a wiki so that we can all edit. Give me a second."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-20 20:34:25+00:00",
                    "text": "I added a few more of mine (neural-fortran, tsunami, tcp-client-server).\nAwesome Fortran is a useful list."
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 20:36:40+00:00",
                    "text": "Done: https://github.com/fortran-lang/stdlib/wiki/List-of-popular-open-source-Fortran-projects\n@marshallward, @jacobwilliams would you mind putting the codes you mentioned into the wiki please?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 20:38:19+00:00",
                    "text": "@marshallward  We can lower the threshold. I set it at 30 to make the number of codes manageable, but it looks like there is not that many. We can lower it to 25 or 20."
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 20:41:29+00:00",
                    "text": "@milancurcic there is lots of Fortran codes out there, but if it is not on GitHub, not even a GitHub mirror (like I've done for LFortran), then I feel those codes are pretty much not developed anymore (or not open source). So restricting to only codes at GitHub I think is a proxy for codes that are \"modern enough\". (There are some codes however that didn't get a single commit in 5 or more years...)"
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-20 20:42:35+00:00",
                    "text": "I couldn't see a way to edit the wiki, might need a permissions change?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 20:52:22+00:00",
                    "text": "@marshallward try again, I made the wiki editable by any GitHub user."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-20 20:59:51+00:00",
                    "text": "Thanks, working now."
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 21:15:29+00:00",
                    "text": "I found a nice list here: https://github.com/topics/fortran, again, not all the codes, but quite a few listed above are there plus more. Let's keep the number of stars at 29 or more, and we'll see how many codes we get."
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 22:09:58+00:00",
                    "text": "I extracted all projects that I was able to find so far. The github page  https://github.com/topics/fortran as well as the various searches do not actually show all the projects for some reason, but I think the list is starting to get quite accurate. Here is some statistics:\n# of contributors, # of projects\n1 - 10\n2 - 5\n3 - 5\n4 - 4\n5 - 5\n6 - 2\n7 - 1\n8 - 2\n9 - 0\n10 - 0\n...\n13 - 1\n14 - 1\n22 - 1\n23 - 1\n25 - 1\n27 - 1\n30 - 1\n41 - 2\n43 - 1\n46 - 1\n\nTotal: 45\n\nIn particular, if we require at least 3 contributors to exclude one man projects, then there are only ~ 30 projects with at least 29 stars. And there is only 11 projects with more than 8 contributors."
                },
                {
                    "user": "rweed",
                    "date": "2019-12-20 22:26:24+00:00",
                    "text": "Don't know if its still actively maintained but Fortranwiki (fortranwiki.org/fortran/show/HomePage)\nused to have some lists of codes/projects broken down by application type etc. I would guess some of the links though are stale or broken."
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 22:54:10+00:00",
                    "text": "@rweed thanks! You are right, the links there are broken, but the names of packages are correct. I will go through it soon. I already found one (it's on GitLab, not GitHub, that's why I didn't find it before): https://gitlab.com/octopus-code/octopus, which looks healthy. For LFortran, the GitLab / GitHub star ratio is 52 to 113. So Octopus has 22 stars on GitLab, so that could have been something like 50 on GitHub, which is not bad.\nThere will be more codes like that, no doubt."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-20 23:24:03+00:00",
                    "text": "I added over a dozen more projects, some of them heavy-hitters.\nSome comments:\n\nAs Ondrej mentioned, stars aren't indicative of how popular or used a project is. Instead, stars are a measure of how much a project page was visited + how interesting or cool it seems. Some of my projects (functional-fortran, tcp-client-server) have many stars for the Fortran standard (hur hur), but that is only because I posted them on Hacker News and they happened to be upvoted and discussed, and brought in traffic.\nMost big Fortran projects, including the ones on this list, are developed and maintained at big labs. The GitHub repo is in many cases only a mirror (WRF, FV3-GFS, ROMS, probably many others). Such repos may have one or few GitHub contributors, but behind the curtains have contributions from dozens or hundreds of people.\nMost big Fortran projects started many years ago (before git or GitHub), and many simply didn't transition to development on GitHub yet, and likely won't soon.\nPeople that program Fortran (scientists, engineers, and a few oddballs) are a somewhat different culture from web developers that follow the latest trends in technology. Communities that started early on GitHub (10 years ago) had much more runway to grow. When I first started datetime-fortran in 2013, there weren't this many Fortran projects on GitHub."
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 23:30:14+00:00",
                    "text": "@milancurcic thank you so much for adding more projects --- indeed some of them are doing well.\nCan you add your comments into the Wiki?\nThis has been very helpful to get an overview how the opensource Fortran landscape looks like."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-20 23:38:35+00:00",
                    "text": "Interesting that fortran-machine (web server) by @mapmeld has Arjen's flibs as a dependency (for the CGI and SQL pieces if I recall correctly). That dependency could be stdlib for some similar future project."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-20 23:40:41+00:00",
                    "text": "Relevant article by Nick from few years back: https://medium.com/@mapmeld/fortran-culture-on-github-a257dd595061"
                },
                {
                    "user": "septcolor",
                    "date": "2019-12-21 02:10:13+00:00",
                    "text": "(Edit: Both have been added to Wiki)\nAre these packages also candidates?\nHANDE (QMC code)\nhttps://github.com/hande-qmc/hande\nDFTB+ (density functional tight-binding code)\nhttps://github.com/dftbplus/dftbplus"
                },
                {
                    "user": "certik",
                    "date": "2019-12-21 03:43:08+00:00",
                    "text": "Yes! Would you mind adding it in please?\n\u2026\nOn Fri, Dec 20, 2019, at 7:10 PM, septcolor wrote:\n Is this also a candidate? HANDE (QMC code)\n https://github.com/hande-qmc/hande\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#28?email_source=notifications&email_token=AAAFAWGC3EJ6H7Z6BTS3MTLQZV3INA5CNFSM4J6CBZX2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHOS2XY#issuecomment-568143199>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWEF5CV65WQI7SILF3DQZV3INANCNFSM4J6CBZXQ>."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-21 15:15:39+00:00",
                    "text": "These codes all have more than 30 stars and are not yet in the list. Some have only one or two contributors though.\nNode-Fortran\nhttps://github.com/IonicaBizau/node-fortran\nhttps://github.com/IonicaBizau/node.fortran\nDBCSR: Distributed Block Compressed Sparse Row matrix library\nhttps://github.com/cp2k/dbcsr\nStarlink software collection:\nhttps://github.com/Starlink/starlink\nParticle-in-Cell Skeleton Codes\nhttps://github.com/UCLA-Plasma-Simulation-Group/PIC-skeleton-codes\nCompDam - Deformation Gradient Decomposition (DGD)\nhttps://github.com/nasa/CompDam_DGD\nFlexi - Open Source High-Order Unstructured Discontinuous Galerkin Fluid Dynamics Solver\nhttps://github.com/flexi-framework/flexi\nspecfem3d\nhttps://github.com/geodynamics/specfem3d\nkdtree2\nhttps://github.com/jmhodges/kdtree2\nADflow - finite volume RANS solver tailored for gradient-based aerodynamic design optimization\nhttps://github.com/mdolab/adflow\nclfortran - Open source implementation of a Fortran interface to Khronos OpenCL API\nhttps://github.com/cass-support/clfortran\nMODFLOW6\nhttps://github.com/MODFLOW-USGS/modflow6\nNek5000\nhttps://github.com/Nek5000/Nek5000\nfds - Fire Dynamics Simulator\nhttps://github.com/firemodels/fds\nElmerFEM\nhttps://github.com/ElmerCSC/elmerfem\narpack-ng\nhttps://github.com/opencollab/arpack-ng\nGALAHAD - A library of modern Fortran modules for nonlinear optimization\nhttps://github.com/ralna/GALAHAD\nfgsl - Fortran interface to the GNU Scientific Library\nhttps://github.com/reinh-bader/fgsl\nFortranPatterns - Popular design patterns implemented in Fortran\nhttps://github.com/farhanjk/FortranPatterns\nLaGriT - Los Alamos Grid Toolbox\nhttps://github.com/lanl/LaGriT\nfluidity\nhttps://github.com/FluidityProject/fluidity\nfortranlib\nhttps://github.com/astrofrog/fortranlib\nogpf - Object based interface to GnuPlot from Fortran 2003, 2008 and later\nhttps://github.com/kookma/ogpf\ncoretran\nhttps://github.com/leonfoks/coretran\nsigma - Fortran 2003 library for sparse matrix algebra\nhttps://github.com/danshapero/sigma\naenet - Atomic interaction potentials based on artificial neural networks\nhttps://github.com/atomisticnet/aenet\nIAMR - A parallel, adaptive mesh refinement (AMR) code\nhttps://github.com/AMReX-Codes/IAMR\nPoisFFT - Free parallel fast Poisson solver\nhttps://github.com/LadaF/PoisFFT\nOpenSWPC\nhttps://github.com/tktmyd/OpenSWPC"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-21 15:38:37+00:00",
                    "text": "Yes! Nek5000, how could I've missed that! :)\n@ivan-pi Can you please add these to the wiki?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-21 16:35:37+00:00",
                    "text": "It will be painful to sort them in the right positions. I'll see what I can do.\nEdit: The list is updated! With the help of some Sublime multi-cursor magic it turned out to be easier than expected."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 04:49:45+00:00",
                    "text": "@ivan-pi thanks a lot for this! The list looks a lot better than when I first started. It's revealing to see these different Fortran projects and see how people use Fortran."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-22 11:06:10+00:00",
                    "text": "From what I can see it is mostly codes for computational chemistry, sparse and dense linear algebra (including eigenvalue problems), computational fluid dynamics and solid mechanics, computational seismology, reservoir simulation, nonlinear optimization, and the rest are general Fortran utilities (file I/O, containers, patterns, plotting...)."
                },
                {
                    "user": "rweed",
                    "date": "2019-12-22 14:32:21+00:00",
                    "text": "Obviously we have LOTs of open source/public domain software to choose from, I think we should stick to the things a standard library to support Fortran programming should be focused on. That is what functions/capabilities that don't current exist in Fortran that Matlab, NumPy/SciPy, and the C++ STL provide that reduce the amount of code you need to generate a CFD, FEM, sparse/dense matrix code etc. My priority list is as follows\nContainers/ADTs\nI would draw (because I already have) from Ruegers FTL project, Arjen's FLIBS, and implementation ideas outlined in a few books. However, if someone can point to a better approach I'm all in on that to.\nCommonly used mathematical/statistical functions not current part of Fortran\nThings like mean and standard deviations. Probability Density Functions, Cumlative Distribution Functions (CDF) and their siblings, normal (Gaussian) distributions, (ie  better support for random distributions and perturbations), factorials, and binomial coefficients and a host of other functions in this area.  A feature comparison of what is supported in Fortran and what NumPi/SciPy provides would probably be a good first step. We can then cherry pick all of the current and old implementations of these functions as candidates for the library.\nBetter support for creating, modifying, and manipulating arrays and matrices (which I remind everyone are not the same thing. one is a container, the other is a mathematical entity)\nThese include things like identity matrix (eye), linspace, meshgrid, the ability to generate real or integer sequences based on an fixed increment, dynamically adding rows and columns to a matrix\ndynamically, sorting rows and/or columns, and a form of reallocate or resize that wraps MOVE_ALLOC to allow a dynamic reallocations capability.\nFinally, sorting.\nThere are lots of implementations of all most commonly used sorting algorithms (quicksort, mergesort, heapsort, hashsort etc). The trick is to find a way to make them generic."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 15:23:08+00:00",
                    "text": "@rweed would you mind posting your last comment into #1? The issue here is about looking at the Fortran landscape of what (opensource) projects use Fortran, so that we can see what conventions they use and these projects can end up depending on stdlib. Your comment seemed to indicate that we can choose these projects as dependencies for stdlib, which is not the intention, and that's why I think your comment belongs into #1."
                },
                {
                    "user": "rweed",
                    "date": "2019-12-22 16:08:00+00:00",
                    "text": "@certik no problem. I just thought when we start listing CFD codes etc we were straying from what I thought the intent of the library was. My comments were an attempt to get the discussion focused back on what I thought the purpose of the library was."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 16:12:34+00:00",
                    "text": "I think the intent of the library, as discussed in #1, is to provide basic functionality, for example along the lines of your comment, so that stdlib can be used in codes such as listed in this issue #28, including the CFD codes."
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 15:13:28+00:00",
                    "text": "I added stdlib to the list. ;) With 47 stars and 7 contributors, we now belong there too."
                },
                {
                    "user": "rjfarmer",
                    "date": "2020-01-11 17:39:03+00:00",
                    "text": "Do you want non-github open-source fortran projects listed?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-11 17:46:04+00:00",
                    "text": "Yes! But only if we can reasonably estimate to have over 30 stars if they were on github.\n\u2026\nOn Sat, Jan 11, 2020, at 10:39 AM, Robert Farmer wrote:\n Do you want non-github open-source fortran projects listed?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#28?email_source=notifications&email_token=AAAFAWE7WPLJMSIWAY2J6L3Q5H73RA5CNFSM4J6CBZX2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIWG7SQ#issuecomment-573337546>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWFJJJWZ6O7REBXX74DQ5H73RANCNFSM4J6CBZXQ>."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-12 19:05:15+00:00",
                    "text": "Yeah.  The 30 stars on github is reasonable in a lot of ways, but some of those sites have been up\nfor years.  I have a fledgling one whose goal was exactly to promote something like the functionality\nof a standard utility library that only has a few stars that I still thought was a good fit as a seed for discussion in this project, which I would like to move towards contributing to.\nPreviously I was trying to start a group of github repositories with a similar goal relatively recently but I was primarily concentrating on setting up an automated process to extract codes from my heavily personalized development environment to a simple release format ( hopefully requiring others to have no need for more than a modern Fortran compiler and make(1)) so I could reduce the issues I had with putting something on github.\nAfter this project started  I wanted to switch to contributing to it and felt some of the materials I started were a good fit at least as part of discussion points about various utilities,  various documentation methods,  what APIs should look like, what compiler requirements should be for\nexperimental codes  ... (ie good for part 2 and 3).\nBut, since I do not have thirty stars, is there still an approved way to have others give the materials a look and let me know if there is anything there that would be a good candidate for moving to this project?\nafter looking at this sites' documenation:\nI started by opening an issue here for a topic covered by one of the modules I thought would be a\nsimple starting point; but that did not seem to elicit any response(but I'm not sure I have figured out how this all works yet).\nSo before surrendering I thought I would try directly eliciting feedback.  Does anyone find anything worth discussing at\nhttps://github.com/urbanjost?tab=repositories\nSo If no one finds anything interesting there that's fine and I can do my own thing; but there are some things on date and time, strings, and a POSIX interface I have seen discussed here that I\nthought were a good fit.\nMine has some basic PD self-contained  modules that anyone here can feel free to use for anything they want for discussion or use.  The larger GPF development repository has some mixed MIT, GNU, ... licensing in it so even though it has a lot more stuff in it, it is not 100% unencumbered at this point (working on that).\nSo for something that does not meet the \"github thirty stars\" criteria should I have\n\nwaited for 30 stars before asking anyone to look at this,\ntry to start related issues here from scratch and just use my stuff as anyone would if it was not even on github,\nmake a one-time solicitation to have it looked over? There does not seem to be an \"official\" way to\nask for something not meeting the gold standard to be evaluated.\ntry contributing my stuff to one of the sites that has 30 stars to piggyback on a more successful project\n-???\n\nThis project has all the goals and more collaborators and stars than I could reasonably hope for at this point, so I was basically hoping to contribute  any generic functions to this project and just leave mine for some esoteric stuff that would not fit into a standard library."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-12 19:20:56+00:00",
                    "text": "@urbanjost thanks for the info. Many of your things are of interest for stdlib.\nYou could probably start an issue similar to #103 or #104, and listing all the things that could contribute to stdlib"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-12 21:55:41+00:00",
                    "text": "@urbanjost I agree with @jvdp1. Much of what you have is in scope in my opinion, and the issue you opened for dates and times (#106) is the correct approach. Don't worry if there hasn't been feedback yet. I will write there soon and request feedback from others. We should handle dates and times with stdlib, we just need to work toward an API that most of the community will agree upon.\nThe 30 stars mentioned in this thread is arbitrary and meant only to keep the list of projects in the Wiki manageable. These projects are not meant as projects for transition to stdlib, but more as reference projects for us to learn how if Fortran used in real-life applications."
                },
                {
                    "user": "awvwgk",
                    "date": "2020-09-05 08:41:18+00:00",
                    "text": "The of popular Fortran projects in the wiki got quite out of date, in case it should still be maintained, one could automate at least the way meta data is fetched, a hacky example to do so using shields.io is in the details below.\n\n\n\n\nProject\nStars\nContributors\n\n\n\n\nABINIT\n\n\n\n\nADflow\n\n\n\n\naenet\n\n\n\n\narpack-ng\n\n\n\n\nbandup\n\n\n\n\nbspline-fortran\n\n\n\n\nCastro\n\n\n\n\nCFD\n\n\n\n\nCFL3D\n\n\n\n\nclfortran\n\n\n\n\nCompDam\n\n\n\n\ncoretran\n\n\n\n\ncp2k\n\n\n\n\nCTSM\n\n\n\n\ndatetime-fortran\n\n\n\n\nDBCSR\n\n\n\n\nDFTB+\n\n\n\n\nElmerFEM\n\n\n\n\nfdict\n\n\n\n\nfds\n\n\n\n\nFEconv\n\n\n\n\nfgsl\n\n\n\n\nFLAP\n\n\n\n\nFlexi\n\n\n\n\nfluidity\n\n\n\n\nFMS\n\n\n\n\nFOODIE\n\n\n\n\nforpy\n\n\n\n\nfortran2018-examples\n\n\n\n\nFortran-Astrodynamics-Toolkit\n\n\n\n\nfortran-csv-module\n\n\n\n\nfortranlib\n\n\n\n\nfortran-machine\n\n\n\n\nFortranPatterns\n\n\n\n\nfortran-utils\n\n\n\n\nfox\n\n\n\n\nfreeCappuccino\n\n\n\n\nftl\n\n\n\n\nfunctional-fortran\n\n\n\n\nFV3-GFS\n\n\n\n\nGALAHAD\n\n\n\n\nGFR\n\n\n\n\ngtk-fortran\n\n\n\n\nh5fortran\n\n\n\n\nHANDE-QMC\n\n\n\n\nIAMR\n\n\n\n\nICAR\n\n\n\n\njson-fortran\n\n\n\n\nkdtree2\n\n\n\n\nLaGriT\n\n\n\n\nLAPACK\n\n\n\n\nlesgo\n\n\n\n\nMODFLOW6\n\n\n\n\nMOM6\n\n\n\n\nMPAS\n\n\n\n\nNASTRAN-93\n\n\n\n\nNASTRAN-95\n\n\n\n\nNek5000\n\n\n\n\nNetCDF-Fortran\n\n\n\n\nneural-fortran\n\n\n\n\nnode-fortran\n\n\n\n\nnode.fortran\n\n\n\n\nnumerical-methods-fortran\n\n\n\n\nNWChem\n\n\n\n\nOFF\n\n\n\n\nogpf\n\n\n\n\nOpenBLAS\n\n\n\n\nOpenCMISS\n\n\n\n\nOpenCoarrays\n\n\n\n\nOpenSWPC\n\n\n\n\npFUnit\n\n\n\n\nPIC Skeleton Codes\n\n\n\n\nPoisFFT\n\n\n\n\npyplot-fortran\n\n\n\n\nQuantum ESPRESSO\n\n\n\n\nROMS\n\n\n\n\nSciFortran\n\n\n\n\nSHTOOLS\n\n\n\n\nsigma\n\n\n\n\nslsqp\n\n\n\n\nSNAP\n\n\n\n\nspecfem3d\n\n\n\n\nStarlink\n\n\n\n\nstdlib\n\n\n\n\nStringiFor\n\n\n\n\ntcp-client-server\n\n\n\n\nTRACMASS\n\n\n\n\nTruchas\n\n\n\n\ntsunami\n\n\n\n\nVTKFortran\n\n\n\n\nWAVEWATCH III\n\n\n\n\nWPS\n\n\n\n\nwrf_hydro_nwm_public\n\n\n\n\nWRF"
                }
            ]
        },
        {
            "number": 27,
            "user": "rweed",
            "date": "2019-12-20 04:00:54+00:00",
            "title": "Define a base user class to support ADTs, sorting etc.",
            "text": "I implement a user base class to support some of the Abstract Data Types (lists etc) and sorting codes I've implemented. It contains no data but defines dummy procedures for things I need to do to support sorting , generic lists etc. mainly relational operators (> < >= <= ==  assighment etc) and a print method. I implement this as a concrete (non-abstract) class to avoid having to overide all the methods as would be required with an abstract class with deferred abstract interfaces for the procedures since I might not need all of the procedures defined in the concrete class in the extended class. I think we will need something similar to this (or maybe a God or World class ala java that all classes are derived from) to support user defined types.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2019-12-20 14:21:45+00:00",
                    "text": "I like the idea. Can you show the prototype? How would this class and module be called?"
                },
                {
                    "user": "rweed",
                    "date": "2019-12-20 16:10:48+00:00",
                    "text": "OK. the entire module (again sorry about the length) follows. Again, I implement this as a concrete and not an abstract class because an abstract class with deferred interfaces obligates the user to implement all of the methods in the extended class. If someone can suggest a better approach please let me know. I wrote this about 5 years ago when compilers where still gagging on some of the OO features so there might be a better way to do this. However, this works so I've not seen any need to change it. I can post a use case where I extend the user type into a point class to store coordinates of nodes in a FEM mesh and then use quickSort to sort the points based on distance from the origin\n*** userType.F90 ****\n!  Copyright (C) 2015-2019 Richard Weed.\n!  All rights reserved.\n  \n!  Redistribution and use in source and binary forms, with or without \n!  modification, are permitted provided that the following conditions are met:\n  \n!  1. Redistributions of source code, in whole or in part, must retain the  \n!  above copyright notice, this list of conditions and the following \n!  disclaimer.\n  \n!  2. Redistributions in binary form, in whole or in part, must reproduce the \n!  above copyright notice, this list of conditions and the following disclaimer \n!  in the documentation and/or other materials provided with the distribution.\n  \n!  3. The names of the contributors may not be used to endorse or promote from \n!  products derived from this software without specific prior written \n!  permission.\n\n!  4. Redistributions of this software, in whole or in part, in any form, \n!  must be freely available and licensed under this original License. The \n!  U.S. Government may add additional restrictions to their modified and \n!  redistributed software as required by Law. However, these restrictions \n!  do not apply to the original software distribution.\n \n!  5. Redistribution of this source code, including any modifications, may \n!  not be intentionally obfuscated.\n  \n!  6. Other code may make use of this software, in whole or in part, without \n!  restriction, provided that it does not apply any restriction to this \n!  software other than outlined above.\n  \n!  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\n!  IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,\n!  THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n!  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS AND\n!  CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, \n!  EXEMPLARARY OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, \n!  PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; \n!  OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, \n!  WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR \n!  OTHERWISE), ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n!  ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nModule userClass\n\n! Defines an base container class for creating user defined types to be\n! used with generic ADT routines. It is intended that this base class\n! be extended and should not be used directly. We implement this as a\n! concrete class instead of an abstract one to allow users to override \n! only the type bound procedures they will use in their applications. An\n! abstract interface forces users to implement all of the procedures.  \n\n! Written by: Richard Weed, Ph.D.\n!             Missississippi State University\n!             Center for Advanced Vehicular Systems\n\n! Version No. : 1\n\n! Revision History : Initial version - December 2014\n\n  Implicit NONE\n\n! Define a User class that can be used to create other\n! classes. Its primary use is in createing ADT lists\n! but can also be used in any case where unlimited\n! polymorphic dummy arguments are used to create\n! a generic routine that mixes both intrinsic and\n! user defined data types.\n\n  Type :: User_t\n\n  Contains\n\n    Procedure :: isUserEQ\n    Procedure :: isUserGT\n    Procedure :: isUserLT\n    Procedure :: isUserGTE\n    Procedure :: isUserLTE\n    Procedure :: isUserNE\n    Procedure :: printUserValue\n    Procedure :: assignValue \n    Generic :: OPERATOR(==)  => isUserEQ \n    Generic :: OPERATOR(/=)  => isUserNE \n    Generic :: OPERATOR(<)   => isUserLT \n    Generic :: OPERATOR(>)   => isUserGT \n    Generic :: OPERATOR(<=)  => isUserLTE \n    Generic :: OPERATOR(>=)  => isUserGTE \n    Generic :: ASSIGNMENT(=) => assignValue\n    Generic :: printValue    => printUserValue\n  End Type\n\n  Type :: UserPtr_t\n\n    Class(User_t), Pointer :: userptr\n\n  End Type\n\nCONTAINS\n\n  Logical Function isUserEQ(this, value)\n\n    Implicit NONE\n\n    Class(User_t), Intent(IN) :: this\n    Class(*),      Intent(IN) :: value\n\n    isUserEQ = .FALSE.\n\n    Select Type(r=>this)\n\n      Class Is(User_t)\n        Select Type(p=>value)\n          Class Is(User_t)\n            Print *,' ** User_t isUserEQ not overridden'\n      End Select \n\n    End Select\n\n  End Function isUserEQ\n\n  Logical Function isUserGT(this, value)\n\n    Implicit NONE\n\n    Class(User_t), Intent(IN) :: this\n    Class(*),      Intent(IN) :: value\n\n    isUserGT = .FALSE.\n\n    Select Type(r=>this)\n\n      Class Is(User_t)\n        Select Type(p=>value)\n          Class Is(User_t)\n            Print *,' ** User_t isUserGT not overridden'\n        End Select \n\n     End Select\n\n  End Function isUserGT\n\n  Logical Function isUserLT(this, value)\n\n    Implicit NONE\n\n    Class(User_t), Intent(IN) :: this\n    Class(*),      Intent(IN) :: value\n\n    isUserLT = .FALSE.\n\n    Select Type(r=>this)\n\n     Class Is(User_t)\n       Select Type(p=>value)\n         Class Is(User_t)\n           Print *,' ** User_t isUserLT not overridden'\n        End Select \n\n     End Select\n\n  End Function isUserLT\n\n  Logical Function isUserGTE(this, value)\n\n    Implicit NONE\n\n    Class(User_t), Intent(IN) :: this\n\n    Class(*),      Intent(IN) :: value\n\n    isUserGTE = .FALSE.\n\n    Select Type(r=>this)\n\n     Class Is(User_t)\n       Select Type(p=>value)\n         Class Is(User_t)\n           Print *,' ** User_t isUserGTE not overridden'\n       End Select \n\n     End Select\n\n  End Function isUserGTE\n\n  Logical Function isUserLTE(this, value)\n\n    Implicit NONE\n\n    Class(User_t), Intent(IN) :: this\n    Class(*),      Intent(IN) :: value\n\n    isUserLTE = .FALSE.\n \n    Select Type(r=>this)\n\n      Class Is(User_t)\n        Select Type(p=>value)\n          Class Is(User_t)\n            Print *,' ** User_t isUserLTE not overridden'\n      End Select \n\n    End Select\n\n  End Function isUserLTE\n\n  Logical Function isUserNE(this, value)\n\n    Implicit NONE\n\n    Class(User_t), Intent(IN) :: this\n    Class(*),      Intent(IN) :: value\n\n    isUserNE = .FALSE.\n\n    Select Type(r=>this)\n\n      Class Is(User_t)\n       Select Type(p=>value)\n          Class Is(User_t)\n            Print *,' ** User_t isUserNE not overridden'\n        End Select \n\n    End Select\n\n  End Function isUserNE\n\n  Subroutine printUserValue(this, iunit)\n\n    Implicit NONE\n\n    Class(User_t), Intent(IN), TARGET   :: this\n    Integer,       Intent(IN), OPTIONAL :: iunit\n\n     Select Type(r=>this)\n\n      Class Is(User_t)\n        If (PRESENT(iunit)) Then\n          Print *,' ** User_t printUserValue not overridden for iunit ', iunit\n        Else \n          Print *,' ** User_t printUserValue not overridden '\n        EndIf\n     End Select \n\n  End Subroutine printUserValue\n\n  Subroutine assignValue(this, that)\n\n    Implicit NONE\n \n    Class(User_t), Intent(INOUT) :: this\n    Class(User_t), Intent(IN)    :: that\n\n    Select Type(r=>this)\n\n      Class Is(User_t)\n        Select Type(p=>that)\n          Class Is(User_t)\n            Print *,' ** User_t assignValue not overridden'\n        End Select\n\n    End Select\n\n  End Subroutine assignValue\n\nEnd Module userClass"
                }
            ]
        },
        {
            "number": 26,
            "user": "rweed",
            "date": "2019-12-20 03:44:11+00:00",
            "title": "Define a consistent naming scheme for derived types",
            "text": "I think we should have as part of the style guide and/or coding practices a standard naming convention (or two) for derive types. I currently append an _t tail to all derived type names ala\nType :: user_t\nHowever, as I use more extended types and classes I'm considering either using _et or _c to define\nan extended type. ala\nType :: user_et or user_c\nJust an idea I would like to throw out",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-20 23:20:22+00:00",
                    "text": "Is the reason to append _t as in user_t so that the variable can be named user, as in type(user_t) :: user?\nIt might be helpful to go over the most popular codes listed in https://github.com/fortran-lang/stdlib/wiki/List-of-popular-open-source-Fortran-projects and see what conventions they use and list them here, so that we can make a more informed decision."
                },
                {
                    "user": "rweed",
                    "date": "2019-12-20 23:54:07+00:00",
                    "text": "Yes and also to allow the module that contains the class/type to be named with a similar name so that there is no conflict.\nie\nModule userClass\nType :: UserClass_t\nThis is one of the things recommended in Clerman and Spector's very excellent book, \"Modern Fortran, Style and Usage\"  although I saw it used by other folks prior to their book. Again just another way of avoiding naming conflicts. Note you can always rename it on USE if you prefer in your code. Just makes the name somewhat unique. Adding an _et for extended types just gives you a visual signal in the source that the type is extended from something else when the original code author might have chosen to make all or parts of the class private."
                },
                {
                    "user": "septcolor",
                    "date": "2019-12-21 01:46:24+00:00",
                    "text": "FWIW, my convention is also similar to the above one (i.e., UserClass_t) such that it does not interfere with local variable names. I also sometimes rename it into a shorter one (e.g., FB_t => FooBaa_t) when importing it in a local module (if I want to type less). But I am also interested in other conventions."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-21 21:13:04+00:00",
                    "text": "The appended _t for types and _m for modules is also found in the \"opinionated\" best Fortran practices: https://github.com/Fortran-FOSS-Programmers/Best_Practices\nSometimes I also go for the longer _type to be more explicit. The iso_fortran_env module contains a lock_type as example."
                }
            ]
        },
        {
            "number": 25,
            "user": "certik",
            "date": "2019-12-19 22:42:40+00:00",
            "title": "How should stdlib handle single, double, quadruple precision types",
            "text": "When we declare a real variable in our API, we have to use some variable to represent the real kind. Available options for single, double and quadruple precision that people have used in codes:\n\nreal(sp), real(dp), real(qp)\nreal(real32), real(real64), real(real128)\nreal(r32), real(r64), real(r128)\nreal(float32), real(float64), real(float128)\nreal(f32), real(f64), real(f128)\nreal(wp) (for default real)\nreal(r4), real(r8), real(r16)\n\nI will keep appending to this list if we find some code that uses different names.\nThose variables must be defined somewhere. I will use the case 1. below, for other cases we simply substitute different names. The available options:\na. stdlib_types module that provides sp, dp, qp for single, double and quadruple precision as follows:\ninteger, parameter :: sp=kind(0.), &             ! single precision\n                      dp=kind(0.d0), &           ! double precision\n                      qp=selected_real_kind(32)  ! quadruple precision\nThe main idea behind this option is that there is a module in stdlib that provides the types and every other module uses it. The proposal #13 is similar to it. There are several options how the types are defined inside the module: one can define sp and dp using selected_real_kind also. Another alternative is to define sp, dp and qp using iso_fortran_env as in b. to a. The module stdlib_types  can be called differently also.\nb. use iso_fortran_env, only: sp=>real32, dp=>real64, qp=>real128 (if the case 2. above is used, then one does not need to rename, so it simplifies to just use iso_fortran_env, only: real32, real64, real128). Unlike a., this option does not introduce a new module in stdlib. One simply uses iso_fortran_env everywhere directly.\nc. use iso_c_binding, only: sp=>c_float, dp=>c_double, qp=>c_float128. Unlike a., this option does not introduce a new module in stdlib.\nI will keep this list updated if more options become available.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-19 22:43:19+00:00",
                    "text": "My own preference that I have been using is 1. together with a., so 1a."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 22:53:30+00:00",
                    "text": "I think the most important is to figure out which of 1. - 7. to use. One criteria is verbosity. These kinds are used all over the place every time you declare a real. So using a two character variable is the shortest, which leads to either 1., 6. or 7. The option 6. only works for a \"default\" real (whatever it is), and option 7. has three characters for quadruple precision. So the option 1. is the only option that allows to select any precision with just two characters. Using the terms single, double and quadruple are well established terms in Fortran, for example Lapack and other codes use the convention in the subroutine names as s for single and d for double. One could in principle use just single variables s, d and q, but that would clash with user defined variables. So appending p as \"precision\" is natural. Thus I really like sp, dp and qp, as they are short, thus easy to write and read and follow established Fortran precision terminology.\nMy next favorite would be 7., as it is two characters for single and double precision, and three characters for quadruple. After that probably 3. and then 2. The 7., 3. and 2. are less clear to read and write, because in Fortran when we talk about precision, most people use the terms single, double and quadruple. It takes time to convert the terms into numbers and to be honest I have to think a bit -- is double precision 8 bytes? How many bytes is quadruple precision? And in Fortran, we typically do not think in terms of how many bits or bytes variables occupy in memory, but rather we think in terms of precision of our numbers. So from this perspective, option 1. is more natural than options 7., 3. or 2."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-19 22:59:02+00:00",
                    "text": "This should also consider integer (int32,int64,..).\nMy own preference would be to use the definitions of iso_fortran_env directly (so, to use real32, real64, int32,...). It is a bit more verbose, but it is already standart.\nSo, in your example, it would be 2-."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 23:11:22+00:00",
                    "text": "I also like to use built-in type kinds from iso_fortran_env, so my preference is option 2. I like the shorter variants, so 1b, 3b, and 5b are all palatable to me.\nThere have been concerns that the constants from iso_fortran_env are only portable in terms of byte width and not precision (https://software.intel.com/en-us/blogs/2017/03/27/doctor-fortran-in-it-takes-all-kinds). For example, real128 is not guaranteed to be true quad-precision. I don't know how much is this still an issue."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 23:28:08+00:00",
                    "text": "@jvdp1 I think you meant to write 2b. It's a good point that the case 2. uses names that are in the standard.\nNote that there is a long discussion about this topic here:\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=COMP-FORTRAN-90;2d0ccba2.1304\nOne must click on \"Next\" by Topic to see the next messages in the thread, so I am posting the links directly here and I'll try to summarize the ideas there later:\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=18711\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=19277\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=20030\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=20905\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=21662\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=22596\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=23429\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=24008\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=24879\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=25654\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=26570\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=27946\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=28555\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=28767\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=29559\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=30358\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=31147\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=32768\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=33612\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=34260\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=35079\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=35663\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=36599\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=37105\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=37938\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=38784\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=39675\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=40553\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=41513\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=42275\nhttps://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=ind1304&L=COMP-FORTRAN-90&D=0&P=43064"
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 23:39:13+00:00",
                    "text": "Personally,  I like options 1a and 1c."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 23:56:47+00:00",
                    "text": "@milancurcic in that blog post you linked to, Steve Lionel is pretty clear that he recommends not to use the constants from iso_fortran_env.\nThe safest is to define a module, where we define our our constants (option a.), we can call them real64 if you like that name (so option 2 above --- although as I conclude below, I don't like that name at all), but we ensure that they are the right kind on all compilers and platforms. As indicated, the real128 didn't actually provide the right kind on all compilers. That issue is completely avoided if we introduce a module with our own real64 variable. Because we can then easily ensure that it is declared properly to work in all compilers. How it is defined inside our stdlib_types module is another issue, I don't really care about that.\nMore generally, tying double and quadruple precision to bytes is artificial. The same with real16 and bfloat16 (also 16bit, but different than real16).\nRather, I recommend we provide our numerical code for single, double and quadruple precision (perhaps also half precision and/or bfloat16 later if those types become available) and that we control those kinds and declare them in some module. So option b.\nRegarding that it is already in the standard: we are designing a standard library. So we can use any of the options above I think if we determine that they are better than what is already in the standard.\nI think we'll not be able to resolve this quickly. But I do want to move forward. One compromise that would be ok with me right away is: 1b, that is:\nuse iso_fortran_env, only: sp=>real32, dp=>real64, qp=>real128\n\nand get rid of the stdlib_types module. That still allows us to easily move the definition to a separate module if needed, without having to rewrite all the code --- as I said, I don't care that much how it is defined, as definitions can be changed relatively easily, but I do care a lot how the actual code that defines real variables looks like. @milancurcic indicated he would be ok with it. @jvdp1 what do you think?"
                },
                {
                    "user": "rweed",
                    "date": "2019-12-20 03:38:43+00:00",
                    "text": "This is one of things I was trying to address with issue #13.\nI commonly use either RK or WP for the default real kind but am moving to use just WP since that is the most commonly used name I see in a lot of other projects (LAPACK90 etc. I think). My position is we should use a multi-\"layer\" approach where you define (as I do in #13) the equivalent of REAL64 etc as the base names, shorter aliaises for the specific types (DP, QP etc) and then a default type name (WP etc)."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-20 04:38:07+00:00",
                    "text": "I'd suggest avoiding some of the simpler two-character names like sp or rk for the kind handles, since it would be best to preserve the namespace for users as much as possible.  The verbosity does not bother me, and as @rweed suggests one can always define a \"working precision\" wp for their own code.\nOne possible solution to management of kinds is to try and identify the available data types which have known hardware implementations, or at least have been defined in some sense (IEEE 754), and then name the kinds after these well-defined formats.  The library would then map the kind to the type, and the user could invoke the type unambiguously.\nFor example, descriptive names like float and double (or float32 and float64) could be explicitly assigned to their IEEE types.  float80 could explicitly map to the x86 80-bit float, doubledouble onto the IBM XL quad type, and so on.  The build system would determine which ones exist and which kind to assign to them.  (Missing ones could be set to a defined MISSING_KIND)\nThis would seem to me to avoid the issues with real128, since \"16-byte float\" was not well-defined for a long time.  By addressing this at library build time, we would never have to deal with this ambiguity.\nThis is not something that can be done in the language standard, since it strives to be hardware-agnostic, and a user without stdlib would have to resort to selected_real_kind or kind(0.0) checks.  But it may make more sense in a library whose parameters are set at build time.\nAnd if there's any types that I have missed (float8 or a decimal float, for example), then they could be added to a custom implementation of stdlib, with the hope that the label would eventually be integrated into the reference library."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-20 06:47:41+00:00",
                    "text": "I think we'll not be able to resolve this quickly. But I do want to move forward. One compromise that would be ok with me right away is: 1b, that is:\nuse iso_fortran_env, only: sp=>real32, dp=>real64, qp=>real128\nand get rid of the stdlib_types module. That still allows us to easily move the definition to a separate module if needed, without having to rewrite all the code --- as I said, I don't care that much how it is defined, as definitions can be changed relatively easily, but I do care a lot how the actual code that defines real variables looks like. @milancurcic indicated he would be ok with it. @jvdp1 what do you think?\n\n@certik I am ok with your proposition. It would allow us to move forward in the different modules, while discussing what is the best solution for everyone, and maybe defining a stdlib_types.f90 that could be used across all modules."
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 18:40:36+00:00",
                    "text": "@jvdp1 thank you. I'll update the PR #23.\n(Btw, we should probably call it stdlib_kinds.f90 instead of stdlib_types.f90 if we introduce the module later.)\n@marshallward in order to move #23 forward, what do you suggest we do? What names should we use for the kind variables? It seems most people would be ok with sp, dp and qp. Your objection:\n\nI'd suggest avoiding some of the simpler two-character names like sp or rk for the kind handles, since it would be best to preserve the namespace for users as much as possible.\n\nThe sp, dp and qp names will be used internally in stdlib. User code is free to use other kinds variables if they wish. So it would not clash. Can you elaborate on this concern a little bit?"
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-20 18:45:29+00:00",
                    "text": "If they're only used internally then there's no issue.  I think I misunderstood the issue and had thought that the library would be providing types for users.\nWithin the library there's no objection from me."
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 18:48:47+00:00",
                    "text": "Note: I am going to wait until the list at https://github.com/fortran-lang/stdlib/wiki/List-of-popular-open-source-Fortran-projects is reasonably complete, and then I'll update the information below.\nI'll use this comment to collect the usage in codes. I put the number of GitHub stars in parentheses.\nCodes that I know about off top of my head:\n\nVASP: REAL(q)\nQuantum ESPRESSO (219): REAL(DP)  (USE kinds, ONLY : DP)\ncp2k (167): REAL(KIND=sp), REAL(KIND=dp), REAL(real_4) (USE kinds, ONLY: sp, dp, real_4, real_8) Note: most code seems to use sp and dp, but some modules use real_4 and real_8.\nfortran-utils (123): real(dp) (use types, only: dp)\nABINIT (97): real(dp)\nTruchas (30): real(r8) (use kinds, only: r8)\n\nCodes found using this search query at GitHub (for some reason this query does not show any of the highly starred projects above...):\n\nOpenCMISS (56): REAL(DP) (USE KINDS)\nTRACMASS (31): REAL(DP), REAL (KIND=DP)\nSNAP (29): REAL(r_knd) (USE global_module, ONLY: r_knd)\n\nI then tried this query:\n\nCrunchYuchen (0): REAL(DP)\ndgswe (1): REAL(rp) (USE globals, ONLY: rp)\n2DNoise_Adjoint_tomography (2): real(kind=CUSTOM_REAL) (use constants, only: CUSTOM_REAL)\nCESM (0): real(r8) (use shr_kind_mod, only: r8 => shr_kind_r8)\nUMD_Etc (0): REAL(r_size) (USE common, ONLY: r_size)\nFAST-SC-DLL-OC3Hywind (0): REAL(ReKi) (USE Precision)\nACME_20180417 (0): real(r8)\nCMEM (0): REAL(KIND = JPRM) (USE PARKIND1  ,ONLY : JPIM,JPRM)\nNEMO_MyTrc (0): REAL(wp)\nCESM2GC_GCSrc (0): REAL(fp) (USE PRECISION_MOD)\nPrueba (0): real(kind=dp) (use precision, only: dp)\nCEQUALW2Component (1): REAL(R8) (INTEGER, PARAMETER :: R8=SELECTED_REAL_KIND(15))\n\nFor some reason the GitHub queries do not return highly starred projects... So I started #28 to ensure the above analysis captures all the popular projects."
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 18:50:11+00:00",
                    "text": "@marshallward initially it would provide these types to users, but above we decided on a compromise that for now it would be internal to stdlib, until we can agree on a solution."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-31 04:31:24+00:00",
                    "text": "another factor to consider is that some compilers including GCC 9 can be buggy with quad-precision. Sometimes compile/link errors, sometimes runtime errors. I would consider making real128 be optionally included perhaps as a submodule for everyplace real128 might be a desired kind. The option to include could be manual or a build system check check_fortran_source_runs()\nalso consider for long term, growing momentum of half-precision float16 in general, including Fortran e.g. NAG. So having a modular approach to kinds may be useful and not burdensome."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 19:34:35+00:00",
                    "text": "This is certainly a complicated issue.\nOne of the wonderful things about Jin2For is it queries the kind parameter arrays provided by iso_fortran_env so you can implement an interface for all available intrinsic kinds. This is very nice from a client-code usability perspective: Call a procedure in stdlib that takes any intrinsic kind and it will work (baring bugs, such as those mentioned above by @scivision. The downside is that users either need to have and run Jin2For locally to generate code that matches their compiler, or we would need to provide a pre-processed source distribution for each compiler.\nBecause of these limitations in Jin2For, I'd prefer to see kinds supported that correspond to standardized floating point (and integer) formats with standardized ABIs like IEEE 754. This way they should exist across all compilers and be more interoperable with C and other languages. My inclination is to go with @certik's proposed 1-3 or 7 but use option c: iso_c_binding to declare the types in hopes that they exist and match the standardized floating point model the programmer is thinking of. But this may also be the case with approaches \"a\" and \"b\".\nI also note that care must be taken with approach \"a\", i.e., selected_real_kind(32) since kinds like the 80-bit float might be present that you were not expecting. For example, if one knows that double precision (IEEE 754) has a precision() of 15, then one might assume the next available real kind must be quad precision and request selected_real_kind(precision(1.0D0) + 1), which, for GFortran, would return a real kind of 10, which appears to be the x86 80-bit real, and is likely not what the naive programmer intended."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-31 20:53:35+00:00",
                    "text": "In my opinion option (c) using iso_c_binding would be necessary to work with many real-world projects that interface with C or use C interfaces. To keep relevance and growth of Fortran I think this is necessary. Almost every project I work with needs to have a C-like interface, and that requires iso_c_binding in my opinion. I think iso_fortran_env real32/64 int32/64 is more aesthetically appealing, but I suppose if we're going to be motivated by interfaces to C than maybe it's best to go all with the way with iso_c_binding instead\nI think there are good and valid reasons for the other methods too in a pure-Fortran environment, but I think there are too many important real-world use cases where there must be an interface to other languages, whether hidden or visible to the user (e.g. libraries that internally use C interfaces, or those whose ABI explicitly uses C interfaces)"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-31 21:06:08+00:00",
                    "text": "In my opinion option (c) using iso_c_binding would be necessary to work with many real-world projects that interface with C or use C interfaces. To keep relevance and growth of Fortran I think this is necessary. Almost every project I work with needs to have a C-like interface, and that requires iso_c_binding in my opinion. I think iso_fortran_env real32/64 int32/64 is more aesthetically appealing, but I suppose if we're going to be motivated by interfaces to C than maybe it's best to go all with the way with iso_c_binding instead\n\nHmm, I haven't considered this but I think it's a good point and I agree with it. If this would help non-Fortran projects to more easily interface Fortran stdlib (I think so), we should seriously consider this."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 22:05:29+00:00",
                    "text": "Would it make sense to put the kinds variables (say sp, dp, qp or whatever we decide) into a module stdlib_kinds.f90, and inside the module we can for example use iso_c_binding to define them? That way if the definition had to be changed for some reason, only one module stdlib_kinds.f90 has to change, the rest of the code stays the same."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-31 22:22:14+00:00",
                    "text": "Would it make sense to put the kinds variables (say sp, dp, qp or whatever we decide) into a module stdlib_kinds.f90, and inside the module we can for example use iso_c_binding to define them? That way if the definition had to be changed for some reason, only one module stdlib_kinds.f90 has to change, the rest of the code stays the same.\n\nIf we are going to use iso_c_binding, then I think it would make sense indeed.\nA module stdlib_kind.f90 would replace iso_fortran_env for the different kinds. Therefore such a module should also define the different kinds for integers, to avoid something like:\nuse iso_fortran_enc, only: int32,int64\nuse stdlib_kinds, only: sp, dp, qp"
                },
                {
                    "user": "nshaffer",
                    "date": "2020-01-02 08:45:54+00:00",
                    "text": "Let's not forget complex kinds! (and character kinds, but that warrants separate discussion)"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 16:02:14+00:00",
                    "text": "Let's not forget complex kinds! (and character kinds, but that warrants separate discussion)\n\nI totally agree. I would guess that most people are implicitly considering complex kinds when discussing reals because the available kinds for complex are the same as for reals, with the same properties (range, precision, epsilon, tiny, huge, etc.)\nAs for character kinds, that's a trickier issue."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 16:14:02+00:00",
                    "text": "I implemented this latest idea of a stdlib_kinds module using iso_c_bindings at #63."
                }
            ]
        },
        {
            "number": 24,
            "user": "certik",
            "date": "2019-12-19 19:20:44+00:00",
            "title": "Reading CSV files",
            "text": "Here is how NumPy and Pandas do it:\nhttps://stackoverflow.com/questions/3518778/how-do-i-read-csv-data-into-a-record-array-in-numpy#3519314\nand @jacobwilliams wrote a module for it here: https://github.com/jacobwilliams/fortran-csv-module",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2019-12-20 02:32:18+00:00",
                    "text": "It would be interesting to see how does Fortran compare with the supposedly fast Pandas read_csv function: https://wesmckinney.com/blog/a-new-high-performance-memory-efficient-file-parser-engine-for-pandas/"
                },
                {
                    "user": "jacobwilliams",
                    "date": "2019-12-20 05:19:27+00:00",
                    "text": "I make no claim that my lib is the fastest thing in the world. \ud83d\ude04 Probably there is massive room for improvement."
                }
            ]
        },
        {
            "number": 23,
            "user": "certik",
            "date": "2019-12-19 18:24:15+00:00",
            "title": "Implement loadtxt and savetxt",
            "text": "This also includes a minimal CMake build system. We can improve the\nbuild system in further PRs.\nFixes #16.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 18:37:34+00:00",
                    "text": "Thanks @certik. Should we make feature PRs to go into feature branches, for example feature/loadtxt?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 19:27:02+00:00",
                    "text": "My own preference is to simply send PRs against master. That seems to scale really well even for big projects and it's simple for newcomers to understand. But if others feel we should use another workflow, I am happy to adjust. How would the feature branch work? Would it be long lived?\nWhat I was thinking is simply merging to master and we would use master as the latest version, that way people can easily test it out etc.\nHowever, one thing that I am not sure if we should have an \"experimental\" section, perhaps src/experimental. And put new features there first. The module would be called stdlib_x_io, or something like that, to show that it is experimental (i.e. freshly implemented) and we need to gain experience actually using it to see if we are willing to commit to (forever) maintain backwards compatible API."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-19 19:39:51+00:00",
                    "text": "This also includes a minimal CMake build system. We can improve the\nbuild system in further PRs.\nFixes #16.\n\nNice.\nRegarding extension to other types than dp (e.g. float, integer4/8,...), would it be beter using data polymorphism (unlimited polymorphic) or repeating the procedures and overloading (maybe a question for the issues)?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 19:41:41+00:00",
                    "text": "@jvdp1 good point, I think the double precision is the most common, so we can start with that. We either have to repeat it by hand, or use some templated systems (there are a few) that generate it for us."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 20:01:55+00:00",
                    "text": "However, one thing that I am not sure if we should have an \"experimental\" section, perhaps src/experimental. And put new features there first. The module would be called stdlib_x_io, or something like that, to show that it is experimental (i.e. freshly implemented) and we need to gain experience actually using it to see if we are willing to commit to (forever) maintain backwards compatible API.\n\nCould a git branch (devel or even experimental) be used for this purpose, like @zbeekman suggested in #5?"
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-19 20:07:40+00:00",
                    "text": "@certik I often use single-precision ;) This could be also an issue for other modules (e.g. linalg?). So it would be maybe good to discuss it broadly at some point. I never work with templated systems, but I am not against. It would be probably more efficient (easier?) than using unlimited polymorphism."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 20:12:53+00:00",
                    "text": "@milancurcic it can. But things can stay experimental for quite some time (I can easily see something being experimental for a year). And managing two branches becomes painful. For example, with this PR, it requires some infrastructure setup (CMake, etc.), so if we put it in an experimental branch, we have to redo the CMake setup in another PR which will need it also. We can extract the CMake stuff, put into master, and try to keep the experimental branch small. But it's still going to be quite some work. Then how about releases? If everything is in master, we just need to create one release tarball and everybody can test it out. If we have an experimental branch, do we release two tarballs? We can, but it feels like a lot of administrative overhead.\nI was thinking of doing something like C++ does:\nhttps://en.cppreference.com/w/cpp/experimental\nAs an example: https://en.cppreference.com/w/cpp/experimental/parallelism_2, the experimental (new) feature is simply in an experimental/... header file, but my understanding is that it is part of the main standard library (e.g., part of \"master\")."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 20:18:36+00:00",
                    "text": "I would suggest to develop like Microsoft develops the C++ standard library. Here is their main repo:\nhttps://github.com/microsoft/STL\nOnly one branch (master). The experimental features are in master, in the experimental directory, e.g.:\nhttps://github.com/microsoft/STL/blob/28ec9a32952e0d7443936f8d5ae5d675ba6cf65c/stl/inc/experimental/deque\nHere is an example of a PR, against master, with an experimental feature:\nmicrosoft/STL#361\nIt's simple, it's proven, it works for C++ and Microsoft. And then if we need to make some adjustment to a proven workflow, we can."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 20:19:36+00:00",
                    "text": "@jvdp1 good point, we should implement single precision version also in this PR."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 20:29:19+00:00",
                    "text": "@certik Got it, I didn't consider all the separate infrastructure that would be needed, and indeed that would be a pain in a separate branch. Having a separate repo for this would also be a pain I think. Separate directory as you suggest seems reasonable."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 21:59:39+00:00",
                    "text": "Ok, so let's just use master with a separate directory called experimental, as the C++ stdlib. How should we rename the module? Because in C++, you import as #include <experimental/deque>, so in your code you know you are using an experimental API. In Fortran, we do not import using the path, so we need to rename the module (until j3-fortran/fortran_proposals#86 is implemented). Here are some ideas how to rename it:\n\nstdlib_x_io\nx_stdlib_io\nstdlib_io_x\nstdlib_experimental_io\n\nThe last one stdlib_experimental_io is probably in line with the C++ idea, i.e. #include <experimental/deque> would correspond to stdlib_experimental_deque. Also by spelling experimental fully would be consistent with the name of the directory."
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 18:13:32+00:00",
                    "text": "Let's keep the discussion going, so that we can merge this.\nShould I move the io module into: stdlib_experimental_io per the discussion above?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 23:03:28+00:00",
                    "text": "@milancurcic please let me know your opinion regarding stdlib_experimental_io, see above."
                },
                {
                    "user": "certik",
                    "date": "2019-12-21 04:59:33+00:00",
                    "text": "I moved all new code to stdlib_experimental in 559bfd7. If feels right, because now we don't need to get everything 100% right in each PR. We just need to get it mostly right, and then the rest we can improve collaboratively with subsequent PRs, and get some real world usage, until we are all convinced that the functionality is rock solid. Then we can move it to stdlib_io from experimental."
                },
                {
                    "user": "certik",
                    "date": "2019-12-21 05:09:47+00:00",
                    "text": "I also just added a single precision version.\n@milancurcic, @marshallward, @jvdp1 would you mind giving it another review please?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-21 13:25:40+00:00",
                    "text": "Send a PR against my branch in my fork. When I merge it, your commits will appear here.\n\u2026\nOn Sat, Dec 21, 2019, at 2:07 AM, Jeremie Vandenplas wrote:\n ***@***.**** commented on this pull request.\n\n In src/stdlib_experimental_io.f90\n <#23 (comment)>:\n\n > +real(dp), allocatable :: tmp(:,:)\n +call dloadtxt(filename, tmp)\n *This implies a additional copy of the array d (in dp). This could be\n quite inefficient for large files/arrays.\n  *This way could be also difficult to generalize for quad precision qp.\n\n I implemented a more general solution and extended it to qp. How could\n I propose these changes?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#23?email_source=notifications&email_token=AAAFAWA2MNUAQVM2HKGVIJTQZXMERA5CNFSM4J5MX6U2YY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCQAMZGI#pullrequestreview-335596697>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWEHKRYZNZMMGHEFCXLQZXMERANCNFSM4J5MX6UQ>."
                },
                {
                    "user": "certik",
                    "date": "2019-12-21 13:39:32+00:00",
                    "text": "The alternative workflow is that we merge this PR, and you simply send a PR with improvements against master. In fact I think I would prefer that --- simpler and it scales better, as there are a lot more improvements that we need to make:\n\nyou can work on better single and quadruple support\nI can work on setting up a CI\nsomebody else can work on the ascii module, ...\n\n@milancurcic would you be ok with merging this PR now so that others can send subsequent PRs?"
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-21 14:39:43+00:00",
                    "text": "The alternative workflow is that we merge this PR, and you simply send a PR with improvements against master. In fact I think I would prefer that --- simpler and it scales better, as there are a lot more improvements that we need to make:\n\nyou can work on better single and quadruple support\nI can work on setting up a CI\nsomebody else can work on the ascii module, ...\n\n\n@certik , @milancurcic At this point, I think it is the easiest solution indeed.  @ivan-pi ? is maybe also waiting on a first implementation for the ascii module"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-21 14:41:07+00:00",
                    "text": "I like the idea of implementations going into the staging area like experimental and getting further work there before becoming part of the \"stable\" stdlib. stdlib_experimental_io is okay with me.\nTo move faster, I also agree that we can merge PRs into stdlib/experimental. There will be quite a few things that we'll want to fix or change, and this could keep the PR from being merged and slowing down next contributions that depend on it (but should really be their own PRs).\nI think that we can merge PRs into stdlib/experimental as soon as:\n\nCommunity agrees on the API (that's why better keep PRs small);\nTests pass\n\nBasically, treat is as an MVP -- minimum viable product. Then we can refine with additional PRs, but other contributions that depend on this can be made because the code is merged in master.\nI will give this another review now."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-21 15:16:51+00:00",
                    "text": "The only outstanding issue is that the test data (in src/tests/loadtxt/) are not copied or linked to where the test executables are built with CMake, if they're built in a separate directory. For example, my default habit was to do\nmkdir build\ncd build\ncmake ..\nmake\nctest\n\nIn which case the tests fail because test data is not there.\nWe should somehow either ensure that test data is next to the test executables, or put an instruction in README.md that the library must be built in the top-level directory.\nI will have a few suggestions for changes after merge, which can be one or more new PRs."
                },
                {
                    "user": "certik",
                    "date": "2019-12-21 22:11:31+00:00",
                    "text": "@jvdp1 it's merged! Go ahead and submit PRs against master now (into an experimental module)."
                },
                {
                    "user": "certik",
                    "date": "2019-12-21 22:39:01+00:00",
                    "text": "@milancurcic what you wrote in #23 (comment) is I think exactly how we should do it. Merging to experimental modules can be treated similarly as merging to any other opensource project --- the community must agree on the API, tests must pass and it must pass review. It doesn't have the be 100% ready, as in this PR --- but we must be able to get to the 100% solution by sending subsequent PRs.\nOnce we get to the 100% solution in experimental, we'll have to figure out another workflow how to move it from experimental into main. For now our workflow is enough to keep going.\nThanks for the review!"
                }
            ]
        },
        {
            "number": 22,
            "user": "marshallward",
            "date": "2019-12-19 18:17:45+00:00",
            "title": "Interface to POSIX I/O API",
            "text": "stdlib may include a module which provides an interface to the POSIX I/O calls in the C standard library.  Such a module would support higher level functionality proposed in #14 on Unix-like platforms.\nThis module, or specific components, could be conditionally integrated into stdlib by the build system (CMake, autotools, etc) depending on whether they are available.\nSuch a module could also be extended to include more POSIX calls, e.g. thread support, memory allocation, lower-level system calls.  For now, I'd say to keep the scope more narrow in order to keep it achievable.",
            "comments": []
        },
        {
            "number": 21,
            "user": "certik",
            "date": "2019-12-19 17:27:48+00:00",
            "title": "Include FFT",
            "text": "We can use FFTPACK, or my own modern Fortran refactoring of it: https://github.com/certik/hfsolver/blob/b4c50c1979fb7e468b1852b144ba756f5a51788d/src/fourier.f90 and we need to allow optionally using MKL or FFTW.\nNumPy uses FFTPACK that they transformed into C and heavily modified: https://github.com/numpy/numpy/tree/a9bb517554004cf2ce7a4be93bcbfb63ee149844/numpy/fft. We could use it also, but I think it might be valuable to stay in Fortran (see #20).",
            "comments": [
                {
                    "user": "rweed",
                    "date": "2019-12-20 19:08:47+00:00",
                    "text": "Be careful with MKL. I don't know about FFT etc. but I encountered a problem with their implementation of LAPACK90 where they changed the argument list (same arguments but in different order) on some of the subroutines. Not a problem if you know about it before hand and use the keyword arguments but you would hope that Intel would have had the good sense to keep the netlib LAPACK90 interfaces as is."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-09 04:37:25+00:00",
                    "text": "@certik  At the top of your fourier.f90 you mention that its an O(n^2) code? Or is that just for the dft and idft subs?  Isn't the Cooley Tukey algorithm O(nlogn)?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-09 23:31:51+00:00",
                    "text": "@leonfoks yes, the dft is slow O(n^2), and the fft_pass is the fast O(n*log(n)) FFTPACK algorithm. I think I have an improved API in my internal code that is not open source.\nIn the stdlib, there should just be a function fft that works in 1D, 2D, 3D and that uses the FFTPACK version."
                }
            ]
        },
        {
            "number": 20,
            "user": "certik",
            "date": "2019-12-19 17:21:49+00:00",
            "title": "Which implementation languages can be used in stdlib",
            "text": "Obviously Fortran.\nIn #19, it looks like also using C might be beneficial.\nI was hoping to avoid depending on C++, because that will make stdlib much simpler to distribute (and statically link, etc.). Down the road I would like stdlib to be shipped by default with compilers. So to make it as simple as possible to distribute will be key.\nEven simpler would be if we can stay in pure Fortran, but I don't know if we can do that.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-19 17:25:06+00:00",
                    "text": "Related to this is what dependencies we can have. In #10 we will have to depend on a LAPACK implementation. The reference Lapack is in pure Fortran, but we want to be able to link to optimized implementations such as OpenBLAS and MKL. The same with FFT (#21), we can use FFTPACK (Fortran), but we should also allow linking with other implementations such as MKL or FFTW."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 17:28:32+00:00",
                    "text": "I agree, the general principle we could take:\n\nImplement anything we can in Fortran;\nDefer to C for things that we have to;\nAny other language and tool, think and discuss hard and long why it's needed\n\nI can't think of what we'd need C++ for, unless we were writing a Fortran interface to an existing C++ library.\nI think this also touches on build systems discussed in #2. Adding a foreign language tool or library increases the complexity of the project (both for us and for users) by more than just the sum of the parts."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 17:32:50+00:00",
                    "text": "Agreed. Regarding C, what do we need to use C for besides #19? For example in #21 there are Fortran implementations, so we do not need C there.\nI think we might need C to implement low level system dependent access to files, processes, etc. as suggested in #14 (comment)."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 17:39:06+00:00",
                    "text": "As of right now only #19 is looking in that direction. If a POSIX proposal is more seriously considered, that may still be just a set of interfaces with iso_c_binding, so still Fortran."
                },
                {
                    "user": "cmacmackin",
                    "date": "2019-12-19 17:39:38+00:00",
                    "text": "Related to this is what dependencies we can have. In #10 we will have to depend on a LAPACK implementation. The reference Lapack is in pure Fortran, but we want to be able to link to optimized implementations such as OpenBLAS and MKL. The same with FFT, we can use FFTPACK (Fortran), but we should also allow linking with other implementations such as MKL or FFTW.\n\nSomething to keep in mind with FFTW is that it is under the GPL (very unusual for a library). Therefore, if we provide a wrapper able to link against it, it is very important that this be optional so non-GPL software can still use it. Or we could just license all of stdlib under GPL, which I  wouldn't object to but I suspect most others will ;)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 17:45:34+00:00",
                    "text": "Something to keep in mind with FFTW is that it is under the GPL (very unusual for a library). Therefore, if we provide a wrapper able to link against it, it is very important that this be optional so non-GPL software can still use it. Or we could just license all of stdlib under GPL, which I wouldn't object to but I suspect most others will ;)\n\nYes. The plan is to only depend on MIT or BSD licensed libraries by default. Then we can have optional wrappers for other libraries like MKL or FFTW, and since they are optional, and stdlib works perfectly fine without them, we can keep our MIT license for stdlib."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 17:49:48+00:00",
                    "text": "@milancurcic even in #19 it looks like we'll probably stay in Fortran. So why don't we try hard to stay in Fortran and see if that works for us. That would make things very simple. If we cannot do that, then let's revisit."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-19 18:23:44+00:00",
                    "text": "I agree that the reference implementation should use Fortran as much as possible.  If there are cases where it cannot be used, then it will highlight a critical limitation of the language, and allow the issue to be handed to the standards committee.\nBut certainly other implementations, say from vendors, should not feel obliged to use Fortran."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 18:29:41+00:00",
                    "text": "@marshallward good point. I think this stdlib can act as a reference implementation, like the reference Lapack implementation (in Fortran). Then vendors can provide more optimized versions and they do not need to use Fortran, as long as they provide the same API."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 18:40:45+00:00",
                    "text": "I would also try to stick with Fortran and C for the beginning. Not only can it be a reference implementation, but hopefully also a good example of what modern Fortran code should look like."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 21:25:37+00:00",
                    "text": "Having just said that, I would like to hear your opinions on are we willing to wrap any F77 code with modern interfaces? I can guess the opinion of @jacobwilliams already \ud83d\ude1d\nI suspect that at some point, we will end up refactoring some old Fortran routines (the first two examples that come to my mind are the good ol'  zeroin and fmin functions)."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 22:25:24+00:00",
                    "text": "@ivan-pi I think the answer is that for the API, we should use modern Fortran API (modules, assumed-shape arrays, etc.). How things are actually implemented underneath do not matter as much --- we can start with F77, then refactor later if needed. In fact, vendors might provide their own optimized implementations in other languages."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2019-12-20 05:51:52+00:00",
                    "text": "@ivan-pi I will die a little inside for every fixed-format Fortran file that gets added. \ud83e\udd23\nBut, yes, my preference would be to modernize any old code. At a bare minimum, convert any fixed-form to free-form style. The library should be an example of what good, modern Fortran code should look like. And I already have modernized versions of zeroin and fmin!"
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 07:44:40+00:00",
                    "text": "I would also prefer to rely on modern Fortran and use C-bindings to system-related functionality whenever needed."
                }
            ]
        },
        {
            "number": 19,
            "user": "cmacmackin",
            "date": "2019-12-19 17:11:49+00:00",
            "title": "C-style formatting",
            "text": "In #14 @milancurcic indicated he'd like to have something along the lines of a printf function, like in C. I suggested a way to do this:\n\n\nC-style formatting is something I'd very much like in Fortran. I think it may help some newcomers to the language as well because this kind of formatting is more common in other languages. But that's for another proposal. :)\n\nThis actually wouldn't be too difficult to implement in a standard library. We'd just write a series of wrappers in C, taking different numbers of void*t arguments. We'd then use interoperability to call these from Fortran and wrap them in a generic block. We could have versions accepting between, say, 1 and 30 arguments (tedious, but could be automatically generated), which should be enough for anyone.\n\nI went on to comment:\nMy suggestion of calls to C was specifically for a printf function. This would avoid the combinatorial explosion because printf works on void* data types. These can be passed in from Fortran using a \"deferred-type\" argument, type(*). The interface would look something like this:\nvoid printf_wrapper1(const char *format, void *arg1) {\n    printf(format, arg1, arg2)\n} \n\nvoid printf_wrapper2(const char *format, void *arg1, void *arg2) {\n    printf(format, arg1, arg2)\n} \ninterface printf\nsubroutine printf_wrapper1(format_str, arg1) bind(c)\n    character(len=1), dimension(*), intent(in) :: format_str\n    type(*), intent(in) :: arg1\nend subroutine printf_wrapper1\n\nsubroutine printf_wrapper2(format_str, arg1, arg2) bind(c)\n    character(len=1), dimension(*), intent(in) :: format_str\n    type(*), intent(in) :: arg1, arg2\nend subroutine printf_wrapper2\nend interface printf\nThe main complication with this is how to convert between Fortran and C strings. It wouldn't be hard to provide wrapper routines which do this for the Format string, but string arguments to printf could be more of a challenge.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-19 17:31:00+00:00",
                    "text": "We can start with using C, and later we can perhaps reimplement in Fortran if we decide it is valuable to stay in pure Fortran (see #20)."
                },
                {
                    "user": "cmacmackin",
                    "date": "2019-12-19 17:43:23+00:00",
                    "text": "A bit more thought makes me wonder if it would in fact be better to do this in Fortran, as converting between Fortran and C strings is quite a painful really.\nFurthermore, some of the behaviour of printf is not exactly idiomatic for Fortran. In particular, Fortran does not have the concept of \\t, \\n, etc. within strings. Also, printing in Fortran would normally result in a new-line after, while this is not the default behaviour for printf (although it would be very easy to add a new-line). As such, it might be worth considering whether we want to define formatted printing that is specific to Fortran, perhaps using a syntax more like Python's format strings."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 17:48:03+00:00",
                    "text": "Perhaps using the Python 3 formatting syntax would work for Fortran: https://docs.python.org/3.1/library/string.html#format-specification-mini-language (see examples)."
                },
                {
                    "user": "cmacmackin",
                    "date": "2019-12-19 18:00:37+00:00",
                    "text": "@certik Yes, that's what I was thinking of, although I don't think it would be practical to allow named-arguments in the format string, given Fortran doesn't have features like that."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-19 18:36:47+00:00",
                    "text": "Python 3 formatting is becoming quite widespread; I know that C# and Rust use them.  It would be great to reach this point, but I agree with @cmacmackin that it might not be practical with Fortran syntax.\nThose languages also offer C-style formatting, so I see no harm in pursuing both."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 19:29:19+00:00",
                    "text": "We can start without named arguments. Then go from there, perhaps there is a way to specify the names somehow, that is quite reasonable syntax-wise."
                },
                {
                    "user": "longb",
                    "date": "2019-12-19 23:16:56+00:00",
                    "text": "Note that the Fortran 202X proposal list includes intrinsic functions for converting Fortran characters to C strings and vice versa."
                },
                {
                    "user": "gronki",
                    "date": "2019-12-31 17:59:58+00:00",
                    "text": "I agree C-style formatting is already considered obsolete in Python. I would prefer just improving the currect capabilities of Fortran i/o.\nOn a side note, there has been recently a whole discussion whether \"things easy to implement should be implemented or left for the programmer\". My stand on this is \"they should be implemented if they are the recommended way of doing things\". Using C stdlib in Fortran is certainly not the purest way of doing things (and might possibly bring portability issues) so I would leave this burden and responsibility to the programmer.\nWhat do you think?"
                },
                {
                    "user": "14NGiestas",
                    "date": "2020-09-08 16:35:13+00:00",
                    "text": "I agree with @gronki and I think this whole issue should migrate to a \"string style formatting\" type of discussion (For instance: #69 ) closing this one. We could implement some facility to convert a easier to write and read syntax to the standard way.\nFor example, take some sane string:\n\"My name is (A) and I want a readable spec, so I can show pi = (G0) and fruits = (I0) to my friends.\"\nand convert to the weird and sometimes infuriating standard I/O\n'(\"My name is \",A,\" and I want a readable spec, so I can show pi = \",G0,\" and fruits = \",I0,\" to my friends.\")'\nThen, finally using it as a sane format\nwrite(f, sane_fmt) 'Ian', PI, my_fruits\nSuch facility would fit into a string module (like Python did, actually).\nIDK, what you all think @certik @gronki @cmacmackin ?\nPS: Related J3 proposal by gronki #69"
                }
            ]
        },
        {
            "number": 18,
            "user": "certik",
            "date": "2019-12-19 16:26:56+00:00",
            "title": "meshgrid",
            "text": "Here is a 2D implementation https://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/src/mesh.f90#L164, but NumPy's meshgrid is much more general. Here is Matlab's meshgrid.",
            "comments": []
        },
        {
            "number": 17,
            "user": "certik",
            "date": "2019-12-19 16:23:40+00:00",
            "title": "linspace and logspace",
            "text": "The linspace API is implemented here: https://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/src/mesh.f90#L157\nMatlab's linspace.\nThe logspace is similar, but I don't have it implemented yet -- historically I have used a function called meshexp, which is more general --- it allows you to change the gradation of the mesh, which the Matlab's logspace does not allow. The NumPy's logspace allows to set different base which allows to change gradation. So I think my meshexp can be implemented using NumPy's logspace. NumPy also has geomspace where you can specify the end points directly (just like in my meshexp) but it does not allow to change gradation. So I think there is room for meshexp, perhaps we should change the name somehow to be consistent with the other functions.",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 18:58:36+00:00",
                    "text": "Personally, for linspace I like the extended API of the numpy linspace; ported to Fortran this is:\nfunction linspace(start,end,num,endpoint,step) result(samples)\n\nI have created a gist with my linspace version here."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 19:42:41+00:00",
                    "text": "A minor downside of mirroring the numpy API, is that since the step is an intent(out) argument, meaning the function can not have the pure attribute."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 19:46:07+00:00",
                    "text": "Have you ever used the step argument? I've never used it."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 19:51:26+00:00",
                    "text": "Along the lines of \"Let's use pure Fortran whenever we can\" from #20, I suggest we aim for pure implementations whenever we can.\nIf we have an intent(out) parameter here, I'd argue that linspace should be a subroutine (a function shouldn't modify state elsewhere), which I'm not in favor of."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 21:16:21+00:00",
                    "text": "I have used the step argument before. A simple use case is setting up a simple finite difference method:\nx = linspace(0.0_dp,1.0_dp,101,step=dx) \n! call linspace(0.0_dp,1.0_dp,101,x,dx) ! subroutine version\n\n! ... assemble the tridiagonal matrix and rhs, dx appears in the matrix entries ... \n! ... solve system for field  u  using Thomas algorithm or gttrf and gttrs from LAPACK ...\n\ncall print_file(\"result.txt\",x,u)\nBut I can agree with the pure argument of @milancurcic . If the step size is added to the function prototype, then linspace should be a subroutine.\nIn the end, the user can always recover the step size as follows\nx = linspace(0.0_dp,1.0_dp,11)\ndx = x(2)-x(1)\nwhich I suppose is easier to remember and more intuitive than a subroutine version..."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 22:22:18+00:00",
                    "text": "Indeed, I feel the second option:\nx = linspace(0.0_dp, 1.0_dp, 11)\ndx = x(2)-x(1)\nis perhaps even clearer what it is doing, and it allows us to stay \"pure\". Matlab's linspace does not have this dx either."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-22 18:09:57+00:00",
                    "text": "How would this module be called? stdlib_numerical and stdlib_experimental_numerical?\nmeshgrid() from #18 would belong here as well."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 18:47:17+00:00",
                    "text": "In fortran-utils I call it a mesh.f90. NumPy has this directly in the numpy namespace. Matlab also seems to have this directly in the built-in namespace. For us, here are some options:\n\nstdlib_mesh.f90\nstdlib_grid.f90\nstdlib_numerical.f90\nstdlib_space.f90\nstdlib_mesh_utilities.f90\n\nI feel \"numerical\" is too general. I would prefer something more concrete. I like \"mesh\" or \"grid\" so far the most."
                }
            ]
        },
        {
            "number": 16,
            "user": "certik",
            "date": "2019-12-19 16:15:02+00:00",
            "title": "loadtxt and savetxt",
            "text": "Implementation: https://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/src/utils.f90#L176\nThe interface is compatible with NumPy (e.g., you can do savetxt from Fortran and do loadtxt from NumPy and it just works, and vice versa).\nThe loadtxt has the argument as allocatable, intent(out), because you typically do not know the size of the matrix ahead of time.\nNumPy: savetxt, loadtxt",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 17:09:08+00:00",
                    "text": "I think these are great functions to start with and figure out the workflow. Good to go ahead as far as I'm concerened.\nWhat module would this belong to? stdlib_io in io.f90?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 17:14:29+00:00",
                    "text": "I think we agreed to prefix modules with stdlib_.\nThe io module (stdlib_io.f90) might be a good name for it. NumPy has this directly in the numpy namespace, but I think we should have things in modules, not the global stdlib namespace. Because we can always later expose some frequently used functionality in stdlib.f90 directly, but if we put it there now, it will be hard to remove later, as it would break people's code.\nThere is also scipy.io, with loadmat that loads Matlab's file.\nSo stdlib_io.f90 works."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-19 17:16:22+00:00",
                    "text": "@certik Nice examples. I think it could be easily combine with something like\nreal, allocatable :: a(:)\ntype(File) :: f\nf = File('log.txt')\ncall f%read(a)\ncall f%close()\n\nFloat, double-precision,integer,... could be then supported."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 17:19:33+00:00",
                    "text": "@certik Correct, I just re-read #9. module stdlib_io in stdlib_io.f90 is good."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 17:23:05+00:00",
                    "text": "@jvdp1 Indeed, plain savetxt and loadtxt will be useful on their own, and the File derived type (a higher level abstraction) can later figure out if and how to use these more basic building blocks."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 18:27:28+00:00",
                    "text": "I sent a PR in #23."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2019-12-19 19:14:41+00:00",
                    "text": "We can also get some inspiration from this csv read/write one of mine: https://github.com/jacobwilliams/fortran-csv-module"
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 19:22:07+00:00",
                    "text": "@jacobwilliams good point, I created a standalone issue #24 for CSV. You are right that it is related, as in NumPy one can use genfromtxt to read CSV."
                },
                {
                    "user": "epagone",
                    "date": "2019-12-20 13:16:03+00:00",
                    "text": "Very nice start. What do you think of adding some optional functionalities like the following?\n\nHeader handling (we might need to define a \"comment\" character that introduces the header):\n\nwhen reading simply detect it and store it somewhere;\nwhen writing add it and number the columns automatically (very useful for writing plotting scripts).\n\n\ncolumn sorting or indexing using, for example, ODERPACK (if there is no licence clash).\n\nI found very useful (actually necessary) both them but I don't know how much general interest there is."
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 18:11:52+00:00",
                    "text": "@epagone, yes, we can add the header, footer, comments, newline, delimiter arguments for savetxt that NumPy has. We can also do the fmt argument and pass in Fortran formatting string.\nAll these arguments go after the fname and X arguments, so I think we can add them in subsequent PRs after #23 is merged.\nCan you elaborate on the column sorting or indexing using? I don't think NumPy does that. What prevents the user to sort the data before calling savetxt?"
                }
            ]
        },
        {
            "number": 15,
            "user": "certik",
            "date": "2019-12-18 21:08:23+00:00",
            "title": "What compilers and platforms should be supported",
            "text": "Let's use this issue to figure out what compilers we have to support (which version and platform).\nFor my own usage I need at least:\n\nGFortran (master works as of f300f4a)\nIntel Fortran (master works as of f300f4a)\nNAG (#108)\n\nIn addition my colleagues use: PGI (#107), Cray, IBM.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-18 21:08:46+00:00",
                    "text": "In addition I suggest we only use features that work with CMake."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-18 23:53:59+00:00",
                    "text": "I agree that supporting and testing on as many compilers as we can is good for stdlib. I'm concerned that requiring support for several compilers may put a brake on the language features we can use for implementation. (example: do all compilers support finalization? I don't know)\nEnsuring that non-free compilers build and run stdlib will require some custom CI+CD hacking with dedicated machines with these compilers.\nFor start, can we require support for free compilers at first, run it through CI with free tools, and then work on scripts that members with access to Cray, IBM, and similar machines could run there and provide build reports?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 19:48:09+00:00",
                    "text": "We need to try and see. For the CI, we would simply use gfortran, and we would just test other compilers by hand. Later we can see if there is a way to automate it."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 18:06:08+00:00",
                    "text": "One of the nice things about CMake is its introspection capabilities. Rather than maintaining a list of supported compilers & compiler versions you can test at configure time if a certain language feature is working and enable it or disable it as part of the build.\nAdditionally, there are ways to BYOL (bring your own license) for the commercial compilers."
                },
                {
                    "user": "certik",
                    "date": "2020-01-13 17:17:09+00:00",
                    "text": "I tested GFortran, Intel, NAG and PGI, and updated the issue description, either things work, or I created an issue.\nI do not have access to other compilers such as Cray or IBM. Does anyone have access to those?"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-14 17:03:46+00:00",
                    "text": "IBM arch is available via Travis-CI--I haven't tried to see if no-cost XL compiler is also there.\nOn CMake's Gitlab instance, there are a couple people who have contributed code to CMake for Cray Fortran:\n\nChuck Craynor\nWillem Deconinck"
                },
                {
                    "user": "scivision",
                    "date": "2020-01-14 17:17:01+00:00",
                    "text": "If stdlib brings in Fortran 2008 improvements, then the current releases of all commonly used Fortran compilers should be doable. Corner cases can be handled by build system detection.\n\nNAG 7.0 - OK Fortran 2008 as would be used by stdlib\nPGI 19.10 - OK Fortran 2008. PGI 19.4 was a lot buggier/missing syntax\nGfortran >= 6  OK Fortran 2008\nIntel >= 16 (2016)\nFlang >= 6\nCray (several years ago)\nIBM (several years ago)\n\nThat leaves a few small but impactful communities using Fortran 95 compilers and Fortran 2003-ish compilers. Will those communities have migrated to newer compilers by the time stdlib is \"ready\"."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 21:37:38+00:00",
                    "text": "I think for a standard library, it is important to have clear rules on the following questions:\n\nWhich Fortran standard is required. While this question sounds simple, most of the compilers implement even older standards only partly and a few corner case statements are missing (see e.g. https://gcc.gnu.org/wiki/Fortran2008Status)\nWhat do we do if a compiler theoretically compiles a certain statement, but execution crashes during runtime or gives wrong results (I experienced that for do concurrent)\n\nFor applications, it is practicable to specify a compiler version explicitly (Requires GNU > 8.1 or Intel > 18.1, but note that 18.2 has a bug, etc).\nOn the long term, if the standard library project is successful, missing features are probably more relevant than actual compiler bugs. Let's assume that the Compiler update from version X to Y results in invalid code for do concurrent, but do concurrent is used in the standard library. Hopefully, the compiler vendors will run the test suite of the standard library before releasing version Y and know that they have to fix their product.\nThe most practical way is probably the use of a test suite that contains all supported compiler versions. Then one can make a case by case decision whether it is worth to drop compatibility with a certain compiler to support a certain statement."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-05-31 19:55:16+00:00",
                    "text": "The most practical way is probably the use of a test suite that contains all supported compiler versions. Then one can make a case by case decision whether it is worth to drop compatibility with a certain compiler to support a certain statement.\n\nIs it possible to implement such a test suite with GitHub CI? Maybe at least for free compilers?"
                },
                {
                    "user": "scivision",
                    "date": "2020-05-31 21:07:01+00:00",
                    "text": "For GCC we can test across versions. I would guess offhand that at least back to GCC 6 is OK.\nFor Intel oneAPI, I ran across a GitHub repo that was demoing using Intel oneAPI no-cost compiler in GitHub Actions. Intel provide oneAPI Docker container but this repo was using the PPA / apt install method that they claimed was faster.\nUnfortunately I didn't bookmark that GitHub repo but I could probably find it again if this is of interest.\nThe oneAPI HPC toolkit provides a rebadged Intel Parallel Studio XE compiler for Fortran, C, C++ but with less strict licensing (currently, no login is required to download oneAPI compilers and libraries).\nWhat I understand from the last Fortran stdlib conference call is that LLVM Flang/f18 might be ready in the next year or so to use for this.\nTravis has PowerPC arch available, but I don't know if the XL Fortran compiler is installed there.\nPGI has cloud images available, but given the general bugginess at the moment of PGI 19.10 for Fortran 2003 I'm not sure if that would be worth the effort yet."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-31 21:15:37+00:00",
                    "text": "Another possibility would be to provide a conda forge package and use their well developed CI (windows, Mac, Linux). Since this could be seen as a misuse of resources, we should ask beforehand."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-05 06:14:11+00:00",
                    "text": "Another possibility would be to provide a conda forge package and use their well developed CI (windows, Mac, Linux). Since this could be seen as a misuse of resources, we should ask beforehand.\n\nI think this is the way to go for the long term. But I guess that we should have first a first version/release, right?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-06-05 06:16:19+00:00",
                    "text": "For Intel oneAPI, I ran across a GitHub repo that was demoing using Intel oneAPI no-cost compiler in GitHub Actions. Intel provide oneAPI Docker container but this repo was using the PPA / apt install method that they claimed was faster.\nUnfortunately I didn't bookmark that GitHub repo but I could probably find it again if this is of interest.\n\n@scivision Thank you for this input. It could be a possiblity, at least for the short term. It would be nice if you could find back the GitHub repo :)"
                }
            ]
        },
        {
            "number": 14,
            "user": "milancurcic",
            "date": "2019-12-18 18:47:10+00:00",
            "title": "Proposal for high level I/O",
            "text": "Branched from #1 (comment)\n\nOne personal challenge I have with stock Fortran are its somewhat awkward and low-level I/O facilities -- open, read, write, inquire, rewind, and close. I often wished for a higher-level interface, like what you get with Python's open() -- you open a file with a function, get a file-like instance with methods that let you do stuff with it.\nThis would do away with unit numbers, which I don't think application developers should have to deal with. It could also be a solution to the problem that allocatable character strings must be pre-allocated before use on read statement.\nIs there anything similar out there for Fortran? Would this be of interest to people here? I'd use it.\n@jvdp1 wrote: I would use it too.\n@cmacmackin wrote: I'd personally like something along these lines. However, the problem is in defining methods on the file-object; these would need to know the number and type of arguments at compile-time. It would be impractical to produce methods with every conceivable permutation of object types. It would also require variadic functions, which are not available. As such, this can not be implemented well in Fortran, although perhaps something would be possible if we were to wrap some C-routines and pass in deferred-type objects.",
            "comments": [
                {
                    "user": "milancurcic",
                    "date": "2019-12-18 18:50:27+00:00",
                    "text": "However, the problem is in defining methods on the file-object; these would need to know the number and type of arguments at compile-time. It would be impractical to produce methods with every conceivable permutation of object types. It would also require variadic functions, which are not available.\n\n@cmacmackin Can you explain why the number and type of arguments aren't known at compile time? How many can there possibly be? I think you'd need just clever formatting of numeric types to characters, but I may be missing the point."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-18 18:53:23+00:00",
                    "text": "I think he means that with standard write you can pass an arbitrary number of variables of different types. That makes it hard for a file%write() method to be generic because how do you create a sufficiently generic interface? I may be miss-interpreting his comment, but this is my current understanding."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-18 19:08:44+00:00",
                    "text": "I see, that didn't even cross my mind. Wouldn't for most purposes one argument (character string for text, numeric or strings for binary) suffice?\nThe only time I put multiple variables on write or read statements is for list-directed I/O. When I do it, the language-provided write or read are simple enough.\nIf we had nice on-the-fly formatting like Python does, then this becomes trivial I think."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 19:21:56+00:00",
                    "text": "@milancurcic can you elaborate a bit why the unit numbers are insufficient? The recommended approach with newunit from Fortran 2008 seems very simple: https://www.fortran90.org/src/best-practices.html#file-input-output. The unit number integer is your file like instance. That's how I always viewed it. The summarize the current approach:\nTo read from a file:\ninteger :: u\nopen(newunit=u, file=\"log.txt\", status=\"old\")\nread(u, *) a, b\nclose(u)\nWrite to a file:\ninteger :: u\nopen(newunit=u, file=\"log.txt\", status=\"replace\")\nwrite(u, *) a, b\nclose(u)\nTo append to an existing file:\ninteger :: u\nopen(newunit=u, file=\"log.txt\", position=\"append\", status=\"old\")\nwrite(u, *) N, V(N)\nclose(u)\nThe only annoying thing to me is that you have to put status=\"old\" when you want to read from a file, you cannot just do open(newunit=u, file=\"log.txt\") because the default status is undefined or something like that (I forgot the exact reason)."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-18 21:23:43+00:00",
                    "text": "Yes, unit numbers work. They were tedious before newunit, now they're OK. I think of them as file handles. Now, I can at best say they're not as elegant as having a file-like instance that carries the unit number abstracted away from the user. So, this is perhaps more of a style preference. I think managing unit numbers for different files (say, if you have multiple files open) may be more error-prone and harder to develop than if using file-like instances, but this is kinda hand-wavy.\nWith a high-level interface, your examples would be something like this. Read from a file:\ntype(file_type) :: f\nf = file_type('log.txt', 'r')\na = f % read()\nf % close()\nWrite to a file:\ntype(file_type) :: f\nf = file_type('log.txt', 'w')\ncall f % write(a)\nf % close()\nAppend to an existing file:\ntype(file_type) :: f\nf = file_type('log.txt', 'r+')\ncall f % write(a)\nf % close()\nThe pros as I see them:\n\nA bit more elegant style;\nDon't need to carry unit numbers, only file instances;\nPretty abstraction of status, position, and action attributes;\nclose could be baked into file_type's destructor so that the file is automatically closed when f goes out of scope;\n\nCons:\n\nWould need elegant, on-the-fly formatting system between strings and numeric values;\nTrivial implementation can write one variable per method call\nOthers?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 21:46:04+00:00",
                    "text": "I talked with @zjibben about this and he pointed out another advantage of your approach: automatic closing of files when the instance goes out of scope. Also I would suggest that r is the default as in Python. So your first example can become just:\ntype(file_type) :: f\nf = file_type('log.txt')\na = f % read()\nAlso perhaps the type could be called File, or File_t, we should discuss this in #3.\nOne issue is that you need to be able to read different types and I don't know if you can override read based on the result type. So it might need to be called as call f%read(a)."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 21:50:57+00:00",
                    "text": "Another issue: how do you distinguish between:\nread(u,*) a, b\nand\nread(u,*) a\nread(u,*) b\nThe first reads two numbers one a line, the second reads a number from two lines --- or are the two equivalent?"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-18 23:21:45+00:00",
                    "text": "I like just File.\nIn the case of reading and writing formatted data, the trivial implementation doesn't operate on multiple variables. It reads or writes a string, for example:\ncharacter(len=:), allocatable :: a\ntype(File) :: f\nf = File('log.txt')\nf % read(a) ! reads whole file into string a\nf % seek(0) ! rewind\nf % readline(a) ! reads a single line into string a\nTo write:\nf = File('log.txt', 'w')\nf % write('pi = %.3f' .fmt. 3.141)\nsimilar to Python. The last line would write 'pi = 3.141' to log.txt. This is an example of on-the-fly formatting that I mentioned earlier, which I think is needed if you want to elegantly read and write multiple variables. .fmt. here is our implementation of %.\nC-style formatting is something I'd very much like in Fortran. I think it may help some newcomers to the language as well because this kind of formatting is more common in other languages. But that's for another proposal. :)"
                },
                {
                    "user": "cmacmackin",
                    "date": "2019-12-19 02:24:37+00:00",
                    "text": "I think he means that with standard write you can pass an arbitrary number of variables of different types. That makes it hard for a file%write() method to be generic because how do you create a sufficiently generic interface? I may be miss-interpreting his comment, but this is my current understanding.\n\nYes, that's what I was trying to communicate, albeit not very well."
                },
                {
                    "user": "cmacmackin",
                    "date": "2019-12-19 02:36:59+00:00",
                    "text": "C-style formatting is something I'd very much like in Fortran. I think it may help some newcomers to the language as well because this kind of formatting is more common in other languages. But that's for another proposal. :)\n\nThis actually wouldn't be too difficult to implement in a standard library. We'd just write a series of wrappers in C, taking different numbers of void*t arguments. We'd then use interoperability to call these from Fortran and wrap them in a generic block. We could have versions accepting between, say, 1 and 30 arguments (tedious, but could be automatically generated), which should be enough for anyone."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 09:52:19+00:00",
                    "text": "I like the idea. As mentioned by @cmacmackin  this would be easier to implement if Fortran had support for variadic functions (in fact I mentioned exactly this use case in my comment at j3-fortran/fortran_proposals#76 (comment)).\nThe idea of wrapping a bunch of C subroutines in a generic block seems like a good idea. I am only worried about a combinatorial explosion. Say I want to read 3 integers, 4 reals, and a character array, etc., from a single line, wouldn't we then need to generate all possible combinations of all intrinsic types? Or would you somehow convert everything internally to a C pointer and use a format specifier? (Hopefully, my idea makes sense.)\ntype(File) :: f\ninteger :: a, b, c\nreal :: d, e, ff, g, h\ncharacter(len=1) :: char_arr(5)\n\ncall f%open(\"data.txt\",\"r\")\ncall f%readline(a, b, c, d, e, ff, g, h, char_arr, fmt=\" ... some kind of format specifier ...\")\nOr we could just read lines as an allocatable character string and do the type conversion ourselves:\nread(f%readline(),*) a, b, c, d, e, ff, g, h, char_arr ! <-- assuming this works?\nI suppose this would work:\ncharacter(len=:), allocatable :: line\n! ... open file ...\ncall f%readline(line)\nread(line,*) a, b, c, d, e, ff, g, h, char_arr"
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-19 10:52:50+00:00",
                    "text": "I would suggest to keep high-level I/O for ASCII files with formatted data (e.g., table of reals; something similar to File suggested by @milancurcic). Maybe some formats, like CSV, could be supported too.\nIf the user wants something more complex (mix of  integers/reals/characters), or binary/stream files, the user can still use newunit (or the readline op proposed by @ivan-pi ; but probably less efficient)."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 11:15:51+00:00",
                    "text": "I would suggest to keep high-level I/O for ASCII files with formatted data (e.g., table of reals; something similar to File suggested by @milancurcic). Maybe some formats, like CSV, could be supported too.\n\nSo more like np.loadtxt(), but with the possibility to load the individual columns or rows directly into arrays (1d or 2d)?"
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-19 11:27:01+00:00",
                    "text": "So more like np.loadtxt(), but with the possibility to load the individual columns or rows directly into arrays (1d or 2d)?\n\nYes, it was my idea.\nI observed that I/O is usually quite a difficult step for most beginners when they come from R/Python/Matblab. Such high-level I/O could maybe help them.\nAlso, when performance is not an issue, high-level I/O could also simplify programs."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-19 15:28:29+00:00",
                    "text": "I would also like to see a more POSIX-like interface to the filesystem.  I would also like to see this as independent from the Fortran interface, with a focus on data streams rather than the list-directed I/O for which Fortran I/O has been tailored.\nI also think that there should be a generic File type, but it would be good to start with complete interfaces to the low level file I/O C functions, such as POSIX open, read, etc.  More elegant interfaces can then be build from these.\nI like the way Python does this, with a top level os module which provides a commont platform which conditionally wraps to a low level interface: posix module in Linux/OSX, nt for Windows, etc.  Perhaps even the Fortran intrinsics could be supported as an additional backend of necessary, along with more exotic platforms (OpenVMS?)."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 16:15:35+00:00",
                    "text": "@ivan-pi, @jvdp1 see #16 for loadtxt."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 17:06:26+00:00",
                    "text": "Great ideas for C-style formatting implementation. A basic implementation for File can work on just strings at first, and parsing the strings into numeric variables and vice versa can be a separate issue (and module) that File would eventually depend on. I can prepare a prototype for File that works on strings.\n@marshallward I'd like a maintained and tested POSIX interface as well. Do you mind opening a proposal for this? (Update: done in #22.)\n@cmacmackin We can have a dedicated proposal to just C-style formatting. I like your idea for implementation. Do you mind opening a proposal for this? (Update: done in #19.)"
                },
                {
                    "user": "cmacmackin",
                    "date": "2019-12-19 17:07:23+00:00",
                    "text": "@ivan-pi My suggestion of calls to C was specifically for a printf function. This would avoid the combinatorial explosion because printf works on void* data types. These can be passed in from Fortran using a \"deferred-type\" argument, type(*). The interface would look something like this:\nvoid printf_wrapper1(const char *format, void *arg1) {\n    printf(format, arg1, arg2)\n} \n\nvoid printf_wrapper2(const char *format, void *arg1, void *arg2) {\n    printf(format, arg1, arg2)\n} \ninterface printf\nsubroutine printf_wrapper1(format_str, arg1) bind(c)\n    character(len=1), dimension(*), intent(in) :: format_str\n    type(*), intent(in) :: arg1\nend subroutine printf_wrapper1\n\nsubroutine printf_wrapper2(format_str, arg1, arg2) bind(c)\n    character(len=1), dimension(*), intent(in) :: format_str\n    type(*), intent(in) :: arg1, arg2\nend subroutine printf_wrapper2\nend interface printf\nThe main complication with this is how to convert between Fortran and C strings. It wouldn't be hard to provide wrapper routines which do this for the Format string, but string arguments to printf could be more of a challenge."
                },
                {
                    "user": "rweed",
                    "date": "2019-12-20 23:03:21+00:00",
                    "text": "Three things I've implemented that I find useful for IO particularly input data where I create my own keyword based input. One is a File class that basically wraps current Fortran IO (open, read, write etc) but hides the unit number. I have read and write wrappers that allow you to read/write formatted, list-directed or binary of the intrinsic data types from the same subroutine. Another useful class is a deferredLenString class that is a defined type that contains a deferred length string with some routines to convert back and forth to regular strings and do the equivalent of LEN, LEN_TRIM etc. Finally, I define a fileImage class that uses an array of the deferredLenString class to hold all the records in a formatted input file in memory as a \"file image\". I have filters that can change case, strip delimiters etc from the original file. When processing keyword based input files, using a file image instead of the disk file is a lot faster. Some or all of these might prove useful for implementing IO classes specifically for processing text files etc."
                },
                {
                    "user": "gronki",
                    "date": "2019-12-31 18:06:03+00:00",
                    "text": "I think we do not need a derived type wrapper for Fortran i/o. The current i/o covers many of the general needs. Some missing capabilities can be (and gradualy are) improved from the language side and introducing a wrapper would not help with anything. For a particular file format (such as PPM), anyone can write their own wrapper using derived types. This is literally what derived types are for. They should not be used for introducing another way of doing the same thing (which is universally bad). So I am strongly against this proposal."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 00:20:02+00:00",
                    "text": "I generally agree with @gronki on this --- it's similar in #69. Rather than creating our own string_t, let's use the intrinsic, and work with the language and compilers to improve it if needed.\nHowever, as a pragmatic approach, I think the best it to have both: a low level API that uses the language features. People like @gronki and I will use that primarily. And optionally a high level API, that lots of people can also use. I think we can have both. What we should not have is just the high level API without the low level one."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-03 00:32:58+00:00",
                    "text": "Yes, perhaps it's better for this to start as a separate project, and after having something concrete to look at we can discuss whether people would like to have it in stdlib or not."
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 02:53:21+00:00",
                    "text": "@milancurcic let's separate the genuine new functionality, which would go into the low level API, from a convenience wrapper, which would go into the high level OO API.\nHere are some ideas off top of my head that would go into the low level API:\n\nUsing the unit handle u (of type integer) directly\nThe standard Fortran functions read, write, close, etc.\nReading a string from a file and returning it as properly allocated (related to #69)\nReading an array of numbers (real or integer) and returning a properly allocated array back\nPerhaps some easier function open (so that one can do u = open(filename) and u = open(filename, \"w\") as in Python etc. instead of the current open(newunit=u, file=\"log.txt\", status=\"old\", action=\"read\") and open(newunit=u, file=\"log.txt\", status=\"replace\", action=\"write\"), which is so complicated that I literally just had to look it up again --- the standard is badly designed that it left both status and action undefined --- we should work on fixing it) See #71.\n... what else?\n\nThe high level API would then wrap these in a convenience derived type wrapper file_t and methods.\n\nI see a repeated pattern across many of the issues in stdlib ---- the high level \"simple\" OO interface is motivated by the fact that the low level built-in Fortran language features are insufficient. In order to fix the low level API, which a lot of people would otherwise use, let's use the OO interface as a vehicle to figure out what features we want and need (not being constrained by the limitations of the low level API: we can design our derived type and methods in any way we like). Then extract the genuine new functionality, and put it into the low level API, and the high level API is just a thin wrapper. Then let's create proposals to get some of the stdlib's improvements of the low level API into the Fortran standard itself -- backed by wide support here and our future users using it. And let people choose between the low level API and the high level API. It looks like we will have users for both."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-03 03:57:10+00:00",
                    "text": "I've always found it really strange that Fortran's read and write actually muddled the jobs of parsing and formatting together with the I/O. It leads to input files/specifications that are predicated on that functionality, which in my opinion is not a good thing. You're users shouldn't have to care about the peculiarities of the language you're using. I once was porting some Fortran code to Python and had to write something to simulate Fortran's IO in order to make sure old input files would still work properly.\nI'm pretty fond of Python's file API. I think we should mimic that as a library and see if it works well for everybody. We need a string type to implement it properly though since readlines returns an array of strings. An on-the-fly formatting library would be really helpful too."
                },
                {
                    "user": "gronki",
                    "date": "2020-01-03 22:58:36+00:00",
                    "text": "@certik I am not sure if I undestood correctly the last paragraph. Do you mean that the wrapper should be developed as the protype/testbench for the features that will be handled intrinsically in the future?\n@everythingfunctional I disagree there is any reason to mimic Python's io library in fortran I/O. Is there anything that can be done in Python that Fortran does not enable to do with its current functionality? I would even argue that Fortran has superior functionality in some aspects and that the lesser brevity in other situations comes from lacks in string manipulation capabilities (for example, having to use write/read to parse strings to numbers).\nAgain, sorry for being a bitter potato. I am all for changes and criticizing Fortran where it sucks but I also want to make sure that we do not re-invent what's already good just because other languages handle it differently. Please do not take my opinions personally. :)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-03 23:08:56+00:00",
                    "text": "@gronki yes, that's what I meant.\n\nIs there anything that can be done in Python that Fortran does not enable to do with its current functionality?\n\nHere is one example: #71. Look how much simpler the new open function is. Opening files in Fortran is so complicated that I literally have to look it up every time. This new function, on the other hand, I can remember, as it would be identical to Python."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-03 23:18:14+00:00",
                    "text": "Yes, ease of use is the key motivation for me here, and IMO is one of highest priorities for stdlib. I also learn standard Fortran I/O every time I use it. Teaching it is especially tedious."
                },
                {
                    "user": "gronki",
                    "date": "2020-01-03 23:26:11+00:00",
                    "text": "I understand your point. But my counter point is: then why not just use Python. :) What I want to say is that \"just because it looks like Python\" is not an argument because Fortran is not Python.\nIn this particular issue, the \"Python-like\" (or actually, C-like, because that's its origin) syntax takes the same amount of information (unit number, filename, access mode), just arranges it differently. It does not change the quality of life in any way. Nor would derived type wrapper of current I/O.\nI am all for quality improvements that actually do make I/O more functional. But I disagree any of the ones discussed so far do that. That's only my opinion though and please don't be discouraged. As it was mentioned by someone before, since this is stdlib project (and not standard proposal project), it's probably best to let people make their packages and see if the solution produced ends up actually being better. :)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-04 00:30:54+00:00",
                    "text": "It's about making Fortran easier to use. This:\ns = open(filename)\ns = open(filename, \"w\")\nis simpler and more consistent than this:\nopen(newunit=s, file=filename, status=\"old\", action=\"read\")\nopen(newunit=s, file=filename, status=\"replace\", action=\"write\")\nThat's all there is to it. Just like Fortran has arrays, which do have similar information as the various C++ array libraries, but they are much easier to use. That's the whole point. So the goal of stdlib is to make Fortran easier to use and more productive, with a standard syntax, agreed upon by a wide community."
                },
                {
                    "user": "everythingfunctional",
                    "date": "2020-01-04 03:47:33+00:00",
                    "text": "Is there anything that can be done in Python that Fortran does not enable to do with its current functionality?\n\nNo, Python doesn't have nearly the number of options as Fortran, but that's the point. Fortran has too many options, and that makes it difficult to use. It would be nice if there was a simpler, more user friendly way to deal with files so you wouldn't have to look it up every time."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-06 21:38:20+00:00",
                    "text": "After some discussions and implementations (see #71, #77, #86, #91), the function open has been added to stdlib_experimental_io:\ninteger function open(filename, mode, iostat) result(u)\n    character(*), intent(in) :: filename\n    character(*), intent(in), optional :: mode\n    integer, intent(out), optional :: iostat\n    ...\nend function\nThis function returns a unit number for a file opened following the provided mode.\nThe mode can be include the following letters (following the Python open):\n\nr (read), w (write and replace the file if it exists), x (write in a new file), a (append)\n+ (readwrite)\nt (text), b (binary)\nThe default mode is rt.\n\nCurrently, both text and binary files are opened with access = stream.\nSo, should this API support the other accesses (sequential and direct)? What are the pros and cons to support them (or not)?\nSo let 's discuss this API (@milancurcic @zbeekman @certik @cmacmackin @ivan-pi @marshallward @rweed @gronki @everythingfunctional and all others I maybe missed)\nSupporting direct access would require to add recl to the API too. IMHO this would defeat the purpose of stdlib function open that aims to propose a more friendly way to deal with files.\nA draft PR (#91) has been opened to propose an API to support at least sequential access (default is still stream):\ninteger function open(filename, mode, iostat, access) result(u)\n    character(*), intent(in) :: filename\n    character(*), intent(in), optional :: mode\n    character(*), intent(in), optional :: access\n    integer, intent(out), optional :: iostat\nend function"
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 21:53:39+00:00",
                    "text": "To start: what is the advantage of unformatted sequential, compared to unformatted stream? There is a disadvantage that the format is compiler version specific. But is there any advantage? Could it be perhaps faster, or is that not the case."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-07 22:13:10+00:00",
                    "text": "In this comment, @jacobwilliams mentioned:\n\ndelete a file or directory (I know for files we can open and then close(..status='delete') but that is just so non-modern).\n\nWould it be an interest to implement a subroutine/function in stlib to delete a file? For example, this would check if the file exists, if it is not opened, and if both are true, would delete the file.\nSuch a subroutine/function could be implemented in stdlib_experimenatl_io.\nPossible interface:\nio = delete('file.txt')\nor\ncall delete('file.txt',iostat=io)\nwith iostat being optional\nSuch a function/subroutine would avoid the 'traditional':\nopen(newunit=u, file = 'file.txt', status = 'old')\nclose(u, status = 'delete')"
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 22:58:52+00:00",
                    "text": "I think the answer is yes, only we should make the naming consistent. Python has remove, and we should survey other languages."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-07 23:13:14+00:00",
                    "text": "To delete a file:\n\nPython: remove\nJulia: rm\nR: remove\nMatlab: delete\nC/C++: remove\n-D: remove\nFortran: delete in built-in close\n\nand more examples here\nremove (or rm) seems to be quite popular in other languages after a quick scan."
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 23:17:33+00:00",
                    "text": "I am fine with calling it delete. I assume this would go into the io module?"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-07 23:25:44+00:00",
                    "text": "I am fine with calling it delete.\n\nMe too. delete would be also in agreement with close(...='delete').\nHowever, if we want to extend that to directories, rm or remove could be more appropriate (with e.g. rmdir to remove directories.\n\nI assume this would go into the io module?\n\nIt would make sense to me, since open is already in the io module.\nIf we want to implement more stuff around file systems #100, we should probably have a new module dedicated to file system stuff (e.g., rm, rmdir, ls, mkdir,...)"
                }
            ]
        },
        {
            "number": 13,
            "user": "rweed",
            "date": "2019-12-17 18:09:34+00:00",
            "title": "Proposal for a common data model module to set default KINDS",
            "text": "The following (sorry about the length) is a module that sets defaults for real and integer KIND parameters (what I call a data model) but allows users to define there own or change the defaults using preprocessor defines. I think something like this along with some module procedures for checking things like storage size and interrogating machine parameters ala R1MACH from Linpack etc. should be a basic part of the library. This would allow users to build different versions with different combinations of integer and real default types. I prefer this approach over trying to provide a different routine for each possible combination of integer and real types. Again, thats a personal preference but I prefer having 4 different versions of a library over trying to to provide four different versions of a subroutine/function and providing a generic interface. Also, I think part of the coding standard for the library should forbid real(8), real*8, implicit double precision etc.\n*** dataModel.F90 ***\nModule dataModel\n\n! Define default data model precisions (kinds) for a project\n! The default data model is assumed to be 32 bit integers and\n! 64 bit reals\n\n! Define intrinsic KIND parameters for Modern Fortran programs. \n! If we have a Fortran 2008 compliant version of ISO_FORTRAN_ENV, we will \n! use it; if not we will create our own versions of the equivalent Fortran \n! integer and real kinds using SELECT_INT_KIND and SELECT_REAL_KIND. We\n! also define a \"machine zero\" function for both 32 and 64 bit Real values \n\n  Use ISO_FORTRAN_ENV\n\n#ifdef HAVE_USER_DATA_MODEL\n  USE USERDATAMODEL, ONLY: USER_DEFAULT_INT, USER_DEFAULT_REAL\n#endif\n\n  Implicit NONE \n\n#ifdef NO_F2008_ENV\n\n! Define Integer and Real intrinsic KINDS with same names as in Fortran 2008\n! ISO_FORTRAN_ENV\n   \n  Integer, Parameter :: INT8    = SELECTED_INT_KIND(2) \n  Integer, Parameter :: INT16   = SELECTED_INT_KIND(4) \n  Integer, Parameter :: INT32   = SELECTED_INT_KIND(9)\n  Integer, Parameter :: INT64   = SELECTED_INT_KIND(18)\n  Integer, Parameter :: REAL32  = SELECTED_REAL_KIND(P=6,  R=37)\n  Integer, Parameter :: REAL64  = SELECTED_REAL_KIND(P=15, R=307)\n\n#endif\n\n#ifdef NO_REAL128\n!  Integer, Parameter :: REAL128 = REAL64\n#else\n#ifdef NO_F2008_ENV\n  Integer, Parameter :: REAL128 = SELECTED_REAL_KIND(p=33, R=4931)\n#endif\n#endif\n\n#ifdef HAVE_USER_DATAMODEL\n\n! Set DEFAULT_INT and DEFAULT_REAL to USER DATAMODEL\n! values. Otherwise use native defaults\n\n  Integer, Parameter :: DEFAULT_INT  = USER_DEFAULT_INT\n  Integer, Parameter :: DEFAULT_REAL = USER_DEFAULT_REAL\n\n#else \n\n! Set default values to 32 bit integers and 64 bit reals but allow\n! users to change this at compile time by setting -DI8INT or -DR4REAL\n! to select 64 bit integers and/or 32 bit reals\n\n#ifdef I8INT \n  Integer, Parameter :: DEFAULT_INT  = INT64\n#else\n  Integer, Parameter :: DEFAULT_INT  = INT32\n#endif\n\n#ifdef R4REAL\n  Integer, Parameter :: DEFAULT_REAL = REAL32\n#else\n#ifdef R16REAL\n  Integer, Parameter :: DEFAULT_REAL = REAL128\n#else\n  Integer, Parameter :: DEFAULT_REAL = REAL64\n#endif\n#endif\n\n#endif\n\n! Define short(er) names and comman aliases for the default kind parameters\n\n  Integer, Parameter :: WP   = DEFAULT_REAL \n  Integer, Parameter :: IWP  = DEFAULT_INT \n  Integer, Parameter :: QP   = REAL128\n\n! Define a C_ENUM type for use with Fortran ENUMERATOR variables. This\n! should be just C_INT but we define an explicit C_ENUM to handle\n! the possiblility that its not. This should have been included in\n! the Fortran 2003 C-Interop facility but for some reason known\n! only to the standards folks was not. \n\n  Enum, BIND(C)\n    ENUMERATOR :: dummy\n  End Enum\n\n  Private :: dummy\n\n  Integer, Parameter :: C_ENUM=KIND(dummy)\n\n  Public :: INT8, INT16, INT32, INT64, REAL32, REAL64, REAL128, C_ENUM, WP, &\n            IWP, QP\n\nEnd Module dataModel",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-17 18:20:50+00:00",
                    "text": "I typically prefer dp instead of wp (https://www.fortran90.org/src/best-practices.html#floating-point-numbers). Yes, for user code, writing it once is the way to go. For library code like stdlib, I think it's better to provide implementations for all precisions I think, so that users can simply call functions from stdlib without having to modify any file in stdlib to match their precision."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2019-12-17 18:53:17+00:00",
                    "text": "I think ideally, we want all the procedures in the library to work for all the integer/real/logical kinds that are available on the compiler. We don't want to force a user to have to recompile it for different kinds, and there are many use cases where the same application needs to use multiple kinds of real variables. Example: if a compiler adds real16, we shouldn't have to change any code, just recompile and it works.\nSince this is basically impossible with standard Fortran, it's going to require some kind of external templating tool, e.g. jin2for."
                }
            ]
        },
        {
            "number": 12,
            "user": "certik",
            "date": "2019-12-17 17:56:05+00:00",
            "title": "Proposal for bit-reproducible numerical operations",
            "text": "@marshallward wrote in #1 (comment):\nI would like to see greater support for bit-reproducible numerical operations.  This is a very high priority for us since our models are used in weather and climate forecasting, and much of our time is devoted to bit reproducibility of our numerical calculations.\nA common problem is intrinsic Fortran reduction operations like sum(), where the order is ambiguous (deliberately, one might say), and therefore not reproducible.  A more serious problem for us is transcendental functions, like exp() or cos(), which will give different results for different optimizations, and we typically cannot say where it was invoked (libm?  Vendor library?  etc.).\nA standard library may be a place to provide bit-reproducible implementations.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-17 18:01:18+00:00",
                    "text": "@marshallward, can you elaborate exactly what you mean by bit-reproducible numerical operations and why you need it?\nTypically, even the most accurate libraries, such as https://openlibm.org/, do not actually guarantee correct rounding, say of sin(x) for all x. When I tested it, typically it is rounded correctly for 75% of all x to all bits, but in 25% it gives the second nearest floating point. So it is incredibly accurate. But it is not correctly rounded in 100% of cases.\nI assume you do not need things to be correctly rounded, but you want to get the exact bits on all platforms? I think openlibm might be able to do that.\nFor my codes, I do not require bit reproducibility, as I don't think it's even possible --- with MPI and BLAS and LAPACK, the bits are not guaranteed. Only the overall accuracy. Also I like to use -ffast-math, which again does not guarantee bit reproducibility. Instead, I want performance, and correct results (as verified by tests)."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-17 18:39:04+00:00",
                    "text": "That's right, we are primarily focused on reproducing the bits over a range of configurations, and at least for now we're not too concerned with the overall accuracy of the lowest bits.  As an example, if we increase our optimization level, say -O2 to -O3 in gcc, then intrinsics like exp() seem to hop over to different bytecode and give slightly different results.\nIdeally, we would like an implementation that we can control, which won't be implicitly chosen by the compiler.\nYou're right about the issues with other libraries.  It's a bit off-topic and I won't go into detail, but for our MPI reduction operations we convert our floating points to an extended fixed-precision format to ensure that the result is invariant to ordering.  We also aggressively apply parentheses in all of our expressions, and only use compilers which honor the parenthesis ordering.\nBit reproducibility is extremely challenging, but we have managed to achieve it in our climate models for many years.  At the very least, it has vastly improved the quality of our test suites.\nThe issues around transcendentals appears to be a \"final frontier\" for us, but so far we have been reluctant to abandon the Fortran intrinsics.\nI am not familiar with OpenLibm, but I will look into it more.  I'm also not sure if something like this belongs in a standard library, so hoping for more feedback on this issue."
                },
                {
                    "user": "certik",
                    "date": "2019-12-17 18:51:45+00:00",
                    "text": "I am just trying to understand your use case better, so that we can later discuss where this belongs to.\nFor MPI, you take double precision number, convert to quadruple, accumulate in parallel with random order, and convert back to double?\nI wasn't aware you could even get bit reproducibility for a complicated parallel code. How do you handle cases where the hardware itself gives different results for the same binary? That has happened to me once (some nodes on the HPC cluster gave slightly different results than other nodes with the same binary and operating system). My solution was to ensure the code is robust against such issues."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-17 20:01:43+00:00",
                    "text": "The MPI summation method uses an extended fixed precision method, which basically converts the floats to tuples of integers, each value denoting a fixed precision over a selected range.  MPI operations are then applied for the integer data, which is reproducible.  It is described in this paper and this source code but I would guess that it's very similar to other extended precision implementations.\nWe have the luxury of solving hydrostatic fluid dynamics equations - hyperbolic PDEs, with no elliptic pressure solvers - so summations and other collectives are very rare and are primarily used for diagnostics like the total mass and energy of the system, which are computed infrequently, so we can overlook issues like performance of collectives.  Others may not be so lucky.\nIt's hard to summarize everything required to achieve bit reproducibility, but careful ordering of arithmetic using parentheses is a big part.  There are other rules, such as restricting the number of divisions in an expression (usually only once).  We also do very aggressive testing of initialization and memory accesses, so we never see stray values in our memory (or so we hope).  We also never commit any changes to our codebase which modify answers, unless it is done intentionally (e.g. bug fix).\nThe ability to reproduce such runs is also a part of the tender process, so that may prevent some of the issues you have seen.  But there have also been more exotic problems.  In one case - before my time with this group - there was a tridiagonal solver which failed to reproduce, and was tracked down to anomalous voltage noise in the CPU, which the vendor acknowledged and had to fix.\nI guess the short answer to your question is that due to a combination of software practices and the hardware tender process, we do not see variability across nodes."
                },
                {
                    "user": "certik",
                    "date": "2019-12-17 21:29:44+00:00",
                    "text": "Thanks for the details. I had no idea this was possible. I suspect there might be performance hits in some cases, so perhaps your method might not work in all cases, even if it works for you.\nRegarding bit reproducible functions, let me know if the openlibm does what you want. Then we can think if Fortran stdlib should have some functionality for this."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-17 23:20:44+00:00",
                    "text": "I think there are a few different problems conflated here:\n\nBeing bit-reproducible between consecutive executions of the same binary;\nBeing bit-reproducible between optimization levels with the same compiler and platform;\nBeing bit-reproducible between consecutive executions of the same binary that has a parallel reduction operation, on the same system.\n\nI agree that 1) is crucial and stdlib should have it as a requirement.\nI think 2) is out the door. Higher optimization flags mean \"generate slightly less accurate results faster\". The compiler generates different code. Am I misunderstanding this?\n\nis common and known and I think Hallberg&Adcroft's solution is elegant. I have this challenge in my work as well, so am interested in it.\n\nSo back to the original post, it seems to me it asks for transcendental function implementations that are guaranteed to be cross-platform bit reproducible (item 1). Am I correct or still not understanding? If yes, I agree this would be useful (though specialized), but a high technical challenge -- I guess it would need multi-platform assembly implementations. If yes, then I'd say it's more fitting for a specialized library rather than a stdlib.\nIt's also quite possible I'm not understanding this well so please correct me :)."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-18 02:43:07+00:00",
                    "text": "The underlying issue is that if we invoke a transcendental intrinsic, then we really just don't know where it is coming from.  For example, we once had our system math library change without our knowledge (possibly libm, but we cannot say for sure) after which we could no longer reproduce the original input fields for selected runs.  Currently, the Fortran intrinsics are not a safe option.\nThe optimization issue is secondary, but also of concern for us.  If I compile a Fortran application with -O2 and -O3, then my exp() calls will give different answers, even though I would have thought these were compiled elsewhere and not subject to the optimization of my application code.  I find it troubling that intrinsics can change in response to user code optimization.\nI am less concerned about a particular implementation changing answers if the math library itself is compiled with different settings, which is what I think you are describing in 2).\nWhile we could just force ourselves to use certain math libraries, such as OpenLibm, I would really like for this to be more controllable within the language itself.  I'm still not sure if this is the place to be having this discussion, but it would be nice if there was a safe and \"standard\" way to address it.\nBTW I wanted to say that it was #10 which prompted this discussion for me.  Mostly I was just wondering if there was any aspiration to provide bit reproducibility for users in certain controlled situations.  The transcendental function is a particular issue for us, but I think that bit reproducibility is a broader question that is worth considering."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 03:37:56+00:00",
                    "text": "@marshallward the reason exp and other functions change based on optimization levels is that if you are willing to give up a tiny bit of accuracy (I am, but you are not), then you can get a much faster implementation.\nAs such, it seems the possible bit-reproducible versions of every function would need to be separate functions. Say linalg provides eig that just uses Lapack and Blas and thus is not bit-reproducible, and then we can have linalg_bit with the bit-reproducible versions."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-18 04:18:50+00:00",
                    "text": "@certik True, though it's not necessarily accuracy that matters in our case.  I just want the same numbers!"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-18 16:51:57+00:00",
                    "text": "The underlying issue is that if we invoke a transcendental intrinsic, then we really just don't know where it is coming from. For example, we once had our system math library change without our knowledge (possibly libm, but we cannot say for sure) after which we could no longer reproduce the original input fields for selected runs. Currently, the Fortran intrinsics are not a safe option.\n\nOkay, thanks, I understand better now. I've had the same issue and I agree it's unsettling. Specific to this issue, I think this is the scenario. I have a Fortran program executable that is dynamically linked to the libraries on system.\nldd my_fortran_executable\n\tlinux-vdso.so.1 (0x00007ffc95b68000)\n\tlibgfortran.so.5 => /lib64/libgfortran.so.5 (0x00007f6ebb0a6000)\n\tlibm.so.6 => /lib64/libm.so.6 (0x00007f6ebad12000)\n\tlibgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x00007f6ebaafa000)\n\tlibquadmath.so.0 => /lib64/libquadmath.so.0 (0x00007f6eba8ba000)\n\tlibc.so.6 => /lib64/libc.so.6 (0x00007f6eba4fc000)\n\tlibz.so.1 => /lib64/libz.so.1 (0x00007f6eba2e5000)\n\t/lib64/ld-linux-x86-64.so.2 (0x00007f6ebb520000)\n\nThis executable works well and produces the same output given same input. However, there may come a system update that upgrades libm.so.6 to a new version, but is still ABI-compatible. The executable still works but now produces slightly (or in case of simulating chaotic flows, not so slightly) different results.\nThe proposal here is to add a mirrored set of transcendental functions that would be expressed in stdlib using only intrinsic arithmetic operators and parentheses to enforce order of operations. Then, you always know what function you're calling.\nA few questions come up for me now:\n\nEven with this approach, can we be sure that the compiler will still produce same code between -O0 and -O3? I think the compiler has full reign to make any binary code it wants. Again, when you do -O3 you're kinda telling it \"give me different results, but faster\". It still seems like a strange requirement or expectation that different optimization levels be bit-reproducible. I don't think they're supposed to be.\nLet's say we figure out item 1, this seems like a rather advanced and specialized application. Wouldn't the MOM team have some specialized library in place already? If not, then this likely falls into a hard research problem, which I think puts a bar high for stdlib implementation.\n\n\nAs an aside, a known and popular problem in numerical weather prediction is that if you recompile the same WRF code (or other weather model) with the new compiler version (say, ifort-18 -> ifort-19), you can get the simulated hurricane to make landfall in a completely different US state."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 17:20:49+00:00",
                    "text": "It's an old debate regarding rearrangement. Theoretically unless you use -ffast-math (which I do), the compiler should keep parentheses (I think even with -O3). My understanding is that in Fortran, unlike C, the compiler is free to rearrange the order of operation, unless you put parentheses in. If you put parentheses in, it should preserve it, unless you use -ffast-math, then it is free to completely rearrange.\nThat's in theory. In practice, there are all kinds of issues, but apparently @marshallward was able to resolve most of them, which is amazing.\n@marshallward do you agree that if you want bit-reproducibility, you might not always get the best performance as if you are willing to sacrifice it?"
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-18 18:58:02+00:00",
                    "text": "@milancurcic You've captured the main issue, which is an implicit link to some libm.so.* binary (or a custom library, I suspect, in other cases).  We have had situations where there was an ABI-compatible update to libm (or equivalent) which changed answers.\nFWIW I am less worried about -O flags changing answers in our own code.  I do more or less accept this tradeoff, or at least the responsibility.  But it would be nice if the external functions were not affected by those flags.\nThe MOM team does not yet have custom transcendentals, but we have started to prototype them in Python preprocessing scripts, and may find ourselves using them at some point.  I suppose that I am starting to send out feelers to see if something like stdlib is a place to hold such functions.\n@certik I don't want to take credit for this work, it is really due to my colleagues at GFDL - Robert Hallberg in particular - who have refined these methods.  As a relatively new member of the group, I am more of a student than a practitioner.\nThe methods do rely on rigid enforcement of parentheses, as you correctly point out.  I haven't yet perused the language standard to see what it says about the matter.\nAs for your question: no, we would not expect such functions or methods to be highly performant.  I think everyone understands that there is some computational cost associated with reproducibility."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 19:16:39+00:00",
                    "text": "As for your question: no, we would not expect such functions or methods to be highly performant. I think everyone understands that there is some computational cost associated with reproducibility.\n\nI see, thanks. In that case, it seems that bit-reproducible capabilities should be implemented in addition to high performance (but not strictly bit-reproducible) capabilities, not instead of them."
                }
            ]
        },
        {
            "number": 11,
            "user": "ivan-pi",
            "date": "2019-12-16 23:16:31+00:00",
            "title": "Proposal for ascii",
            "text": "This module should include functions for character classification and conversion (lower, upper). I have prepared a basic implementation at https://github.com/ivan-pi/fortran-ascii.\nThe plan is to cover the same functionality as found in the C, C++, and D libraries:\n\nC : http://www.cplusplus.com/reference/cctype/\nC++: https://en.cppreference.com/w/c/string/byte\nD: https://dlang.org/phobos/std_ascii.html)\n\n@zbeekman has already opened an issue (see ivan-pi/fortran-ascii#1) on dealing with different character kinds. The problem is that the ascii and iso_10646 character sets need not be supported by the compilers. Even if they are supported their bitwise representation might be different from the default kind.\nI realized while creating these functions, that agreeing upon a style guide #3 and documentation #4 early on would be helpful to improve future pull requests. Some agreement upon unit testing will also be necessary.\ncc: @jacobwilliams",
            "comments": [
                {
                    "user": "ivan-pi",
                    "date": "2019-12-16 23:28:53+00:00",
                    "text": "One of the simple points to discuss (connected to the style guide #3) is naming conventions. For example for the function that checks whether a character is a letter some of the possible names are:\n\nis_alpha\nisalpha (C/C++)\nisAlpha (D language, but in Fortran it's the same as the previous suggestion)\n\nPersonally, I like the underscored version (it matches the general verbosity of Fortran).\nI have also noticed that in C++, they have a separate set of the these function for \"wide\" strings (e.g. iswalpha, see https://en.cppreference.com/w/c/string/wide) which if I understand correctly are Unicode characters."
                },
                {
                    "user": "certik",
                    "date": "2019-12-16 23:57:31+00:00",
                    "text": "@ivan-pi let's move the naming conventions discussion into #3 (comment), where I just commented."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-17 15:53:21+00:00",
                    "text": "To address character kinds, this is my comment from the ascii proto-type repo:\n\nIf I understand correctly you are suggesting I create several copies of these function to operate on the following character kinds:\n\nWell, not exactly, because, as you noted, they're not guaranteed to exist, and when they do exist, \"DEFAULT\" is often/usually the same kind as \"ASCII\", so you can't create overloaded functions with arguments that are \"ascii\" and \"default\". (In that case you'd have a duplicate interface.)\nThat's one nice thing about jin2for: It doesn't assume anything and interrogates the numeric kinds from the compiler to then generate the code. So if only one character kind is supported then your code will only have that one kind. I'll cross post this on the new issue you made."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 23:17:09+00:00",
                    "text": "I see what you mean. If \"default\" and \"ascii\" weren't the same kind, then I could just create generic interfaces for all three character kinds (with conditional compilation if the compiler supports UCS using CMake).\nHow likely are we to meet a processor where \"ascii\" is not equal to \"default\"?\nIn Modern Fortran explained (2018) EBCDIC is mentioned. It seems to still be in use on some IBM mainframes: https://www.quora.com/Is-EBCDIC-replaced-by-ASCII-or-Unicode\nSince the module is supposed to work for ascii characters, I think it is possible to write all the functions in such a way that they work with either \"default\" (non-ascii) or \"ascii\" straight of the box (as long as the processor supports ascii) using the achar and iachar conversion routines.\nFor the ascii subset of unicode characters it should be possible to create overloaded functions because they have a different kind (more bits). Since there are not so many functions in this module I could just do it manually. We can always bring in jin2for later."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-19 23:23:36+00:00",
                    "text": "For the current use case, I don't think it makes sense to use Jin2For either.\nLet's start with default character kinds while we consider if there's anything clever that we can do. We can always do some introspection with CMake and then use configure_file() to achieve overloading."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 23:23:50+00:00",
                    "text": "Is it possible to have the operating system somehow simulate \"EBCDIC\" defaults or maybe it is possible setup a Docker image? I have no means of testing non-\"ascii\" defaults at the moment."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-20 02:26:19+00:00",
                    "text": "I think the way the procedures are written now (https://github.com/ivan-pi/fortran-ascii/blob/master/stdlib_ascii.f90) would work with both \"default\" and \"ascii\" characters."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-21 16:19:04+00:00",
                    "text": "Before I submit a pull request, there are a few more issues worth discussing:\n\nShould these procedure be pure or elemental?\nHow to handle control characters? Just as character constants? Or would it be better to simulate an enumerator using a derived type? A potential issue I see is that, the control characters constants might end up inadvertently polluting someones namespace if he does use stdlib_ascii and forgets to use the only clause. By wrapping them in a derived-type (singleton) you could only access these via something like ascii_control_char%vt (to access the vertical tab).\nNaming convention; in the other thread #3 the general agreement was to keep the longer - more explanatory names - with the verb separated by an underscore. I have prepared a table of the functions, their proposed name in the Fortran stdlib and their names in other languages:\n\nI see some potential confusion between the is_white and is_blank functions, also given that they have a different name in C/C++. The is_white returns true for the characters including the space, tab, vertical tab, form feed, carriage return, and linefeed characters. The is_blank (or isblank in C) was standardized in C99 and returns true if the character is the space character ' ' or the tab character. It would be interesting to know, what was the reason to introduce this as a separate function.\n\n\n\n\nPersonally, I am happy with the verbose underscored names, but I thought it is still worth discussing whether or not we would prefer the shorter seven-letter abbreviations.\n\n\n\n\nPurpose\nFortran\nC/C++\nD\nPython*\n\n\n\n\nchecks if a character is alphabetic\nis_alpha\nisalpha\nisAlpha\nisalpha\n\n\nchecks if a character is alphanumeric\nis_alphanum\nisalnum\nisAlphaNum\nisalnum\n\n\nchecks if a character is in the ASCII character set\nis_ascii\n/\nisASCII\nisascii\n\n\nchecks if a character is a control character\nis_control\niscntrl\nisControl\n\n\n\nchecks if a character is a digit\nis_digit\nisdigit\nisDigit\nisdigit\n\n\nchecks if a character is a octal character\nis_octal_digit\n/\nisOctalDigit\n\n\n\nchecks if a character is a hexadecimal character\nis_hex_digit\nisxdigit\nisHexDigit\n\n\n\nchecks if a character is a punctuation character\nis_punctuation\nispunct\nisPunctuation\n\n\n\nchecks if a character is a graphical character\nis_graphical\nisgraph\nisGraphical\n\n\n\nchecks if a character is a printing character\nis_printable\nisprint\nisPrintable\nisprintable\n\n\nchecks if a character is an uppercase character\nis_upper\nisupper\nisUpper\nisupper\n\n\nchecks if a character is lowercase\nis_lower\nislower\nisLower\nislower\n\n\nchecks if a character is a whitespace character\nis_white\nisspace\nisWhite\nisspace\n\n\nchecks if a character is a blank character (space or tab)\nis_blank\nisblank\n/\n\n\n\nconverts a character to lowercase\nto_lower\ntolower\ntoLower\n\n\n\nconverts a character to uppercase\nto_upper\ntoupper\ntoUpper\n\n\n\n\n\n\n\nNote*: In Python these are bound methods of the built-in string type\n\n\n\n\nAnother issue is what should be the behavior for non-ASCII characters? In D the function returns false for non-ascii characters, and the toX functions do nothing. This is probably a separate issue to discuss, once we work out the best way to also support the UCS character set."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 04:44:15+00:00",
                    "text": "Thanks @ivan-pi for submitting a PR with this! Much appreciated. Let's discuss the API."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-22 08:58:21+00:00",
                    "text": "Thanks @ivan-pi for this nice implementation.\nQuestion: should the long cases (implemented in the test) be also present in the module? or do we expect that the user would implement them for their own use?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-22 11:35:17+00:00",
                    "text": "Perhaps I have not understood your question correctly. The long tests generally loop through all characters (therefore they are \"long\") and are meant only as unit tests to verify the correctness of the functions. Since the short/long adjectives might lead to some confusion I would not mind if we rename them.\nThe last test - test_ascii_table - reproduces the table from the C++ functions available at https://en.cppreference.com/w/cpp/string/byte\nSince the functions follow the same pattern what might be worth including in the module is an abstract interface:\n abstract interface\n        pure logical function validation_func_interface(c)\n            character(len=1), intent(in) :: c\n        end function\n end interface\nalthough apart from my test case which uses an array of procedure pointers to loop through the character validation routines, I don't really know if their would be any use cases."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-22 11:45:33+00:00",
                    "text": "Since the short/long adjectives might lead to some confusion I would not mind if we rename them.\n\n@ivan-pi I think they are fine.\nI was not clear enough. Here is an example of what I meant:\ncharacter(len=30)::examplelower,exampleupper\nexample='abc'\nexampleupper=to_upper(examplelower)\nprint*,trim(exampleupper) !it prints 'ABC'\n\nwe can discuss and see later if it could be useful or not."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-22 20:55:55+00:00",
                    "text": "This would be useful and indeed and I would not mind preparing some examples for users. The way I see this done with other languages/libraries is to add usage examples in the documentation string. We should work this out under issue #4 . These could be integrated into a documentation website, kind of like with Sympy or D (see here. I am sure @milancurcic or @certik have some ideas how to publish the API and documentation as a website in the future."
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 18:55:00+00:00",
                    "text": "@ivan-pi ideally in the future we could write doctests just like in Python, as I just commented at #4 (comment)."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-24 18:44:36+00:00",
                    "text": "@ivan-pi Thank you for your work and sorry to be late to this thread, I missed reading it all the way through.\n\nShould these procedure be pure or elemental?\n\nOverall, if a pure procedure can be made also elemental I think there are only benefits to it and not penalties, so we should do it even when use cases are not apparent.\nI just checked and confirmed that they can all be made elemental as well. We can do it in a separate PR if the community agrees."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-24 19:31:34+00:00",
                    "text": "One downside of elemental procedures is that they cannot be used as procedure pointers (https://stackoverflow.com/questions/15225007/elemental-functions-cannot-be-pointed-to-by-procedure-pointers).\nI am not sure whether this matters in practical usage cases or not."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-24 19:38:58+00:00",
                    "text": "Ah, okay, I didn't know. That seems like an important restriction to take into account. We may just have to consider elemental on a case by case basis.\nIn this case, I don't know the answer as I don't have much experience working with text in Fortran (this may change now that we have ascii module :)). I can imagine it being useful to feed an array of characters to to_upper or to_lower. I can't think of a use case of passing them as proc. pointer."
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 19:46:12+00:00",
                    "text": "We can start with elemental, and since we are still in \"experimental\", we can remove elemental if we discover issues."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-27 16:23:08+00:00",
                    "text": "Question regarding control characters. They are currently defined as public parameters:\n! All control characters in the ASCII table (see www.asciitable.com).\ncharacter(len=1), public, parameter :: NUL = achar(z'00') !! Null\ncharacter(len=1), public, parameter :: SOH = achar(z'01') !! Start of heading\n... ! 30 more parameters ommitted\ncharacter(len=1), public, parameter :: DEL = achar(z'7F') !! Delete\nFirst, consider that a user may just do use stdlib_experimental_ascii, which imports everything, including the control characters (even though not recommended). All of them have names that are 2 or 3 characters long. Some of them could easily clash with other variable names because they're short and somewhat common, for example bs, lf, vt, ff, or cr. This scenario is okay (I think) because then the user is forced to do use stdlib_experimental_ascii, only: ..., which is recommended.\nHowever, consider a user that wants to work specifically with control characters. Their only options are:\n\nuse stdlib_experimental_ascii (imports everything, not recommended)\nuse stdlib_experimental_ascii, only: list, every, single, control, character, here, ... (recommended, but tedious)\n\nAlternatives would be to wrap these in a private derived type ascii_control_characters_type, and publicly expose a parameter instance of the type, ascii_control_characters. Then the use would do use stdlib_experimental_ascii, only: ascii_control_characters, and access them by, say, ascii_control_characters % BEL.\nSo, are we happy with the current API of control characters or is this a concern?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-27 16:43:36+00:00",
                    "text": "I agree this is a concern.\nYour suggestion is in line with one of my previous comments:\n\nHow to handle control characters? Just as character constants? Or would it be better to simulate an enumerator using a derived type? A potential issue I see is that, the control characters constants might end up inadvertently polluting someones namespace if he does use stdlib_ascii and forgets to use the only clause. By wrapping them in a derived-type (singleton) you could only access these via something like ascii_control_char%vt (to access the vertical tab).\n\nPersonally, I think we should go with your suggestion. In fact in D, they have something similar (https://dlang.org/phobos/std_ascii.html#ControlChar).\nI can prepare a new pull request with your suggestion, modify the procedures to be elemental, and also replace the whitechar function used in the stdlib_experimental_io module."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-28 15:38:06+00:00",
                    "text": "Today I was listing through the book \"Migrating to Fortran 90\" by James F. Kerrigan and on page 195 the author uses a derived type to encapsulate a set of cursor control strings useful for communication with an ANSI 3.64 compliant video display terminal.\nGiven this prior art, I think we can go ahead with the solution @milancurcic has suggested."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-29 13:59:15+00:00",
                    "text": "Thanks @ivan-pi. Another minor nit-pick. Should this:\npure logical function is_alphanum(c)\n    character(len=1), intent(in) :: c !! The character to test.\n    is_alphanum = (c >= '0' .and. c <= '9') .or. (c >= 'a' .and. c <= 'z') &\n        .or. (c >= 'A' .and. c <= 'Z')\nend function\nbe written as this?\npure logical function is_alphanum(c)\n    character(len=1), intent(in) :: c !! The character to test.\n    is_alphanum = is_digit(c) .or. is_alpha(c)\nend function"
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-29 15:47:33+00:00",
                    "text": "I agree the second version is cleaner and saves a few characters.\nIt would be interesting to compare the differences at assembly level with regard to different optimization flags."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-29 17:45:33+00:00",
                    "text": "Should we think here about getting the most optimized code? Certainly some optimizations are needed. But, as a user, I would first focus on the ease of use. If I would need performance, I would most likely implement what I need myself.\nAlso, as a developer, I prefer the second solution of @milancurcic . If something must be changed, modifiying only is_digit and is_alpha  would be enough, and the developer doesn't need to search for the same code in the code."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-29 18:28:25+00:00",
                    "text": "I tried to create a benchmark to test the two versions above and it is more difficult than I expected \ud83d\ude26 . With no optimization flags and a low number of runs it seems like the second version is a bit slower as is it invokes two function calls. With -O3 even after reading a file with 150 MB (or 80000000 random characters) I cannot reliably say which version is faster as differences in code layout, CPU temperature, etc., create variations.\nLet\u00b4s go for the second version then. I will make the changes in the next iteration of my PR after we agree what to do with the character constants in #49."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-29 19:51:21+00:00",
                    "text": "Since we are already discussing implementation details I was wondering how the character classification functions are defined in the C library. They use a different approach, quoting from Wikipedia:\n\n... the character classification routines are not written as comparison tests. In most C libraries, they are written as static table lookups instead of macros or functions.\n\nThis can be done in Fortran by setting up a constant array of 127 integers (say 16-bit) for the set of ascii characters (this could be done with a list of binary literals). The bit values are then used to indicate the different properties of a character (alphabetical, digit, punctuation, control, etc.).\nFor example if the first bit is used to represent whether the character is alphabetical or not, the is_alpha function would be:\nelemental logical function is_alpha(c)\ncharacter, intent(in) :: c\ninteger :: ic\nic = iachar(c)\nis_alpha = btest(table(ic),0)  ! access ascii character table\nend function\nI am not sure though what is the behavior of iachar if passed no ascii-characters, are these simply truncated or is the behavior processor-dependent.\nSuch a table can be easily generated using the \"current\" functions:\nprogram gen_ascii_table\n    use stdlib_experimental_ascii\n    implicit none\n    integer :: ascii_table(0:127)\n    integer :: i\n    character(len=1) :: c\n\n    ! initialize all bits to zero\n    ascii_table = 0\n\n    do i = 0, 127\n        c = achar(i)\n        if (is_alpha(c))       ascii_table(i) = ibset(ascii_table(i),0)\n        if (is_digit(c))       ascii_table(i) = ibset(ascii_table(i),1)\n        if (is_alphanum(c))    ascii_table(i) = ibset(ascii_table(i),2)\n        if (is_punctuation(c)) ascii_table(i) = ibset(ascii_table(i),3)\n        if (is_control(c))     ascii_table(i) = ibset(ascii_table(i),4)\n        if (is_graphical(c))   ascii_table(i) = ibset(ascii_table(i),5)\n        if (is_printable(c))   ascii_table(i) = ibset(ascii_table(i),6)\n        if (is_white(c))       ascii_table(i) = ibset(ascii_table(i),7)\n        if (is_blank(c))       ascii_table(i) = ibset(ascii_table(i),8)\n        if (is_lower(c))       ascii_table(i) = ibset(ascii_table(i),9)\n        if (is_upper(c))       ascii_table(i) = ibset(ascii_table(i),10)\n        if (is_octal_digit(c)) ascii_table(i) = ibset(ascii_table(i),11)\n        if (is_hex_digit(c))   ascii_table(i) = ibset(ascii_table(i),12)\n    end do\n    write(*,'(A,128(I0,:,\",\"))',advance='no') \"[\",(ascii_table(i),i=0,127)\n    write(*,'(a1)') \"]\"\nend program\nThe table of integers is then:\n[16,16,16,16,16,16,16,16,16,400,144,144,144,144,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,448,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,6246,6246,6246,6246,6246,6246,6246,6246,4198,4198,104,104,104,104,104,104,104,5221,5221,5221,5221,5221,5221,1125,1125,1125,1125,1125,1125,1125,1125,1125,1125,1125,1125,1125,1125,1125,1125,1125,1125,1125,1125,104,104,104,104,104,104,4709,4709,4709,4709,4709,4709,613,613,613,613,613,613,613,613,613,613,613,613,613,613,613,613,613,613,613,613,104,104,104,104,16]\n\nAs you can see different integers correspond to different character properties (e.g. 613 are lowercase letters which are note hex digits, 104 are punctuation characters, 6246 are octal digits...).\nIs there any reason we would prefer to go down this bit route?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-29 21:44:43+00:00",
                    "text": "I am not sure though what is the behavior of iachar if passed no ascii-characters, are these simply truncated or is the behavior processor-dependent.\n\nTrying to compile the program\nprogram test\nuse stdlib_experimental_ascii, only: is_alpha\nimplicit none\nprint *, iachar('\u00e4'), iachar('\u00e0'), is_alpha('\u00e4'), is_alpha('\u00e0')\nend program\n\nI get the following errors with gfortran:\ntest2.f90:4:16:\n\n print *, iachar('\u00e4'), iachar('\u00e0'), is_alpha('\u00e4'), is_alpha('\u00e0')\n                1\nError: Argument of IACHAR at (1) must be of length one\ntest2.f90:4:30:\n\n print *, iachar('\u00e4'), iachar('\u00e0'), is_alpha('\u00e4'), is_alpha('\u00e0')\n                              1\nError: Argument of IACHAR at (1) must be of length one\n\nHowever for the is_alpha function which only accepts a character(len=1) the compiler does not flag an error. Any idea if this is supposed to be this way?"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-30 03:58:08+00:00",
                    "text": "On my phone so I\u2019ll be brief/terse and can\u2019t easily look at the code.\nis_alpha() might be elemental? Non-ascii text takes up multiple bytes, ascii just one byte. The compiler is seeing two (or more) byte sequences and thinks that they are multiple 1-byte ascii chars.\nAlso, FYI, IIRC: compilers may not be required to handle non-ascii characters by the standard. I seem to recall this to be true from when I implemented Unicode support in JSON-Fortran."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-30 10:23:49+00:00",
                    "text": "is_alpha() might be elemental? Non-ascii text takes up multiple bytes, ascii just one byte. The compiler is seeing two (or more) byte sequences and thinks that they are multiple 1-byte ascii chars.\n\nIf I make the procedures pure instead of elemental, I am still \"allowed\" to pass non-ascii characters to the non-intrinsic is_alpha routine. Maybe I should check what is with the file encoding. I am working in a German locale.\n\nAlso, FYI, IIRC: compilers may not be required to handle non-ascii characters by the standard. I seem to recall this to be true from when I implemented Unicode support in JSON-Fortran.\n\nIn that case is the best we can do to simply state in the documentation the behavior is undefined for non-ascii symbols?"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-30 16:24:42+00:00",
                    "text": "Sorry, I wasn't entirely clear in my previous comment. My recollection is that compilers are not required to handle non-ascii characters in program source code. But I may be mistaken here.\nI seem to recall having to use the backslash notation with GFortran:\n-fbackslash\nChange the interpretation of backslashes in string literals from a single backslash character to \u201cC-style\u201d escape characters. The following combinations are expanded \\a, \\b, \\f, \\n, \\r, \\t, \\v, \\\\, and \\0 to the ASCII characters alert, backspace, form feed, newline, carriage return, horizontal tab, vertical tab, backslash, and NUL, respectively. Additionally, \\xnn, \\unnnn and \\Unnnnnnnn (where each n is a hexadecimal digit) are translated into the Unicode characters corresponding to the specified code points. All other combinations of a character preceded by \\ are unexpanded.\n\nhttps://gcc.gnu.org/onlinedocs/gfortran/Fortran-Dialect-Options.html"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-30 16:26:25+00:00",
                    "text": "Also, file encoding issues may be in play here, as you noted."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-24 10:43:48+00:00",
                    "text": "@dev-zero wrote in #32 (comment):\n\nsince I've been pointed here, this project might be interesting: https://github.com/lemire/fastvalidate-utf-8 althought I don't see how that could be implemented in Fortran given missing inline assembly.\n\nThanks for your suggestion! We could also just directly call the C routines.\nOver at https://github.com/ivan-pi/fortran-ascii/tree/master I've actually prepared 4 different versions of the character validation routines (three in Fortran, and one directly calling the C routines). I've done some micro-benchmarking and the differences can be up to a factor of 4. C++ still comes out a tiny bit faster for some reason. I'm writing a blog post about it (hopefully I finish it this weekend)."
                },
                {
                    "user": "certik",
                    "date": "2020-04-24 16:16:03+00:00",
                    "text": "I use the following simple routines in C++ to encode and decode unicode strings: https://github.com/certik/terminal/blob/69ee07e5aee2fe4c4bff4fa164364ec049c66069/terminal.h#L430\nHere is how to use the utf8_decode_step routine: https://github.com/certik/terminal/blob/69ee07e5aee2fe4c4bff4fa164364ec049c66069/terminal.h#L493. If you are only interested to know if it is a valid string, one can return true / false instead of rising the exception.\nI wrote the codepoint_to_utf8 routine myself, but I took the utf8_decode_step one from somewhere else --- I think these might be pretty fast and competitive and are very simple to implement in Fortran I think."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-26 20:29:54+00:00",
                    "text": "I've done some testing of different implementation approaches of the character validation routines:\n\ndirect approach (the one currently in stdlib) using relational operators and the character collating sequence\nusing select case constructs\nusing a lookup table and bitmask operations (the way it's typically done in the C/C++ library)\ninterface to the C standard library\n\nIf anyone is interested, the results are available here (scroll up for a description). There is no clear winner (besides C++).\nThe results do change around 5 % if I switch compiler flags, or even if I change the order of comparison in certain relational operations. I did not check what's going on at assembly level, and I think even the timing routines might skew the results somehow (e.g. the Fortran timings improved when I switched from cpu_time to system_count)\nIf anyone has some suggestions, how to improve the routines or make the measurements more accurate, please open an issue at my repository: https://github.com/ivan-pi/fortran-ascii\nI'd also be interested in results from other compilers, operating systems or processors."
                }
            ]
        },
        {
            "number": 10,
            "user": "certik",
            "date": "2019-12-16 19:25:41+00:00",
            "title": "Proposal for linalg",
            "text": "eig, eigh, inv, solve, det, svd, ... . A possible implementation is here: https://github.com/certik/fortran-utils/blob/b43bd24cd421509a5bc6d3b9c3eeae8ce856ed88/src/linalg.f90.\nAll these functions will be implemented in stdlib_linalg module, and they would probably just call Lapack. The general idea of these routines is to be general routines that will just work, with a simple intuitive interface, and the highest performance given the simple API. One can always achieve higher performance with more specialized routines for a particular problem (and more complicated API), but that is not the point here. Rather we would like a Matlab / NumPy style routines to do linear algebra.\nIn particular, let's start with eig, for an eigenvalue and eigenvectors of a general (non-symmetric) matrix. Both NumPy and Matlab have a very similar interface called eig, that I propose we use:\n\nNumPy: https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eig.html\nMatlab: https://www.mathworks.com/help/matlab/ref/eig.html\n\nJulia seems to have more of an \"object oriented\" interface called eigen: https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/index.html#LinearAlgebra.eigen, which uses some Julia language features to emulate the Matlab style vals, vecs = eigen([1.0 0.0 0.0; 0.0 3.0 0.0; 0.0 0.0 18.0]).",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-16 19:42:03+00:00",
                    "text": "Let's discuss the API for eig. Fortran cannot return more than one result in a function, and eig must return both eigenvalues and eigenvectors. So the only solution is a subroutine. The first argument should be the input matrix, to be consistent with NumPy and Matlab. The second argument can be an optional B matrix for the generalized eigenvector problem. The next argument can be eigenvalues and the last argument eigenvectors (NumPy, Julia style) or they can be switched (Matlab style). For efficiency reasons the eigenvalues should be just a vector (NumPy, Julia style) not a diagonal matrix (Matlab style: the default is a matrix, but the eigvalOption input option can specify vector to return a vector as well).\nThat reasoning leads to the following API:\n  interface eig\n     module procedure seig\n     module procedure seig_generalized\n     module procedure deig\n     module procedure deig_generalized\n     module procedure zeig\n     module procedure zeig_generalized\n  end interface eig\nHere s means single precision, d double, z complex (double). Here is an example of a double precision interface:\n    subroutine deig(A, lam, c)\n    ! Solves a standard eigenproblem A*c = lam*c\n    real(dp), intent(in) :: A(:, :)  ! matrix A\n    complex(dp), intent(out) :: lam(:)  ! eigenvalues: A c = lam c\n    complex(dp), intent(out) :: c(:, :)  ! eigenvectors: A c = lam c; c(i,j) = ith component of jth vec.\n    ...\n    end subroutine\n\n    subroutine deig_generalized(A, B, lam, c)\n    ! Solves a generalized eigenproblem A*c = lam*B*c\n    real(dp), intent(in) :: A(:, :)  ! matrix A\n    real(dp), intent(in) :: B(:, :)  ! matrix B\n    complex(dp), intent(out) :: lam(:)  ! eigenvalues: A c = lam c\n    complex(dp), intent(out) :: c(:, :)  ! eigenvectors: A c = lam c; c(i,j) = ith component of jth vec.\n    ...\n    end subroutine"
                },
                {
                    "user": "certik",
                    "date": "2019-12-16 19:53:05+00:00",
                    "text": "Here are some common points that should be discussed:\n\n\nShould the return arrays be allocatable, intent(out)? I would say no, for efficiency reasons.\n\n\nShould there be some optional options such as algorithm in the Matlab's API? I think there could.\n\n\nWe need to implement all combinations of types. The above proposal assumes real input matrices. We should also allow a complex input matrix.\n\n\nModify inplace? Lapack sometimes returns the result by overwriting the input matrix, although in the case of eig that does not seem to be the case (it is the case for cholesky), but the input matrix is destroyed, so internally there is an extra copy happening. The simple solution is the above proposal, that requires an extra copy, but the input matrix is never modified. Another solution is to have two kinds of eig subroutines, the one above, and another one called eig_inplace which will modify the matrix A and return the eigenvalues there."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 23:34:08+00:00",
                    "text": "@cmacmackin, @milancurcic, @septcolor what do you think of this proposal? I chose it so that it's something we might be able to agree quickly, and then we can figure out the proper workflow."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 00:14:40+00:00",
                    "text": "I'm not experienced with linalg stuff, but all looks reasonable. Procedure names are short and intuitive.\nI agree that allocatable for intent(out) dummy arguments should be avoided unless necessary.\nI don't like APIs that modify variables in-place, so I suggest we make an extra copy in default implementation, but if desired by the community we can also have a variant with an intent(in out) argument as you suggested.\nOtherwise, full steam ahead as far as I'm concerned."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 10:28:00+00:00",
                    "text": "From my experience with using LAPACK routines in some fluid-solvers (immersed boundary method, lattice boltzmann equation, etc) and PDE routines (orthogonal collocation), the right hand-side is rarely required after the solution of the system. If it is needed the user can always make a copy beforehand. Would the A matrix be returned factorize or would there be another copy?\nreal, allocatable(:) :: x, b\nreal, allocatable(:) :: A\nA = reshape([1,3,2,4],[2,2])\nb = [5, 6]\nx = b  ! user creates the copy\ncall solve(A,x) ! solve A*x=b\nIf you follow a more functional style you could write\nx = solve(A,b)\nThe annoying thing is that a subroutine and a function cannot be in the same generic interface block (perhaps something to discuss in the J3 Fortran proposal), meaning we would need two routines with different names.\nWhile I like the idea to have convenience routines, I think it is also worth considering a more object-oriented interface, similar to the one in the Eigen library: http://eigen.tuxfamily.org/dox/group__TutorialLinearAlgebra.html. A major difference compared to Eigen is that in Fortran we would like to use native real arrays and not some abstract matrix data types, meaning the solvers would likely become the abstract data type, e.g.:\ntype(linalg_solver) :: solver\n! ... create A and b ...\ncall solver%init(A,factorization=\"LU\") \nx = solver%solve(b)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 16:41:28+00:00",
                    "text": "@milancurcic, @ivan-pi I think you just demonstrated that we need both \"copy\" and \"inplace\" API. Julia does that, they append ! after the name of functions that modify arguments inplace, e.g. cholesky vs cholesky!. Fortran does not allow ! as part of the name, so we need some other convention. Any ideas?\nFinally, @ivan-pi also has a good point that besides the direct \"copy\" and \"inplace\" API, some people might also prefer an object oriented API. So I think we might need 3 APIs.\n@milancurcic so I can submit a PR for eig. But I would like new code to land in some kind of \"experimental\" namespace in stdlib. So that we can start using it and trying it out, but to reserve a right to change the API, if we discover issues. Only after some time and real usage in real codes, we should consider moving a functionality from experimental to the actual stdlib, after which we must support the API in a backwards compatible way."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 16:42:56+00:00",
                    "text": "@jacobwilliams, @marshallward do you have any thoughts on this workflow? Let's just concentrate on eig for now. We'll tackle solve and others later."
                },
                {
                    "user": "cmacmackin",
                    "date": "2019-12-19 17:54:18+00:00",
                    "text": "Personally, my preference would be for using derived types to store the matrix and/or its factorisation. With LAPACK, the factorisation requires more information than can be stored in the original matrix (e.g., pivot information), requiring additional arrays to be passed in. There are use-cases that reuse the factorisation, so we don't want that information to be lost. An example of an OOP approach can be found here: https://github.com/cmacmackin/OOP-Fortran-Examples/blob/master/04-lapack-wrapper.f90.\nIn terms of returning multiple results, another approach, aside from using a subroutine, would be to define a transparent derived type with these results as components and just to return that."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 18:59:11+00:00",
                    "text": "@milancurcic, @ivan-pi I think you just demonstrated that we need both \"copy\" and \"inplace\" API.\n\nAt best, I'd say we may need both. Let's focus on one, and consider another later.\nI'd caution against involving derived types or OOP here from the get-go. Obviously there are implementations with procedures only. I suggest taking an incremental approach here:\n\nImplement the most basic building block, say, eig that doesn't modify in-place (makes a copy);\nEvaluate and hear from community if in-place variant is really needed. It's likely to be more computationally efficient, albeit slightly less elegant. Does the community want it? Great! Let's do it;\nEvaluate the basic 2 implementations and discuss if higher-level abstractions (derived types) are needed.\n\nIn summary, let's make a banana first, and jungle later. Gorilla will come for the banana sooner or later. Let's worry about it then."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 19:02:33+00:00",
                    "text": "Fortran does not allow ! as part of the name, so we need some other convention. Any ideas?\n\nIn case of eig, it seems that both variants would need to be subroutines. The number of arguments will be different for the \"copy\" and \"in-place\" specific procedures. Can we then use a generic interface for both?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 19:06:05+00:00",
                    "text": "I agree with your plan to start with eig, then possibly an inplace variant, and then possibly an OO interface."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-19 19:06:27+00:00",
                    "text": "@certik Mostly just agreement on my part.  I am not a big user of linear algebra so I'm reluctant to weigh in here too heavily.  But since you asked...\n\n\nI agree subroutine is the best option.  You could use a type to bundle eigenvalues and eigenvectors, but then the user would have to use both the subroutine and the type which is clunky.\n\n\nA related consideration is ordering of arguments: output first or input first?  I only ask because the decision will likely propagate into later functions.  (And to tell the truth, I am not sure which I prefer...)\n\n\nI think @ivan-pi's suggestion of a solver object is interesting, but could also be designed to support the simple subroutine API.\n\n\n\n\nAgreed that allocation should not be used for output, and internally stack should be used if possible.  Users need to control OS resources.\n\n\nI think in-place does need to be considered at some level; linalg operations are great at blowing away memory (again, users should control resources).  Not sure if it should be in a separate function, but I think it ought to be at least provisionally resolved before development starts.\n\n\nAgree that users ought to have algorithm control, e.g. stiff matrices, or reproducibility (#12).  But I also think it can be addressed later in development an optional argument.\n\nShould sparse arrays be considered here?  Or separately?  (This can also be handled later, btw!)\n\n\n\nMostly though I agree with @milancurcic - make the \ud83c\udf4c !"
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 19:09:41+00:00",
                    "text": "Regarding argument ordering: NumPy, Matlab and Julia just return the result. So we do not have a prior implementation. To me the natural thing is to do output arguments at the end of the argument list. So the API is then very similar to NumPy: one simply calls eig() like you would in NumPy, and then one looks up the output arguments and appends them.\nWhich ordering do people prefer?"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-19 19:10:22+00:00",
                    "text": "Example of using generic interface to specific implementations:\ninterface :: eig\n  module procedure :: deig_copy, deig_inplace\n  ...\nend interface eig\n\ncontains\n\nsubroutine deig_copy(A, lam, c)\n  real(dp), intent(in) :: A(:, :)  ! matrix A\n  complex(dp), intent(out) :: lam(:)  ! eigenvalues: A c = lam c\n  complex(dp), intent(out) :: c(:, :)\n  ...\n\nsubroutine deig_inplace(A, lam)\n  real(dp), intent(in out) :: A(:, :)  ! matrix A and result c\n  complex(dp), intent(out) :: lam(:)  ! eigenvalues: A c = lam c\n  ..."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-19 19:10:58+00:00",
                    "text": "1. Should sparse arrays be considered here?  Or separately?  (This can also be handled later, btw!)\n\n\nSince sparse arrays and sparse matrix solvers use quite different data structures than dense arrays and factorizations, I would prefer to see them in a separate module. That is also how it is done in Scipy (https://docs.scipy.org/doc/scipy/reference/sparse.html)."
                },
                {
                    "user": "certik",
                    "date": "2019-12-19 19:16:42+00:00",
                    "text": "@milancurcic I like your idea. My only worry is if this can work for all our routines or not. If not, then for consistency reason I would prefer to be explicit. Some ideas to use for eig!:\n\neig_inplace\neig_i or eig_I\neigI\n\nFrom these I like the eigI version the most. It's visually similar to eig!, and I is for inplace."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-19 19:59:47+00:00",
                    "text": "1. Should sparse arrays be considered here?  Or separately?  (This can also be handled later, btw!)\n\n\nSince sparse arrays and sparse matrix solvers use quite different data structures than dense arrays and factorizations, I would prefer to see them in a separate module. That is also how it is done in Scipy (https://docs.scipy.org/doc/scipy/reference/sparse.html).\n\nI agree with @ivan-pi: I would also prefer to see sparse matrices in a separate module, especially that there are mutiple ways to store sparse matrices.\nAre sparse matrices something of high interest by the users? We could start with simple formats (e.g., COO and CRS3) and associate them to e.g., sparse BLAS?"
                },
                {
                    "user": "epagone",
                    "date": "2019-12-20 13:03:50+00:00",
                    "text": "Example of using generic interface to specific implementations:\ninterface :: eig\n  module procedure :: deig_copy, deig_inplace\n  ...\nend interface eig\n\ncontains\n\nsubroutine deig_copy(A, lam, c)\n  real(dp), intent(in) :: A(:, :)  ! matrix A\n  complex(dp), intent(out) :: lam(:)  ! eigenvalues: A c = lam c\n  complex(dp), intent(out) :: c(:, :)\n  ...\n\nsubroutine deig_inplace(A, lam)\n  real(dp), intent(in out) :: A(:, :)  ! matrix A and result c\n  complex(dp), intent(out) :: lam(:)  ! eigenvalues: A c = lam c\n  ...\n\nWhy not defining only one deig subroutine with optional argument c? Are there efficiency penalties? Or it is to keep the implementation more streamlined?"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-20 14:10:39+00:00",
                    "text": "It could be done with optional argument instead. I don't know if there are performance penalties. I like specific procedures + generic interface better as its more explicit and clear what it does, even if more verbose. With optional arguments, A would be intent(in out) in both modes, and it's modified only in one."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-20 14:14:25+00:00",
                    "text": "Some ideas to use for eig!:\n\neig_inplace\neig_i or eig_I`\neigI\n\nFrom these I like the eigI version the most. It's visually similar to eig!, and I is for inplace.\n\nI like eig_inplace and eig_i best, but eigI is okay. I'm not the likely user of this procedure, so happy to defer the vote to others. :)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-20 23:09:29+00:00",
                    "text": "We can do eig_inplace. Presumably it will not be used as often as just eig, and so it's ok to make it a bit more verbose to know what it is doing."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 18:01:20+00:00",
                    "text": "One thing we should try to do is to keep the serial API consistent with the possible parallel API in #67."
                },
                {
                    "user": "certik",
                    "date": "2020-05-03 20:53:44+00:00",
                    "text": "I split the in-place discussion into its own issue #177."
                }
            ]
        },
        {
            "number": 9,
            "user": "milancurcic",
            "date": "2019-12-15 21:38:55+00:00",
            "title": "Module naming convention",
            "text": "Tangential to #3. The choice of a module naming pattern is important because a module with a generic name can cause conflict in the client code. In the absence of namespaces, the standard library modules should have a specific enough prefix to prevent such conflicts.\nOne approach could be to use\n\nstdlib for the top-level module;\nstdlib_<group> for specific modules, e.g. stdlib_collections, stdlib_sorting, etc. you get the idea.\n\nIn the recent years, I tend to name modules with a mod_ prefix, e.g. mod_functional.  I see in the wild that module_, m_ prefixes, or even _m suffix are used. If I name the source file the same as the module, then I can easily see which source files contain modules and which don't. To me, this is useful if I haven't looked at the library in a long time, but now I can't think of any other benefit to this \"convention\". If this convention is used for stdlib, then we'd have:\n\nmod_stdlib\nmod_stdlib_<group>\n\nHowever, this seems unnecessarily verbose, and most library files are likely to be modules anyway (with the exception of tests which would be programs in their own directory, see #7). Thus, if we use the stdlib_ prefix universally, I don't think we need mod_ or similar.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-16 19:19:41+00:00",
                    "text": "This would be ultimately fixed by j3-fortran/fortran_proposals#86, then the top level module would be called stdlib and everything else will be nested underneath, such as sorting, linalg, etc.\nUntil then, I suggest to use underscore to emulate \"nested modules\", so as you suggested, I would use stdlib_linalg, stdlib_sorting, etc.\nI don't like the mod_* convention, as I try to recommend for every .f90 file to be a module. For stdlib I think every .f90 file can be a module."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-17 16:03:46+00:00",
                    "text": "I don't like the mod_* convention, as I try to recommend for every .f90 file to be a module. For stdlib I think every .f90 file can be a module.\n\nOr submodule... but yes I agree."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-17 16:10:06+00:00",
                    "text": "We follow a convention on our project where there is one module per file, and the module name matches the filename.  This is close to Python, where the file is the module.  This has worked very well for us.  (We also do not use any _mod style suffix.)"
                }
            ]
        },
        {
            "number": 8,
            "user": "milancurcic",
            "date": "2019-12-15 00:05:23+00:00",
            "title": "Continuous Integration",
            "text": "What should we use for continuous integration?\nGitLab's CI tools are amazing, but on GitHub I struggle every time I want to set up something. What's the state-of-the-art here for a Fortran+C project, ideally with builds for as many platforms we can get, and ideally free of charge?\n@zbeekman @jacobwilliams @scivision\nWe have some time to explore and decide, but at the point when we have some code + tests in, we should CI.",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2019-12-15 17:38:47+00:00",
                    "text": "My vote is for a combination of Github Actions and CircleCI. If we want/need exotic hardware, I have some aarch64 machines that we could host self-hosted github actions builders or gitlab-ci workers on. Docker can emulate other arches too, and I may be able to convince some folks at University of Oregon to allow access to dockerized test runners on things like Xeon Phi, and NEC VE, PPC, etc.\nI've recently really been enjoying using pipenv to manage some additional tools and the build-run environment. I install the latest CMake this way, as well as Jin2For and pre-commit hooks that way in ZstdFortranLib.\nI'd be happy to help implement CI&build stuff. And I'd love to be part of the GH org."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-15 17:41:39+00:00",
                    "text": "In the past year Travis-CI added ARM and IBM POWER arch. It seems after a dry spell there is a renewed interest in Travis development. Generally I have good success with GitHub actions as a primary choice."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-15 17:53:25+00:00",
                    "text": "Oh, wow! I left Travis-CI for dead after getting too frustrated with it. I'll have to go take another look. Is the ARM and IBM POWER documented?"
                },
                {
                    "user": "scivision",
                    "date": "2019-12-17 04:23:37+00:00",
                    "text": "https://blog.travis-ci.com/2019-11-12-multi-cpu-architecture-ibm-power-ibm-z"
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-22 21:27:38+00:00",
                    "text": "I have a simple Travis script (only for gfortran) that works for MacOS (with brew) and Linux in my Fortran interface for METIS: https://github.com/ivan-pi/fmetis/blob/master/.travis.yml\nThe script is is very similar to the Github-CI."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 21:33:22+00:00",
                    "text": "We could add Travis. I'm not sure there's a compelling need, unless we want to test ARM/power, etc. archs"
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 21:36:24+00:00",
                    "text": "@ivan-pi thanks. As @zbeekman said, we can add Travis (and Appveyor and Azure Pipelines or CircleCI). The main advantage of GitHub Actions is that the Windows, macOS and Linux configuration is uniform, in the single configure file:\nhttps://github.com/fortran-lang/stdlib/blob/c6b81196d495884558e653aae064f4d8781c0a96/.github/workflows/main.yml\nand it seems (at least so far) quick to run."
                }
            ]
        },
        {
            "number": 7,
            "user": "milancurcic",
            "date": "2019-12-14 23:43:47+00:00",
            "title": "Directory structure",
            "text": "Mostly cosmetic, but affects quality of life: What kind of directory structure should we use for the library?\nPotentially touching on #2 and #3.\nI tend to like structures like this:\nstdlib/\n  src/\n    lib/\n      mod_stdlib.f90\n      subdir1/\n      subdir2/\n      ...\n    tests/",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2019-12-17 16:14:46+00:00",
                    "text": "Tests\nI really think that it's important to make it easy for people to write and add tests, preferably before they write the implementation.\nIn my ZstdFortranLib project adding tests for a source file that makes up a library or executable target is as simple as adding a corresponding file with the same name, but ending in _test in the test directory. I have some CMake logic that searches through all Fortran sources associated with a target and looks for corresponding test files, and then automatically adds them. In this way, adding tests for a new source file is easier (from the build system perspective) than adding the actual source file is.\n.e.g., if foo.F90 is used in libfoo then putting foo_test.F90 in the test subdirectory automatically creates the test executable, links it to libfoo and adds the CMake test.\nFlat is better than nested\nIn general, I think we should strive for a directory structure that is as flat as possible, and only start adding subdirectories when we reach some threshold of 3-4 files implementing a well defined, cohesive idea. I also generally like having a test or tests directory in each source directory, i.e., lib/tests, subdir1/tests, etc too because it narrows the scope of looking for a test that corresponds to a source file. (Or even just putting tests along side with the _test.[Ff]90 ending in the same directory until it gets too cluttered to be sustainable.)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-17 17:51:29+00:00",
                    "text": "I agree with @zbeekman to have tests and more flat structure. I usually name tests as test_*.f90."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-17 18:00:24+00:00",
                    "text": "Great, I agree, I like the flat structure as well. I'd caution against keeping test source files together with module files at first. We don't have any modules now, but where we want to arrive is a place with a ~dozen to a few dozen modules. In a flat directory structure, it'd soon become cluttered to keep test programs in the same directory.\nLess important and personal preference, but when I explore libraries, I first like to look in the library source directory and see what does this library have unless already covered in the README.md. Test files would get in the way of readability here. We should think of the first impression that a new user gets when landing onto the repo page."
                },
                {
                    "user": "certik",
                    "date": "2019-12-17 18:04:44+00:00",
                    "text": "I think @zbeekman is suggesting to keep tests in the tests subdirectory. I think we all agree on that one, so that the tests do not clutter the source files."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-17 18:08:23+00:00",
                    "text": "Yes, I definitely misread that. :) We're on the same page."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-17 23:08:42+00:00",
                    "text": "Yes, I'd recommend putting tests in a test or tests subdirectory of the directory that holds the sources to be tested: E.g., src/lib/subdirA/tests for unit tests and specs corresponding to files in src/lib/subdirA. At least for unit tests and specs this makes sense. For integration tests or any test that doesn't have an obvious one-to-one mapping a test or tests directory at the project root (or directly under src if src/lib is where the library code goes) is needed to hold them.\nI'm not sure I see the benefit of src/lib/... over just src/ unless we want to pack, e.g., development scripts, etc. into src/, but I'm open to being convinced/wrong. \ud83d\ude09"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-17 23:29:21+00:00",
                    "text": "Great, so if we have tests/ in each sub-directory, then I agree that src/lib is redundant, and go with just src/. Given this, how would you organize tests for modules that don't have subdirectories, for example, if our first implementation module is ascii.f90 from #11, do we have:\nsrc/\n  stdlib.f90\n  ascii.f90\n  tests/\n    test_ascii.f90"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-18 03:15:20+00:00",
                    "text": "That looks good to me. I typically name the directory `test` without the s\n(one less letter) and name the files <name>_test.f90 but either convention\nis fine by me. As stuff gets added if src gets too cluttered you can break\nout more nesting and structure. E.g. `src/strings/ascii.f90` etc. where\nother string stuff gets gets grouped there.\n\u2026\nOn Tue, Dec 17, 2019 at 6:29 PM Milan Curcic ***@***.***> wrote:\n Great, so if we have tests/ in each sub-directory, then I agree that\n src/lib is redundant, and go with just src/. Given this, how would you\n organize tests for modules that don't have subdirectories, for example, if\n our first implementation module is ascii.f90 from #11\n <#11>, do we have:\n\n src/\n   stdlib.f90\n   ascii.f90\n   tests/\n     test_ascii.f90\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#7?email_source=notifications&email_token=AACEIPFAQKXOMPFNEQLGGL3QZFOFFA5CNFSM4J25IBJKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHEJ5UQ#issuecomment-566795986>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AACEIPH6OOVQZXINDO6RZ4TQZFOFFANCNFSM4J25IBJA>\n ."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 03:50:44+00:00",
                    "text": "@milancurcic that's precisely how I would do it."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:12:33+00:00",
                    "text": "Is this finalized? Should I work on CMake helper functions to detect and add tests?\ni.e. src/ascii.f90 --> src/tests/test_ascii.f90?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 17:36:20+00:00",
                    "text": "Isn't it better to list tests explicitly? I feel the automatic detection requires programming in CMake and I would prefer to avoid as much programming as possible in CMake, because CMake is not a very good language for programming. Also, I think a lot of people asked us to also maintain manual Makefiles. Which is quite easy if we keep CMake programming to minimum."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:43:11+00:00",
                    "text": "Sure, we can take either approach, but automatic addition of tests is really nice for contributors because THEY don't have to program in CMake... They just create a test and it gets added and run. Otherwise they need to call add_executable add_test target_link_libraries etc etc. With automatic detection creating a file with the right name in the right place causes the test to get added, compiled, linked and run..."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:43:52+00:00",
                    "text": "I personally think this is worth the CMake \"headache\" and I am happy to maintain and create it..."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-22 18:00:39+00:00",
                    "text": "They just create a test and it gets added and run. Otherwise they need to call add_executable add_test target_link_libraries etc etc.\n\nIf done in a loop, it's really just typing out the test name, which is minimal work.\nI recommend against depending on a \"key man\" for any specific task, for example Zaak's CMake expertise. If we keep the workflow simple enough, a developer can (and should) work through the whole cycle: Writing code and tests, documentation, and adding to build systems. On one hand, automating things like adding tests to CMake will help every developer. On the other hand, everybody having to \"touch\" each part of the workflow will help them be more versed in the whole workflow. In a nutshell, growing a community of generalists rather than that of specialists.\nThe question of maintaining manual Makefiles raises a deeper question: How do we maintain build systems that we agree on? I see the value in manual Makefiles, but we would as a community have to agree that everybody who contributes a feature also has to contribute the changes to all build systems that we agree to maintain. Specifically, we can't have one person running around patching up manual Makefiles while other developers are rapidly adding and updating the API.\nShould we discuss maintaining CMake and manual Makefiles in separate issues (they're off-topic here)?"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-22 18:05:54+00:00",
                    "text": "I realize that there will be some balance here. There will likely be some contributors who will implement a feature but won't know how to update build systems and will need help. Expecting them to learn the whole flow and knowing how to update build systems may slow down implementations moving forward. I don't know what's a good approach here."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 18:19:31+00:00",
                    "text": "I recommend against depending on a \"key man\" for any specific task, for example Zaak's CMake expertise.\n\nI definitely agree with the sentiment here. We don't want our \"bus factor\" to be low. (I.e., how many people getting hit by a bus will cause the project problems...)\nI think that having the automation of setting up tests will improve the project because people already don't want to write tests. Making the lowest possible barrier to entry, i.e., name it with the same name and prefix test_ and put it in the tests subdirectory will go a long way towards making it easy for people to contribute. Even if they have no CMake experience adding the test to CMake makes it so that they don't need to do anything... It's not THAT hard to loop over a target's source files and look for ones that correspond to tests. If the CMake is well commented even relative novices should be able to follow along.\nEven if adding tests is automated, we should document manually adding tests; sometimes you need to do this. We can have examples of manual tests too. However, I think that the automation and ease of use make it worthwhile to have automated finding and running of tests. The build system could even warn you if you add a new source file without a corresponding test.\nI know CMake can be awkward, and scary, but creating this will ultimately lead to fewer lines of CMake code and should make peoples lives easier, and lead to more tests being submitted with PRs."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 18:20:22+00:00",
                    "text": "We can help contributors update the build system, just like we are already helping them with git, see the other issue.\n\nI agree to try to keep our build system as simple as possible, and yes, perhaps a little bit more manual as a result.\n\nAlso keep in mind that at least initially, most projects will simply copy the stdlib_*.f90 files into their repositories and use their buildsystems.\n\nSo I think our goal should be to keep our infrastructure as simple and straightforward as possible.\n\u2026\nOn Sun, Dec 22, 2019, at 11:05 AM, Milan Curcic wrote:\n I realize that there will be some balance here. There will likely be\n some contributors who will implement a feature but won't know how to\n update build systems and will need help. Expecting them to learn the\n whole flow and knowing how to update build systems may slow down\n implementations moving forward. I don't know what's a good approach\n here.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#7?email_source=notifications&email_token=AAAFAWAZ3OYUZ2E5TGGA5N3QZ6UAHA5CNFSM4J25IBJKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHPWOOI#issuecomment-568289081>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWB2NRK53WFMSONLGBTQZ6UAHANCNFSM4J25IBJA>."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 18:23:30+00:00",
                    "text": "Why don't you try to submit a PR. If you lower the amounts of CMake lines we have to maintain, then we can have a discussion if it outweighs the added complexity. If the PR adds CMake lines while doing the same things, then probably its not worth it.\n\u2026\nOn Sun, Dec 22, 2019, at 11:19 AM, zbeekman wrote:\n >\n > I recommend against depending on a \"key man\" for any specific task, for example Zaak's CMake expertise.\n\n I definitely agree with the sentiment here. We don't want our \"bus\n factor\" to be low. (I.e., how many people getting hit by a bus will\n cause the project problems...)\n\n I think that having the automation of setting up tests will improve the\n project because people already don't want to write tests. Making the\n lowest possible barrier to entry, i.e., name it with the same name and\n prefix `test_` and put it in the `tests` subdirectory will go a long\n way towards making it easy for people to contribute. Even if they have\n no CMake experience adding the test to CMake makes it so that they\n don't need to do anything... It's not THAT hard to loop over a target's\n source files and look for ones that correspond to tests. If the CMake\n is well commented even relative novices should be able to follow along.\n\n Even if adding tests is automated, we should document manually adding\n tests; sometimes you need to do this. We can have examples of manual\n tests too. However, I think that the automation and ease of use make it\n worthwhile to have automated finding and running of tests. The build\n system could even warn you if you add a new source file without a\n corresponding test.\n\n I know CMake can be awkward, and scary, but creating this will\n ultimately lead to fewer lines of CMake code and should make peoples\n lives easier, and lead to more tests being submitted with PRs.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#7?email_source=notifications&email_token=AAAFAWHN3CN5BPCWDV7HL2TQZ6VTHA5CNFSM4J25IBJKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHPWWFY#issuecomment-568290071>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWHAJMINE4QBDARAXJTQZ6VTHANCNFSM4J25IBJA>."
                }
            ]
        },
        {
            "number": 6,
            "user": "milancurcic",
            "date": "2019-12-14 23:35:23+00:00",
            "title": "License",
            "text": "How should Fortran stdlib be licensed?\nI initially chose my favorite license, which is MIT. We can discuss and change this if other license is preferred.\nI think it's important that the license:\n\nis friendly for commercial / closed-source projects;\ngrants copyright to contributors\n\nWhat else or anything I'm missing?",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2019-12-16 19:39:20+00:00",
                    "text": "I too like MIT, FWIW."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-17 04:26:52+00:00",
                    "text": "LLVM C++ stdlib is MIT https://libcxx.llvm.org/"
                },
                {
                    "user": "certik",
                    "date": "2019-12-17 05:04:47+00:00",
                    "text": "I think we should use MIT."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-17 17:20:32+00:00",
                    "text": "Closing this for now, it looks like we will mostly be on the same page. Please re-open if needs to be reconsidered."
                }
            ]
        },
        {
            "number": 5,
            "user": "milancurcic",
            "date": "2019-12-14 23:32:06+00:00",
            "title": "Workflow for contributors",
            "text": "Use this issue to discuss the workflow that we should adopt. This will eventually become part of the Workflow doc\nFor the time being:\n\nUse #1 to broadly discuss what should be part of stdlib;\nOpen a new issue for a specific proposal;\nOnce the proposal gets reasonably enough discussion and support from the community, open a pull request to add code to the stdlib;\nWe can flesh out the specific requirements regarding quality control and similar in this thread.\n\nWe can also discuss the preferred git/GitHub workflows for contributing to the reop, such as feature branches, pull requests, etc.",
            "comments": [
                {
                    "user": "zbeekman",
                    "date": "2019-12-17 16:33:17+00:00",
                    "text": "CD and conventional commits/automatic semantic versioning\nI propose we adopt conventional commits https://www.conventionalcommits.org/en/v1.0.0/ and semantic versioning https://semver.org.\nConventional commits are a means of ensuring compliance with semver and automating the release process and changelog generation.\nAs such I propose master is where stable code is continuously delivered and released, devel is a protected development branch and all contributions are done via a forking workflow on feature branches (on the contributors fork)."
                },
                {
                    "user": "certik",
                    "date": "2019-12-17 17:09:28+00:00",
                    "text": "The \"conventional commits\" is an interesting idea, but it seems way too complicated, and for that reason the projects that are listed there as example projects do not actually follow it, e.g.:\n\nBlazeSoftware/blaze#220\nyargs/yargs#1506\n\nThe reason is that most new contributors do not know how to format their commits properly, and thus you can either reject such contributions or it puts more work on project maintainers to rebase / squash commits properly, and squashing is bad because it destroys history and removes attribution if there is more than one author in the PR.\nA better approach is to tie the changelog to the PR itself, not the individual commits. We do that in SymPy, here is an example:\n\nsympy/sympy#17974\n\nAnd here is documentation about how it works: https://github.com/sympy/sympy/wiki/Writing-Release-Notes. We have a tool that creates the release notes automatically from the description in the PR. That way the project maintainers can easily create proper changelog description for each PR that anybody submits, and there is no need to rewrite commit history, so it scales well with people."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-17 23:23:38+00:00",
                    "text": "I agree that conventional commits can be a little bit awkward. However I've developed CMake modules for some of my projects that detect when being built from a git repository, install (locally) the required npm modules, and then inject a git hook so that git commit really fires up git-cz. After the interactive commit formatting via git-cz the message is opened in your editor for review and modification.\nThe largest benefit of this is that commit messages end up clearly indicating breaking changes, and what types of changes were made, not to mention the large eco-system of tools for automatically releasing, versioning, creating changelogs, etc.\nBut this is not my hill to die on, and the reduced complexity and/or burden on contributors might be worth not using conventional commits. Basically, you can trade burden on committers for complexity in ensuring people have git hooks setup properly etc."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-17 23:50:36+00:00",
                    "text": "I took a look at Conventional Commits and am personally not a fan. Seems like a lot of technical bureaucracy for not much reward. I don't think I've written more than a single-line, simple sentence commit message.\nChangelogs in PR make sense to me.\nSemver.... sure. This becomes meaningful at scale when people start using this in production. We'll probably be in 0.1.x for some time.\nI like the master for latest stable and develop in feature branches, e.g. feature/ascii or similar."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:26:01+00:00",
                    "text": "Sure, that's fine. They have a nice tool that holds your hand as you write the commit message and can be installed as a hook. But I'm happy to use less structured commit messages if people prefer."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-30 21:48:41+00:00",
                    "text": "Let's bring back the discussion on workflow. We're very early on in the project and learning as we go what will work best for this community. Let's keep the discussion to how we work as people and open separate issues for topics such as versioning or any CI-related technicalities.\nWhat do you think about this flow:\n\nYou have an idea or a proposal. Open an issue to discuss it. This is on the level of \"is there interest in having image reader/writer functions in stdlib?\"\nWhen there seems to be significant interest in the proposal, like 80/20 participants think it's a good/bad idea, move on to discuss the specific API. It's OK to propose the API off the bat if you already have an idea for it.\nDiscuss the API and iterate. When there is ~80/20 approval for the API, move on to implement it and submit a PR. Small PRs are always better than large. It's OK to implement only a few functions of a new module, and continue work on the others in a later PR.\nWhen opening a PR, request reviews from one or more people that are most relevant to it. These are likely to be people involved in prior steps of the workflow. Other contributors (not explicitly invited) may provide reviews and suggestions as well. Iterate until all (or most) participants are on the same page. We should never merge before requested reviewers approve."
                },
                {
                    "user": "certik",
                    "date": "2019-12-31 00:11:28+00:00",
                    "text": "@milancurcic in addition, I would mention in step 3. that new features go into \"experimental\" modules. In step 4. I would change the wording from \"Other contributors (not explicitly invited) may provide reviews and suggestions as well.\" to \"Other contributors (not explicitly invited) are encouraged to provide reviews and suggestions as well.\" I would change \"We should never merge before requested reviewers approve.\" to \"We should not merge if there is a very strong objection from the reviewers or from somebody in the wider community.\"\nFinally, we need to figure out a step \"5. Moving from experimental to main\". We can get there in few months once we get actual real world usage of the features in experimental."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 16:57:01+00:00",
                    "text": "I agree with the proposal above from @milancurcic and suggestions from @certik.\nA more logistical question: Do we always want to merge PRs with non-fast-forward merge commits? Do we ever want to be able to fast-forward merge? Or rebase then fast-forward? (no merge commit created)\nThe potential advantage of this is that it makes git history easier to understand and simpler. The disadvantage is that it can be harder or less obvious to figure out how to revert an entire merge/PR.\nIn general, I'm against fast-forward merges of PRs, but recently I have been seeing the appeal for using them in simple cases where there are only one or two commits and the changes in question are well contained."
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 17:05:27+00:00",
                    "text": "I would keep using the default merge commits --- the main advantage that I can see is that when I need to find the associated discussion and review for a given commit in history, one just has to find the merge commit and it has the PR number in it, so one can go to GitHub and read the discussion to understand why it was merged."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 17:08:10+00:00",
                    "text": "ah, I see. So you'd advocate against doing a local merge and push as well. In that case I will refrain from doing that too! (And, I didn't think of that, but for this project that is an extremely compelling case to merge through the GH interface given the amount of discussion we can expect on PRs! Good call!)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-02 18:03:07+00:00",
                    "text": "@zbeekman Yes, exactly. I don't think local merge and push is even allowed is it? I thought I disabled it.\nUpdate: I guess it might still be allowed. In GitLab I always disable direct pushes into master (it's actually really easy to make a mistake and push into the master by accident!), but I guess that is not possible in GitHub? The master branch protection is enabled and \"Require status checks to pass before merging\", so I thought that would disable direct pushes, because then obviously one cannot guarantee that the CI will pass. But I guess it does not do that.\nEither way, yes, please let's not push directly to master. Always create a PR, and always get the PR reviewed and all tests pass before merging."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 18:35:20+00:00",
                    "text": "Either way, yes, please let's not push directly to master. Always create a PR, and always get the PR reviewed and all tests pass before merging.\n\nIf you set master a protected branch then you aren't allowed to push directly to master, unless doing so is equivalent to closing the PR. So you can push a merge commit that corresponds to an open PR and closes it. Then depending on the other settings (i.e. allow squash and rebase) you might be able to also do that locally and push.\nAnyway, I'll merge through the online web interface going forwards. It has some downsides (like merge commits created that way won't be signed with my GPG signing key, but they might be signed with a different GH key) but that's fine and preserving the default merge comment is worth it."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-02 18:36:43+00:00",
                    "text": "(and, just FYI, I would never intentionally push anything to master other than a merge commit to close an open PR, but I will refrain from doing that as well)"
                },
                {
                    "user": "certik",
                    "date": "2020-01-06 19:14:33+00:00",
                    "text": "I discussed this with @nncarlson and we both think the final 5. step should be to write a \"specification\". As an example, we think the current open function in src/stdlib_experimental_io.f90 is read for it. The specification is an independent document that describes the API and the functionality, so that anyone can then create an implementation just based on the document. stdlib then provides a reference implementation. And it is this specification document that should be \"approved\", by the wide community and hopefully also informally by the standards committee. And if it gets \"approved\", we can then move code from \"experimental\" to \"main\".\nI created #94, where I tried to write down this workflow based on the above discussion."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-19 17:52:47+00:00",
                    "text": "The specification is an independent document that describes the API and the functionality, so that anyone can then create an implementation just based on the document.\n\nWhere should this document be saved? Next to the .f90 file? What about the format (.md)? Wht about the name (e.g., stdlib_experimental_io.md for stdlib_experimental.f90)?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-19 17:58:17+00:00",
                    "text": "@jvdp1 thanks for staring a discussion about this.\nI was hoping the specification would be in some form that we can then automatically generate online html documentation (as well as perhaps a pdf document?). Also I was hoping we could somehow automatically understand the types of the arguments, something like FORD.\nFormat should be Markdown I think.\nSo one option is stdlib_experimental_io.md for stdlib_experimental_io.f90. The other option is inline inside stdlib_experimental_io.f90 like FORD.\nWhy don't we start with stdlib_experimental_io.md to get started. We can discuss how to automate it further as we go."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 07:51:52+00:00",
                    "text": "I would strongly recommend to accept only functionality that comes with a set of unit tests for all relevant use cases. It might be a little bit pessimistic, but I consider code without test as broken until a unit test convinces me from the opposite"
                },
                {
                    "user": "certik",
                    "date": "2020-05-30 14:25:30+00:00",
                    "text": "@MarDiehl that is exactly what we do. Every PR has to have tests for all new functionality before it gets merged."
                },
                {
                    "user": "MarDiehl",
                    "date": "2020-05-30 15:12:55+00:00",
                    "text": "@MarDiehl that is exactly what we do. Every PR has to have tests for all new functionality before it gets merged.\n\ud83d\udc4d"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-30 18:05:00+00:00",
                    "text": "@certik is right that we do this for every feature PR, but @MarDiehl raises an important point: This isn't obvious from the workflow doc. We should require tests in step 4 (implementation).\n@MarDiehl Do you mind opening a PR to add a brief statement about tests in the workflow doc?\n(of course, this can't answer the question what makes good and sufficient tests)"
                }
            ]
        },
        {
            "number": 4,
            "user": "milancurcic",
            "date": "2019-12-14 23:26:03+00:00",
            "title": "Documentation",
            "text": "Use this issue how to best document the stdlib. I put a placeholder Markdown file here.",
            "comments": [
                {
                    "user": "jvdp1",
                    "date": "2019-12-22 09:01:26+00:00",
                    "text": "Regarding the documention, is it planned to use some tools, like Doxygen or Ford to generate documention from the code?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 15:30:35+00:00",
                    "text": "I think we should write documentation as comments in the code and generate nice html documentation from it, that way the documentation and code is at one place and easier to maintain and keep in sync. So whatever tool allows us to do that, or if we have to write or improve some tools, I think we should do that."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:14:12+00:00",
                    "text": "FORD is my preference unless someone knows a good way to do that with sphinx.\nI think it can be worthwhile to have additional docs. I like hosting markdown based docs on RTD and API docs on gh-pages."
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 18:53:21+00:00",
                    "text": "Down the road I would like to use LFortran to execute \"doctests\" just like in Python. Here is the issue for it: https://gitlab.com/lfortran/lfortran/issues/73"
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-25 11:40:01+00:00",
                    "text": "FORD also supports the option to include additional markdown based docs (http://d3denergetic.github.io/FIDASIM/ is my favourite example).\nPersonally, I find the FORD generated documentation easier to navigate than doxygen. In case we decide to use FORD we should agree on the symbols to indicate documentation and whether we use preceding documentation strings or not.\nI am not sure if FORD can be used together with jin2for. Does one only document the generic interface block in that case?\ncc: @cmacmackin"
                },
                {
                    "user": "cmacmackin",
                    "date": "2019-12-25 11:47:40+00:00",
                    "text": "@ivan-pi I've never used jin2for so I can't be certain. However, FORD does allow files to be preprocessed prior to it parsing for documentation, so that could work. You'd probably want to give a detailed explanation only in the generic blocks, but still document the arguments in each specific implementation."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-25 13:45:23+00:00",
                    "text": "MOM6 uses Doxygen-style comments, but these are converted into reST files which are then passed onto Sphinx.\nAn example Doxygen-marked file: https://github.com/NOAA-GFDL/MOM6/blob/dev/gfdl/src/parameterizations/vertical/MOM_vert_friction.F90\nThis uses the !<and !! syntax for marking up variables, subroutines, etc.\nThe Doxygen XML is then converted to reST by a local tool developed by a former visitor (itself forked from another project): https://github.com/angus-g/sphinxcontrib-autodoc_doxygen\nalthough we are looking to migrate to this tool: https://github.com/vovkos/doxyrest\nOnce it's been converted to reST, then we just run it through the usual Sphinx process.\nThis is the generated output: https://mom6.readthedocs.io/en/dev-gfdl/api/generated/modules/mom_vert_friction.html#f/mom_vert_friction\nSome limitations of the above system are that the Doxygen -> reST process depends on an unsupported tool which only exposes a fraction of the Doxygen content, and that there are apparently bugs inside of Doxygen's Fortran support which prevent adoption of doxyrest (which is a supported tool).  We have someone here working on this problem, but it's not ready to go at this moment.\nNot necessarily advocating this approach BTW, only hoping to show what alternatives are out there and what is possible.\nI agree with others that the native Doxygen output is not that pleasant to navigate, and I don't think we'd continue to use it if we didn't have the pipeline above."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-30 04:08:53+00:00",
                    "text": "I am not sure if FORD can be used together with jin2for. Does one only document the generic interface block in that case?\n\nI usually generate the sources with jin2for then run FORD on those."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-30 16:20:51+00:00",
                    "text": "I do quite like Sphinx but the Doxygen to Sphinx pipeline seems complicated. Ideally whichever tool we choose will be Fortran aware enough to provide additional useful information beyond the source file markup.\nFor high-level documentation I really like read-the-docs and using mkdocs. E.g.,  https://zstdfortranlib.readthedocs.io/en/latest/?badge=latest (WIP)"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-05 14:11:47+00:00",
                    "text": "I think it would be a good time to introduce a documentation.\nSeveral modules are now present in stdlib, and it would be useful to have some documentations to show what is already implemented to the new contributors (and users).\nFrom the different comments, it seems that FORD could be a good tool for generating a doc from Fortran files, while @marshallward  and @zbeekman  proposed more complicated (better?) approaches. Should we give a try to FORD first?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 17:22:43+00:00",
                    "text": "Does FORD support Markdown? I would suggest to write our documentation in Markdown in the comments. We can start with FORD.\n\u2026\nOn Sun, Jan 5, 2020, at 7:11 AM, Jeremie Vandenplas wrote:\n I think it would be a good time to introduce a documentation.\n  Several modules are now present in `stdlib`, and it would be useful to\n have some documentations to show what is already implemented to the new\n contributors (and users).\n\n From the different comments, it seems that `FORD` could be a good tool\n for generating a doc from Fortran files, while @marshallward\n <https://github.com/marshallward> and @zbeekman\n <https://github.com/zbeekman> proposed more complicated (better?)\n approaches. Should we give a try to FORD first?\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#4?email_source=notifications&email_token=AAAFAWHO6Q6NIKB2GYF4HRDQ4HTCJA5CNFSM4J25GCIKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIDX2EA#issuecomment-570916112>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWC364JQWTTJ3GEGGDDQ4HTCJANCNFSM4J25GCIA>."
                },
                {
                    "user": "cmacmackin",
                    "date": "2020-01-05 17:35:08+00:00",
                    "text": "Yes, ford is markdown based.\n\u2026\nOn Sun, 5 Jan 2020, 17:22 Ond\u0159ej \u010cert\u00edk, ***@***.***> wrote:\n Does FORD support Markdown? I would suggest to write our documentation in\n Markdown in the comments. We can start with FORD.\n\n On Sun, Jan 5, 2020, at 7:11 AM, Jeremie Vandenplas wrote:\n > I think it would be a good time to introduce a documentation.\n > Several modules are now present in `stdlib`, and it would be useful to\n > have some documentations to show what is already implemented to the new\n > contributors (and users).\n >\n > From the different comments, it seems that `FORD` could be a good tool\n > for generating a doc from Fortran files, while @marshallward\n > <https://github.com/marshallward> and @zbeekman\n > <https://github.com/zbeekman> proposed more complicated (better?)\n > approaches. Should we give a try to FORD first?\n >\n > \u2014\n > You are receiving this because you commented.\n > Reply to this email directly, view it on GitHub\n > <\n #4?email_source=notifications&email_token=AAAFAWHO6Q6NIKB2GYF4HRDQ4HTCJA5CNFSM4J25GCIKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIDX2EA#issuecomment-570916112>,\n or unsubscribe <\n https://github.com/notifications/unsubscribe-auth/AAAFAWC364JQWTTJ3GEGGDDQ4HTCJANCNFSM4J25GCIA\n >.\n >\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#4?email_source=notifications&email_token=AB6ESPIXRLGF4TSO32Z542TQ4IJOJA5CNFSM4J25GCIKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEID3MKQ#issuecomment-570930730>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AB6ESPMT7OMOU33PISZVEA3Q4IJOJANCNFSM4J25GCIA>\n ."
                },
                {
                    "user": "certik",
                    "date": "2020-01-05 17:41:29+00:00",
                    "text": "Perfect. I would give it a try.\n\u2026\nOn Sun, Jan 5, 2020, at 10:35 AM, Chris MacMackin wrote:\n Yes, ford is markdown based.\n\n  On Sun, 5 Jan 2020, 17:22 Ond\u0159ej \u010cert\u00edk, ***@***.***> wrote:\n\n  > Does FORD support Markdown? I would suggest to write our\n documentation in\n  > Markdown in the comments. We can start with FORD.\n  >\n  > On Sun, Jan 5, 2020, at 7:11 AM, Jeremie Vandenplas wrote:\n  > > I think it would be a good time to introduce a documentation.\n  > > Several modules are now present in `stdlib`, and it would be\n useful to\n  > > have some documentations to show what is already implemented to\n the new\n  > > contributors (and users).\n  > >\n  > > From the different comments, it seems that `FORD` could be a good\n tool\n  > > for generating a doc from Fortran files, while @marshallward\n  > > <https://github.com/marshallward> and @zbeekman\n  > > <https://github.com/zbeekman> proposed more complicated (better?)\n  > > approaches. Should we give a try to FORD first?\n  > >\n  > > \u2014\n  > > You are receiving this because you commented.\n  > > Reply to this email directly, view it on GitHub\n  > > <\n  >\n #4?email_source=notifications&email_token=AAAFAWHO6Q6NIKB2GYF4HRDQ4HTCJA5CNFSM4J25GCIKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIDX2EA#issuecomment-570916112>,\n  > or unsubscribe <\n  >\n https://github.com/notifications/unsubscribe-auth/AAAFAWC364JQWTTJ3GEGGDDQ4HTCJANCNFSM4J25GCIA\n  > >.\n  > >\n  >\n  > \u2014\n  > You are receiving this because you were mentioned.\n  > Reply to this email directly, view it on GitHub\n  >\n <#4?email_source=notifications&email_token=AB6ESPIXRLGF4TSO32Z542TQ4IJOJA5CNFSM4J25GCIKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEID3MKQ#issuecomment-570930730>,\n  > or unsubscribe\n  >\n <https://github.com/notifications/unsubscribe-auth/AB6ESPMT7OMOU33PISZVEA3Q4IJOJANCNFSM4J25GCIA>\n  > .\n  >\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#4?email_source=notifications&email_token=AAAFAWC5O6NOOW5BCLBZUFLQ4IK43A5CNFSM4J25GCIKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEID3T4I#issuecomment-570931697>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWDBOD4EJHKATAA3TB3Q4IK43ANCNFSM4J25GCIA>."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-07 16:22:06+00:00",
                    "text": "A question for @milancurcic and @certik: Should we host FORD API documentation with github pages? If so then I suggest we pick one of the following approaches for hosting and then deploy the documentation during CI.\nApproach 1\nPublish API documentation as part of this repository using an orphan gh-pages branch. This would replace the readme at http://fortran-lang.org with the FORD documentation, but the landing page could include the readme.\nApproach 2\nCreate a new github repo to host the FORD API documentation and tweak the DNS settings for fortran-lang.org to point something like api-docs.fortran-lang.org to the documentation published in the other repository. I'd be happy to lead administering that documentation repo and help to setup a GitHub action to publish with FORD."
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 16:28:29+00:00",
                    "text": "I would do the second approach and use a url docs.fortran-lang.org. That way we can keep the landing page separate from the documentation. If you could set it up, that would be awesome."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-07 16:43:24+00:00",
                    "text": "I think approach 2 is better if we're considering landing page for fortran-lang to be its own thing eventually (separate from stdlib). I think we should as the fortran-lang website should encompass more than just stdlib -- eventually fpm, getting started, resources etc.\nAs for the stdlib landing page, it makes sense to me that it goes together with the documentation. For example, FORD docs for wavy include the README as the landing page: https://wavebitscientific.github.io/wavy/\nIf we make the Org (fortran-lang) GH page to be fortran-lang.org, then the GH page for stdlib will automatically become fortran-lang.org/stdlib, which I think is the most meaningful and intuitive url. docs.fortran-lang.org would make sense at the time being, but would be confusing when fortran-lang.org transcends stdlib."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-07 16:48:53+00:00",
                    "text": "Sorry, on re-reading Zaak's question and my response, I'd like to take that back.\nIf we agree that stdlib landing page + docs make sense as one website (I think they do, see the wavy example; FORD just tacks on documentation pages and styles it, but you still need a meaningful landing page for the docs), then I would do FORD docs as a GH site in the existing repo (stdlib), just as the current website is. So this is approach 1.\nWhen we need other websites, they can go in their own repos:\n\nfortran-lang home page as Org-level GH website;\nfpm website and docs in the fpm repo;\nand so on"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-07 17:05:36+00:00",
                    "text": "Publish API documentation as part of this repository using an orphan gh-pages branch\n\nAlternative (and my preference) to gh-pages branch is to have a docs/ directory in master."
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 17:13:26+00:00",
                    "text": "I would not put any auto generated files (such as FORD docs) into the stdlib repository, otherwise everybody has to clone it all the time, increasing the download traffic and download time. I would definitely not put it into the docs/ directory into the master branch, but I would not even put it into the gh-pages branch (because it still gets cloned, and forked, etc.). Instead, let the stdlib repository CI generate the docs, and push them to a separate repository. That separate repository will then get hosted at some url online (we can discuss where)."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-07 17:43:21+00:00",
                    "text": "I haven't considered size. wavy docs/ is 21M, which is quite heavy, and stdlib will be bigger than this. I think it's important that stdlib repo is small and lean on disk. I think it's okay to use a separate repo, even if less elegant approach."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-07 18:13:02+00:00",
                    "text": "OK, I think the 3 of us are in agreement that we'll put the FORD API docs into a separate repository. If this is true, what should we call the repository (on github, separate from what the URL is)? If we create an org page later, then I think something like fortran-lang/stdlib-docs, fortran-lang/stdlib-API-docs or similar would be the best bet because it will be accessible at fortran-lang.org/stdlib-docs. For the near-term a dns entry like api.fortran-lang.org or stdlib-docs.fortran-lang.org etc. would be a good place to start.\nFYI I don't have sufficient org permissions to create a repo under the fortran-lang organization. So if we can pick a good name and then someone create it that would be great. Having owner or admin perms on the documentation repo might be needed/helpful, but I can try to do what I can with push only access and see if I run into any issues. I'd also be happy to help out with DNS provider stuff etc etc but figuring out credentials and permissions/roles can be tricky so I'll defer to you guys."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-07 18:27:18+00:00",
                    "text": "Okay, I thought Org members can create new repos but maybe not. Ondrej or I can create a repo and set adequate permissions at the repo level.\nFor the repo name, I prefer stdlib-docs over stdlib-API-docs (redundant).\nWe can worry about subdomains and DNS stuff later. I own the domain so I can manage that end."
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 18:34:03+00:00",
                    "text": "Let's go with stdlib-docs. We can always rename it I think. If you agree, I'll create it and set the permissions so that @zbeekman can take it from there."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-07 19:17:47+00:00",
                    "text": "Perfect, let's do it."
                },
                {
                    "user": "certik",
                    "date": "2020-01-07 19:23:13+00:00",
                    "text": "Here you go, and @zbeekman is the admin for it:\nhttps://github.com/fortran-lang/stdlib-docs\nso you should be able to take it from here."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-08 01:27:18+00:00",
                    "text": "I've had great success with Ford. Markdown makes it super easy to include code snippets to help a user.\nI might have missed this being stated somewhere, but is there a strict requirement for documentation of all functions and subroutines. If not I think that should be added to the style guide? or somewhere else. Having documentation debt is worse than having to use MPI in R.\nOnce the tool is decided on, a set of example style guides for functions, subs, interfaces, derived types, modules and submodules would be nice to follow.  (I can help with this if needed)\nFinally, having docs for the arguments of functions is nice, but having usability code snippets really helps too. Something like this which produces these docs using Ford. This is also an example of when to ignore the dependency diagram :P"
                },
                {
                    "user": "zbeekman",
                    "date": "2020-01-08 01:50:18+00:00",
                    "text": "Once the tool is decided on, a set of example style guides for functions, subs, interfaces, derived types, modules and submodules would be nice to follow. (I can help with this if needed)\n\nThis would be great. As a place to start collecting this, we could create a page (or pages) on the wiki while we get automated documentation bootstrapped and deployed. Then, since it's markdown, we can migrate it to FORD. I think FORD also has a warning flag to catch un-documented entities that we could integrate into the CI process to try to ensure properly documented code.\n\nFinally, having docs for the arguments of functions is nice, but having usability code snippets really helps too.\n\nI agree. I just helped a colleague figure out how to grab items from an array of json objects with JSON Fortran. There is great API documentation in that great project (I may be biased here...) but there are not as many examples as there could be. Or at least easy to find examples."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-03-30 18:22:12+00:00",
                    "text": "Found this issue back. Is it any agreements on this topic?"
                },
                {
                    "user": "certik",
                    "date": "2020-03-30 21:14:32+00:00",
                    "text": "@zbeekman do you still plan to get it setup https://github.com/fortran-lang/stdlib-docs? If you got busy, let us know, there is no problem. I am just asking so that we do not duplicate your work.\n@jvdp1 I think we all agree we need documentation. And regarding the details, who ever is pushing this should simply choose something, get started, and then if something better comes along, we can switch. It seems FORD is the only documentation tool currently that allows to extract comments, so it might be the only option, unless we want to implement something from scratch, which I would recommend not to do initially."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-03-30 22:21:00+00:00",
                    "text": "Yes, I got busy, but just migrated documentation deployment for a work\nproject to a de GitHub actions and should be able to take a crack at this\ntonight or later this week.\n\u2026\nOn Mon, Mar 30, 2020 at 5:14 PM Ond\u0159ej \u010cert\u00edk ***@***.***> wrote:\n @zbeekman <https://github.com/zbeekman> do you still plan to get it setup\n https://github.com/fortran-lang/stdlib-docs? If you got busy, let us\n know, there is no problem. I am just asking so that we do not duplicate\n your work.\n\n @jvdp1 <https://github.com/jvdp1> I think we all agree we need\n documentation. And regarding the details, who ever is pushing this should\n simply choose something, get started, and then if something better comes\n along, we can switch. It seems FORD is the only documentation tool\n currently that allows to extract comments, so it might be the only option,\n unless we want to implement something from scratch, which I would recommend\n not to do initially.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#4 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AACEIPGVVNN62SFZPTSUKB3RKEDUPANCNFSM4J25GCIA>\n ."
                },
                {
                    "user": "certik",
                    "date": "2020-03-30 22:45:14+00:00",
                    "text": "@zbeekman that would be awesome! We'll wait."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-04-19 19:32:44+00:00",
                    "text": "@zbeekman Let us know if you need any help with this."
                },
                {
                    "user": "zbeekman",
                    "date": "2020-05-18 21:36:53+00:00",
                    "text": "Should this be closed now that #183 is merged, or should we keep it open?"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-05-18 21:49:30+00:00",
                    "text": "We're far from done. This should stay open."
                }
            ]
        },
        {
            "number": 3,
            "user": "milancurcic",
            "date": "2019-12-14 23:23:55+00:00",
            "title": "Style guide",
            "text": "Use this issue to discuss the code style for the stdlib.\nThe most widely supported elements of style will eventually be merged into the Style Guide for contributors.",
            "comments": [
                {
                    "user": "certik",
                    "date": "2019-12-16 23:46:59+00:00",
                    "text": "@ivan-pi wrote in #11 (comment):\nFor example for the function that checks whether a character is a letter some of the possible names are:\n\nis_alpha\nisalpha (C/C++)\nisAlpha (D language, but in Fortran it's the same as the previous suggestion)\n\n\nI have discussed this particular issue with several people many years ago and we eventually converged towards the following compromise:\nhttps://www.fortran90.org/src/best-practices.html#naming-convention\nSo in the above case, isAlpha would not be used, but both is_alpha and isalpha would be allowed, and in this case isalpha would be preferred (only two syllables). If the name was is_char_alpha vs ischaralpha, then the underscore version would be preferred because it is three syllables. However, if the API had lots of methods like is_alpha, is_char_alpha, is_not_alpha, then for consistency it should be named is_* with underscore.\nLet me know what you think.\nP.S. Some examples from current Fortran. No underscore: matmul, maxloc, minloc, iachar, adjustl, adjustr, maxexponent, minexponent, rrspacing, ishftc. Underscore: set_exponent, dot_product, bit_size, cpu_time. The standard is not consistent (e.g., maxexponent vs set_exponent) but it seems to be very close to the rule of 2 syllables -> no underscore, otherwise use underscore (e.g. matmul vs dot_product)."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-17 00:18:43+00:00",
                    "text": "isalpha contains three syllables.\nIn general I agree with your suggested naming conventions and also the ones in Fortran Best Practices. To stay close to the standard, I think it's best if we avoid CamelCase.\nSpecifically, for the ascii functions there are 11 functions starting with is, some are short (is_alpha), but some are long (is_hex_digit, is_octal_digit). I suppose it's easiest to just follow the C library and get rid of the underscores and shorten the names to 7-8 characters (isalpha, iszdigit - z is used in hexadecimal boz constants, isodigit - o is used in octal boz constants)."
                },
                {
                    "user": "certik",
                    "date": "2019-12-17 00:26:57+00:00",
                    "text": "You are right, isalpha is 3 syllables.\n\nI think the rules can be broken where it makes sense and we have a good reason. Otherwise if we have no reason then the rules provide a good consistent default.\n\u2026\nOn Mon, Dec 16, 2019, at 5:18 PM, Ivan wrote:\n `isalpha` contains three syllables.\n\n In general I agree with your suggested naming conventions and also the\n ones in Fortran Best Practices\n <https://github.com/Fortran-FOSS-Programmers/Best_Practices>. To stay\n close to the standard, I think it's best if we avoid CamelCase.\n\n Specifically, for the ascii functions there are 11 functions starting\n with `is`, some are short (`is_alpha`), but some are long\n (`is_hex_digit`, `is_octal_digit`). I suppose it's easiest to just\n follow the C library <https://en.cppreference.com/w/c/string/byte> and\n get rid of the underscores and shorten the names to 7-8 characters\n (`isalpha`, `iszdigit` - z is used in hexadecimal boz constants,\n `isodigit` - o is used in octal boz constants).\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#3?email_source=notifications&email_token=AAAFAWE3XEAVNGIXF5BNKJLQZALGHA5CNFSM4J25FZ62YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHAT2DY#issuecomment-566312207>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWCAIOCRTWMOKJEVFX3QZALGHANCNFSM4J25FZ6Q>."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-17 03:16:16+00:00",
                    "text": "I'm on the same page here. I like all lowercase with underscores universally. For short variable and procedure names, dropping the underscore is OK I think. It's nice to have a universal rule to follow (always use underscores to separate words), but for some short names I think it's OK to make an exception.\nI don't think the Standard being inconsistent (maxexponent and set_exponent) should be an excuse for us to be \"consistently inconsistent\". There's also a difference between names that are made of whole words (e.g. dot_product is nicer than dotproduct), vs. portmanteaus like matmul (instead of mat_mul which seems awkward).\nIn this specific case, even though iszdigit and isodigit are short and nice, there's a risk of them being less clear what they mean. To my eye, is_hex_digit and is_octal_digit were obvious. For iszdigit and isodigit, I had to read Ivan's explanation to understand. So I slightly prefer the underscore variants here, but I'm not hell-bent on it."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-17 15:58:38+00:00",
                    "text": "Yes, I generally agree but for assertion-y stuff I think separating the verb with an underscore makes sense is_alpha. The legibility is much improved and client code can always consume it as a different name through use association.\nuse fortran_stdlib, only: is_alpha => isalpha"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-17 16:25:11+00:00",
                    "text": "Automation of pedantry\nI think that we should also adopt solutions like Editorconfig, possibly findent cmake-format (if we use CMake) and clang-format (for any C code).  Tools like these that integrate with IDEs and editors will help get everyone on the same page allowing them to focus on semantics and code rather than style and formatting. In addition, I've really been appreciating and enjoying pre-commit to codify conventions on a per-project basis, and help catch silly issues before developers even commit/push code."
                },
                {
                    "user": "certik",
                    "date": "2019-12-17 17:18:50+00:00",
                    "text": "Yes, I agree with @zbeekman we should try to automate as much as possible (formatting, release notes, etc.).\nAnd rather use our time and effort to discuss the actual API, not how it is formatted.\nI agree that is_alpha looks better in this case. I would caution against recommending use fortran_stdlib, only: is_alpha => isalpha, because that is a pain to have to do that --- rather, let's do our best to choose the name well, and recommend people to use it. That way all the codes will use the same name and it will be easy for people reading the code to understand."
                },
                {
                    "user": "smwesten-usgs",
                    "date": "2019-12-17 18:07:56+00:00",
                    "text": "In this specific case, even though iszdigit and isodigit are short and nice, there's a risk of them being less clear what they mean. To my eye, is_hex_digit and is_octal_digit were obvious. For iszdigit and isodigit, I had to read Ivan's explanation to understand. So I slightly prefer the underscore variants here, but I'm not hell-bent on it.\n\nShould I get a vote, I also prefer more verbose but hopefully clearer names, and prefer lowercase and underscores universally:\nis_hex_digit > iszdigit\nis_octal_digit > isodigit\nRegarding names of string functions/subroutines, I'd definitely prefer more verbose and explicit over the short and cryptic. Thus:\nas_integer > atoi\nas_double > atof"
                },
                {
                    "user": "certik",
                    "date": "2019-12-17 18:13:15+00:00",
                    "text": "@smwesten-usgs thanks for the feedback. Yes, I agree on the examples you gave that underscores look better.\nHere are some examples where no underscores I think look better (from NumPy and Matlab):\n\nlinspace vs lin_space\nmeshgrid vs mesh_grid\nargsort vs arg_sort"
                },
                {
                    "user": "longb",
                    "date": "2019-12-17 21:53:00+00:00",
                    "text": "Just speculation, but I suspect the difference between the underscore usage between  maxexponent and set_exponent is that max is already the name of a different intrinsic function."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-17 23:02:02+00:00",
                    "text": "I agree, and for the record, I wasn't suggesting we pick whatever and let people rename through use association; Good names from the get-go are important."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:27:29+00:00",
                    "text": "Can we make some choices about indentation and tabs vs spaces? My preference is indent all indent-able things by two spaces; never use tabs. We can codify this in an editor-config file."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 17:38:27+00:00",
                    "text": "My preference is 4 spaces, no tabs."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 17:45:37+00:00",
                    "text": "A quick note: I'm happy with 2 or 4 but with the 132 character line limit, you can start to run out of real estate pretty quickly with 4 spaces."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 18:11:16+00:00",
                    "text": "I also propose to stick to 80 characters per line.\n\nMore importantly though we should figure out automatic formatting checks at the CI and provide instructions how developers can format the code before submitting a PR.\n\u2026\nOn Sun, Dec 22, 2019, at 10:45 AM, zbeekman wrote:\n A quick note: I'm happy with 2 or 4 but with the 132 character line\n limit, you can start to run out of real estate pretty quickly with 4\n spaces.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#3?email_source=notifications&email_token=AAAFAWCALED2B7ENIAUQTPLQZ6RUFA5CNFSM4J25FZ62YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHPV5RY#issuecomment-568286919>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWDCAOJSSZM3QLGLKE3QZ6RUFANCNFSM4J25FZ6Q>."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 20:18:14+00:00",
                    "text": "80 characters per line and 4 spaces?! That seems like there will be an awful lot of line continuations and leading blanks... findent defaults to 2 spaces. The standard caps line length at 132 chars. I think we should shorten the line length allowed XOR pick 4 spaces of indentation, but I'd be weary to use both at once."
                },
                {
                    "user": "certik",
                    "date": "2019-12-22 20:38:49+00:00",
                    "text": "Yes, I've been using 80 characters and 4 spaces in all my projects.\nBut whatever we decide is fine with me. Here are my priorities for stdlib:\n\n\nThe Fortran sources themselves: simple, well organized modules, super well designed API, building with \"any\" compiler on \"any\" platform, with no warnings, and excellent performance in Release mode.\n\n\nA build system that works on all platforms (including Windows) and is \"simple\"\n\n\nGood tests\n\n\nGood CI infrastructure that supports the above\n\n\nHow we format the files are low on my priorities list, so whatever makes us work together works for me."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-22 21:37:31+00:00",
                    "text": "I generally use 4 spaces (same as Python and most C++ codes I've seen), but I also don't mind if we agree to use 2 and I agree with the points of @certik. Generally, I try to stick to an 80 character limit, but I am happy to break the rule if it makes the indentation nicer."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 21:52:46+00:00",
                    "text": "OK, let's go with 4 then, and we could admonish users to be within 80 characters (or 100, or whatever) but enforce a hard limit of 132 during CI. I'm working on getting a style document updated with comments from here and an .editorconfig file as well as CI testing and enforcement."
                },
                {
                    "user": "longb",
                    "date": "2019-12-22 21:55:52+00:00",
                    "text": "I generally use whatever the number of spaces created by emacs when I hit \"tab\".  Note that the line length limit will probably get really long (10,000 characters) in the next standard, so debates over 80 versus 132 are a bit dated.  Personally I prefer to be able to read a line of code in a terminal window without horizontal scrolling.  But I think that most \"style guides\" include a lot of unnecessary \"nanny\" rules that don't matter that much.  I think a rule like \"a sequence of lines that form a block in Fortran should be indented compared to the code lines that delineate the block\" is sufficient.  Much more relevant (in my view) would be code style rules such as \"do not use include lines\", or \"never use preprocessing directives\", or \"never use tools like configure, cmake, or spack\" would be more useful and relevant to Fortran."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 22:01:59+00:00",
                    "text": "@longb haha \"never use tools like ... cmake\"\nSometimes there are necessary evils.\nI agree about reading things in the terminal. Thats the spirit of creating a limit.\nConcerning emacs, it's easy to setup to respect .editorconfig.\nHere is what I have in my .emacs (I use use-package)\n(use-package editorconfig\n  :ensure t\n  :after ws-butler\n  :init\n  (setq editorconfig-trim-whitespaces-mode\n         'ws-butler-mode)\n  :config\n  (editorconfig-mode 1)\n  ;; Always use tabs for Makefiles\n  (add-hook 'editorconfig-hack-properties-functions\n\t    '(lambda (props)\n\t       (when (derived-mode-p 'makefile-mode)\n\t\t (puthash 'indent_style \"tab\" props)))))"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-22 22:09:43+00:00",
                    "text": "I've started trying to capture this discussion in PR #42"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-22 23:01:02+00:00",
                    "text": "I prefer 2 spaces to indent, and try (but sometimes fail) to stay within 80-character line length. This is not for compatibility reasons, but for the same reason as Python recommendation -- I work in terminals of similar width and don't like the lines to wrap around.\nI think consistency is more important than any specific style \"rule\". I also don't think we need style enforcement (just yet). A brief style guide with recommendations and common sense go a long way."
                },
                {
                    "user": "longb",
                    "date": "2019-12-23 23:39:26+00:00",
                    "text": "Some style suggestions that are probably obvious, but seem to be violated in some user code:\n\nDo not use language features that have been deleted (PAUSE, Arithmetic IF, ...).\nAvoid using language features that are obsolescent (such as COMMON).\nAvoid vendor syntax extensions (such as REAL*8), especially when there are standard alternatives.\nAvoid vendor-specific, nonstandard intrinsic procedures (such as ETIME).\n\nViolating these leads to portability problems."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-24 17:03:29+00:00",
                    "text": "Do not use language features that have been deleted (PAUSE, Arithmetic IF, ...).\nAvoid using language features that are obsolescent (such as COMMON).\nAvoid vendor syntax extensions (such as REAL*8), especially when there are standard alternatives.\nAvoid vendor-specific, nonstandard intrinsic procedures (such as ETIME).\n\n\nI agree. We can express these in the style guide as simply as:\n\nUse only standard features and intrinsic procedures that have not been deleted or maked obsolescent."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-24 18:26:38+00:00",
                    "text": "@certik I'm looking at some merged code and I now understand why you're okay with 4 spaces to indent and 80 character line limit: You don't indent module, program, and procedure bodies. I think we should.\nI like 2 space-indents but can work with 4 spaces as well. But I think we should indent all program unit bodies consistently. The recommendation can then be applied to indenting bodies of all Fortran constructs:\n\nUse 4 spaces to indent the body of any Fortran construct"
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 19:15:12+00:00",
                    "text": "Yes, indeed, I don't indent subroutines. The reason for that is that if you do, then every single subroutine is indented by 4 spaces. That's unfortunate, as that is lost space. Just like in C++, if you use namespaces, you do not indent the functions inside namespaces for the same reason. The indentation does not buy you anything. You know that every subroutine is inside a module. And module is like a C++ namespace with this respect.\nInside the functions bodies, I also don't indent (I don't think it buys you any readability and you lose horizontal space), but if you feel strongly about it, then we can.\nDoing 2 spaces for subroutines and 4 spaces for everything else is pretty complicated --- I would need to figure out how to setup my Vim editor to support that. Doing 4 spaces everywhere then risks of running out of the 80 character limit more often, precisely as @zbeekman was worried.\nBut since we relaxed the 80 char limit rule, I think it's fine to use 4 spaces everywhere.\nOverall, this is relatively low priority for me, so I am happy to do whatever you feel strongly about. Let's setup tools to do the formatting automatically though --- that I feel strongly about. :)"
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-24 19:24:46+00:00",
                    "text": "I like indenting everything, but it'd be a stretch to say I feel strongly about it. It does help readability for me, but only because my eyes are attuned to it.\nLet's hear from others and hopefully the decision will be easy.\n@marshallward @jacobwilliams @zbeekman @ivan-pi @jvdp1 @longb @smwesten-usgs Where are you on indenting bodies of program units?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-24 19:42:44+00:00",
                    "text": "What we can do is to choose something reasonable (anything we discussed above is reasonable for me) and setup automatic formatting. Then as we have more code, we can compare different formatting options side by side and we can change the default formatting by changing some configuration option in the formatting tool if we like one option better as a community."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-24 22:04:45+00:00",
                    "text": "MOM6 does two-space indents. \u00a0My personal preference is 4 spaces since 2-space indent \"errors\" are harder to detect visually and can slip in more easily. \u00a0But I haven't noticed much of an issue using 2-space in MOM6.\nWe do not indent a module's contents, as long as we stick to one module per file. \u00a0In this interpretation, the model statement/ending, the contains, etc are more like declarations than indications of scope. \u00a0But these rules might not make sense if there were multiple modules per file.\nOtherwise, I'd say everything that moves into a more narrow scope is indented: subroutine contents, type definitions, control blocks, etc.\nI wouldn't want to deal with mixed rules, I'd say either 2 or 4 spaces for everything.\nI am personally militant about 80-character limits, since I usually resize my fonts to fit about ~190 characters, or ~85 on two parallel terminals.  MOM6 \"encourages\" 100, with a hard limit on 120.  This works well overall (for everyone except me and my font sizes, that is!)\nFor all the various edge cases, like how to split binary operators, I tend to follow PEP8.  But that mostly reflects my undying love for Python.\nAs an acquaintance of mine says: \"If your code only looks good under a particular style, then I probably won't like reading your code anyway\". \u00a0As long as things can be broken\u00a0up into modular pieces, then it ought to look good under 2-, 4- or even 8-space indents.\nPS if anyone wants to see the (incomplete) MOM6 style guide.\n(And for the record I do not necessary agree with all of these rules!)"
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-24 22:08:05+00:00",
                    "text": "Where are you on indenting bodies of program units?\n\nI use 1-space for indenting subroutines/functions, but also interfaces, derived types,...\nI am fine with 2-space indents, and 80 (soft)-/132(hard)-character limits. 4-space indents seems a bit too much to me, but it would not be a problem neither."
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-25 15:58:43+00:00",
                    "text": "Where are you on indenting bodies of program units?\n\nI tend to indent everything (besides for contain statements which stay parallel to the enclosing module/type).\nSince we plan to have a single file per module I can agree with @certik and @marshallward that indentation at module level would save some horizontal space. However I would prefer to indent subroutine/function bodies (like in Python). I think it helps to visually separate the functions/subroutines bodies from each other without the need for comment lines such as\n!-------------------------------------------\n\nwhich I find are just a nuisance to create and maintain."
                },
                {
                    "user": "gronki",
                    "date": "2019-12-27 16:54:28+00:00",
                    "text": "If I can have an annoying remark, I don't feel about indentations as\nstrongly as I do about using spaces. For example,\n\nif(s%value==3)error stop\n\nIs nightmare to read compared to\n\nif (s % value == 3) error stop\n\nAnd since someone will likely disagree with this too, I would like suggest\nthat people will be always unhappy with how things are indented and spaced\nout. Even here everyone has expressed a different opinion. I personally\nwould only require sane indentation and not using tabs.\n\n\u015br., 25 gru 2019, 16:58 u\u017cytkownik Ivan <notifications@github.com> napisa\u0142:\n\u2026\n Where are you on indenting bodies of program units?\n\n I tend to indent everything (besides for contain statements which stay\n parallel to the enclosing module/type).\n\n Since we plan to have a single file per module I can agree ***@***.***\n and @marshallward <https://github.com/marshallward> that indentation at\n module level would save some horizontal space. However I would prefer to\n indent subroutine/function bodies (like in Python). I think it helps to\n visually separate the functions/subroutines bodies from each other without\n the need for comment lines such as\n\n !-------------------------------------------\n\n which I find are just a nuisance to create and maintain.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <#3?email_source=notifications&email_token=AC4NA3I6PPIGWTRVTVICHGTQ2N7LLA5CNFSM4J25FZ62YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHUOLAI#issuecomment-568911233>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AC4NA3KC3D2X74KZ26SJBALQ2N7LLANCNFSM4J25FZ6Q>\n ."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-29 22:12:17+00:00",
                    "text": "Distilling the above comments down, and adding my own opinion it appears that:\n\nMost people want procedure bodies indented (I do too)\nMost people are OK with a \"shoot for 80 chars, but hard limit of 132\" line length\nWith only one program or module per file, indenting these scopes does eat up blank space. With an indentation level of 4 this seems to be a bigger issue. While I agree that it isn't really necessary to indent these scopes if we adopt the convention of 1-per-file, from a tooling/enforcement perspective most tools, editors, etc. that I've seen want to indent these scopes by default.\n\nTakin points 1-3 into consideration, as well as the comments expressed thus far, I would be inclined to indent two (2) spaces for all procedures and module and program scopes too. I'll go ahead and implement this in the EditorConfig file and style guide I've started in #42.\nI would also recommend that we take this discussion over to the PR (#42) and that people make suggestions of how and where they would like to see the ideas discussed in this issue expressed. I've started working on a style guide document, and if you have expressed an opinion in this issue, you should look at #42 to ensure that the document is acceptable and that your opinion or suggestion has been sufficiently addressed."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-25 18:52:51+00:00",
                    "text": "For all documentation I try to always include a complete working example program. I always call\nit \"program demo_NNNNN\" where NNNN is the name of the routine being tested, so it is easy\nto automate extracting and running the sample code, and to extract the code into a directory of\nsmall programs for use by users of the procedure.  This lets the developer easily test code supplied\nin the documentation, and prevents simple syntax errors and problems like I found in the\ndocumentation for the experimental open(3f) routine:\nprogram test\n    use stdlib_experimental_stats, only: mean\n    implicit none\n    integer :: io, u\n    u = open('example.dat', 'rt', iostat = io)\nend program\nSo as to facilitate something like that in the long term, this should start with \"program demo_open\" and end with \"end program demo_open\".   If all the steps were implemented the typo in the above\nwould be automatically caught. In the mean time when writing documentation you could use\nsomething like\nman -s $SECTION $TOPIC|\ncol -b|\nexpand|\nsed -n -e '%^[ !]*program  *demo_%,%^[ !]*end  *program  *demo_%{p}' >$FILE\nwhich is a line extracted from an automatic tester of syntax and/or whether a demo routine can be compiled and loaded in manpages.  If would be easy to change this to handle multiple demos in a single markdown file in the long term.\nPS: In the sample program in the document it is OPEN(3f) that should be added to the local scope, not the MEAN(3f) function in stdlib_experimental_io.md."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-25 19:20:47+00:00",
                    "text": "@urbanjost Thank you for spotting the errors and for the suggestions.\nI support this idea of an automati tester. Maybe the automatic tester could be also added to CMake and the CI? @certik would it be possible for the CI?\nI also think it would be good to add a template of a spec. The spec for open was a first attempt. and suggestions as @urbanjost ones can be useful."
                },
                {
                    "user": "certik",
                    "date": "2020-01-25 21:00:57+00:00",
                    "text": "Yes, I would recommend to run documentation tests. We can call them doctests, just like in Python.\nLFortran could eventually be used to run those naturally. Until then, I suggest we append end and compile + run manually using gfortran."
                },
                {
                    "user": "fiolj",
                    "date": "2020-01-28 14:42:22+00:00",
                    "text": "In order to have a consistent code style, could we advice to use a formatting tool with the specified standard?\nFor instance, currently I am using fprettify (https://github.com/pseewald/fprettify) with some options (in my case fprettify -w 3 -i 2) wich gives two spaces indentation, but any tool would be useful."
                },
                {
                    "user": "certik",
                    "date": "2020-01-28 16:15:23+00:00",
                    "text": "Yes, the plan is to use a tool and enforce it by the CI. @zbeekman do you still plan to do work on that?"
                },
                {
                    "user": "aradi",
                    "date": "2020-01-29 09:28:30+00:00",
                    "text": "Line length should be chosen IMHO by considering, what is the longest line length you can easily still scan with your eyes. I made good experience with 80 and 100 (preferred) chars per line. For me, everything beyond 100 is hard to read.\nFor the indentation: I think, it is most consistent to require, that whenever you open a scope / block construct, you increase indentation. That means, all subroutines within the module-construct would be indented. I think, most editors handle that this way anyway, so that would be easiest for the contributors.\nFinally, 2 or 4 chars for indentation. If we are really going to use a preprocessor for generating specifics from a template, the according constructs should be also indented to enhance the readability of the generic code (the one most programmers would have to deal with):\n#:include \"common.fypp\"\n#:set RANKS = range(1, MAXRANK + 1)\n\nsubmodule (stdlib_experimental_stats) stdlib_experimental_stats_mean\n  use stdlib_experimental_error, only: error_stop\n  implicit none\n\ncontains\n\n  #:for k1, t1 in REAL_KINDS_TYPES\n    #:for rank in RANKS\n      module function mean_${rank}$_all_${k1}$_${k1}$(x) result(res)\n        ${t1}$, intent(in) :: x${ranksuffix(rank)}$\n        ${t1}$ :: res\n\n        res = sum(x) / real(size(x, kind = int64), ${k1}$)\n\n      end function mean_${rank}$_all_${k1}$_${k1}$\n    #:endfor\n  #:endfor\n\n [...]\n\nend submodule\n\nversus\n#:include \"common.fypp\"\n#:set RANKS = range(1, MAXRANK + 1)\n\n\nsubmodule (stdlib_experimental_stats) stdlib_experimental_stats_mean\n    use stdlib_experimental_error, only: error_stop\n    implicit none\n\ncontains\n\n    #:for k1, t1 in REAL_KINDS_TYPES\n        #:for rank in RANKS\n            module function mean_${rank}$_all_${k1}$_${k1}$(x) result(res)\n                ${t1}$, intent(in) :: x${ranksuffix(rank)}$\n                ${t1}$ :: res\n\n                res = sum(x) / real(size(x, kind = int64), ${k1}$)\n\n            end function mean_${rank}$_all_${k1}$_${k1}$\n        #:endfor\n    #:endfor\n\n [...]\n\nend submodule\n\nSo, my 2 cents would be:\n\nIndentation by 2 chars, consistently whenever a block construct is opened.\nMax. line length: 100 chars."
                },
                {
                    "user": "certik",
                    "date": "2020-01-29 16:37:28+00:00",
                    "text": "I think @zbeekman is busy.\n@fiolj or @aradi would you be willing to setup automatic enforcing of the formatting at our CI? That would be super helpful."
                },
                {
                    "user": "longb",
                    "date": "2020-01-29 20:52:15+00:00",
                    "text": "I find the proposed 2 space indentation and 100 character line limit very reasonable.\n\nThe foreign preprocessing notation in the example is horrifying.  There is a template proposal before WG5 that would make this sort of awkwardness unnecessary.   In general, a coding style document for Fortran should include a hard prohibition on any sort of preprocessing.\n\nCheers,\nBill\n On Jan 29, 2020, at 3:28 AM, B\u00e1lint Aradi ***@***.***> wrote:\n\n Line length should be chosen IMHO by considering, what is the longest line length you can easily still scan with your eyes. I made good experience with 80 and 100 (preferred) chars per line. For me, everything beyond 100 is hard to read.\n\n For the indentation: I think, it is most consistent to require, that whenever you open a scope / block construct, you increase indentation. That means, all subroutines within the module-construct would be indented. I think, most editors handle that this way anyway, so that would be easiest for the contributors.\n\n Finally, 2 or 4 chars for indentation. If we are really going to use a preprocessor for generating specifics from a template, the according constructs should be also indented to enhance the readability of the generic code (the one most programmers would have to deal with):\n\n #:include \"common.fypp\"\n #:set RANKS = range(1, MAXRANK + 1)\n\n submodule (stdlib_experimental_stats) stdlib_experimental_stats_mean\n   use stdlib_experimental_error, only: error_stop\n   implicit none\n\n contains\n\n   #:for k1, t1 in REAL_KINDS_TYPES\n     #:for rank in RANKS\n       module function mean_${rank}$_all_${k1}$_${k1}$(x) result(res)\n         ${t1}$, intent(in) :: x${ranksuffix(rank)}$\n         ${t1}$ :: res\n\n         res = sum(x) / real(size(x, kind = int64), ${k1}$)\n\n       end function mean_${rank}$_all_${k1}$_${k1}$\n     #:endfor\n   #:endfor\n\n  [...]\n\n end submodule\n\n versus\n\n #:include \"common.fypp\"\n #:set RANKS = range(1, MAXRANK + 1)\n\n\n submodule (stdlib_experimental_stats) stdlib_experimental_stats_mean\n     use stdlib_experimental_error, only: error_stop\n     implicit none\n\n contains\n\n     #:for k1, t1 in REAL_KINDS_TYPES\n         #:for rank in RANKS\n             module function mean_${rank}$_all_${k1}$_${k1}$(x) result(res)\n                 ${t1}$, intent(in) :: x${ranksuffix(rank)}$\n                 ${t1}$ :: res\n\n                 res = sum(x) / real(size(x, kind = int64), ${k1}$)\n\n             end function mean_${rank}$_all_${k1}$_${k1}$\n         #:endfor\n     #:endfor\n\n  [...]\n\n end submodule\n\n So, my 2 cents would be:\n\n \t\u2022 Indentation by 2 chars, consistently whenever a block construct is opened.\n \t\u2022 Max. line length: 100 chars.\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n\nBill Long                                                                       longb@cray.com\nPrincipal Engineer, Fortran Technical Support &   voice:  651-605-9024\nBioinformatics Software Development                      fax:  651-605-9143\nCray, a Hewlett Packard Enterprise company/ 2131 Lindau Lane/  Suite 1000/  Bloomington, MN  55425"
                },
                {
                    "user": "certik",
                    "date": "2020-01-29 22:01:30+00:00",
                    "text": "@longb thanks for the feedback.\nIndeed, the pre-processing is not super readable. However, the other alternatives that we considered are even worse. We should strive to include enough features into Fortran so that this kind of pre-processing will become unnecessary, but that's for the long term."
                },
                {
                    "user": "fiolj",
                    "date": "2020-01-29 22:23:07+00:00",
                    "text": "@fiolj or @aradi would you be willing to setup automatic enforcing of the formatting at our CI? That would be super helpful.\n\nI never used nor modified any CI in my projects, and do not know how to work with EditorConfig yet, so if somebody else take this task would be better. Otherwise, I'll start learning..."
                },
                {
                    "user": "aradi",
                    "date": "2020-01-30 07:54:39+00:00",
                    "text": "The foreign preprocessing notation in the example is horrifying. There is a template proposal before WG5 that would make this sort of awkwardness unnecessary. In general, a coding style document for Fortran should include a hard prohibition on any sort of preprocessing.\n\n@longb I absolutely agree, pre-processing is evil! But it is IMHO even more evil, that we are forced to use pre-processing due to the lack of an appropriate feature in the language.\nWould you mind to take a look, as an example, on the implementation of the mean() function in this library, which allows the reduction of the rank of an arbitrary multi-dimensional array by one. Do you see any better solution without pre-processing which avoids duplicating basically the same code 100-times and which is available now (and not in 10-20 years)?"
                },
                {
                    "user": "aradi",
                    "date": "2020-01-30 08:15:37+00:00",
                    "text": "@certik I could try to have a look at it (although I am not experienced with the CI in GitHub), but not earlier than end of next week..."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-30 14:40:52+00:00",
                    "text": "For cases where the preprocessor is not being used for conditional selection of a programming environment but to expand a template or allow for single-file source with documentation and unit tests and so on the distribution should include the expanded source. Requiring a specific development environment to be available for someone to just build and use the code is very unattractive.  I keep virtually all my code in a preprocessor file format and use a very heavily customized and automated build environment but if I put something out for public consumption I put out standard *.f90 *.c ... files and an (automatically generated) makefile with some cpp(1) directives (if conditionals are absolutely necessary).  It's one thing to expect a developer to have to have fypp, cmake, doxygen, ... installed, but very disturbing that someone that wants to use the results is required to install a full development environment.  Ideally one should have an expanded directory in the distribution that you need nothing but a Fortran compiler to build from.\nOn another note,  since for the integer versions of mean(3f) everything is promoted to a REAL type\nyou could write a single routine with a CLASS(*) argument and a short select type instead of a template which might not be quite as efficient but would be much simpler to maintain. so there are alternatives in some cases to a template."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-30 15:45:00+00:00",
                    "text": "For cases where the preprocessor is not being used for conditional selection of a programming environment but to expand a template or allow for single-file source with documentation and unit tests and so on the distribution should include the expanded source. Requiring a specific development environment to be available for someone to just build and use the code is very unattractive. I keep virtually all my code in a preprocessor file format and use a very heavily customized and automated build environment but if I put something out for public consumption I put out standard *.f90 *.c ... files and an (automatically generated) makefile with some cpp(1) directives (if conditionals are absolutely necessary). It's one thing to expect a developer to have to have fypp, cmake, doxygen, ... installed, but very disturbing that someone that wants to use the results is required to install a full development environment. Ideally one should have an expanded directory in the distribution that you need nothing but a Fortran compiler to build from.\n\nIn addition to have the templated code on Github, it has already been suggested by @certik in #35 comment to provide release tarballs that contain all necessaty generated files to the users. I think it is the way to go (i.e., providing templated codes, and generated tarballs). We just need someone to implement it ;)\n\nOn another note, since for the integer versions of mean(3f) everything is promoted to a REAL type\nyou could write a single routine with a CLASS(*) argument and a short select type instead of a template which might not be quite as efficient but would be much simpler to maintain. so there are alternatives in some cases to a template\n\nI think it is easier to maintain if the mean function for integer is (almost) the same as the mean function for real. You only need to think about one structure, but it is maybe only my way of thinking."
                },
                {
                    "user": "aradi",
                    "date": "2020-01-30 15:51:33+00:00",
                    "text": "@urbanjost The plan is to \"ship\" the library with the preprocessed proper Fortran standard files. The repository, however, should contain the sources with the un-preprocessed files. Otherwise, you get crazy with diffs, if you have any changes in those routines. What we could consider is to add the preprocessor (1 single file) to the repository, so having Python (which is quite common) would be enough to build the library. (I have created #133 on this.)\nAs for class(*): It deserves maybe a separe issue as well. But what you do then, is making the code repetition on a lower lever (inside the subroutine instead of repeating the subroutine). But you still have to make a case for each possible data type there, and do something different (but almost identical) for each rank to be considered as well. So, currently I don't see a way to avoid code repetition, and if we have to repeat code ca. 50-times with minimal changes, I still prefer the ugly preprocessor-trick."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-30 16:18:00+00:00",
                    "text": "I find I have a number of routines where it is desirable or tolerable to always promote to doubleprecision.  An elemental routine that takes any scalar and returns a double is called. There are pros and cons but it is very useful in practice for me.  For example if you had something like\npure elemental function anyscalar_to_double(valuein) result(d_out)\nuse, intrinsic :: iso_fortran_env, only : error_unit !! ,input_unit,output_unit\nimplicit none\n!anyscalar_to_double(3f): convert integer or real parameter of any kind to doubleprecision\nclass(*),intent(in)       :: valuein\ndoubleprecision           :: d_out\ndoubleprecision,parameter :: big=huge(0.0d0)\n   select type(valuein)\n   type is (integer(kind=int8));   d_out=dble(valuein)\n   type is (integer(kind=int16));  d_out=dble(valuein)\n   type is (integer(kind=int32));  d_out=dble(valuein)\n   type is (integer(kind=int64));  d_out=dble(valuein)\n   type is (real(kind=real32));    d_out=dble(valuein)\n   type is (real(kind=real64));    d_out=dble(valuein)\n   type is (real(kind=real128))    d_out=dble(valuein)\n   class default\n     d_out=nan(d_out)\n     !!stop '*M_anything::anyscalar_to_double: unknown type'\n   end select\nend function anyscalar_to_double\nthen other routines have an argument of class() and call this routine to convert it to a double. I use\ntemplating only where for optimization reasons it is justified. For a public library where anyone might be using it for anything templating is fine in lieu of Fortran features that support something similiar; but class() can be used very effectively and makes the code very easy to maintain.\nNot a panacea but very useful for cases it is a fit for."
                },
                {
                    "user": "aradi",
                    "date": "2020-01-30 16:56:13+00:00",
                    "text": "@urbanjost  Thanks for the example! Your approach is quite elegant and much shorter than the preprocessed version, I agree!\nOne big disadvantage of any class(*) based solution is, however, that it prohibits extensions by the consumers of the library. Assuming a routine, like your anyscalar_to_double() function is part of the library. A consumer of the library would not be able to extend it to additional data types without changing a library itself. If we have routines with specific types hidden behind a generic interface instead, a consumer can add further routines with additional data types using that generic name in his code without having to touch the standard library itself."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-30 18:16:10+00:00",
                    "text": "Thanks @urbanjost for the class example. I like class and use it for some specific things.\nHowever, I would argue against it for the implementation of mean for mainly three reasons (in addition to @aradi 's one):\n\nusing class, we would still need different functions for the real arrays, because mean must return a result of the same type as the input for real arrays. It is only when integer arrays are provided to mean that dp results are returned. The current behaviour of mean is in agreement with the intrinsic sum function, and I believe it is a nice feature.\nI think we also need to focus a bit on efficiency inside stdlib; the user does not care about the readibility of the code or how things are implemented in the library. In this case of mean I would say we still must focus on efficiency.\nthe current implementation is probably more portable across compilers than class that may not be supported by all compilers (especially by the older compilers).\n\nFinally I think class could be useful for the subroutines loadtxt and savetxt where preprocessing is also used to repeat the code for different kinds."
                },
                {
                    "user": "longb",
                    "date": "2020-01-30 19:13:40+00:00",
                    "text": "Well, the main argument against implementing mean(x) this way is that the meat of the computation is\n\nsum(x)/real(size(x))\n\nwhich is AREADY rank and type independent because the involved intrinsics are already generic.  Generally, writing a trivial, one-line function is bad programming practice. Just write the line in the spot where the function is referenced.   A more sensible example might be helpful.\n\nCheers,\nBill\n On Jan 30, 2020, at 12:16 PM, Jeremie Vandenplas ***@***.***> wrote:\n\n Thanks @urbanjost for the class example. I like class and use it for some specific things.\n\n However, I would argue against it for the implementation of mean for mainly three reasons (in addition to @aradi 's one):\n\n \t\u2022 using class, we would still need different functions for the real arrays, because mean must return a result of the same type as the input for real arrays. It is only when integer arrays are provided to mean that dp results are returned. The current behaviour of mean is in agreement with the intrinsic sum function, and I believe it is a nice feature.\n \t\u2022 I think we also need to focus a bit on efficiency inside stdlib; the user does not care about the readibility of the code or how things are implemented in the library. In this case of mean I would say we still must focus on efficiency.\n \t\u2022 the current implementation is probably more portable across compilers than class that may not be supported by all compilers (especially by the older compilers).\n Finally I think class could be useful for the subroutines loadtxt and savetxt where preprocessing is also used to repeat the code for different kinds.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n\nBill Long                                                                       longb@cray.com\nPrincipal Engineer, Fortran Technical Support &   voice:  651-605-9024\nBioinformatics Software Development                      fax:  651-605-9143\nCray, a Hewlett Packard Enterprise company/ 2131 Lindau Lane/  Suite 1000/  Bloomington, MN  55425"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-30 19:53:23+00:00",
                    "text": "Well, the main argument against implementing mean(x) this way is that the meat of the computation is...\n\n@longb I am not sure which way you meant. From your comment, it understand you are against the mean function because it is a simple one. First I implemented it with loops, that have been removed through the review (to help for the clarity of the code mainly (and it was a good thing IMO)).\nOtherwise, the main goal is to develop a module with multiple statistical functions (mean, variance, median, ....) inside stdlib.  A module about statistics without mean would make little sense to me. Would it?\nI think that this submodule could serve as an example for other functions that will be include in stdlib_experimental_stats (it also served as spotting some issues, like how to return NaN), like computing the variance with the Welford 's method:\nfunction variance(x) result(res)\n  real, intent(in) :: x(:)\n  real :: res\n\n  integer :: i\n  real :: M, S, delta\n\n  M = 0.\n  S = 0.\n  do i = 1, size(x)\n   delta = x(i) - M\n   M = M + delta/real(i)\n   S = S + delta * (x(i)-M)\n  enddo\n  \n  res = S/real(size(x)-1))\n\nend function\nIs this a more sensible example, assuming that it would be extended to have an API compatible with sum (i.e., with dim and mask included)?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-30 22:14:18+00:00",
                    "text": "Indeed, the only reason we started with mean was because it was the simplest. More complicated functions will follow soon. Finally, yes, it could be easily computed by hand using sum and size, but other libraries have such functions also, such as NumPy's mean or Matlab's mean (for examples in other languages see #113)."
                },
                {
                    "user": "longb",
                    "date": "2020-01-30 22:27:02+00:00",
                    "text": "Comparison with Python or Matlab does not seem relevant. In both cases, native code is very slow, and they have to resort to libraries for any reasonable performance.  Most compiled languages don\u2019t have native support for arrays. Fortran does.\n On Jan 30, 2020, at 4:14 PM, Ond\u0159ej \u010cert\u00edk ***@***.***> wrote:\n\n Indeed, the only reason we started with mean was because it was the simplest. More complicated functions will follow soon. Finally, yes, it could be easily computed by hand using sum and size, but other libraries have such functions also, such as NumPy's mean or Matlab's mean (for examples in other languages see #113).\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n\nBill Long                                                                       longb@cray.com\nPrincipal Engineer, Fortran Technical Support &   voice:  651-605-9024\nBioinformatics Software Development                      fax:  651-605-9143\nCray, a Hewlett Packard Enterprise company/ 2131 Lindau Lane/  Suite 1000/  Bloomington, MN  55425"
                },
                {
                    "user": "longb",
                    "date": "2020-01-30 22:31:11+00:00",
                    "text": "Interesting example, though the code for Welford\u2019s method does not vectorize and would not perform well on modern processors.  I tried a simple example of the direct code and your welford example:\n\nprogram test_var\n  use,intrinsic :: iso_fortran_env, only: int64, real64\n  implicit none\n  real :: x(1000), v\n  integer(int64) :: t1,t2,t3\n  real(real64) :: rate\n\n  call random_number(x)\n\n  call system_clock(t1, count_rate=rate)\n  v = variance(x)\n  call system_clock(t2)\n  print *, v, (t2-t1)/rate, \" sec for Welford method\"\n\n  call system_clock(t2)\n  v = var(x)\n  call system_clock(t3)\n  print *, v, (t3-t2)/rate, \" sec for simple method\"\n\ncontains\n\n\nfunction var(x) result (res)\n  real,intent(in) :: x(:)\n  real :: res\n\n  real :: M, S\n  integer :: i\n\n  M = sum(x)/real(size(x))\n  S = sum( (x-m)**2 )\n  res = S/real(size(x)-1)\n\nend function var\n\nfunction variance(x) result(res)\n  real, intent(in) :: x(:)\n  real :: res\n\n  integer :: i\n  real :: M, S, delta\n\n  M = 0.\n  S = 0.\n  do i = 1, size(x)\n   delta = x(i) - M\n   M = M + delta/real(i)\n   S = S + delta * (x(i)-M)\n  enddo\n\n  res = S/real(size(x)-1)\n\nend function variance\n\nend program test_var\n\n\nThe output on a generic Intel processor that has SSE registers:\n ftn test.f90\n ./a.out\n8.192101866E-2,  7.15724721261053416E-6  sec for Welford method\n 8.192101866E-2,  7.80853517877739328E-7  sec for simple method\n\nAs you can see, the \u201csimple\u201d method is faster.\n\nCheers,\nBill\n On Jan 30, 2020, at 1:53 PM, Jeremie Vandenplas ***@***.***> wrote:\n\n Well, the main argument against implementing mean(x) this way is that the meat of the computation is...\n\n @longb I am not sure which way you meant. From your comment, it understand you are against the mean function because it is a simple one. First I implemented it with loops, that have been removed through the review (to help for the clarity of the code mainly (and it was a good thing IMO)).\n\n Otherwise, the main goal is to develop a module with multiple statistical functions (mean, variance, median, ....) inside stdlib. A module about statistics without mean would make little sense to me. Would it?\n\n I think that this submodule could serve as an example for other functions that will be include in stdlib_experimental_stats (it also served as spotting some issues, like how to return NaN), like computing the variance with the Welford 's method:\n\n function variance(x\n ) result(res)\n\n real, intent(in) ::\n  x(:)\n\n real ::\n  res\n\n\n integer ::\n  i\n\n real ::\n  M, S, delta\n\n   M\n = 0\n .\n   S\n = 0\n .\n\n do i = 1, size\n (x)\n    delta\n = x(i) -\n  M\n    M\n = M + delta/real\n (i)\n    S\n = S + delta * (x(i)-\n M)\n\n enddo\n\n\n   res\n = S/real(size(x)-1\n ))\n\n\n end function\n Is this a more sensible example, assuming that it would be extended to have an API compatible with sum (i.e., with dim and mask included)?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n\nBill Long                                                                       longb@cray.com\nPrincipal Engineer, Fortran Technical Support &   voice:  651-605-9024\nBioinformatics Software Development                      fax:  651-605-9143\nCray, a Hewlett Packard Enterprise company/ 2131 Lindau Lane/  Suite 1000/  Bloomington, MN  55425"
                },
                {
                    "user": "certik",
                    "date": "2020-01-30 22:31:32+00:00",
                    "text": "Comparison with Python or Matlab does not seem relevant. In both cases, native code is very slow, and they have to resort to libraries for any reasonable performance.\n\nThey do not do it for performance reasons, but for convenience reasons. If you look at NumPy's implementation:\nhttps://github.com/numpy/numpy/blob/d9b1e32cb8ef90d6b4a47853241db2a28146a57d/numpy/core/_methods.py#L134\nthis is not more performing than doing it by hand in NumPy. So performance is not the reason why NumPy has the API. Rather, I suspect, the reason is that users like to use such a function."
                },
                {
                    "user": "milancurcic",
                    "date": "2020-01-30 22:50:33+00:00",
                    "text": "@longb The comparison to Python and MATLAB is quite relevant because it informs our API design. We share much of the target audience with those and some other languages."
                },
                {
                    "user": "leonfoks",
                    "date": "2020-01-30 22:52:10+00:00",
                    "text": "Welford's method takes care of two things.  Possible numerical instability; it's a single pass algorithm. It's a choose your poison scenario as with most robust computation algorithms.\nRegardless of the examples we use, and implementation we finally decide on for a stdlib that is generally applicable, I also think a lot of people will appreciate a centralized statistics based module. More and more people are using Python and Matlab over Fortran, following their direction at this point is absolutely the way to go, and saves us a lot of effort too!\nDiscussions about individual algorithms is key to developing the best choice in each case. If the choice of any one algorithm is a bottleneck in a user's code, hopefully they give us some feedback, but they are also free to roll their own version of that algorithm."
                },
                {
                    "user": "gronki",
                    "date": "2020-01-31 00:05:13+00:00",
                    "text": "If a statistic or any kind of numerical algorithm is to make it in the\nstdlib, I think it should be highly optimized or not implemented at all\n(since, as Bill Long said, Fortran has enough intrinsic to not need a\nfunction for average). If the algorithm is sub-optimal and not using the\nbest vectorization possible then nobody will use it and it will be dead.\nThe whole point of using Fortran is that here compiler can optimize things\nbut many of these optimizations are not possible if the calculations are\nclosed behind calls to libraries. Simple procedures (such as mean)\nparticularly \"feel\" that penalty. More complicated ones, not so much. So\nmaybe that could be critera what makes it into stdlib numerical part? Is\nthe procedure simple enough that calling it would introduce a significant\npenalty? After all, I believe what makes it into stdlib should be in the\nend considered exemplary and the best way of doing things.\n\nczw., 30 sty 2020 o 23:52 Leon Foks <notifications@github.com> napisa\u0142(a):\n\u2026\n Welford's method takes care of two things. Possible numerical instability;\n it's a single pass algorithm. It's a choose your poison scenario as with\n most robust computation algorithms.\n\n Regardless of the examples we use, and implementation we finally decide on\n for a stdlib that is generally applicable, I also think a lot of people\n will appreciate a centralized statistics based module. More and more people\n are using Python and Matlab over Fortran, following their direction at this\n point is absolutely the way to go, and saves us a lot of effort too!\n\n Discussions about individual algorithms is key to developing the best\n choice in each case. If the choice of any one algorithm is a bottleneck in\n a user's code, hopefully they give us some feedback, but they are also free\n to roll their own version of that algorithm.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#3?email_source=notifications&email_token=AC4NA3LEUVDMBU4WOJ7G47DRANKZXA5CNFSM4J25FZ62YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKM3Q7Q#issuecomment-580499582>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AC4NA3LB5BZLSAKZTXSQDSLRANKZXANCNFSM4J25FZ6Q>\n ."
                },
                {
                    "user": "gronki",
                    "date": "2020-01-31 00:09:11+00:00",
                    "text": "Sorry for the spam, one more thought. There was an argument some time ago\nalong the lines \"procedures should not be standarized/implemented if they\nare simple to write\". While I generally disagree with that statement, I\nthink numerical algorithms is where some exception needs to be made,\nbecause Fortran excels in numerical computation (unlike in everything else)\nand its syntax allow writing most things in the most easy and efficient\nway. So I would dare to argue that numerical part should be the least focus\nof the stdlib because it is the part that least needs \"fixing\". What do you\nthink?\n\npt., 31 sty 2020 o 01:04 Dominik Gronkiewicz <gronki@gmail.com> napisa\u0142(a):\n\u2026\n If a statistic or any kind of numerical algorithm is to make it in the\n stdlib, I think it should be highly optimized or not implemented at all\n (since, as Bill Long said, Fortran has enough intrinsic to not need a\n function for average). If the algorithm is sub-optimal and not using the\n best vectorization possible then nobody will use it and it will be dead.\n The whole point of using Fortran is that here compiler can optimize things\n but many of these optimizations are not possible if the calculations are\n closed behind calls to libraries. Simple procedures (such as mean)\n particularly \"feel\" that penalty. More complicated ones, not so much. So\n maybe that could be critera what makes it into stdlib numerical part? Is\n the procedure simple enough that calling it would introduce a significant\n penalty? After all, I believe what makes it into stdlib should be in the\n end considered exemplary and the best way of doing things.\n\n czw., 30 sty 2020 o 23:52 Leon Foks ***@***.***> napisa\u0142(a):\n\n> Welford's method takes care of two things. Possible numerical\n> instability; it's a single pass algorithm. It's a choose your poison\n> scenario as with most robust computation algorithms.\n>\n> Regardless of the examples we use, and implementation we finally decide\n> on for a stdlib that is generally applicable, I also think a lot of people\n> will appreciate a centralized statistics based module. More and more people\n> are using Python and Matlab over Fortran, following their direction at this\n> point is absolutely the way to go, and saves us a lot of effort too!\n>\n> Discussions about individual algorithms is key to developing the best\n> choice in each case. If the choice of any one algorithm is a bottleneck in\n> a user's code, hopefully they give us some feedback, but they are also free\n> to roll their own version of that algorithm.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <#3?email_source=notifications&email_token=AC4NA3LEUVDMBU4WOJ7G47DRANKZXA5CNFSM4J25FZ62YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKM3Q7Q#issuecomment-580499582>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AC4NA3LB5BZLSAKZTXSQDSLRANKZXANCNFSM4J25FZ6Q>\n> .\n>"
                },
                {
                    "user": "certik",
                    "date": "2020-01-31 00:47:09+00:00",
                    "text": "To answer that, we need to have benchmarks.\n\nAnd as a user, I feel the compilers are not doing their job if they can't inline functions like mean().  That is one of the motivations why I started LFortran, to try to fix such deficiencies. This is long term, obviously.\n\nThe idea of all the efforts that we are doing (J3 GitHub, stdlib, fpm, as well as new compilers) is to fix all the things that have been bothering us about Fortran. It's not going to get fixed overnight, but it will get fixed eventually.\n\u2026\nOn Thu, Jan 30, 2020, at 5:05 PM, Dominik Gronkiewicz wrote:\n If a statistic or any kind of numerical algorithm is to make it in the\n  stdlib, I think it should be highly optimized or not implemented at all\n  (since, as Bill Long said, Fortran has enough intrinsic to not need a\n  function for average). If the algorithm is sub-optimal and not using the\n  best vectorization possible then nobody will use it and it will be dead.\n  The whole point of using Fortran is that here compiler can optimize things\n  but many of these optimizations are not possible if the calculations are\n  closed behind calls to libraries. Simple procedures (such as mean)\n  particularly \"feel\" that penalty. More complicated ones, not so much. So\n  maybe that could be critera what makes it into stdlib numerical part? Is\n  the procedure simple enough that calling it would introduce a significant\n  penalty? After all, I believe what makes it into stdlib should be in the\n  end considered exemplary and the best way of doing things.\n\n  czw., 30 sty 2020 o 23:52 Leon Foks ***@***.***> napisa\u0142(a):\n\n  > Welford's method takes care of two things. Possible numerical\n instability;\n  > it's a single pass algorithm. It's a choose your poison scenario as\n with\n  > most robust computation algorithms.\n  >\n  > Regardless of the examples we use, and implementation we finally\n decide on\n  > for a stdlib that is generally applicable, I also think a lot of\n people\n  > will appreciate a centralized statistics based module. More and more\n people\n  > are using Python and Matlab over Fortran, following their direction\n at this\n  > point is absolutely the way to go, and saves us a lot of effort too!\n  >\n  > Discussions about individual algorithms is key to developing the best\n  > choice in each case. If the choice of any one algorithm is a\n bottleneck in\n  > a user's code, hopefully they give us some feedback, but they are\n also free\n  > to roll their own version of that algorithm.\n  >\n  > \u2014\n  > You are receiving this because you commented.\n  > Reply to this email directly, view it on GitHub\n  >\n <#3?email_source=notifications&email_token=AC4NA3LEUVDMBU4WOJ7G47DRANKZXA5CNFSM4J25FZ62YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKM3Q7Q#issuecomment-580499582>,\n  > or unsubscribe\n  >\n <https://github.com/notifications/unsubscribe-auth/AC4NA3LB5BZLSAKZTXSQDSLRANKZXANCNFSM4J25FZ6Q>\n  > .\n  >\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#3?email_source=notifications&email_token=AAAFAWGSWDMRIH7HII4ZMK3RANTLVA5CNFSM4J25FZ62YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKNAOYI#issuecomment-580519777>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFAWH5IP3UTOPCQDK4XXTRANTLVANCNFSM4J25FZ6Q>."
                },
                {
                    "user": "urbanjost",
                    "date": "2020-01-31 02:39:50+00:00",
                    "text": "Even simple routines should consider robustness not just speed; and in a perfect world avoid pitfalls users are not always considering, such as data conditioning.  Are you more impressed by a compiler whose SUM() function returns  the value of OUTLIER() on the first call or one that generates the last value calculated no matter where the OUTLIER() value is placed in the ARR() array?\nprogram testit\n   integer,parameter :: elements=10000000\n   real    :: arr(elements)\n   real    :: summary\n   real    :: outlier=huge(summary)/10.0**30\n   integer :: i\n   arr=1.0\n   arr(1)=outlier\n   write(*,*)'biggest=',arr(1)\n\n   summary=0.0\n   do i=1,elements\n      summary=summary+arr(i)\n   enddo\n   write(*,*)'loop sum biggest first=',summary\n   write(*,*)'biggest first sum=',sum(arr)\n\n   summary=0.0\n   arr(1)=1.0\n   arr(elements)=outlier\n   do i=1,elements\n      summary=summary+arr(i)\n   enddo\n   write(*,*)'loop sum biggest last=',summary\n   write(*,*)'biggest last sum=',sum(arr)\nend program testit\nDo you get this:\nbiggest=   340282336.\nloop sum biggest first=   340282336.\nbiggest first sum=   340282336.\nloop sum biggest last=   350282336.\nbiggest last sum=   350282336.\nor is \"biggest first sum\"  350282336. ?\nThis is an artificial case, but reflects real-world errors that often happen in real-world problems. So I can easily imagine a MEAN() function that is a lot more substantial than just replacing a single line;\nand a MASK ability is very useful but can run into similar issues like having a mask that says X.ne.REAL_VALUE, for example.  Does speed outweigh robustness in stdlib?  I have to admit I have seen fewer intrinsic implementations that condition data lately.  Is the cost of such checks so high we not want them for the \"typical\" datasets?"
                },
                {
                    "user": "certik",
                    "date": "2020-01-31 04:28:46+00:00",
                    "text": "There can be different versions of sum, e.g., Julia has a regular sum and also sum_kbn for a much slower, but more accurate sum algorithm.\n(All my production applications do not depend on the order of summation, but for some users that can be helpful, and in that case they can call such different method.)\nAnyway, this is not related to the style guide. Please open separate issues for that. And even better, let's start discussing and submitting PRs for all this functionality, so that we can get towards our goal sooner."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-01-31 08:25:17+00:00",
                    "text": "As you can see, the \u201csimple\u201d method is faster.\n\n\nIf a statistic or any kind of numerical algorithm is to make it in the\nstdlib, I think it should be highly optimized or not implemented at all\n(since, as Bill Long said, Fortran has enough intrinsic to not need a\nfunction for average). If the algorithm is sub-optimal and not using the\nbest vectorization possible then nobody will use it and it will be dead.\n\nIn a general way, IMO the algorithms must be first robust and accurate (at least as mush as the intrinsic functions; see comment) for a vast majority of the cases available in the community (and not for a personal/specific case). What is the point to have a fast and very efficient algorithm that returns a wrong answer in some general cases?  E.g., the \"simple\" method in comment is faster (while I think most of you could optimize the other one), but in many of my real cases this \"faster\" function may return a wrong answer. So, there is a trade-off between accuracy/robustness and efficiency, and this may vary depending on the real scenarios. We need to weight advantages and disavantages of both (e.g, I would be happy if the faster method is implemented but the spec should mention its limitations if its robustness is below the one of intrinsic functions).\nFinally, I think stdlib should try to answer the need of the community that probably includes a large number of \"average\" Fortran users , and not the need of the current stdlib developers (who have most likely already something like stdlib for their own use). \"Average\" Fortran users would probably prefer (real case in my field):\ninteger(int8) :: x(:,:)\nprint*, mean(x, x < 3) !dp result\nover\ninteger(int8) :: x(:,:)\nprint*, sum(real(x,dp), x < 3) / real(count(x < 3, kind = int64), dp)\nIf you are interested in the discussion about descriptive statistics and want to participate to it, please see #113 and #128 .\nfor discussion on a possible trade-off between effeciency and robustness/accuracy, see #134.\nI am sorry to have opened a discussion about utility/usefulness/efficiency of specific procedures (mean, variance) (it was not my aim). I hope this issue will restart where it was, i.e., here"
                }
            ]
        },
        {
            "number": 2,
            "user": "milancurcic",
            "date": "2019-12-14 23:21:23+00:00",
            "title": "Build systems",
            "text": "Use this issue to discuss and propose build systems and/or methods.\nSome candidates so far:\n\nautotools (configure && make && make install);\nCMake\nHand-written Makefiles",
            "comments": [
                {
                    "user": "scivision",
                    "date": "2019-12-17 04:51:04+00:00",
                    "text": "Meson generally has better Fortran support than CMake."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-17 16:01:06+00:00",
                    "text": "Can you elaborate on particulars, @scivision?\nI don't have much Meson experience, but CMake has a whole host of useful infrastructure for reproducible builds, finding MPI, introspection, following standard installation conventions, writing package config modules, testing... And I've found recent versions to have excellent Fortran support."
                },
                {
                    "user": "certik",
                    "date": "2019-12-17 17:28:42+00:00",
                    "text": "I would recommend CMake as it is known to work on all platforms with excellent support and usage in lots of projects. So we know it will deliver, even though I don't like how easy it is to write ugly CMake files.\nIn addition, I think we should maintain simple manual Makefiles (and test them on CI), to show how to compile it by hand. So that people can easily integrate things into their projects.\nIn particular, I would like the stdlib to be preferably written in a way so that big projects can simply copy the files into their repository and things will just work.\nI have done exactly that in https://github.com/certik/dftatom and I have seen people do both: some people use the provided cmake build system, and some other people literally copy the .f90 files into their project. And so I recommend for both to be easy. In addition to CMake, it has manual Makefiles:\nhttps://github.com/certik/dftatom/blob/fe479fd27a7e0f77c6a88a1949996406ec935ac2/Makefile.manual\nhttps://github.com/certik/dftatom/blob/fe479fd27a7e0f77c6a88a1949996406ec935ac2/src/Makefile.manual\nAs you can see they are super simple, and so there is value in having those in addition to CMake."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-17 23:16:11+00:00",
                    "text": "My only complaint about standard Makefiles is that dependency resolution can get pretty hairy. Also, a potential issue with standard makefiles is you may want to alter the build based on system introspection. For example, if you need to work around a compiler bug. But as long as I don't have to write maintain vanilla Makefiles, (or auto-hell) I'm happy to defer to others' preferences for including vanilla makefiles."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-18 18:41:02+00:00",
                    "text": "I think CMake is a good common ground. Meson supports more submodule syntax than CMake, but it's not a big deal here. Maybe if we try to keep the common build system choice (perhaps CMake) as the one that's known to work for everything, it wouldn't hurt to have other build systems also available e.g. Meson. This is what I do for most projects, although for me Meson is the primary choice.\nA prime example: https://github.com/scivision/fortran2018-examples/\nCMake and Meson are generally equally supported, except for a few things needlessly tricky in CMake, I did only in Meson. Each directory has CMakeLists.txt and meson.build that are independent, to allow users of either build system to enjoy."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-18 18:44:39+00:00",
                    "text": "@scivision I'm curious which submodule features are missing from CMake? Their Ninja patch was upstreamed and should be included in the next release of Ninja, and I've been using submodules extensively without issue since 13.4.3 with MSVS and Makefile generators."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-18 20:20:06+00:00",
                    "text": "for CMake, consider requiring at least 3.14 so that check_fortran_source_runs is available, or at least if() else() it. That's necessary to check if Coarrays are fully working to avoid confusing runtime errors.  A compile/link check is not adequate."
                },
                {
                    "user": "scivision",
                    "date": "2019-12-18 20:21:28+00:00",
                    "text": "This doesn't work with CMake, last I tried https://github.com/scivision/fortran-submodule/blob/master/src/parent1.f90\nMODULE PURE SUBROUTINE or module pure function"
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 21:39:10+00:00",
                    "text": "I would suggest we do not use any features that CMake can't support. See #15."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-19 23:16:16+00:00",
                    "text": "FWIW, the issues reported have an easy work around that gets CMake to work:\nSwitch MODULE PURE SUBROUTINE to PURE MODULE SUBROUTINE. Additionally, within an interface block this is a non-issue, as far as I can tell.\nThis is an issue only when you have a separate module procedure and the first prefix-spec is MODULE followed by additional prefix-specs then SUBROUTINE, FUNCTION or PROCEDURE outside of an INTERFACE block. See https://gitlab.kitware.com/cmake/cmake/issues/18427 for a discussion."
                }
            ]
        },
        {
            "number": 1,
            "user": "milancurcic",
            "date": "2019-12-14 23:19:29+00:00",
            "title": "What should be part of stdlib?",
            "text": "Existing libraries, for inspiration or adoption\n\nAwesome Fortran\nflibs by @arjenmarkus\nfortran-utils by @certik\nPolycon by @cmacmackin\nStefano Zaghi made a lot of good stuff\ndatetime-fortran and functional-fortran by myself\nSciFortran by @aamaricci\nCoretran by @leonfoks\nFutility\nGeneral-Purpose Fortran by @urbanjost\nA FORTRAN 90 Numerical Library by Alberto Ramos\nMany others -- if we missed anything, please let us know\n\n\nFirst issue in this repo which evolved from this thread. This is a broad, open ended, high-level issue, so feel free to go wide and crazy here.\nTo propose a specific module, procedure, or derived type, please open a new issue. You can follow the same format as in Fortran Proposals.\nWishlist from upthread\nFrom @apthorpe:\n\nWhat I miss when writing Fortran\nWhat should a Fortran stdlib contain, Part 1\nWhat should a Fortran stdlib contain, Part 2\n\n\nFrom @FortranFan:\n\nContainers\n\nstring type\nbitsets\nEnhanced 'array' types such as vectors, singly-linked and doubly-linked lists, etc.\nAdapters such as stacks, queues, etc.\nAssociative ones such as dictionaries (maps), hash_sets, etc.\n\n\nAlgorithms\n\nGeneric methods for sort, findloc, etc. that can work with any type, intrinsic and derived,\nOperations and permutations on a range of elements such as merge/union, difference,\netc.\n\n\nUtilities\n\nIterator-like facilities which make it easy to work with Containers,\nOperator (<, >, ==, etc. ) and assignment(=) overload abstractions that perhaps make\nthe use of standard algorithms more efficient?\nMiscellaneous other functions, subroutines (like generic swap), datetime, named\nconstants, etc.\n\n\nSpecial\n\nAny basic facilities (extensions perhaps to ABSTRACT INTERFACE block?) needed toward\n\"special\" functions such as Variadic ones in the language e.g., MAX, MIN\nAbility to \"overload\" array subsection notation facility with Containers that standard Fortran\nprovides with its 2 built-in containers: arrays and CHARACTER intrinsic type.\nAny special mechanisms that can help aid with improved constructors of arrays/containers\nand derived types ('classes'). I envision certain fundamental 'computer engineering' aspects\nbeing pursued here that can enable, say, efficient operation on the diagonal of a matrix or\ninitialization to an identity matrix; or efficient 'dynamic' construction of 'classes' in Fortran similar\nto that is achieved near universally using new keyword in other languages.\n\n\n\n\nFrom @zbeekman:\n\nStrings\n\nConversion to/from integer/real/logical (all kinds of each)\nConversion on string concatenation\nraw string processing functions inspired by Ruby & Python\nstring class to make using all the machinery easier via TBPs\n\n\nFiles\n\nFor now just name manipulations like dirname, basename, etc.\n\n\nOS/Environment integration\n\nis_a_tty(), OS%env(\"HOME\"), .envExists. \"USER\", etc.\n\n\nUnit testing & assertions stuff\n\nSubtest summaries w/ color\nFile and line number triggering failures\n\n\nError Stack class/object\n\nMaintain a call-stack\nRaise errors, but optionally trap them later with good call stack including line number and file",
            "comments": [
                {
                    "user": "FortranFan",
                    "date": "2019-12-15 00:58:00+00:00",
                    "text": "@milancurcic  wrote:\n\n..\n\nMany others -- what did I miss?\n\n\nGreat start, perhaps @tclune et al at NASA with https://github.com/nasa/gFTL can contribute or be an inspiration?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-15 16:12:06+00:00",
                    "text": "The D standard library can also serve as reference/inspiration: https://dlang.org/library/. For many of the D modules there are already some existing open-source modules in Fortran (like dealing with CSV and JSON files, datetime objects, low-level string operations).\nInspired by the D library, I prepared a bunch of functions for checking ASCII characters: https://github.com/ivan-pi/fortran-ascii"
                },
                {
                    "user": "ivan-pi",
                    "date": "2019-12-16 01:10:58+00:00",
                    "text": "Several interesting modules are available in the General-Purpose Fortran package (command line arguments, strings, expression parsers,messages, io, hot keys, fortran/C calls, graphics, sorting, unit conversions).\nGeorge Benthien has also made some string utilities and expression parsers.\nAlso Alan Miller's Fortran software contain many routines that are suitable for a stdlib.\nThe Rosetta Code Fortran pages contain simple implementations of several algorithms (greatest common divisors, sorting, searching, etc.) and data types (priority queues, decks, linked lists, etc.)."
                },
                {
                    "user": "marshallward",
                    "date": "2019-12-17 16:21:35+00:00",
                    "text": "I would like to see greater support for bit-reproducible numerical operations.  This is a very high priority for us since our models are used in weather and climate forecasting, and much of our time is devoted to bit reproducibility of our numerical calculations.\nA common problem is intrinsic Fortran reduction operations like sum(), where the order is ambiguous (deliberately, one might say), and therefore not reproducible.  A more serious problem for us is transcendental functions, like exp() or cos(), which will give different results for different optimizations, and we typically cannot say where it was invoked (libm?  Vendor library?  etc.).\nA standard library may be a place to provide bit-reproducible implementations."
                },
                {
                    "user": "rweed",
                    "date": "2019-12-17 17:24:19+00:00",
                    "text": "Fortunately, there is a wealth of libraries etc we can draw from. Some of the older ones like SLATEC etc are still in F77 but can be converted to F90 free format for consistency. One issue that needs to be resolved though are possible license conflicts. Here are a few more suggestions (there are probably a hundred more if we do a deep dive into whats available)\nFor general mathematical functions etc.\nSLATEC/nistCML\nhttps://www/nist/gov/itl/math/software\nhttps://www.netlib.org/slatec\nhttps://people.sc.fsu.edu/~jburkardt/f_src/slatec/slatec.html (F90 translation)\nJohn Burkardt's collection of software at\nhttps://people.sc.fsu.edu/~jburkardt/f_src/f_src.html\nFor containers/ADTs, I would suggest Robert Ruegers Fortran Template Library at\nhttps://github.com/SCM-NV/ftl\nSimilar to @tclune gFTL but Ruegers implementations of the various containers and how he does the preprocessing step was easier for me to follow\nTwo books that have available code that I would suggest are Robin Vowels, \"Algorithms and Data Structures in F and Fortran\" and Dick Hanson and Tim Hopkins, \"Numerical Computing in Modern Fortran\". I've implemented some of the sorting routines from both books. In particular, I have a \"semi\"-generic implementation of Hanson and Hopkins quickSort routines that support all the integer types, 32 and 64 bit reals, character strings, and a user type/class. I have my own implementations of several commonly used ADTs based on unlimited polymorphic variables that I can contribute for reveiw but I need to go back and look at licensing issues since I borrowed ideas from Arjen Markus FLIBS, and Rueger's FTL.  Also, I would personally avoid anything related to Numerical Recipes like the plague due to their restrictive license (and poor implementations of some of the algorithms)"
                },
                {
                    "user": "certik",
                    "date": "2019-12-17 18:02:29+00:00",
                    "text": "@marshallward I created #12 for bit-reproducibility, let's discuss the details there."
                },
                {
                    "user": "jacobwilliams",
                    "date": "2019-12-18 04:37:05+00:00",
                    "text": "One big question is, do we want this library to contain numerical/scientific type codes? For example, ODE solvers, optimizers, interpolation, etc... The sorts of things that were in SLATEC and are in SciPy. A library like that is desperately needed for modern Fortran. Is that this library, or does that belong in another library built upon this one?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 04:59:20+00:00",
                    "text": "@jacobwilliams excellent question. I don't know the answer, we need to discuss it. I am a bit worried if the scope does not become too much if we include everything that potentially can be in SciPy."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-18 17:28:04+00:00",
                    "text": "I am not opposed to numerical and scientific codes being part of stdlib. The scope of Fortran's stdlib doesn't necessarily need to be similar to that of Python, C, or any other language. Fortran is more ubiquitous in science and engineering, and to me it makes sense that the stdlib would have modules similar to numpy and scipy."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-18 17:46:55+00:00",
                    "text": "One personal challenge I have with stock Fortran are its somewhat awkward and low-level I/O facilities -- open, read, write, inquire, rewind, and close. I often wished for a higher-level interface, like what you get with Python's open() -- you open a file with a function, get a file-like instance with methods that let you do stuff with it.\nThis would do away with unit numbers, which I don't think application developers should have to deal with. It could also be a solution to the problem that allocatable character strings must be pre-allocated before use on read statement.\nIs there anything similar out there for Fortran? Would this be of interest to people here? I'd use it."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 18:04:01+00:00",
                    "text": "If we want to go with this broader scope, then one reasonable proposal can be to limit the scope roughly to what is in here:\nhttps://www.mathworks.com/help/matlab/mathematics.html\nWhich seems to cover roughly what is in NumPy and SciPy.\nIf we use the Python analogy, the bare bone Python language does not have much for numerical computing. And if you do any kind of numerical computing in Python (I do), NumPy and SciPy are pretty much the \"standard library\". Not surprisingly, the default \"Matlab standard library\" roughly covers the same range.\nThe Julia standard library (https://github.com/JuliaLang/julia/tree/5da74be66993fb19edce52e4877d8ae2edbe27b0/stdlib, documented at https://docs.julialang.org, in the left column scroll down to \"Standard Library\") does not cover as wide range, but still includes linear algebra (Lapack), sparse arrays, statistics. It used to contain fft, but they moved it out apparently (https://discourse.julialang.org/t/where-is-the-fft/16512) -- it would be interesting to know the reasoning, as Matlab as well as NumPy has fft by default.\nOk, it's not a bad idea."
                },
                {
                    "user": "jvdp1",
                    "date": "2019-12-18 18:12:11+00:00",
                    "text": "Is there anything similar out there for Fortran? Would this be of interest to people here? I'd use it.\n\nI would use it too.\nSomething that might be interesting to include in a standard library is sparse arrays (creation, management)."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 18:18:19+00:00",
                    "text": "I think we can learn from Julia a lot. Here is the discussion related to moving FFT out of Julia's standard library and into a separate package:\nJuliaLang/julia#18389\nand apparently they want to also move much of the linear algebra out. See also:\nhttps://groups.google.com/forum/#!topic/julia-users/ug5Jh6y5biA.\nJuliaLang/julia#5155\nIf I understand their arguments, if it's part of the julia compiler itself, it's hard for them to make a release, test things properly on Travis, etc. Applied to Fortran, that would be like moving things from Fortran compilers (gfortran, ifort, ...) into a separate library like this stdlib."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 18:23:31+00:00",
                    "text": "So here are other things that could be part of stdlib:\n\nsparse matrices\nfft\nspecial functions (like in SciPy) such as spherical harmonics, hypergeometric functions, ...\nrandom numbers\nstatistics\nODE solvers and numerical integration (Gauss-Legendre points and weights and other algorithms)\noptimization (root finding, etc.)"
                },
                {
                    "user": "cmacmackin",
                    "date": "2019-12-18 18:34:48+00:00",
                    "text": "One personal challenge I have with stock Fortran are its somewhat awkward and low-level I/O facilities -- open, read, write, inquire, rewind, and close. I often wished for a higher-level interface, like what you get with Python's open() -- you open a file with a function, get a file-like instance with methods that let you do stuff with it.\nThis would do away with unit numbers, which I don't think application developers should have to deal with. It could also be a solution to the problem that allocatable character strings must be pre-allocated before use on read statement.\nIs there anything similar out there for Fortran? Would this be of interest to people here? I'd use it.\n\nI'd personally like something along these lines. However, the problem is in defining methods on the file-object; these would need to know the number and type of arguments at compile-time. It would be impractical to produce methods with every conceivable permutation of object types. It would also require variadic functions, which are not available. As such, this can not be implemented well in Fortran, although perhaps something would be possible if we were to wrap some C-routines and pass in deferred-type objects."
                },
                {
                    "user": "cmacmackin",
                    "date": "2019-12-18 18:36:27+00:00",
                    "text": "So here are other things that could be part of stdlib:\n* sparse matrices\n\n* fft\n\n* special functions (like in SciPy) such as spherical harmonics, hypergeometric functions, ...\n\n* random numbers\n\n* statistics\n\n* ODE solvers and numerical integration (Gauss-Legendre points and weights and other algorithms)\n\n* optimization (root finding, etc.)\n\n\nSome sort of interface for working with solvers for dense matrices would also be useful. LAPACK is horribly tedious to use, so an object-oriented wrapper could be handy. This could hold the factored version of the matrix, handle allocation of work arrays, etc. I've written code along these lines in the past."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 18:38:41+00:00",
                    "text": "Some sort of interface for working with solvers for dense matrices would also be useful. LAPACK is horribly tedious to use, so an object-oriented wrapper could be handy. This could hold the factored version of the matrix, handle allocation of work arrays, etc. I've written code along these lines in the past.\n\nYes, that's already planned, see #10."
                },
                {
                    "user": "certik",
                    "date": "2019-12-18 18:41:04+00:00",
                    "text": "@milancurcic why don't you start a separate issue for the IO stuff, so that we can discuss it there."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-18 18:50:04+00:00",
                    "text": "One personal challenge I have with stock Fortran are its somewhat awkward and low-level I/O facilities -- open, read, write, inquire, rewind, and close. I often wished for a higher-level interface, like what you get with Python's open() -- you open a file with a function, get a file-like instance with methods that let you do stuff with it.\nThis would do away with unit numbers, which I don't think application developers should have to deal with. It could also be a solution to the problem that allocatable character strings must be pre-allocated before use on read statement.\nIs there anything similar out there for Fortran? Would this be of interest to people here? I'd use it.\n\nThis is one of my primary motivations too. As @cmacmackin pointed out, we may not be able to get a one-to-one mapping of our favorite implementation X for fileIO stuff, but we can certainly make something better than what we have and idiomatically Fortran-like. And were there is very obvious solutions that need to be implemented in the language standard we can lobby for those."
                },
                {
                    "user": "milancurcic",
                    "date": "2019-12-18 18:52:17+00:00",
                    "text": "@zbeekman can you post this message to #14?"
                },
                {
                    "user": "certik",
                    "date": "2019-12-23 19:09:47+00:00",
                    "text": "Do we all agree that the scope is broader (e.g., Python standard libraries + NumPy/SciPy), rather than narrower (e.g., C++ standard library)?\nIf so, let's write down in general terms, what the scope is and put it into README. I started at #43. Can you help me polish it up?"
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 04:09:44+00:00",
                    "text": "PR looks good to me. I think this is an area that will evolve over time. As such I don't think we need to hash out every detail so long as we ensure things only grow in a good way organically...  balance immediate needs  with the threat of incurring technical debt and bad design choices.\nIf we hash things out in too much detail documents won't reflect reality. The PR is looking good last I checked and I'm generally happy with the vast majority of ideas and desires that others have expressed so far."
                },
                {
                    "user": "zbeekman",
                    "date": "2019-12-31 04:11:11+00:00",
                    "text": "A more useful step might be to provide more clarity on governance and workflow since right now the process of deciding when PRs are merged is murky, much less how to decide and agree upon what the grand objectives of the project are."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-13 15:04:31+00:00",
                    "text": "I've noticed the Julia base library wraps the C standard library routines for memory allocation and also some from <time.h>: https://docs.julialang.org/en/v1/base/libc/\nCould this also be a target for the Fortran stdlib? Maybe this could be a possible way to provide support for Unicode characters, time and date functions, etc.?"
                },
                {
                    "user": "certik",
                    "date": "2020-04-13 16:43:48+00:00",
                    "text": "@ivan-pi good point.\nOne question to consider is whether we want at least the core of stdlib to be pure Fortran. I can see a lot of advantages of that (no dependencies on other languages and runtimes, just Fortran is enough). Obviously the disadvantage is that it's nice to just call other libraries instead of reimplement things in Fortran.\nMaybe these \"wrappers\" can be an optional component of stdlib?"
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-04-15 18:30:14+00:00",
                    "text": "I support the idea of having a pure Fortran core with zero external dependencies, as long as it is possible. I can't imagine that many people really need Unicode support in their Fortran codes (it is needed in some, for example in  json-fortran).\nFor the calendar and datetime support (see #106) one suggested solution was to use the C standard library functionality from <time.h>. The datetime-fortran package by @milancurcic also relies on the C routines strptime and strftime to format and parse datetime strings. While I do not doubt a pure Fortran implementation is possible, it could be tedious.\nI've gone ahead and prepared interfaces for a few elements of the C standard library in https://github.com/ivan-pi/fortran-libc (malloc, calloc, realloc, free, qsort, and the entire <time.h>)\nI think it would be nice to have this as an optional component to stdlib. That way not everyone has to go through the trouble of writing these interfaces next time they need to allocate some C memory from Fortran. (Alternatively an automatic interface generator like swig-fortran could be used.)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-04-15 20:00:06+00:00",
                    "text": "@ivan-pi In my opinion, yes.\nI think every Fortran compiler comes with a companion C compiler, no? Which ships with its libc. So is there really any burden to having C-interfaces in stdlib? If there is, then the interfaces should be optional.\nOf course, if we want to support some of libc, we don't have to do so for all of it. Only parts that we decide are needed, as a community."
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-15 20:16:17+00:00",
                    "text": "Is not libc associated with Fortran executables? I just compiled a simple Fortran program and printed the shared object dependencies:\n$ more test.f90 \nprogram tmp\n implicit none\n integer::i\n \n i=1\n print*,i\nend program\n$ \n$ gfortran -O0 test.f90 \n$ ldd a.out \n\tlinux-vdso.so.1 (0x00007ffc2a987000)\n\tlibgfortran.so.5 => /lib64/libgfortran.so.5 (0x00007f7131db2000)\n\tlibm.so.6 => /lib64/libm.so.6 (0x00007f7131c6c000)\n\tlibgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x00007f7131c52000)\n\tlibquadmath.so.0 => /lib64/libquadmath.so.0 (0x00007f7131c08000)\n\tlibc.so.6 => /lib64/libc.so.6 (0x00007f7131a3d000)\n\t/lib64/ld-linux-x86-64.so.2 (0x00007f713208b000)\n$ ifort -O0 test.f90 \n$ ldd a.out \n\tlinux-vdso.so.1 (0x00007ffd12d20000)\n\tlibm.so.6 => /lib64/libm.so.6 (0x00007fbe10b2d000)\n\tlibpthread.so.0 => /lib64/libpthread.so.0 (0x00007fbe10b0b000)\n\tlibc.so.6 => /lib64/libc.so.6 (0x00007fbe10942000)\n\tlibgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x00007fbe10928000)\n\tlibdl.so.2 => /lib64/libdl.so.2 (0x00007fbe1091f000)\n\t/lib64/ld-linux-x86-64.so.2 (0x00007fbe10caa000)"
                },
                {
                    "user": "milancurcic",
                    "date": "2020-04-15 20:20:05+00:00",
                    "text": "@jvdp1 GFortran does this because it uses libc to implement parts of Fortran, but I don't know if that's true for most Fortran compilers. If it is, I think that would be a good argument for not disallowing Fortran interfaces to libc in stdlib."
                },
                {
                    "user": "certik",
                    "date": "2020-04-15 21:16:38+00:00",
                    "text": "I think we can have C wrappers for any C library, such as in #45. Including libc.\nThat being said, I think Fortran language should stand on its own if needed, including compiling without libc if needed.\nHaving \"standard\" C interfaces for most common tasks would be very helpful so that people don't have to reimplement those over and over. Perhaps later those could go into its own package, perhaps even called libc, as part of fpm."
                },
                {
                    "user": "dev-zero",
                    "date": "2020-04-24 09:16:03+00:00",
                    "text": "While working on a large code base (CP2K), a repeating and annoying topic is strings in various forms:\n\nstring lists: still needs a string type AFAIK because you can't put a variable length string inside a variable length list and is therefore very cumbersome without a wrapper for the string, the list or both\nreading into strings: reading into an allocatable string is not supported, hence we need to buffer manually\nreading large files as strings: mmap would be nice to avoid copying data unnecessarily, but this results again in an array of characters instead\nbeing able to interface fast regex engines like re2c, hyperscan (or simply pcre) would be nice\nencoding/decoding strings, multibyte/unicode support (although for most high performance codes probably not relevant), I guess @jacobwilliams  has some experience here ;-) ... also, the discussion UCS4 vs UTF-8/utf8everywhere might be relevant in this context\nANSI support"
                },
                {
                    "user": "jvdp1",
                    "date": "2020-04-24 09:59:13+00:00",
                    "text": "While working on a large code base (CP2K), a repeating and annoying topic is strings in various forms:\n\nstring lists: still needs a string type AFAIK because you can't put a variable length string inside a variable length list and is therefore very cumbersome without a wrapper for the string, the list or both\nreading into strings: reading into an allocatable string is not supported, hence we need to buffer manually\nreading large files as strings: mmap would be nice to avoid copying data unnecessarily, but this results again in an array of characters instead\n\n\nThank you.\nRe: strings I would point to the discussions in #31, #32, and #69.\nI think that the not yet covered topics you mention could be discussed there too (or in another issue if too specific?)."
                },
                {
                    "user": "certik",
                    "date": "2020-04-24 17:30:51+00:00",
                    "text": "@dev-zero thanks for getting in touch. Besides what @jvdp1 posted, see also j3-fortran/fortran_proposals#24, j3-fortran/fortran_proposals#96 and j3-fortran/fortran_proposals#9.\nRegarding Unicode, I think we should support Unicode in stdlib, we should use utf8 and I also posted at #11 (comment) with links to utf8 handling code that is simple enough to port to Fortran / stdlib.\nIf you want to help us implement any of these things, we would really appreciate it!"
                },
                {
                    "user": "dev-zero",
                    "date": "2020-05-04 16:01:26+00:00",
                    "text": "If you want to help us implement any of these things, we would really appreciate it!\n\nWill try, but I'm not sure whether I can spare the time (yet).\nAnother thing which came to mind should be part of an stdlib are: compatibility functions for compilers not fully implementing standards.\nTwo examples we encountered in CP2K or DBCSR:\n\nnewunit argument for open from F2008. If memory serves it was the Cray compiler which was rather late in implementing this one. Providing higher-level OO wrappers will probably make this a moot point, though.\nfindloc from F2008. Implemented in GCC  9.0 & Intel 2018\n\nWhile missing intrinsics could be provided in a compat module, is redefining an intrinsic probably not doable transparently without using the CPP."
                },
                {
                    "user": "ivan-pi",
                    "date": "2020-07-17 15:42:07+00:00",
                    "text": "I found another FORTRAN 90 Numerical Library (https://sourceforge.net/projects/afnl/) developed by Alberto Ramos. I will edit the first post to include it.\nThe contents are the following:\n\nMODULE NumTypes\nMODULE Constants\nMODULE Error\nMODULE Integration\nMODULE Optimization\nMODULE Linear\nMODULE NonNum\nMODULE SpecialFunc\nMODULE Statistics\nMODULE Polynomial\nMODULE Root\nMODULE Fourier\nMODULE Time"
                },
                {
                    "user": "David-Duffy",
                    "date": "2020-09-17 05:50:03+00:00",
                    "text": "I think a good implementation of a data frame. That is, a rectangular array where each column is one homogenous type - integer, character etc, but each column can be of any type. These exist in R, Pandas, Julia etc, and are the workhorse for statistical analysis. One will encounter arguments about whether this should all be in a \"real database\", and so you just need to provide appropriate Fortran interfaces, but the continued success of R, Pandas etc is a potent counter. For speed, there do have to be indices and hashes under the bonnet, and optimized sorts, joins, Fortran array type slices, and so on."
                }
            ]
        }
    ]
}